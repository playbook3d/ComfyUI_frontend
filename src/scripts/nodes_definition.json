{"KSampler": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model used for denoising the input latent."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "The number of steps used in the denoising process."}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01, "tooltip": "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality."}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output."}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], {"tooltip": "The scheduler controls how noise is gradually removed to form the image."}], "positive": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to include in the image."}], "negative": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "latent_image": ["LATENT", {"tooltip": "The latent image to denoise."}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling."}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSampler", "display_name": "KSampler", "description": "Uses the provided model, positive and negative conditioning to denoise the latent image.", "python_module": "nodes", "category": "sampling", "output_node": false, "output_tooltips": ["The denoised latent."]}, "CheckpointLoaderSimple": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderSimple", "display_name": "Load Checkpoint", "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The model used for denoising latents.", "The CLIP model used for encoding text prompts.", "The VAE model used for encoding and decoding images to and from latent space."]}, "CLIPTextEncode": {"input": {"required": {"text": ["STRING", {"multiline": true, "dynamicPrompts": true, "tooltip": "The text to be encoded."}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}}, "input_order": {"required": ["text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncode", "display_name": "CLIP Text Encode (Prompt)", "description": "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.", "python_module": "nodes", "category": "conditioning", "output_node": false, "output_tooltips": ["A conditioning containing the embedded text used to guide the diffusion model."]}, "CLIPSetLastLayer": {"input": {"required": {"clip": ["CLIP"], "stop_at_clip_layer": ["INT", {"default": -1, "min": -24, "max": -1, "step": 1}]}}, "input_order": {"required": ["clip", "stop_at_clip_layer"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPSetLastLayer", "display_name": "CLIP Set Last Layer", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "VAEDecode": {"input": {"required": {"samples": ["LATENT", {"tooltip": "The latent to be decoded."}], "vae": ["VAE", {"tooltip": "The VAE model used for decoding the latent."}]}}, "input_order": {"required": ["samples", "vae"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VAEDecode", "display_name": "VAE Decode", "description": "Decodes latent images back into pixel space images.", "python_module": "nodes", "category": "latent", "output_node": false, "output_tooltips": ["The decoded image."]}, "VAEEncode": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"]}}, "input_order": {"required": ["pixels", "vae"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncode", "display_name": "VAE Encode", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "VAEEncodeForInpaint": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "mask": ["MASK"], "grow_mask_by": ["INT", {"default": 6, "min": 0, "max": 64, "step": 1}]}}, "input_order": {"required": ["pixels", "vae", "mask", "grow_mask_by"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeForInpaint", "display_name": "VAE Encode (for Inpainting)", "description": "", "python_module": "nodes", "category": "latent/inpaint", "output_node": false}, "VAELoader": {"input": {"required": {"vae_name": [["YOZORA.vae.pt", "ae.safetensors", "flux_vae.safetensors", "hunyuan_video_vae_bf16.safetensors", "sdxl.vae.safetensors", "vae-ft-mse-840000-ema-pruned.ckpt", "wan_2.1_vae.safetensors"]]}}, "input_order": {"required": ["vae_name"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "VAELoader", "display_name": "Load VAE", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "EmptyLatentImage": {"input": {"required": {"width": ["INT", {"default": 512, "min": 16, "max": 16384, "step": 8, "tooltip": "The width of the latent images in pixels."}], "height": ["INT", {"default": 512, "min": 16, "max": 16384, "step": 8, "tooltip": "The height of the latent images in pixels."}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentImage", "display_name": "Empty Latent Image", "description": "Create a new batch of empty latent images to be denoised via sampling.", "python_module": "nodes", "category": "latent", "output_node": false, "output_tooltips": ["The empty latent image batch."]}, "LatentUpscale": {"input": {"required": {"samples": ["LATENT"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["samples", "upscale_method", "width", "height", "crop"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentUpscale", "display_name": "Upscale Latent", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentUpscaleBy": {"input": {"required": {"samples": ["LATENT"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "scale_by": ["FLOAT", {"default": 1.5, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "upscale_method", "scale_by"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentUpscaleBy", "display_name": "Upscale Latent By", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentFromBatch": {"input": {"required": {"samples": ["LATENT"], "batch_index": ["INT", {"default": 0, "min": 0, "max": 63}], "length": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["samples", "batch_index", "length"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentFromBatch", "display_name": "Latent From Batch", "description": "", "python_module": "nodes", "category": "latent/batch", "output_node": false}, "RepeatLatentBatch": {"input": {"required": {"samples": ["LATENT"], "amount": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["samples", "amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RepeatLatentBatch", "display_name": "Repeat Latent Batch", "description": "", "python_module": "nodes", "category": "latent/batch", "output_node": false}, "SaveImage": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to save."}], "filename_prefix": ["STRING", {"default": "ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImage", "display_name": "Save Image", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "nodes", "category": "image", "output_node": true}, "PreviewImage": {"input": {"required": {"images": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewImage", "display_name": "Preview Image", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "nodes", "category": "image", "output_node": true}, "LoadImage": {"input": {"required": {"image": [["example.png"], {"image_upload": true}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImage", "display_name": "Load Image", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "LoadImageMask": {"input": {"required": {"image": [["example.png"], {"image_upload": true}], "channel": [["alpha", "red", "green", "blue"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "LoadImageMask", "display_name": "Load Image (as Mask)", "description": "", "python_module": "nodes", "category": "mask", "output_node": false}, "LoadImageOutput": {"input": {"required": {"image": ["COMBO", {"image_upload": true, "image_folder": "output", "remote": {"route": "/internal/files/output", "refresh_button": true, "control_after_refresh": "first"}}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImageOutput", "display_name": "Load Image (from Outputs)", "description": "Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.", "python_module": "nodes", "category": "image", "output_node": false, "experimental": true}, "ImageScale": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["image", "upscale_method", "width", "height", "crop"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScale", "display_name": "Upscale Image", "description": "", "python_module": "nodes", "category": "image/upscaling", "output_node": false}, "ImageScaleBy": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "scale_by": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["image", "upscale_method", "scale_by"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScaleBy", "display_name": "Upscale Image By", "description": "", "python_module": "nodes", "category": "image/upscaling", "output_node": false}, "ImageInvert": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageInvert", "display_name": "Invert Image", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ImageBatch": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatch", "display_name": "Batch Images", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ImagePadForOutpaint": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 40, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "left", "top", "right", "bottom", "feathering"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaint", "display_name": "Pad Image for Outpainting", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "EmptyImage": {"input": {"required": {"width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "color": ["INT", {"default": 0, "min": 0, "max": 16777215, "step": 1, "display": "color"}]}}, "input_order": {"required": ["width", "height", "batch_size", "color"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "EmptyImage", "display_name": "EmptyImage", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ConditioningAverage": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "conditioning_from": ["CONDITIONING"], "conditioning_to_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning_to", "conditioning_from", "conditioning_to_strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningAverage", "display_name": "ConditioningAverage", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningCombine": {"input": {"required": {"conditioning_1": ["CONDITIONING"], "conditioning_2": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_1", "conditioning_2"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningCombine", "display_name": "Conditioning (Combine)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningConcat": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "conditioning_from": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_to", "conditioning_from"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningConcat", "display_name": "Conditioning (Concat)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetArea": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["INT", {"default": 64, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 64, "min": 64, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "x", "y", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetArea", "display_name": "Conditioning (Set Area)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetAreaPercentage": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "height": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "x", "y", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaPercentage", "display_name": "Conditioning (Set Area with Percentage)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetAreaStrength": {"input": {"required": {"conditioning": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaStrength", "display_name": "ConditioningSetAreaStrength", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetMask": {"input": {"required": {"conditioning": ["CONDITIONING"], "mask": ["MASK"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["conditioning", "mask", "strength", "set_cond_area"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetMask", "display_name": "Conditioning (Set Mask)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "KSamplerAdvanced": {"input": {"required": {"model": ["MODEL"], "add_noise": [["enable", "disable"]], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000}], "return_with_leftover_noise": [["disable", "enable"]]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "start_at_step", "end_at_step", "return_with_leftover_noise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSamplerAdvanced", "display_name": "KSampler (Advanced)", "description": "", "python_module": "nodes", "category": "sampling", "output_node": false}, "SetLatentNoiseMask": {"input": {"required": {"samples": ["LATENT"], "mask": ["MASK"]}}, "input_order": {"required": ["samples", "mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "SetLatentNoiseMask", "display_name": "Set Latent Noise Mask", "description": "", "python_module": "nodes", "category": "latent/inpaint", "output_node": false}, "LatentComposite": {"input": {"required": {"samples_to": ["LATENT"], "samples_from": ["LATENT"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feather": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["samples_to", "samples_from", "x", "y", "feather"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentComposite", "display_name": "Latent Composite", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentBlend": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"], "blend_factor": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["samples1", "samples2", "blend_factor"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentBlend", "display_name": "Latent Blend", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "LatentRotate": {"input": {"required": {"samples": ["LATENT"], "rotation": [["none", "90 degrees", "180 degrees", "270 degrees"]]}}, "input_order": {"required": ["samples", "rotation"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentRotate", "display_name": "Rotate Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LatentFlip": {"input": {"required": {"samples": ["LATENT"], "flip_method": [["x-axis: vertically", "y-axis: horizontally"]]}}, "input_order": {"required": ["samples", "flip_method"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentFlip", "display_name": "Flip Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LatentCrop": {"input": {"required": {"samples": ["LATENT"], "width": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["samples", "width", "height", "x", "y"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentCrop", "display_name": "Crop Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LoraLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "clip": ["CLIP", {"tooltip": "The CLIP model the LoRA will be applied to."}], "lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"], {"tooltip": "The name of the LoRA."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the CLIP model. This value can be negative."}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "LoraLoader", "display_name": "Load LoRA", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "CLIPLoader": {"input": {"required": {"clip_name": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["stable_diffusion", "stable_cascade", "sd3", "stable_audio", "mochi", "ltxv", "pixart", "cosmos", "lumina2", "wan", "hidream", "chroma", "ace"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["clip_name", "type"], "optional": ["device"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPLoader", "display_name": "Load CLIP", "description": "[Recipes]\n\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5 xxl/ clip-g / clip-l\nstable_audio: t5 base\nmochi: t5 xxl\ncosmos: old t5 xxl\nlumina2: gemma 2 2B\nwan: umt5 xxl\n hidream: llama-3.1 (Recommend) or t5", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "UNETLoader": {"input": {"required": {"unet_name": [["IC-Light/iclight_sd15_fc.safetensors", "flux-dev-de-distill.safetensors", "flux1-dev-fp8.safetensors", "flux1-dev.safetensors", "flux1-fill-dev.safetensors", "fluxmania_III.safetensors", "hunyuan_video_720_cfgdistill_fp8_e4m3fn.safetensors", "skyreels_hunyuan_i2v_fp8_e4m3fn.safetensors", "wan2.1_i2v_480p_14B_bf16.safetensors"]], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"]]}}, "input_order": {"required": ["unet_name", "weight_dtype"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UNETLoader", "display_name": "Load Diffusion Model", "description": "", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "DualCLIPLoader": {"input": {"required": {"clip_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["sdxl", "sd3", "flux", "hunyuan_video", "hidream"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "type"], "optional": ["device"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "DualCLIPLoader", "display_name": "DualCLIPLoader", "description": "[Recipes]\n\nsdxl: clip-l, clip-g\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\nflux: clip-l, t5\nhidream: at least one of t5 or llama, recommended t5 and llama", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "CLIPVisionEncode": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "image": ["IMAGE"], "crop": [["center", "none"]]}}, "input_order": {"required": ["clip_vision", "image", "crop"]}, "output": ["CLIP_VISION_OUTPUT"], "output_is_list": [false], "output_name": ["CLIP_VISION_OUTPUT"], "name": "CLIPVisionEncode", "display_name": "CLIP Vision Encode", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "StyleModelApply": {"input": {"required": {"conditioning": ["CONDITIONING"], "style_model": ["STYLE_MODEL"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_type": [["multiply", "attn_bias"]]}}, "input_order": {"required": ["conditioning", "style_model", "clip_vision_output", "strength", "strength_type"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "StyleModelApply", "display_name": "Apply Style Model", "description": "", "python_module": "nodes", "category": "conditioning/style_model", "output_node": false}, "unCLIPConditioning": {"input": {"required": {"conditioning": ["CONDITIONING"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "noise_augmentation": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "clip_vision_output", "strength", "noise_augmentation"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "unCLIPConditioning", "display_name": "unCLIPConditioning", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ControlNetApply": {"input": {"required": {"conditioning": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "control_net", "image", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ControlNetApply", "display_name": "Apply ControlNet (OLD)", "description": "", "python_module": "nodes", "category": "conditioning/controlnet", "output_node": false, "deprecated": true}, "ControlNetApplyAdvanced": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"vae": ["VAE"]}}, "input_order": {"required": ["positive", "negative", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["vae"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ControlNetApplyAdvanced", "display_name": "Apply ControlNet", "description": "", "python_module": "nodes", "category": "conditioning/controlnet", "output_node": false}, "ControlNetLoader": {"input": {"required": {"control_net_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}}, "input_order": {"required": ["control_net_name"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ControlNetLoader", "display_name": "Load ControlNet Model", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "DiffControlNetLoader": {"input": {"required": {"model": ["MODEL"], "control_net_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}}, "input_order": {"required": ["model", "control_net_name"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "DiffControlNetLoader", "display_name": "Load ControlNet Model (diff)", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "StyleModelLoader": {"input": {"required": {"style_model_name": [["flux1-redux-dev.safetensors"]]}}, "input_order": {"required": ["style_model_name"]}, "output": ["STYLE_MODEL"], "output_is_list": [false], "output_name": ["STYLE_MODEL"], "name": "StyleModelLoader", "display_name": "Load Style Model", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "CLIPVisionLoader": {"input": {"required": {"clip_name": [["CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors", "CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors", "SD1.5/pytorch_model.bin", "clip_vision_g.safetensors", "sdxl_clip.safetensors", "sigclip_vision_patch14_384_F1.safetensors"]]}}, "input_order": {"required": ["clip_name"]}, "output": ["CLIP_VISION"], "output_is_list": [false], "output_name": ["CLIP_VISION"], "name": "CLIPVisionLoader", "display_name": "Load CLIP Vision", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "VAEDecodeTiled": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 32}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to decode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}}, "input_order": {"required": ["samples", "vae", "tile_size", "overlap", "temporal_size", "temporal_overlap"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VAEDecodeTiled", "display_name": "VAE Decode (Tiled)", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "VAEEncodeTiled": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to encode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}}, "input_order": {"required": ["pixels", "vae", "tile_size", "overlap", "temporal_size", "temporal_overlap"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeTiled", "display_name": "VAE Encode (Tiled)", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "unCLIPCheckpointLoader": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE", "CLIP_VISION"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "CLIP_VISION"], "name": "unCLIPCheckpointLoader", "display_name": "unCLIPCheckpointLoader", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "GLIGENLoader": {"input": {"required": {"gligen_name": [[]]}}, "input_order": {"required": ["gligen_name"]}, "output": ["GLIGEN"], "output_is_list": [false], "output_name": ["GLIGEN"], "name": "GLIGENLoader", "display_name": "GLIGENLoader", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "GLIGENTextBoxApply": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "clip": ["CLIP"], "gligen_textbox_model": ["GLIGEN"], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "width": ["INT", {"default": 64, "min": 8, "max": 16384, "step": 8}], "height": ["INT", {"default": 64, "min": 8, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["conditioning_to", "clip", "gligen_textbox_model", "text", "width", "height", "x", "y"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "GLIGENTextBoxApply", "display_name": "GLIGENTextBoxApply", "description": "", "python_module": "nodes", "category": "conditioning/gligen", "output_node": false}, "InpaintModelConditioning": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "pixels": ["IMAGE"], "mask": ["MASK"], "noise_mask": ["BOOLEAN", {"default": true, "tooltip": "Add a noise mask to the latent so sampling will only happen within the mask. Might improve results or completely break things depending on the model."}]}}, "input_order": {"required": ["positive", "negative", "vae", "pixels", "mask", "noise_mask"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "InpaintModelConditioning", "display_name": "InpaintModelConditioning", "description": "", "python_module": "nodes", "category": "conditioning/inpaint", "output_node": false}, "CheckpointLoader": {"input": {"required": {"config_name": [["anything_v3.yaml", "v1-inference.yaml", "v1-inference_clip_skip_2.yaml", "v1-inference_clip_skip_2_fp16.yaml", "v1-inference_fp16.yaml", "v1-inpainting-inference.yaml", "v2-inference-v.yaml", "v2-inference-v_fp32.yaml", "v2-inference.yaml", "v2-inference_fp32.yaml", "v2-inpainting-inference.yaml"]], "ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["config_name", "ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoader", "display_name": "Load Checkpoint With Config (DEPRECATED)", "description": "", "python_module": "nodes", "category": "advanced/loaders", "output_node": false, "deprecated": true}, "DiffusersLoader": {"input": {"required": {"model_path": [[]]}}, "input_order": {"required": ["model_path"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "DiffusersLoader", "display_name": "DiffusersLoader", "description": "", "python_module": "nodes", "category": "advanced/loaders/deprecated", "output_node": false}, "LoadLatent": {"input": {"required": {"latent": [[]]}}, "input_order": {"required": ["latent"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LoadLatent", "display_name": "LoadLatent", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "SaveLatent": {"input": {"required": {"samples": ["LATENT"], "filename_prefix": ["STRING", {"default": "latents/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["samples", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveLatent", "display_name": "SaveLatent", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": true}, "ConditioningZeroOut": {"input": {"required": {"conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningZeroOut", "display_name": "ConditioningZeroOut", "description": "", "python_module": "nodes", "category": "advanced/conditioning", "output_node": false}, "ConditioningSetTimestepRange": {"input": {"required": {"conditioning": ["CONDITIONING"], "start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["conditioning", "start", "end"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetTimestepRange", "display_name": "ConditioningSetTimestepRange", "description": "", "python_module": "nodes", "category": "advanced/conditioning", "output_node": false}, "LoraLoaderModelOnly": {"input": {"required": {"model": ["MODEL"], "lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "lora_name", "strength_model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoraLoaderModelOnly", "display_name": "LoraLoaderModelOnly", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "LatentAdd": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentAdd", "display_name": "LatentAdd", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false}, "LatentSubtract": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentSubtract", "display_name": "LatentSubtract", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false}, "LatentMultiply": {"input": {"required": {"samples": ["LATENT"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "multiplier"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentMultiply", "display_name": "LatentMultiply", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false}, "LatentInterpolate": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["samples1", "samples2", "ratio"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentInterpolate", "display_name": "LatentInterpolate", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false}, "LatentBatch": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentBatch", "display_name": "LatentBatch", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/batch", "output_node": false}, "LatentBatchSeedBehavior": {"input": {"required": {"samples": ["LATENT"], "seed_behavior": [["random", "fixed"], {"default": "fixed"}]}}, "input_order": {"required": ["samples", "seed_behavior"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentBatchSeedBehavior", "display_name": "LatentBatchSeedBehavior", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false}, "LatentApplyOperation": {"input": {"required": {"samples": ["LATENT"], "operation": ["LATENT_OPERATION"]}}, "input_order": {"required": ["samples", "operation"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentApplyOperation", "display_name": "LatentApplyOperation", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "experimental": true}, "LatentApplyOperationCFG": {"input": {"required": {"model": ["MODEL"], "operation": ["LATENT_OPERATION"]}}, "input_order": {"required": ["model", "operation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LatentApplyOperationCFG", "display_name": "LatentApplyOperationCFG", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "experimental": true}, "LatentOperationTonemapReinhard": {"input": {"required": {"multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["multiplier"]}, "output": ["LATENT_OPERATION"], "output_is_list": [false], "output_name": ["LATENT_OPERATION"], "name": "LatentOperationTonemapReinhard", "display_name": "LatentOperationTonemapReinhard", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "experimental": true}, "LatentOperationSharpen": {"input": {"required": {"sharpen_radius": ["INT", {"default": 9, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}], "alpha": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 5.0, "step": 0.01}]}}, "input_order": {"required": ["sharpen_radius", "sigma", "alpha"]}, "output": ["LATENT_OPERATION"], "output_is_list": [false], "output_name": ["LATENT_OPERATION"], "name": "LatentOperationSharpen", "display_name": "LatentOperationSharpen", "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "experimental": true}, "HypernetworkLoader": {"input": {"required": {"model": ["MODEL"], "hypernetwork_name": [[]], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "hypernetwork_name", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "HypernetworkLoader", "display_name": "HypernetworkLoader", "description": "", "python_module": "comfy_extras.nodes_hypernetwork", "category": "loaders", "output_node": false}, "UpscaleModelLoader": {"input": {"required": {"model_name": [["4x-ClearRealityV1.pth"]]}}, "input_order": {"required": ["model_name"]}, "output": ["UPSCALE_MODEL"], "output_is_list": [false], "output_name": ["UPSCALE_MODEL"], "name": "UpscaleModelLoader", "display_name": "Load Upscale Model", "description": "", "python_module": "comfy_extras.nodes_upscale_model", "category": "loaders", "output_node": false}, "ImageUpscaleWithModel": {"input": {"required": {"upscale_model": ["UPSCALE_MODEL"], "image": ["IMAGE"]}}, "input_order": {"required": ["upscale_model", "image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageUpscaleWithModel", "display_name": "Upscale Image (using Model)", "description": "", "python_module": "comfy_extras.nodes_upscale_model", "category": "image/upscaling", "output_node": false}, "ImageBlend": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "blend_factor": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "blend_mode": [["normal", "multiply", "screen", "overlay", "soft_light", "difference"]]}}, "input_order": {"required": ["image1", "image2", "blend_factor", "blend_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBlend", "display_name": "Image Blend", "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false}, "ImageBlur": {"input": {"required": {"image": ["IMAGE"], "blur_radius": ["INT", {"default": 1, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}]}}, "input_order": {"required": ["image", "blur_radius", "sigma"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBlur", "display_name": "Image Blur", "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false}, "ImageQuantize": {"input": {"required": {"image": ["IMAGE"], "colors": ["INT", {"default": 256, "min": 1, "max": 256, "step": 1}], "dither": [["none", "floyd-steinberg", "bayer-2", "bayer-4", "bayer-8", "bayer-16"]]}}, "input_order": {"required": ["image", "colors", "dither"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageQuantize", "display_name": "Image Quantize", "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false}, "ImageSharpen": {"input": {"required": {"image": ["IMAGE"], "sharpen_radius": ["INT", {"default": 1, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.01}], "alpha": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 5.0, "step": 0.01}]}}, "input_order": {"required": ["image", "sharpen_radius", "sigma", "alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageSharpen", "display_name": "Image Sharpen", "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false}, "ImageScaleToTotalPixels": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "megapixels": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 16.0, "step": 0.01}]}}, "input_order": {"required": ["image", "upscale_method", "megapixels"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScaleToTotalPixels", "display_name": "Scale Image to Total Pixels", "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/upscaling", "output_node": false}, "LatentCompositeMasked": {"input": {"required": {"destination": ["LATENT"], "source": ["LATENT"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "resize_source": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "resize_source"], "optional": ["mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentCompositeMasked", "display_name": "LatentCompositeMasked", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "latent", "output_node": false}, "ImageCompositeMasked": {"input": {"required": {"destination": ["IMAGE"], "source": ["IMAGE"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "resize_source": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "resize_source"], "optional": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCompositeMasked", "display_name": "ImageCompositeMasked", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "image", "output_node": false}, "MaskToImage": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MaskToImage", "display_name": "Convert Mask to Image", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ImageToMask": {"input": {"required": {"image": ["IMAGE"], "channel": [["red", "green", "blue", "alpha"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImageToMask", "display_name": "Convert Image to Mask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ImageColorToMask": {"input": {"required": {"image": ["IMAGE"], "color": ["INT", {"default": 0, "min": 0, "max": 16777215, "step": 1, "display": "color"}]}}, "input_order": {"required": ["image", "color"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImageColorToMask", "display_name": "ImageColorToMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "SolidMask": {"input": {"required": {"value": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["value", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SolidMask", "display_name": "SolidMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "InvertMask": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "InvertMask", "display_name": "InvertMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "CropMask": {"input": {"required": {"mask": ["MASK"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["mask", "x", "y", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CropMask", "display_name": "CropMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "MaskComposite": {"input": {"required": {"destination": ["MASK"], "source": ["MASK"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "operation": [["multiply", "add", "subtract", "and", "or", "xor"]]}}, "input_order": {"required": ["destination", "source", "x", "y", "operation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskComposite", "display_name": "MaskComposite", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "FeatherMask": {"input": {"required": {"mask": ["MASK"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["mask", "left", "top", "right", "bottom"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "FeatherMask", "display_name": "FeatherMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "GrowMask": {"input": {"required": {"mask": ["MASK"], "expand": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "tapered_corners": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mask", "expand", "tapered_corners"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "GrowMask", "display_name": "GrowMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ThresholdMask": {"input": {"required": {"mask": ["MASK"], "value": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["mask", "value"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ThresholdMask", "display_name": "ThresholdMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "MaskPreview": {"input": {"required": {"mask": ["MASK"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mask"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "MaskPreview", "display_name": "MaskPreview", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": true}, "PorterDuffImageComposite": {"input": {"required": {"source": ["IMAGE"], "source_alpha": ["MASK"], "destination": ["IMAGE"], "destination_alpha": ["MASK"], "mode": [["ADD", "CLEAR", "DARKEN", "DST", "DST_ATOP", "DST_IN", "DST_OUT", "DST_OVER", "LIGHTEN", "MULTIPLY", "OVERLAY", "SCREEN", "SRC", "SRC_ATOP", "SRC_IN", "SRC_OUT", "SRC_OVER", "XOR"], {"default": "DST"}]}}, "input_order": {"required": ["source", "source_alpha", "destination", "destination_alpha", "mode"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "PorterDuffImageComposite", "display_name": "Porter-Duff Image Composite", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false}, "SplitImageWithAlpha": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "SplitImageWithAlpha", "display_name": "Split Image with Alpha", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false}, "JoinImageWithAlpha": {"input": {"required": {"image": ["IMAGE"], "alpha": ["MASK"]}}, "input_order": {"required": ["image", "alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "JoinImageWithAlpha", "display_name": "Join Image with Alpha", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false}, "RebatchLatents": {"input": {"required": {"latents": ["LATENT"], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["latents", "batch_size"]}, "output": ["LATENT"], "output_is_list": [true], "output_name": ["LATENT"], "name": "RebatchLatents", "display_name": "Rebatch Latents", "description": "", "python_module": "comfy_extras.nodes_rebatch", "category": "latent/batch", "output_node": false}, "RebatchImages": {"input": {"required": {"images": ["IMAGE"], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["images", "batch_size"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "RebatchImages", "display_name": "Rebatch Images", "description": "", "python_module": "comfy_extras.nodes_rebatch", "category": "image/batch", "output_node": false}, "ModelMergeSimple": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "ratio"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSimple", "display_name": "ModelMergeSimple", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeBlocks": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "input": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "input", "middle", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeBlocks", "display_name": "ModelMergeBlocks", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeSubtract": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSubtract", "display_name": "ModelMergeSubtract", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeAdd": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"]}}, "input_order": {"required": ["model1", "model2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeAdd", "display_name": "ModelMergeAdd", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CheckpointSave": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "filename_prefix": ["STRING", {"default": "checkpoints/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "clip", "vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "CheckpointSave", "display_name": "Save Checkpoint", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "CLIPMergeSimple": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["clip1", "clip2", "ratio"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeSimple", "display_name": "CLIPMergeSimple", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPMergeSubtract": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip1", "clip2", "multiplier"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeSubtract", "display_name": "CLIPMergeSubtract", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPMergeAdd": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"]}}, "input_order": {"required": ["clip1", "clip2"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeAdd", "display_name": "CLIPMergeAdd", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPSave": {"input": {"required": {"clip": ["CLIP"], "filename_prefix": ["STRING", {"default": "clip/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["clip", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "CLIPSave", "display_name": "CLIPSave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "VAESave": {"input": {"required": {"vae": ["VAE"], "filename_prefix": ["STRING", {"default": "vae/ComfyUI_vae"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "VAESave", "display_name": "VAESave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "ModelSave": {"input": {"required": {"model": ["MODEL"], "filename_prefix": ["STRING", {"default": "diffusion_models/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ModelSave", "display_name": "ModelSave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "TomePatchModel": {"input": {"required": {"model": ["MODEL"], "ratio": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "ratio"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TomePatchModel", "display_name": "TomePatchModel", "description": "", "python_module": "comfy_extras.nodes_tomesd", "category": "model_patches/unet", "output_node": false}, "CLIPTextEncodeSDXLRefiner": {"input": {"required": {"ascore": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "width": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip": ["CLIP"]}}, "input_order": {"required": ["ascore", "width", "height", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeSDXLRefiner", "display_name": "CLIPTextEncodeSDXLRefiner", "description": "", "python_module": "comfy_extras.nodes_clip_sdxl", "category": "advanced/conditioning", "output_node": false}, "CLIPTextEncodeSDXL": {"input": {"required": {"clip": ["CLIP"], "width": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "crop_w": ["INT", {"default": 0, "min": 0, "max": 16384}], "crop_h": ["INT", {"default": 0, "min": 0, "max": 16384}], "target_width": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "target_height": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "text_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "text_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "width", "height", "crop_w", "crop_h", "target_width", "target_height", "text_g", "text_l"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeSDXL", "display_name": "CLIPTextEncodeSDXL", "description": "", "python_module": "comfy_extras.nodes_clip_sdxl", "category": "advanced/conditioning", "output_node": false}, "Canny": {"input": {"required": {"image": ["IMAGE"], "low_threshold": ["FLOAT", {"default": 0.4, "min": 0.01, "max": 0.99, "step": 0.01}], "high_threshold": ["FLOAT", {"default": 0.8, "min": 0.01, "max": 0.99, "step": 0.01}]}}, "input_order": {"required": ["image", "low_threshold", "high_threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Canny", "display_name": "Canny", "description": "", "python_module": "comfy_extras.nodes_canny", "category": "image/preprocessors", "output_node": false}, "FreeU": {"input": {"required": {"model": ["MODEL"], "b1": ["FLOAT", {"default": 1.1, "min": 0.0, "max": 10.0, "step": 0.01}], "b2": ["FLOAT", {"default": 1.2, "min": 0.0, "max": 10.0, "step": 0.01}], "s1": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 10.0, "step": 0.01}], "s2": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "b1", "b2", "s1", "s2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreeU", "display_name": "FreeU", "description": "", "python_module": "comfy_extras.nodes_freelunch", "category": "model_patches/unet", "output_node": false}, "FreeU_V2": {"input": {"required": {"model": ["MODEL"], "b1": ["FLOAT", {"default": 1.3, "min": 0.0, "max": 10.0, "step": 0.01}], "b2": ["FLOAT", {"default": 1.4, "min": 0.0, "max": 10.0, "step": 0.01}], "s1": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 10.0, "step": 0.01}], "s2": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "b1", "b2", "s1", "s2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreeU_V2", "display_name": "FreeU_V2", "description": "", "python_module": "comfy_extras.nodes_freelunch", "category": "model_patches/unet", "output_node": false}, "SamplerCustom": {"input": {"required": {"model": ["MODEL"], "add_noise": ["BOOLEAN", {"default": true}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "sampler": ["SAMPLER"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "cfg", "positive", "negative", "sampler", "sigmas", "latent_image"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["output", "denoised_output"], "name": "SamplerCustom", "display_name": "SamplerCustom", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling", "output_node": false}, "BasicScheduler": {"input": {"required": {"model": ["MODEL"], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "scheduler", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "BasicScheduler", "display_name": "BasicScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "KarrasScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "rho": ["FLOAT", {"default": 7.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "rho"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "KarrasScheduler", "display_name": "KarrasScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "ExponentialScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ExponentialScheduler", "display_name": "ExponentialScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "PolyexponentialScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "rho": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "rho"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "PolyexponentialScheduler", "display_name": "PolyexponentialScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "LaplaceScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "mu": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.1, "round": false}], "beta": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "mu", "beta"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "LaplaceScheduler", "display_name": "LaplaceScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "VPScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "beta_d": ["FLOAT", {"default": 19.9, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "beta_min": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "eps_s": ["FLOAT", {"default": 0.001, "min": 0.0, "max": 1.0, "step": 0.0001, "round": false}]}}, "input_order": {"required": ["steps", "beta_d", "beta_min", "eps_s"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "VPScheduler", "display_name": "VPScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "BetaSamplingScheduler": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "alpha": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 50.0, "step": 0.01, "round": false}], "beta": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 50.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["model", "steps", "alpha", "beta"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "BetaSamplingScheduler", "display_name": "BetaSamplingScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "SDTurboScheduler": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 1, "min": 1, "max": 10}], "denoise": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "SDTurboScheduler", "display_name": "SDTurboScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "KSamplerSelect": {"input": {"required": {"sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]]}}, "input_order": {"required": ["sampler_name"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "KSamplerSelect", "display_name": "KSamplerSelect", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerAncestral": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerAncestral", "display_name": "SamplerEulerAncestral", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerAncestralCFGPP": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerAncestralCFGPP", "display_name": "SamplerEulerAncestralCFG++", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerLMS": {"input": {"required": {"order": ["INT", {"default": 4, "min": 1, "max": 100}]}}, "input_order": {"required": ["order"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerLMS", "display_name": "SamplerLMS", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_3M_SDE": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["eta", "s_noise", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_3M_SDE", "display_name": "SamplerDPMPP_3M_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_2M_SDE": {"input": {"required": {"solver_type": [["midpoint", "heun"]], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["solver_type", "eta", "s_noise", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_2M_SDE", "display_name": "SamplerDPMPP_2M_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_SDE": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "r": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["eta", "s_noise", "r", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_SDE", "display_name": "SamplerDPMPP_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_2S_Ancestral": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_2S_Ancestral", "display_name": "SamplerDPMPP_2S_Ancestral", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMAdaptative": {"input": {"required": {"order": ["INT", {"default": 3, "min": 2, "max": 3}], "rtol": ["FLOAT", {"default": 0.05, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "atol": ["FLOAT", {"default": 0.0078, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "h_init": ["FLOAT", {"default": 0.05, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "pcoeff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "icoeff": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "dcoeff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "accept_safety": ["FLOAT", {"default": 0.81, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "eta": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["order", "rtol", "atol", "h_init", "pcoeff", "icoeff", "dcoeff", "accept_safety", "eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMAdaptative", "display_name": "SamplerDPMAdaptative", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SplitSigmas": {"input": {"required": {"sigmas": ["SIGMAS"], "step": ["INT", {"default": 0, "min": 0, "max": 10000}]}}, "input_order": {"required": ["sigmas", "step"]}, "output": ["SIGMAS", "SIGMAS"], "output_is_list": [false, false], "output_name": ["high_sigmas", "low_sigmas"], "name": "SplitSigmas", "display_name": "SplitSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SplitSigmasDenoise": {"input": {"required": {"sigmas": ["SIGMAS"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["sigmas", "denoise"]}, "output": ["SIGMAS", "SIGMAS"], "output_is_list": [false, false], "output_name": ["high_sigmas", "low_sigmas"], "name": "SplitSigmasDenoise", "display_name": "SplitSigmasDenoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "FlipSigmas": {"input": {"required": {"sigmas": ["SIGMAS"]}}, "input_order": {"required": ["sigmas"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "FlipSigmas", "display_name": "FlipSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SetFirstSigma": {"input": {"required": {"sigmas": ["SIGMAS"], "sigma": ["FLOAT", {"default": 136.0, "min": 0.0, "max": 20000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["sigmas", "sigma"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "SetFirstSigma", "display_name": "SetFirstSigma", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "ExtendIntermediateSigmas": {"input": {"required": {"sigmas": ["SIGMAS"], "steps": ["INT", {"default": 2, "min": 1, "max": 100}], "start_at_sigma": ["FLOAT", {"default": -1.0, "min": -1.0, "max": 20000.0, "step": 0.01, "round": false}], "end_at_sigma": ["FLOAT", {"default": 12.0, "min": 0.0, "max": 20000.0, "step": 0.01, "round": false}], "spacing": [["linear", "cosine", "sine"]]}}, "input_order": {"required": ["sigmas", "steps", "start_at_sigma", "end_at_sigma", "spacing"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ExtendIntermediateSigmas", "display_name": "ExtendIntermediateSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "CFGGuider": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "cfg"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "CFGGuider", "display_name": "CFGGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "DualCFGGuider": {"input": {"required": {"model": ["MODEL"], "cond1": ["CONDITIONING"], "cond2": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg_conds": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "cfg_cond2_negative": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}]}}, "input_order": {"required": ["model", "cond1", "cond2", "negative", "cfg_conds", "cfg_cond2_negative"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "DualCFGGuider", "display_name": "DualCFGGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "BasicGuider": {"input": {"required": {"model": ["MODEL"], "conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["model", "conditioning"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "BasicGuider", "display_name": "BasicGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "RandomNoise": {"input": {"required": {"noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}}, "input_order": {"required": ["noise_seed"]}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "RandomNoise", "display_name": "RandomNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/noise", "output_node": false}, "DisableNoise": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "DisableNoise", "display_name": "DisableNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/noise", "output_node": false}, "AddNoise": {"input": {"required": {"model": ["MODEL"], "noise": ["NOISE"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["model", "noise", "sigmas", "latent_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "AddNoise", "display_name": "AddNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "_for_testing/custom_sampling/noise", "output_node": false}, "SamplerCustomAdvanced": {"input": {"required": {"noise": ["NOISE"], "guider": ["GUIDER"], "sampler": ["SAMPLER"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["noise", "guider", "sampler", "sigmas", "latent_image"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["output", "denoised_output"], "name": "SamplerCustomAdvanced", "display_name": "SamplerCustomAdvanced", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling", "output_node": false}, "HyperTile": {"input": {"required": {"model": ["MODEL"], "tile_size": ["INT", {"default": 256, "min": 1, "max": 2048}], "swap_size": ["INT", {"default": 2, "min": 1, "max": 128}], "max_depth": ["INT", {"default": 0, "min": 0, "max": 10}], "scale_depth": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["model", "tile_size", "swap_size", "max_depth", "scale_depth"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "HyperTile", "display_name": "HyperTile", "description": "", "python_module": "comfy_extras.nodes_hypertile", "category": "model_patches/unet", "output_node": false}, "ModelSamplingDiscrete": {"input": {"required": {"model": ["MODEL"], "sampling": [["eps", "v_prediction", "lcm", "x0", "img_to_img"]], "zsnr": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["model", "sampling", "zsnr"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingDiscrete", "display_name": "ModelSamplingDiscrete", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingContinuousEDM": {"input": {"required": {"model": ["MODEL"], "sampling": [["v_prediction", "edm", "edm_playground_v2.5", "eps"]], "sigma_max": ["FLOAT", {"default": 120.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}], "sigma_min": ["FLOAT", {"default": 0.002, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["model", "sampling", "sigma_max", "sigma_min"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingContinuousEDM", "display_name": "ModelSamplingContinuousEDM", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingContinuousV": {"input": {"required": {"model": ["MODEL"], "sampling": [["v_prediction"]], "sigma_max": ["FLOAT", {"default": 500.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}], "sigma_min": ["FLOAT", {"default": 0.03, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["model", "sampling", "sigma_max", "sigma_min"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingContinuousV", "display_name": "ModelSamplingContinuousV", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingStableCascade": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingStableCascade", "display_name": "ModelSamplingStableCascade", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingSD3": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingSD3", "display_name": "ModelSamplingSD3", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingAuraFlow": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 1.73, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingAuraFlow", "display_name": "ModelSamplingAuraFlow", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingFlux": {"input": {"required": {"model": ["MODEL"], "max_shift": ["FLOAT", {"default": 1.15, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 100.0, "step": 0.01}], "width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}]}}, "input_order": {"required": ["model", "max_shift", "base_shift", "width", "height"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingFlux", "display_name": "ModelSamplingFlux", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "RescaleCFG": {"input": {"required": {"model": ["MODEL"], "multiplier": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "RescaleCFG", "display_name": "RescaleCFG", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelComputeDtype": {"input": {"required": {"model": ["MODEL"], "dtype": [["default", "fp32", "fp16", "bf16"]]}}, "input_order": {"required": ["model", "dtype"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelComputeDtype", "display_name": "ModelComputeDtype", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/debug/model", "output_node": false}, "PatchModelAddDownscale": {"input": {"required": {"model": ["MODEL"], "block_number": ["INT", {"default": 3, "min": 1, "max": 32, "step": 1}], "downscale_factor": ["FLOAT", {"default": 2.0, "min": 0.1, "max": 9.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.35, "min": 0.0, "max": 1.0, "step": 0.001}], "downscale_after_skip": ["BOOLEAN", {"default": true}], "downscale_method": [["bicubic", "nearest-exact", "bilinear", "area", "bislerp"]], "upscale_method": [["bicubic", "nearest-exact", "bilinear", "area", "bislerp"]]}}, "input_order": {"required": ["model", "block_number", "downscale_factor", "start_percent", "end_percent", "downscale_after_skip", "downscale_method", "upscale_method"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PatchModelAddDownscale", "display_name": "PatchModelAddDownscale (Kohya Deep Shrink)", "description": "", "python_module": "comfy_extras.nodes_model_downscale", "category": "model_patches/unet", "output_node": false}, "ImageCrop": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "width", "height", "x", "y"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCrop", "display_name": "Image Crop", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "RepeatImageBatch": {"input": {"required": {"image": ["IMAGE"], "amount": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["image", "amount"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RepeatImageBatch", "display_name": "RepeatImageBatch", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/batch", "output_node": false}, "ImageFromBatch": {"input": {"required": {"image": ["IMAGE"], "batch_index": ["INT", {"default": 0, "min": 0, "max": 4095}], "length": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["image", "batch_index", "length"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFromBatch", "display_name": "ImageFromBatch", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/batch", "output_node": false}, "SaveAnimatedWEBP": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "fps": ["FLOAT", {"default": 6.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "lossless": ["BOOLEAN", {"default": true}], "quality": ["INT", {"default": 80, "min": 0, "max": 100}], "method": [["default", "fastest", "slowest"]]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "fps", "lossless", "quality", "method"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAnimatedWEBP", "display_name": "SaveAnimatedWEBP", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/animation", "output_node": true}, "SaveAnimatedPNG": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "fps": ["FLOAT", {"default": 6.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "compress_level": ["INT", {"default": 4, "min": 0, "max": 9}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "fps", "compress_level"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAnimatedPNG", "display_name": "SaveAnimatedPNG", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/animation", "output_node": true}, "SaveSVGNode": {"input": {"required": {"svg": ["SVG"], "filename_prefix": ["STRING", {"default": "svg/ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["svg", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveSVGNode", "display_name": "SaveSVGNode", "description": "Save SVG files on disk.", "python_module": "comfy_extras.nodes_images", "category": "image/save", "output_node": true}, "ImageOnlyCheckpointLoader": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP_VISION", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP_VISION", "VAE"], "name": "ImageOnlyCheckpointLoader", "display_name": "Image Only Checkpoint Loader (img2vid model)", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "loaders/video_models", "output_node": false}, "SVD_img2vid_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "video_frames": ["INT", {"default": 14, "min": 1, "max": 4096}], "motion_bucket_id": ["INT", {"default": 127, "min": 1, "max": 1023}], "fps": ["INT", {"default": 6, "min": 1, "max": 1024}], "augmentation_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "video_frames", "motion_bucket_id", "fps", "augmentation_level"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SVD_img2vid_Conditioning", "display_name": "SVD_img2vid_Conditioning", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "conditioning/video_models", "output_node": false}, "VideoLinearCFGGuidance": {"input": {"required": {"model": ["MODEL"], "min_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}]}}, "input_order": {"required": ["model", "min_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "VideoLinearCFGGuidance", "display_name": "VideoLinearCFGGuidance", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "sampling/video_models", "output_node": false}, "VideoTriangleCFGGuidance": {"input": {"required": {"model": ["MODEL"], "min_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}]}}, "input_order": {"required": ["model", "min_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "VideoTriangleCFGGuidance", "display_name": "VideoTriangleCFGGuidance", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "sampling/video_models", "output_node": false}, "ImageOnlyCheckpointSave": {"input": {"required": {"model": ["MODEL"], "clip_vision": ["CLIP_VISION"], "vae": ["VAE"], "filename_prefix": ["STRING", {"default": "checkpoints/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "clip_vision", "vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImageOnlyCheckpointSave", "display_name": "ImageOnlyCheckpointSave", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "advanced/model_merging", "output_node": true}, "ConditioningSetAreaPercentageVideo": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "height": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "temporal": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "z": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "temporal", "x", "y", "z", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaPercentageVideo", "display_name": "ConditioningSetAreaPercentageVideo", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "conditioning", "output_node": false}, "SelfAttentionGuidance": {"input": {"required": {"model": ["MODEL"], "scale": ["FLOAT", {"default": 0.5, "min": -2.0, "max": 5.0, "step": 0.01}], "blur_sigma": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 10.0, "step": 0.1}]}}, "input_order": {"required": ["model", "scale", "blur_sigma"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "SelfAttentionGuidance", "display_name": "Self-Attention Guidance", "description": "", "python_module": "comfy_extras.nodes_sag", "category": "_for_testing", "output_node": false}, "PerpNeg": {"input": {"required": {"model": ["MODEL"], "empty_conditioning": ["CONDITIONING"], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "empty_conditioning", "neg_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PerpNeg", "display_name": "Perp-Neg (DEPRECATED by PerpNegGuider)", "description": "", "python_module": "comfy_extras.nodes_perpneg", "category": "_for_testing", "output_node": false, "deprecated": true}, "PerpNegGuider": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "empty_conditioning": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "empty_conditioning", "cfg", "neg_scale"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "PerpNegGuider", "display_name": "PerpNegGuider", "description": "", "python_module": "comfy_extras.nodes_perpneg", "category": "_for_testing", "output_node": false}, "StableZero123_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "elevation", "azimuth"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "StableZero123_Conditioning", "display_name": "StableZero123_Conditioning", "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false}, "StableZero123_Conditioning_Batched": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "elevation_batch_increment": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth_batch_increment": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "elevation", "azimuth", "elevation_batch_increment", "azimuth_batch_increment"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "StableZero123_Conditioning_Batched", "display_name": "StableZero123_Conditioning_Batched", "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false}, "SV3D_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "video_frames": ["INT", {"default": 21, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -90.0, "max": 90.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "video_frames", "elevation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SV3D_Conditioning", "display_name": "SV3D_Conditioning", "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false}, "SD_4XUpscale_Conditioning": {"input": {"required": {"images": ["IMAGE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "scale_ratio": ["FLOAT", {"default": 4.0, "min": 0.0, "max": 10.0, "step": 0.01}], "noise_augmentation": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["images", "positive", "negative", "scale_ratio", "noise_augmentation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SD_4XUpscale_Conditioning", "display_name": "SD_4XUpscale_Conditioning", "description": "", "python_module": "comfy_extras.nodes_sdupscale", "category": "conditioning/upscale_diffusion", "output_node": false}, "PhotoMakerLoader": {"input": {"required": {"photomaker_model_name": [[]]}}, "input_order": {"required": ["photomaker_model_name"]}, "output": ["PHOTOMAKER"], "output_is_list": [false], "output_name": ["PHOTOMAKER"], "name": "PhotoMakerLoader", "display_name": "PhotoMakerLoader", "description": "", "python_module": "comfy_extras.nodes_photomaker", "category": "_for_testing/photomaker", "output_node": false}, "PhotoMakerEncode": {"input": {"required": {"photomaker": ["PHOTOMAKER"], "image": ["IMAGE"], "clip": ["CLIP"], "text": ["STRING", {"multiline": true, "dynamicPrompts": true, "default": "photograph of photomaker"}]}}, "input_order": {"required": ["photomaker", "image", "clip", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "PhotoMakerEncode", "display_name": "PhotoMakerEncode", "description": "", "python_module": "comfy_extras.nodes_photomaker", "category": "_for_testing/photomaker", "output_node": false}, "CLIPTextEncodePixArtAlpha": {"input": {"required": {"width": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip": ["CLIP"]}}, "input_order": {"required": ["width", "height", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodePixArtAlpha", "display_name": "CLIPTextEncodePixArtAlpha", "description": "Encodes text and sets the resolution conditioning for PixArt Alpha. Does not apply to PixArt Sigma.", "python_module": "comfy_extras.nodes_pixart", "category": "advanced/conditioning", "output_node": false}, "CLIPTextEncodeControlnet": {"input": {"required": {"clip": ["CLIP"], "conditioning": ["CONDITIONING"], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "conditioning", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeControlnet", "display_name": "CLIPTextEncodeControlnet", "description": "", "python_module": "comfy_extras.nodes_cond", "category": "_for_testing/conditioning", "output_node": false}, "T5TokenizerOptions": {"input": {"required": {"clip": ["CLIP"], "min_padding": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "min_length": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}]}}, "input_order": {"required": ["clip", "min_padding", "min_length"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "T5TokenizerOptions", "display_name": "T5TokenizerOptions", "description": "", "python_module": "comfy_extras.nodes_cond", "category": "sd", "output_node": false}, "Morphology": {"input": {"required": {"image": ["IMAGE"], "operation": [["erode", "dilate", "open", "close", "gradient", "bottom_hat", "top_hat"]], "kernel_size": ["INT", {"default": 3, "min": 3, "max": 999, "step": 1}]}}, "input_order": {"required": ["image", "operation", "kernel_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Morphology", "display_name": "ImageMorphology", "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/postprocessing", "output_node": false}, "ImageRGBToYUV": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["Y", "U", "V"], "name": "ImageRGBToYUV", "display_name": "ImageRGBToYUV", "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/batch", "output_node": false}, "ImageYUVToRGB": {"input": {"required": {"Y": ["IMAGE"], "U": ["IMAGE"], "V": ["IMAGE"]}}, "input_order": {"required": ["Y", "U", "V"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageYUVToRGB", "display_name": "ImageYUVToRGB", "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/batch", "output_node": false}, "StableCascade_EmptyLatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 256, "max": 16384, "step": 8}], "height": ["INT", {"default": 1024, "min": 256, "max": 16384, "step": 8}], "compression": ["INT", {"default": 42, "min": 4, "max": 128, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "compression", "batch_size"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["stage_c", "stage_b"], "name": "StableCascade_EmptyLatentImage", "display_name": "StableCascade_EmptyLatentImage", "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "latent/stable_cascade", "output_node": false}, "StableCascade_StageB_Conditioning": {"input": {"required": {"conditioning": ["CONDITIONING"], "stage_c": ["LATENT"]}}, "input_order": {"required": ["conditioning", "stage_c"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "StableCascade_StageB_Conditioning", "display_name": "StableCascade_StageB_Conditioning", "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "conditioning/stable_cascade", "output_node": false}, "StableCascade_StageC_VAEEncode": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"], "compression": ["INT", {"default": 42, "min": 4, "max": 128, "step": 1}]}}, "input_order": {"required": ["image", "vae", "compression"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["stage_c", "stage_b"], "name": "StableCascade_StageC_VAEEncode", "display_name": "StableCascade_StageC_VAEEncode", "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "latent/stable_cascade", "output_node": false}, "StableCascade_SuperResolutionControlnet": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"]}}, "input_order": {"required": ["image", "vae"]}, "output": ["IMAGE", "LATENT", "LATENT"], "output_is_list": [false, false, false], "output_name": ["controlnet_input", "stage_c", "stage_b"], "name": "StableCascade_SuperResolutionControlnet", "display_name": "StableCascade_SuperResolutionControlnet", "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "_for_testing/stable_cascade", "output_node": false, "experimental": true}, "DifferentialDiffusion": {"input": {"required": {"model": ["MODEL"]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "DifferentialDiffusion", "display_name": "Differential Diffusion", "description": "", "python_module": "comfy_extras.nodes_differential_diffusion", "category": "_for_testing", "output_node": false}, "InstructPixToPixConditioning": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "pixels": ["IMAGE"]}}, "input_order": {"required": ["positive", "negative", "vae", "pixels"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "InstructPixToPixConditioning", "display_name": "InstructPixToPixConditioning", "description": "", "python_module": "comfy_extras.nodes_ip2p", "category": "conditioning/instructpix2pix", "output_node": false}, "ModelMergeSD1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0.", "input_blocks.1.", "input_blocks.2.", "input_blocks.3.", "input_blocks.4.", "input_blocks.5.", "input_blocks.6.", "input_blocks.7.", "input_blocks.8.", "input_blocks.9.", "input_blocks.10.", "input_blocks.11.", "middle_block.0.", "middle_block.1.", "middle_block.2.", "output_blocks.0.", "output_blocks.1.", "output_blocks.2.", "output_blocks.3.", "output_blocks.4.", "output_blocks.5.", "output_blocks.6.", "output_blocks.7.", "output_blocks.8.", "output_blocks.9.", "output_blocks.10.", "output_blocks.11.", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD1", "display_name": "ModelMergeSD1", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD2": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0.", "input_blocks.1.", "input_blocks.2.", "input_blocks.3.", "input_blocks.4.", "input_blocks.5.", "input_blocks.6.", "input_blocks.7.", "input_blocks.8.", "input_blocks.9.", "input_blocks.10.", "input_blocks.11.", "middle_block.0.", "middle_block.1.", "middle_block.2.", "output_blocks.0.", "output_blocks.1.", "output_blocks.2.", "output_blocks.3.", "output_blocks.4.", "output_blocks.5.", "output_blocks.6.", "output_blocks.7.", "output_blocks.8.", "output_blocks.9.", "output_blocks.10.", "output_blocks.11.", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD2", "display_name": "ModelMergeSD2", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSDXL": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0", "input_blocks.1", "input_blocks.2", "input_blocks.3", "input_blocks.4", "input_blocks.5", "input_blocks.6", "input_blocks.7", "input_blocks.8", "middle_block.0", "middle_block.1", "middle_block.2", "output_blocks.0", "output_blocks.1", "output_blocks.2", "output_blocks.3", "output_blocks.4", "output_blocks.5", "output_blocks.6", "output_blocks.7", "output_blocks.8", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSDXL", "display_name": "ModelMergeSDXL", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD3_2B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "context_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embed.", "x_embedder.", "context_embedder.", "y_embedder.", "t_embedder.", "joint_blocks.0.", "joint_blocks.1.", "joint_blocks.2.", "joint_blocks.3.", "joint_blocks.4.", "joint_blocks.5.", "joint_blocks.6.", "joint_blocks.7.", "joint_blocks.8.", "joint_blocks.9.", "joint_blocks.10.", "joint_blocks.11.", "joint_blocks.12.", "joint_blocks.13.", "joint_blocks.14.", "joint_blocks.15.", "joint_blocks.16.", "joint_blocks.17.", "joint_blocks.18.", "joint_blocks.19.", "joint_blocks.20.", "joint_blocks.21.", "joint_blocks.22.", "joint_blocks.23.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD3_2B", "display_name": "ModelMergeSD3_2B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeAuraflow": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "init_x_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "positional_encoding": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cond_seq_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "register_tokens": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "modF.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "init_x_linear.", "positional_encoding", "cond_seq_linear.", "register_tokens", "t_embedder.", "double_layers.0.", "double_layers.1.", "double_layers.2.", "double_layers.3.", "single_layers.0.", "single_layers.1.", "single_layers.2.", "single_layers.3.", "single_layers.4.", "single_layers.5.", "single_layers.6.", "single_layers.7.", "single_layers.8.", "single_layers.9.", "single_layers.10.", "single_layers.11.", "single_layers.12.", "single_layers.13.", "single_layers.14.", "single_layers.15.", "single_layers.16.", "single_layers.17.", "single_layers.18.", "single_layers.19.", "single_layers.20.", "single_layers.21.", "single_layers.22.", "single_layers.23.", "single_layers.24.", "single_layers.25.", "single_layers.26.", "single_layers.27.", "single_layers.28.", "single_layers.29.", "single_layers.30.", "single_layers.31.", "modF.", "final_linear."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeAuraflow", "display_name": "ModelMergeAuraflow", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeFlux1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "img_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "guidance_in": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "vector_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "img_in.", "time_in.", "guidance_in", "vector_in.", "txt_in.", "double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeFlux1", "display_name": "ModelMergeFlux1", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD35_Large": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "context_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embed.", "x_embedder.", "context_embedder.", "y_embedder.", "t_embedder.", "joint_blocks.0.", "joint_blocks.1.", "joint_blocks.2.", "joint_blocks.3.", "joint_blocks.4.", "joint_blocks.5.", "joint_blocks.6.", "joint_blocks.7.", "joint_blocks.8.", "joint_blocks.9.", "joint_blocks.10.", "joint_blocks.11.", "joint_blocks.12.", "joint_blocks.13.", "joint_blocks.14.", "joint_blocks.15.", "joint_blocks.16.", "joint_blocks.17.", "joint_blocks.18.", "joint_blocks.19.", "joint_blocks.20.", "joint_blocks.21.", "joint_blocks.22.", "joint_blocks.23.", "joint_blocks.24.", "joint_blocks.25.", "joint_blocks.26.", "joint_blocks.27.", "joint_blocks.28.", "joint_blocks.29.", "joint_blocks.30.", "joint_blocks.31.", "joint_blocks.32.", "joint_blocks.33.", "joint_blocks.34.", "joint_blocks.35.", "joint_blocks.36.", "joint_blocks.37.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD35_Large", "display_name": "ModelMergeSD35_Large", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeMochiPreview": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_frequencies.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t5_y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t5_yproj.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.40.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.41.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.42.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.43.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.44.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.45.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.46.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.47.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_frequencies.", "t_embedder.", "t5_y_embedder.", "t5_yproj.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "blocks.36.", "blocks.37.", "blocks.38.", "blocks.39.", "blocks.40.", "blocks.41.", "blocks.42.", "blocks.43.", "blocks.44.", "blocks.45.", "blocks.46.", "blocks.47.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeMochiPreview", "display_name": "ModelMergeMochiPreview", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeLTXV": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "patchify_proj.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adaln_single.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "caption_projection.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "scale_shift_table": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "proj_out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "patchify_proj.", "adaln_single.", "caption_projection.", "transformer_blocks.0.", "transformer_blocks.1.", "transformer_blocks.2.", "transformer_blocks.3.", "transformer_blocks.4.", "transformer_blocks.5.", "transformer_blocks.6.", "transformer_blocks.7.", "transformer_blocks.8.", "transformer_blocks.9.", "transformer_blocks.10.", "transformer_blocks.11.", "transformer_blocks.12.", "transformer_blocks.13.", "transformer_blocks.14.", "transformer_blocks.15.", "transformer_blocks.16.", "transformer_blocks.17.", "transformer_blocks.18.", "transformer_blocks.19.", "transformer_blocks.20.", "transformer_blocks.21.", "transformer_blocks.22.", "transformer_blocks.23.", "transformer_blocks.24.", "transformer_blocks.25.", "transformer_blocks.26.", "transformer_blocks.27.", "scale_shift_table", "proj_out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeLTXV", "display_name": "ModelMergeLTXV", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmos7B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "extra_pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "affline_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "extra_pos_embedder.", "x_embedder.", "t_embedder.", "affline_norm.", "blocks.block0.", "blocks.block1.", "blocks.block2.", "blocks.block3.", "blocks.block4.", "blocks.block5.", "blocks.block6.", "blocks.block7.", "blocks.block8.", "blocks.block9.", "blocks.block10.", "blocks.block11.", "blocks.block12.", "blocks.block13.", "blocks.block14.", "blocks.block15.", "blocks.block16.", "blocks.block17.", "blocks.block18.", "blocks.block19.", "blocks.block20.", "blocks.block21.", "blocks.block22.", "blocks.block23.", "blocks.block24.", "blocks.block25.", "blocks.block26.", "blocks.block27.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmos7B", "display_name": "ModelMergeCosmos7B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmos14B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "extra_pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "affline_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "extra_pos_embedder.", "x_embedder.", "t_embedder.", "affline_norm.", "blocks.block0.", "blocks.block1.", "blocks.block2.", "blocks.block3.", "blocks.block4.", "blocks.block5.", "blocks.block6.", "blocks.block7.", "blocks.block8.", "blocks.block9.", "blocks.block10.", "blocks.block11.", "blocks.block12.", "blocks.block13.", "blocks.block14.", "blocks.block15.", "blocks.block16.", "blocks.block17.", "blocks.block18.", "blocks.block19.", "blocks.block20.", "blocks.block21.", "blocks.block22.", "blocks.block23.", "blocks.block24.", "blocks.block25.", "blocks.block26.", "blocks.block27.", "blocks.block28.", "blocks.block29.", "blocks.block30.", "blocks.block31.", "blocks.block32.", "blocks.block33.", "blocks.block34.", "blocks.block35.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmos14B", "display_name": "ModelMergeCosmos14B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeWAN2_1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "patch_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_projection.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "text_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "img_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "head.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "patch_embedding.", "time_embedding.", "time_projection.", "text_embedding.", "img_emb.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "blocks.36.", "blocks.37.", "blocks.38.", "blocks.39.", "head."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeWAN2_1", "display_name": "ModelMergeWAN2_1", "description": "1.3B model has 30 blocks, 14B model has 40 blocks. Image to video model has the extra img_emb.", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "PerturbedAttentionGuidance": {"input": {"required": {"model": ["MODEL"], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": 0.01}]}}, "input_order": {"required": ["model", "scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PerturbedAttentionGuidance", "display_name": "PerturbedAttentionGuidance", "description": "", "python_module": "comfy_extras.nodes_pag", "category": "model_patches/unet", "output_node": false}, "AlignYourStepsScheduler": {"input": {"required": {"model_type": [["SD1", "SDXL", "SVD"]], "steps": ["INT", {"default": 10, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model_type", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "AlignYourStepsScheduler", "display_name": "AlignYourStepsScheduler", "description": "", "python_module": "comfy_extras.nodes_align_your_steps", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "UNetSelfAttentionMultiply": {"input": {"required": {"model": ["MODEL"], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "q", "k", "v", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UNetSelfAttentionMultiply", "display_name": "UNetSelfAttentionMultiply", "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false}, "UNetCrossAttentionMultiply": {"input": {"required": {"model": ["MODEL"], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "q", "k", "v", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UNetCrossAttentionMultiply", "display_name": "UNetCrossAttentionMultiply", "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false}, "CLIPAttentionMultiply": {"input": {"required": {"clip": ["CLIP"], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip", "q", "k", "v", "out"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPAttentionMultiply", "display_name": "CLIPAttentionMultiply", "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false}, "UNetTemporalAttentionMultiply": {"input": {"required": {"model": ["MODEL"], "self_structural": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "self_temporal": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "cross_structural": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "cross_temporal": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "self_structural", "self_temporal", "cross_structural", "cross_temporal"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UNetTemporalAttentionMultiply", "display_name": "UNetTemporalAttentionMultiply", "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false}, "SamplerLCMUpscale": {"input": {"required": {"scale_ratio": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 20.0, "step": 0.01}], "scale_steps": ["INT", {"default": -1, "min": -1, "max": 1000, "step": 1}], "upscale_method": [["bislerp", "nearest-exact", "bilinear", "area", "bicubic"]]}}, "input_order": {"required": ["scale_ratio", "scale_steps", "upscale_method"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerLCMUpscale", "display_name": "SamplerLCMUpscale", "description": "", "python_module": "comfy_extras.nodes_advanced_samplers", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerCFGpp": {"input": {"required": {"version": [["regular", "alternative"]]}}, "input_order": {"required": ["version"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerCFGpp", "display_name": "SamplerEulerCFG++", "description": "", "python_module": "comfy_extras.nodes_advanced_samplers", "category": "_for_testing", "output_node": false}, "WebcamCapture": {"input": {"required": {"image": ["WEBCAM", {}], "width": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "capture_on_queue": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "width", "height", "capture_on_queue"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "WebcamCapture", "display_name": "Webcam Capture", "description": "", "python_module": "comfy_extras.nodes_webcam", "category": "image", "output_node": false}, "EmptyLatentAudio": {"input": {"required": {"seconds": ["FLOAT", {"default": 47.6, "min": 1.0, "max": 1000.0, "step": 0.1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["seconds", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentAudio", "display_name": "EmptyLatentAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "VAEEncodeAudio": {"input": {"required": {"audio": ["AUDIO"], "vae": ["VAE"]}}, "input_order": {"required": ["audio", "vae"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeAudio", "display_name": "VAEEncodeAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "VAEDecodeAudio": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"]}}, "input_order": {"required": ["samples", "vae"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "VAEDecodeAudio", "display_name": "VAEDecodeAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "SaveAudio": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudio", "display_name": "SaveAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "LoadAudio": {"input": {"required": {"audio": [[], {"audio_upload": true}]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "LoadAudio", "display_name": "LoadAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "PreviewAudio": {"input": {"required": {"audio": ["AUDIO"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAudio", "display_name": "PreviewAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "ConditioningStableAudio": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "seconds_start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.1}], "seconds_total": ["FLOAT", {"default": 47.0, "min": 0.0, "max": 1000.0, "step": 0.1}]}}, "input_order": {"required": ["positive", "negative", "seconds_start", "seconds_total"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ConditioningStableAudio", "display_name": "ConditioningStableAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "conditioning", "output_node": false}, "TripleCLIPLoader": {"input": {"required": {"clip_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name3": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "TripleCLIPLoader", "display_name": "TripleCLIPLoader", "description": "[Recipes]\n\nsd3: clip-l, clip-g, t5", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/loaders", "output_node": false}, "EmptySD3LatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptySD3LatentImage", "display_name": "EmptySD3LatentImage", "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "latent/sd3", "output_node": false}, "CLIPTextEncodeSD3": {"input": {"required": {"clip": ["CLIP"], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "empty_padding": [["none", "empty_prompt"]]}}, "input_order": {"required": ["clip", "clip_l", "clip_g", "t5xxl", "empty_padding"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeSD3", "display_name": "CLIPTextEncodeSD3", "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/conditioning", "output_node": false}, "ControlNetApplySD3": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "vae": ["VAE"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["positive", "negative", "control_net", "vae", "image", "strength", "start_percent", "end_percent"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ControlNetApplySD3", "display_name": "Apply Controlnet with VAE", "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "conditioning/controlnet", "output_node": false, "deprecated": true}, "SkipLayerGuidanceSD3": {"input": {"required": {"model": ["MODEL"], "layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "layers", "scale", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "SkipLayerGuidanceSD3", "display_name": "SkipLayerGuidanceSD3", "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/guidance", "output_node": false, "experimental": true}, "GITSScheduler": {"input": {"required": {"coeff": ["FLOAT", {"default": 1.2, "min": 0.8, "max": 1.5, "step": 0.05}], "steps": ["INT", {"default": 10, "min": 2, "max": 1000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["coeff", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "GITSScheduler", "display_name": "GITSScheduler", "description": "", "python_module": "comfy_extras.nodes_gits", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "SetUnionControlNetType": {"input": {"required": {"control_net": ["CONTROL_NET"], "type": [["auto", "openpose", "depth", "hed/pidi/scribble/ted", "canny/lineart/anime_lineart/mlsd", "normal", "segment", "tile", "repaint"]]}}, "input_order": {"required": ["control_net", "type"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "SetUnionControlNetType", "display_name": "SetUnionControlNetType", "description": "", "python_module": "comfy_extras.nodes_controlnet", "category": "conditioning/controlnet", "output_node": false}, "ControlNetInpaintingAliMamaApply": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "vae": ["VAE"], "image": ["IMAGE"], "mask": ["MASK"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["positive", "negative", "control_net", "vae", "image", "mask", "strength", "start_percent", "end_percent"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ControlNetInpaintingAliMamaApply", "display_name": "ControlNetInpaintingAliMamaApply", "description": "", "python_module": "comfy_extras.nodes_controlnet", "category": "conditioning/controlnet", "output_node": false}, "CLIPTextEncodeHunyuanDiT": {"input": {"required": {"clip": ["CLIP"], "bert": ["STRING", {"multiline": true, "dynamicPrompts": true}], "mt5xl": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "bert", "mt5xl"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeHunyuanDiT", "display_name": "CLIPTextEncodeHunyuanDiT", "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "advanced/conditioning", "output_node": false}, "TextEncodeHunyuanVideo_ImageToVideo": {"input": {"required": {"clip": ["CLIP"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}], "image_interleave": ["INT", {"default": 2, "min": 1, "max": 512, "tooltip": "How much the image influences things vs the text prompt. Higher number means more influence from the text prompt."}]}}, "input_order": {"required": ["clip", "clip_vision_output", "prompt", "image_interleave"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "TextEncodeHunyuanVideo_ImageToVideo", "display_name": "TextEncodeHunyuanVideo_ImageToVideo", "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "advanced/conditioning", "output_node": false}, "EmptyHunyuanLatentVideo": {"input": {"required": {"width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 25, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyHunyuanLatentVideo", "display_name": "EmptyHunyuanLatentVideo", "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "latent/video", "output_node": false}, "HunyuanImageToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "vae": ["VAE"], "width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 53, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "guidance_type": [["v1 (concat)", "v2 (replace)"]]}, "optional": {"start_image": ["IMAGE"]}}, "input_order": {"required": ["positive", "vae", "width", "height", "length", "batch_size", "guidance_type"], "optional": ["start_image"]}, "output": ["CONDITIONING", "LATENT"], "output_is_list": [false, false], "output_name": ["positive", "latent"], "name": "HunyuanImageToVideo", "display_name": "HunyuanImageToVideo", "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "conditioning/video_models", "output_node": false}, "CLIPTextEncodeFlux": {"input": {"required": {"clip": ["CLIP"], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "guidance": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["clip", "clip_l", "t5xxl", "guidance"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeFlux", "display_name": "CLIPTextEncodeFlux", "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false}, "FluxGuidance": {"input": {"required": {"conditioning": ["CONDITIONING"], "guidance": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["conditioning", "guidance"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "FluxGuidance", "display_name": "FluxGuidance", "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false}, "FluxDisableGuidance": {"input": {"required": {"conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "FluxDisableGuidance", "display_name": "FluxDisableGuidance", "description": "This node completely disables the guidance embed on Flux and Flux like models", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false}, "LoraSave": {"input": {"required": {"filename_prefix": ["STRING", {"default": "loras/ComfyUI_extracted_lora"}], "rank": ["INT", {"default": 8, "min": 1, "max": 4096, "step": 1}], "lora_type": [["standard", "full_diff"]], "bias_diff": ["BOOLEAN", {"default": true}]}, "optional": {"model_diff": ["MODEL", {"tooltip": "The ModelSubtract output to be converted to a lora."}], "text_encoder_diff": ["CLIP", {"tooltip": "The CLIPSubtract output to be converted to a lora."}]}}, "input_order": {"required": ["filename_prefix", "rank", "lora_type", "bias_diff"], "optional": ["model_diff", "text_encoder_diff"]}, "output": [], "output_is_list": [], "output_name": [], "name": "LoraSave", "display_name": "Extract and Save Lora", "description": "", "python_module": "comfy_extras.nodes_lora_extract", "category": "_for_testing", "output_node": true}, "TorchCompileModel": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]]}}, "input_order": {"required": ["model", "backend"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModel", "display_name": "TorchCompileModel", "description": "", "python_module": "comfy_extras.nodes_torch_compile", "category": "_for_testing", "output_node": false, "experimental": true}, "EmptyMochiLatentVideo": {"input": {"required": {"width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 25, "min": 7, "max": 16384, "step": 6}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyMochiLatentVideo", "display_name": "EmptyMochiLatentVideo", "description": "", "python_module": "comfy_extras.nodes_mochi", "category": "latent/video", "output_node": false}, "SkipLayerGuidanceDiT": {"input": {"required": {"model": ["MODEL"], "double_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "single_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}], "rescaling_scale": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "double_layers", "single_layers", "scale", "start_percent", "end_percent", "rescaling_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "SkipLayerGuidanceDiT", "display_name": "SkipLayerGuidanceDiT", "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.", "python_module": "comfy_extras.nodes_slg", "category": "advanced/guidance", "output_node": false, "experimental": true}, "Mahiro": {"input": {"required": {"model": ["MODEL"]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "name": "Mahiro", "display_name": "Mahiro is so cute that she deserves a better guidance function!! (\u3002\u30fb\u03c9\u30fb\u3002)", "description": "Modify the guidance to scale more on the 'direction' of the positive prompt rather than the difference between the negative prompt.", "python_module": "comfy_extras.nodes_mahiro", "category": "_for_testing", "output_node": false}, "EmptyLTXVLatentVideo": {"input": {"required": {"width": ["INT", {"default": 768, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 32}], "length": ["INT", {"default": 97, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLTXVLatentVideo", "display_name": "EmptyLTXVLatentVideo", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "latent/video/ltxv", "output_node": false}, "LTXVImgToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "image": ["IMAGE"], "width": ["INT", {"default": 768, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 32}], "length": ["INT", {"default": 97, "min": 9, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}]}}, "input_order": {"required": ["positive", "negative", "vae", "image", "width", "height", "length", "batch_size", "strength"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "LTXVImgToVideo", "display_name": "LTXVImgToVideo", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false}, "ModelSamplingLTXV": {"input": {"required": {"model": ["MODEL"], "max_shift": ["FLOAT", {"default": 2.05, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 100.0, "step": 0.01}]}, "optional": {"latent": ["LATENT"]}}, "input_order": {"required": ["model", "max_shift", "base_shift"], "optional": ["latent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingLTXV", "display_name": "ModelSamplingLTXV", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "advanced/model", "output_node": false}, "LTXVConditioning": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "frame_rate": ["FLOAT", {"default": 25.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "frame_rate"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "LTXVConditioning", "display_name": "LTXVConditioning", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false}, "LTXVScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "max_shift": ["FLOAT", {"default": 2.05, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 100.0, "step": 0.01}], "stretch": ["BOOLEAN", {"default": true, "tooltip": "Stretch the sigmas to be in the range [terminal, 1]."}], "terminal": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 0.99, "step": 0.01, "tooltip": "The terminal value of the sigmas after stretching."}]}, "optional": {"latent": ["LATENT"]}}, "input_order": {"required": ["steps", "max_shift", "base_shift", "stretch", "terminal"], "optional": ["latent"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "LTXVScheduler", "display_name": "LTXVScheduler", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "LTXVAddGuide": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "latent": ["LATENT"], "image": ["IMAGE", {"tooltip": "Image or video to condition the latent video on. Must be 8*n + 1 frames.If the video is not 8*n + 1 frames, it will be cropped to the nearest 8*n + 1 frames."}], "frame_idx": ["INT", {"default": 0, "min": -9999, "max": 9999, "tooltip": "Frame index to start the conditioning at. For single-frame images or videos with 1-8 frames, any frame_idx value is acceptable. For videos with 9+ frames, frame_idx must be divisible by 8, otherwise it will be rounded down to the nearest multiple of 8. Negative values are counted from the end of the video."}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "vae", "latent", "image", "frame_idx", "strength"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "LTXVAddGuide", "display_name": "LTXVAddGuide", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false}, "LTXVPreprocess": {"input": {"required": {"image": ["IMAGE"], "img_compression": ["INT", {"default": 35, "min": 0, "max": 100, "tooltip": "Amount of compression to apply on image."}]}}, "input_order": {"required": ["image", "img_compression"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["output_image"], "name": "LTXVPreprocess", "display_name": "LTXVPreprocess", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "image", "output_node": false}, "LTXVCropGuides": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent": ["LATENT"]}}, "input_order": {"required": ["positive", "negative", "latent"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "LTXVCropGuides", "display_name": "LTXVCropGuides", "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false}, "CreateHookLora": {"input": {"required": {"lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["lora_name", "strength_model", "strength_clip"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookLora", "display_name": "Create Hook LoRA", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookLoraModelOnly": {"input": {"required": {"lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["lora_name", "strength_model"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookLoraModelOnly", "display_name": "Create Hook LoRA (MO)", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookModelAsLora": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["ckpt_name", "strength_model", "strength_clip"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookModelAsLora", "display_name": "Create Hook Model as LoRA", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookModelAsLoraModelOnly": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["ckpt_name", "strength_model"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookModelAsLoraModelOnly", "display_name": "Create Hook Model as LoRA (MO)", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "SetHookKeyframes": {"input": {"required": {"hooks": ["HOOKS"]}, "optional": {"hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["hooks"], "optional": ["hook_kf"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "SetHookKeyframes", "display_name": "Set Hook Keyframes", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframe": {"input": {"required": {"strength_mult": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["strength_mult", "start_percent"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframe", "display_name": "Create Hook Keyframe", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframesInterpolated": {"input": {"required": {"strength_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "keyframes_count": ["INT", {"default": 5, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["strength_start", "strength_end", "interpolation", "start_percent", "end_percent", "keyframes_count", "print_keyframes"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframesInterpolated", "display_name": "Create Hook Keyframes Interp.", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframesFromFloats": {"input": {"required": {"floats_strength": ["FLOATS", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["floats_strength", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframesFromFloats", "display_name": "Create Hook Keyframes From Floats", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CombineHooks2": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks2", "display_name": "Combine Hooks [2]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "CombineHooks4": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"], "hooks_C": ["HOOKS"], "hooks_D": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B", "hooks_C", "hooks_D"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks4", "display_name": "Combine Hooks [4]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "CombineHooks8": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"], "hooks_C": ["HOOKS"], "hooks_D": ["HOOKS"], "hooks_E": ["HOOKS"], "hooks_F": ["HOOKS"], "hooks_G": ["HOOKS"], "hooks_H": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B", "hooks_C", "hooks_D", "hooks_E", "hooks_F", "hooks_G", "hooks_H"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks8", "display_name": "Combine Hooks [8]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "ConditioningSetProperties": {"input": {"required": {"cond_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["cond_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetProperties", "display_name": "Cond Set Props", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "ConditioningSetPropertiesAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["cond", "cond_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetPropertiesAndCombine", "display_name": "Cond Set Props Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "PairConditioningSetProperties": {"input": {"required": {"positive_NEW": ["CONDITIONING"], "negative_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["positive_NEW", "negative_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetProperties", "display_name": "Cond Pair Set Props", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "PairConditioningSetPropertiesAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_NEW": ["CONDITIONING"], "negative_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["positive", "negative", "positive_NEW", "negative_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetPropertiesAndCombine", "display_name": "Cond Pair Set Props Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "ConditioningSetDefaultCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_DEFAULT": ["CONDITIONING"]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["cond", "cond_DEFAULT"], "optional": ["hooks"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetDefaultCombine", "display_name": "Cond Set Default Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "PairConditioningSetDefaultCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_DEFAULT": ["CONDITIONING"], "negative_DEFAULT": ["CONDITIONING"]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["positive", "negative", "positive_DEFAULT", "negative_DEFAULT"], "optional": ["hooks"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetDefaultCombine", "display_name": "Cond Pair Set Default Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "PairConditioningCombine": {"input": {"required": {"positive_A": ["CONDITIONING"], "negative_A": ["CONDITIONING"], "positive_B": ["CONDITIONING"], "negative_B": ["CONDITIONING"]}}, "input_order": {"required": ["positive_A", "negative_A", "positive_B", "negative_B"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningCombine", "display_name": "Cond Pair Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "SetClipHooks": {"input": {"required": {"clip": ["CLIP"], "apply_to_conds": ["BOOLEAN", {"default": true}], "schedule_clip": ["BOOLEAN", {"default": false}]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["clip", "apply_to_conds", "schedule_clip"], "optional": ["hooks"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "SetClipHooks", "display_name": "Set CLIP Hooks", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/clip", "output_node": false, "experimental": true}, "ConditioningTimestepsRange": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["start_percent", "end_percent"]}, "output": ["TIMESTEPS_RANGE", "TIMESTEPS_RANGE", "TIMESTEPS_RANGE"], "output_is_list": [false, false, false], "output_name": ["TIMESTEPS_RANGE", "BEFORE_RANGE", "AFTER_RANGE"], "name": "ConditioningTimestepsRange", "display_name": "Timesteps Range", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks", "output_node": false, "experimental": true}, "Load3D": {"input": {"required": {"model_file": [[], {"file_upload": true}], "image": ["LOAD_3D", {}], "width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["model_file", "image", "width", "height"]}, "output": ["IMAGE", "MASK", "STRING", "IMAGE", "IMAGE", "LOAD3D_CAMERA"], "output_is_list": [false, false, false, false, false, false], "output_name": ["image", "mask", "mesh_path", "normal", "lineart", "camera_info"], "name": "Load3D", "display_name": "Load 3D", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": false, "experimental": true}, "Load3DAnimation": {"input": {"required": {"model_file": [[], {"file_upload": true}], "image": ["LOAD_3D_ANIMATION", {}], "width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["model_file", "image", "width", "height"]}, "output": ["IMAGE", "MASK", "STRING", "IMAGE", "LOAD3D_CAMERA"], "output_is_list": [false, false, false, false, false], "output_name": ["image", "mask", "mesh_path", "normal", "camera_info"], "name": "Load3DAnimation", "display_name": "Load 3D - Animation", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": false, "experimental": true}, "Preview3D": {"input": {"required": {"model_file": ["STRING", {"default": "", "multiline": false}]}, "optional": {"camera_info": ["LOAD3D_CAMERA", {}]}}, "input_order": {"required": ["model_file"], "optional": ["camera_info"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Preview3D", "display_name": "Preview 3D", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": true, "experimental": true}, "Preview3DAnimation": {"input": {"required": {"model_file": ["STRING", {"default": "", "multiline": false}]}, "optional": {"camera_info": ["LOAD3D_CAMERA", {}]}}, "input_order": {"required": ["model_file"], "optional": ["camera_info"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Preview3DAnimation", "display_name": "Preview 3D - Animation", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": true, "experimental": true}, "EmptyCosmosLatentVideo": {"input": {"required": {"width": ["INT", {"default": 1280, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 704, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 121, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyCosmosLatentVideo", "display_name": "EmptyCosmosLatentVideo", "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "latent/video", "output_node": false}, "CosmosImageToVideoLatent": {"input": {"required": {"vae": ["VAE"], "width": ["INT", {"default": 1280, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 704, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 121, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE"], "end_image": ["IMAGE"]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image", "end_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "CosmosImageToVideoLatent", "display_name": "CosmosImageToVideoLatent", "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "conditioning/inpaint", "output_node": false}, "SaveWEBM": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "codec": [["vp9", "av1"]], "fps": ["FLOAT", {"default": 24.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "crf": ["FLOAT", {"default": 32.0, "min": 0, "max": 63.0, "step": 1, "tooltip": "Higher crf means lower quality with a smaller file size, lower crf means higher quality higher filesize."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "codec", "fps", "crf"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveWEBM", "display_name": "SaveWEBM", "description": "", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": true, "experimental": true}, "SaveVideo": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to save."}], "filename_prefix": ["STRING", {"default": "video/ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}], "format": [["auto", "mp4"], {"default": "auto", "tooltip": "The format to save the video as."}], "codec": [["auto", "h264"], {"default": "auto", "tooltip": "The codec to use for the video."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["video", "filename_prefix", "format", "codec"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveVideo", "display_name": "Save Video", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": true}, "CreateVideo": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to create a video from."}], "fps": ["FLOAT", {"default": 30.0, "min": 1.0, "max": 120.0, "step": 1.0}]}, "optional": {"audio": ["AUDIO", {"tooltip": "The audio to add to the video."}]}}, "input_order": {"required": ["images", "fps"], "optional": ["audio"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "CreateVideo", "display_name": "Create Video", "description": "Create a video from images.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false}, "GetVideoComponents": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to extract components from."}]}}, "input_order": {"required": ["video"]}, "output": ["IMAGE", "AUDIO", "FLOAT"], "output_is_list": [false, false, false], "output_name": ["images", "audio", "fps"], "name": "GetVideoComponents", "display_name": "Get Video Components", "description": "Extracts all components from a video: frames, audio, and framerate.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false}, "LoadVideo": {"input": {"required": {"file": [[], {"video_upload": true}]}}, "input_order": {"required": ["file"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "LoadVideo", "display_name": "Load Video", "description": "", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false}, "CLIPTextEncodeLumina2": {"input": {"required": {"system_prompt": [["superior", "alignment"], {"tooltip": "Lumina2 provide two types of system prompts:Superior: You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts. Alignment: You are an assistant designed to generate high-quality images with the highest degree of image-text alignment based on textual prompts."}], "user_prompt": ["STRING", {"multiline": true, "dynamicPrompts": true, "tooltip": "The text to be encoded."}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}}, "input_order": {"required": ["system_prompt", "user_prompt", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeLumina2", "display_name": "CLIP Text Encode for Lumina2", "description": "Encodes a system prompt and a user prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.", "python_module": "comfy_extras.nodes_lumina2", "category": "conditioning", "output_node": false, "output_tooltips": ["A conditioning containing the embedded text used to guide the diffusion model."]}, "RenormCFG": {"input": {"required": {"model": ["MODEL"], "cfg_trunc": ["FLOAT", {"default": 100, "min": 0.0, "max": 100.0, "step": 0.01}], "renorm_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "cfg_trunc", "renorm_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "RenormCFG", "display_name": "RenormCFG", "description": "", "python_module": "comfy_extras.nodes_lumina2", "category": "advanced/model", "output_node": false}, "WanImageToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT"], "start_image": ["IMAGE"]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "WanImageToVideo", "display_name": "WanImageToVideo", "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false}, "WanFunControlToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT"], "start_image": ["IMAGE"], "control_video": ["IMAGE"]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "WanFunControlToVideo", "display_name": "WanFunControlToVideo", "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false}, "WanFunInpaintToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT"], "start_image": ["IMAGE"], "end_image": ["IMAGE"]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "end_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "WanFunInpaintToVideo", "display_name": "WanFunInpaintToVideo", "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false}, "WanFirstLastFrameToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_start_image": ["CLIP_VISION_OUTPUT"], "clip_vision_end_image": ["CLIP_VISION_OUTPUT"], "start_image": ["IMAGE"], "end_image": ["IMAGE"]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_start_image", "clip_vision_end_image", "start_image", "end_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "WanFirstLastFrameToVideo", "display_name": "WanFirstLastFrameToVideo", "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false}, "WanVaceToVideo": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}, "optional": {"control_video": ["IMAGE"], "control_masks": ["MASK"], "reference_image": ["IMAGE"]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size", "strength"], "optional": ["control_video", "control_masks", "reference_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["positive", "negative", "latent", "trim_latent"], "name": "WanVaceToVideo", "display_name": "WanVaceToVideo", "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "experimental": true}, "TrimVideoLatent": {"input": {"required": {"samples": ["LATENT"], "trim_amount": ["INT", {"default": 0, "min": 0, "max": 99999}]}}, "input_order": {"required": ["samples", "trim_amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "TrimVideoLatent", "display_name": "TrimVideoLatent", "description": "", "python_module": "comfy_extras.nodes_wan", "category": "latent/video", "output_node": false, "experimental": true}, "LotusConditioning": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["conditioning"], "name": "LotusConditioning", "display_name": "LotusConditioning", "description": "", "python_module": "comfy_extras.nodes_lotus", "category": "conditioning/lotus", "output_node": false}, "EmptyLatentHunyuan3Dv2": {"input": {"required": {"resolution": ["INT", {"default": 3072, "min": 1, "max": 8192}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["resolution", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentHunyuan3Dv2", "display_name": "EmptyLatentHunyuan3Dv2", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "latent/3d", "output_node": false}, "Hunyuan3Dv2Conditioning": {"input": {"required": {"clip_vision_output": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": ["clip_vision_output"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "Hunyuan3Dv2Conditioning", "display_name": "Hunyuan3Dv2Conditioning", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "conditioning/video_models", "output_node": false}, "Hunyuan3Dv2ConditioningMultiView": {"input": {"required": {}, "optional": {"front": ["CLIP_VISION_OUTPUT"], "left": ["CLIP_VISION_OUTPUT"], "back": ["CLIP_VISION_OUTPUT"], "right": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": [], "optional": ["front", "left", "back", "right"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "Hunyuan3Dv2ConditioningMultiView", "display_name": "Hunyuan3Dv2ConditioningMultiView", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "conditioning/video_models", "output_node": false}, "VAEDecodeHunyuan3D": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "num_chunks": ["INT", {"default": 8000, "min": 1000, "max": 500000}], "octree_resolution": ["INT", {"default": 256, "min": 16, "max": 512}]}}, "input_order": {"required": ["samples", "vae", "num_chunks", "octree_resolution"]}, "output": ["VOXEL"], "output_is_list": [false], "output_name": ["VOXEL"], "name": "VAEDecodeHunyuan3D", "display_name": "VAEDecodeHunyuan3D", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "latent/3d", "output_node": false}, "VoxelToMeshBasic": {"input": {"required": {"voxel": ["VOXEL"], "threshold": ["FLOAT", {"default": 0.6, "min": -1.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["voxel", "threshold"]}, "output": ["MESH"], "output_is_list": [false], "output_name": ["MESH"], "name": "VoxelToMeshBasic", "display_name": "VoxelToMeshBasic", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": false}, "VoxelToMesh": {"input": {"required": {"voxel": ["VOXEL"], "algorithm": [["surface net", "basic"]], "threshold": ["FLOAT", {"default": 0.6, "min": -1.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["voxel", "algorithm", "threshold"]}, "output": ["MESH"], "output_is_list": [false], "output_name": ["MESH"], "name": "VoxelToMesh", "display_name": "VoxelToMesh", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": false}, "SaveGLB": {"input": {"required": {"mesh": ["MESH"], "filename_prefix": ["STRING", {"default": "mesh/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mesh", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveGLB", "display_name": "SaveGLB", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": true}, "PrimitiveString": {"input": {"required": {"value": ["STRING", {}]}}, "input_order": {"required": ["value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "PrimitiveString", "display_name": "String", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false}, "PrimitiveStringMultiline": {"input": {"required": {"value": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "PrimitiveStringMultiline", "display_name": "String (Multiline)", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false}, "PrimitiveInt": {"input": {"required": {"value": ["INT", {"min": -9223372036854775807, "max": 9223372036854775807, "control_after_generate": true}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "PrimitiveInt", "display_name": "Int", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false}, "PrimitiveFloat": {"input": {"required": {"value": ["FLOAT", {"min": -9223372036854775807, "max": 9223372036854775807}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "PrimitiveFloat", "display_name": "Float", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false}, "PrimitiveBoolean": {"input": {"required": {"value": ["BOOLEAN", {}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "PrimitiveBoolean", "display_name": "Boolean", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false}, "CFGZeroStar": {"input": {"required": {"model": ["MODEL"]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "name": "CFGZeroStar", "display_name": "CFGZeroStar", "description": "", "python_module": "comfy_extras.nodes_cfg", "category": "advanced/guidance", "output_node": false}, "OptimalStepsScheduler": {"input": {"required": {"model_type": [["FLUX", "Wan", "Chroma"]], "steps": ["INT", {"default": 20, "min": 3, "max": 1000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model_type", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "OptimalStepsScheduler", "display_name": "OptimalStepsScheduler", "description": "", "python_module": "comfy_extras.nodes_optimalsteps", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "QuadrupleCLIPLoader": {"input": {"required": {"clip_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name3": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name4": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3", "clip_name4"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "QuadrupleCLIPLoader", "display_name": "QuadrupleCLIPLoader", "description": "[Recipes]\n\nhidream: long clip-l, long clip-g, t5xxl, llama_8b_3.1_instruct", "python_module": "comfy_extras.nodes_hidream", "category": "advanced/loaders", "output_node": false}, "CLIPTextEncodeHiDream": {"input": {"required": {"clip": ["CLIP"], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "llama": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "clip_l", "clip_g", "t5xxl", "llama"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeHiDream", "display_name": "CLIPTextEncodeHiDream", "description": "", "python_module": "comfy_extras.nodes_hidream", "category": "advanced/conditioning", "output_node": false}, "FreSca": {"input": {"required": {"model": ["MODEL"], "scale_low": ["FLOAT", {"default": 1.0, "min": 0, "max": 10, "step": 0.01, "tooltip": "Scaling factor for low-frequency components"}], "scale_high": ["FLOAT", {"default": 1.25, "min": 0, "max": 10, "step": 0.01, "tooltip": "Scaling factor for high-frequency components"}], "freq_cutoff": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1, "tooltip": "Number of frequency indices around center to consider as low-frequency"}]}}, "input_order": {"required": ["model", "scale_low", "scale_high", "freq_cutoff"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreSca", "display_name": "FreSca", "description": "Applies frequency-dependent scaling to the guidance", "python_module": "comfy_extras.nodes_fresca", "category": "_for_testing", "output_node": false}, "PreviewAny": {"input": {"required": {"source": ["*", {}]}}, "input_order": {"required": ["source"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAny", "display_name": "Preview Any", "description": "", "python_module": "comfy_extras.nodes_preview_any", "category": "utils", "output_node": true}, "TextEncodeAceStepAudio": {"input": {"required": {"clip": ["CLIP"], "tags": ["STRING", {"multiline": true, "dynamicPrompts": true}], "lyrics": ["STRING", {"multiline": true, "dynamicPrompts": true}], "lyrics_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip", "tags", "lyrics", "lyrics_strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "TextEncodeAceStepAudio", "display_name": "TextEncodeAceStepAudio", "description": "", "python_module": "comfy_extras.nodes_ace", "category": "conditioning", "output_node": false}, "EmptyAceStepLatentAudio": {"input": {"required": {"seconds": ["FLOAT", {"default": 120.0, "min": 1.0, "max": 1000.0, "step": 0.1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["seconds", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyAceStepLatentAudio", "display_name": "EmptyAceStepLatentAudio", "description": "", "python_module": "comfy_extras.nodes_ace", "category": "latent/audio", "output_node": false}, "IdeogramV1": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "turbo": ["BOOLEAN", {"default": false, "tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)"}]}, "optional": {"aspect_ratio": ["COMBO", {"options": ["1:1", "4:3", "3:4", "16:9", "9:16", "2:1", "1:2", "3:2", "2:3", "4:5", "5:4"], "default": "1:1", "tooltip": "The aspect ratio for image generation."}], "magic_prompt_option": ["COMBO", {"options": ["AUTO", "ON", "OFF"], "default": "AUTO", "tooltip": "Determine if MagicPrompt should be used in generation"}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "negative_prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Description of what to exclude from the image"}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "turbo"], "optional": ["aspect_ratio", "magic_prompt_option", "seed", "negative_prompt", "num_images"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "IdeogramV1", "display_name": "Ideogram V1", "description": "Generates images using the Ideogram V1 model.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram/v1", "output_node": false, "api_node": true}, "IdeogramV2": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "turbo": ["BOOLEAN", {"default": false, "tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)"}]}, "optional": {"aspect_ratio": ["COMBO", {"options": ["1:1", "4:3", "3:4", "16:9", "9:16", "2:1", "1:2", "3:2", "2:3", "4:5", "5:4"], "default": "1:1", "tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to AUTO."}], "resolution": ["COMBO", {"options": ["Auto", "512 x 1536", "576 x 1408", "576 x 1472", "576 x 1536", "640 x 1024", "640 x 1344", "640 x 1408", "640 x 1472", "640 x 1536", "704 x 1152", "704 x 1216", "704 x 1280", "704 x 1344", "704 x 1408", "704 x 1472", "720 x 1280", "736 x 1312", "768 x 1024", "768 x 1088", "768 x 1152", "768 x 1216", "768 x 1232", "768 x 1280", "768 x 1344", "832 x 960", "832 x 1024", "832 x 1088", "832 x 1152", "832 x 1216", "832 x 1248", "864 x 1152", "896 x 960", "896 x 1024", "896 x 1088", "896 x 1120", "896 x 1152", "960 x 832", "960 x 896", "960 x 1024", "960 x 1088", "1024 x 640", "1024 x 768", "1024 x 832", "1024 x 896", "1024 x 960", "1024 x 1024", "1088 x 768", "1088 x 832", "1088 x 896", "1088 x 960", "1120 x 896", "1152 x 704", "1152 x 768", "1152 x 832", "1152 x 864", "1152 x 896", "1216 x 704", "1216 x 768", "1216 x 832", "1232 x 768", "1248 x 832", "1280 x 704", "1280 x 720", "1280 x 768", "1280 x 800", "1312 x 736", "1344 x 640", "1344 x 704", "1344 x 768", "1408 x 576", "1408 x 640", "1408 x 704", "1472 x 576", "1472 x 640", "1472 x 704", "1536 x 512", "1536 x 576", "1536 x 640"], "default": "Auto", "tooltip": "The resolution for image generation. If not set to AUTO, this overrides the aspect_ratio setting."}], "magic_prompt_option": ["COMBO", {"options": ["AUTO", "ON", "OFF"], "default": "AUTO", "tooltip": "Determine if MagicPrompt should be used in generation"}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "style_type": ["COMBO", {"options": ["AUTO", "GENERAL", "REALISTIC", "DESIGN", "RENDER_3D", "ANIME"], "default": "NONE", "tooltip": "Style type for generation (V2 only)"}], "negative_prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Description of what to exclude from the image"}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "turbo"], "optional": ["aspect_ratio", "resolution", "magic_prompt_option", "seed", "style_type", "negative_prompt", "num_images"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "IdeogramV2", "display_name": "Ideogram V2", "description": "Generates images using the Ideogram V2 model.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram/v2", "output_node": false, "api_node": true}, "IdeogramV3": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation or editing"}]}, "optional": {"image": ["IMAGE", {"default": null, "tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"default": null, "tooltip": "Optional mask for inpainting (white areas will be replaced)"}], "aspect_ratio": ["COMBO", {"options": ["1:3", "3:1", "1:2", "2:1", "9:16", "16:9", "10:16", "16:10", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "1:1"], "default": "1:1", "tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to Auto."}], "resolution": ["COMBO", {"options": ["Auto", "512x1536", "576x1408", "576x1472", "576x1536", "640x1344", "640x1408", "640x1472", "640x1536", "704x1152", "704x1216", "704x1280", "704x1344", "704x1408", "704x1472", "736x1312", "768x1088", "768x1216", "768x1280", "768x1344", "800x1280", "832x960", "832x1024", "832x1088", "832x1152", "832x1216", "832x1248", "864x1152", "896x960", "896x1024", "896x1088", "896x1120", "896x1152", "960x832", "960x896", "960x1024", "960x1088", "1024x832", "1024x896", "1024x960", "1024x1024", "1088x768", "1088x832", "1088x896", "1088x960", "1120x896", "1152x704", "1152x832", "1152x864", "1152x896", "1216x704", "1216x768", "1216x832", "1248x832", "1280x704", "1280x768", "1280x800", "1312x736", "1344x640", "1344x704", "1344x768", "1408x576", "1408x640", "1408x704", "1472x576", "1472x640", "1472x704", "1536x512", "1536x576", "1536x640"], "default": "Auto", "tooltip": "The resolution for image generation. If not set to Auto, this overrides the aspect_ratio setting."}], "magic_prompt_option": ["COMBO", {"options": ["AUTO", "ON", "OFF"], "default": "AUTO", "tooltip": "Determine if MagicPrompt should be used in generation"}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}], "rendering_speed": ["COMBO", {"options": ["BALANCED", "TURBO", "QUALITY"], "default": "BALANCED", "tooltip": "Controls the trade-off between generation speed and quality"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt"], "optional": ["image", "mask", "aspect_ratio", "resolution", "magic_prompt_option", "seed", "num_images", "rendering_speed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "IdeogramV3", "display_name": "Ideogram V3", "description": "Generates images using the Ideogram V3 model. Supports both regular image generation from text prompts and image editing with mask.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram/v3", "output_node": false, "api_node": true}, "OpenAIDalle2": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt for DALL\u00b7E"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "not implemented yet in backend"}], "size": ["COMBO", {"options": ["256x256", "512x512", "1024x1024"], "default": "1024x1024", "tooltip": "Image size"}], "n": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number", "tooltip": "How many images to generate"}], "image": ["IMAGE", {"default": null, "tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"default": null, "tooltip": "Optional mask for inpainting (white areas will be replaced)"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt"], "optional": ["seed", "size", "n", "image", "mask"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OpenAIDalle2", "display_name": "OpenAI DALL\u00b7E 2", "description": "Generates images synchronously via OpenAI's DALL\u00b7E 2 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "api_node": true}, "OpenAIDalle3": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt for DALL\u00b7E"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "not implemented yet in backend"}], "quality": ["COMBO", {"options": ["standard", "hd"], "default": "standard", "tooltip": "Image quality"}], "style": ["COMBO", {"options": ["natural", "vivid"], "default": "natural", "tooltip": "Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images."}], "size": ["COMBO", {"options": ["1024x1024", "1024x1792", "1792x1024"], "default": "1024x1024", "tooltip": "Image size"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt"], "optional": ["seed", "quality", "style", "size"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OpenAIDalle3", "display_name": "OpenAI DALL\u00b7E 3", "description": "Generates images synchronously via OpenAI's DALL\u00b7E 3 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "api_node": true}, "OpenAIGPTImage1": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt for GPT Image 1"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "not implemented yet in backend"}], "quality": ["COMBO", {"options": ["low", "medium", "high"], "default": "low", "tooltip": "Image quality, affects cost and generation time."}], "background": ["COMBO", {"options": ["opaque", "transparent"], "default": "opaque", "tooltip": "Return image with or without background"}], "size": ["COMBO", {"options": ["auto", "1024x1024", "1024x1536", "1536x1024"], "default": "auto", "tooltip": "Image size"}], "n": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number", "tooltip": "How many images to generate"}], "image": ["IMAGE", {"default": null, "tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"default": null, "tooltip": "Optional mask for inpainting (white areas will be replaced)"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt"], "optional": ["seed", "quality", "background", "size", "n", "image", "mask"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OpenAIGPTImage1", "display_name": "OpenAI GPT Image 1", "description": "Generates images synchronously via OpenAI's GPT Image 1 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "api_node": true}, "MinimaxTextToVideoNode": {"input": {"required": {"prompt_text": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt to guide the video generation"}], "model": [["T2V-01", "T2V-01-Director"], {"default": "T2V-01", "tooltip": "Model to use for video generation"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt_text", "model"], "optional": ["seed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "MinimaxTextToVideoNode", "display_name": "MiniMax Text to Video", "description": "Generates videos from prompts using MiniMax's API", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": true, "api_node": true}, "MinimaxImageToVideoNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "Image to use as first frame of video generation"}], "prompt_text": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt to guide the video generation"}], "model": [["I2V-01-Director", "I2V-01", "I2V-01-live"], {"default": "I2V-01", "tooltip": "Model to use for video generation"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt_text", "model"], "optional": ["seed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "MinimaxImageToVideoNode", "display_name": "MiniMax Image to Video", "description": "Generates videos from an image and prompts using MiniMax's API", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": true, "api_node": true}, "VeoVideoGenerationNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text description of the video"}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16"], "default": "16:9", "tooltip": "Aspect ratio of the output video"}]}, "optional": {"negative_prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Negative text prompt to guide what to avoid in the video"}], "duration_seconds": ["INT", {"default": 5, "min": 5, "max": 8, "step": 1, "display": "number", "tooltip": "Duration of the output video in seconds"}], "enhance_prompt": ["BOOLEAN", {"default": true, "tooltip": "Whether to enhance the prompt with AI assistance"}], "person_generation": ["COMBO", {"options": ["ALLOW", "BLOCK"], "default": "ALLOW", "tooltip": "Whether to allow generating people in the video"}], "seed": ["INT", {"default": 0, "min": 0, "max": 4294967295, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "Seed for video generation (0 for random)"}], "image": ["IMAGE", {"default": null, "tooltip": "Optional reference image to guide video generation"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "aspect_ratio"], "optional": ["negative_prompt", "duration_seconds", "enhance_prompt", "person_generation", "seed", "image"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "VeoVideoGenerationNode", "display_name": "Google Veo2 Video Generation", "description": "Generates videos from text prompts using Google's Veo API", "python_module": "comfy_api_nodes.nodes_veo2", "category": "api node/video/Veo", "output_node": false, "api_node": true}, "KlingCameraControls": {"input": {"required": {"camera_control_type": ["COMBO", {"options": ["simple", "down_back", "forward_up", "right_turn_forward", "left_turn_forward"], "default": null}], "horizontal_movement": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider", "tooltip": "Controls camera's movement along horizontal axis (x-axis). Negative indicates left, positive indicates right"}], "vertical_movement": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider", "tooltip": "Controls camera's movement along vertical axis (y-axis). Negative indicates downward, positive indicates upward."}], "pan": ["FLOAT", {"default": 0.5, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider", "tooltip": "Controls camera's rotation in vertical plane (x-axis). Negative indicates downward rotation, positive indicates upward rotation."}], "tilt": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider", "tooltip": "Controls camera's rotation in horizontal plane (y-axis). Negative indicates left rotation, positive indicates right rotation."}], "roll": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider", "tooltip": "Controls camera's rolling amount (z-axis). Negative indicates counterclockwise, positive indicates clockwise."}], "zoom": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider", "tooltip": "Controls change in camera's focal length. Negative indicates narrower field of view, positive indicates wider field of view."}]}}, "input_order": {"required": ["camera_control_type", "horizontal_movement", "vertical_movement", "pan", "tilt", "roll", "zoom"]}, "output": ["CAMERA_CONTROL"], "output_is_list": [false], "output_name": ["camera_control"], "name": "KlingCameraControls", "display_name": "Kling Camera Controls", "description": "Allows specifying configuration options for Kling Camera Controls and motion control effects.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingTextToVideoNode": {"input": {"required": {"prompt": ["STRING", {"default": null, "tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16", "1:1"], "default": "16:9"}], "mode": [["standard mode / 5s duration / kling-v1", "standard mode / 10s duration / kling-v1", "pro mode / 5s duration / kling-v1", "pro mode / 10s duration / kling-v1", "standard mode / 5s duration / kling-v1-6", "standard mode / 10s duration / kling-v1-6", "pro mode / 5s duration / kling-v2-master", "pro mode / 10s duration / kling-v2-master", "standard mode / 5s duration / kling-v2-master", "standard mode / 10s duration / kling-v2-master"], {"default": "standard mode / 5s duration / kling-v1-6", "tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "mode"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingTextToVideoNode", "display_name": "Kling Text to Video", "description": "Kling Text to Video Node", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingImage2VideoNode": {"input": {"required": {"start_frame": ["IMAGE", {"default": null, "tooltip": "The reference image used to generate the video."}], "prompt": ["STRING", {"default": null, "tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt", "multiline": true}], "model_name": ["COMBO", {"options": ["kling-v1", "kling-v1-5", "kling-v1-6", "kling-v2-master"], "default": "kling-v2-master"}], "cfg_scale": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0}], "mode": ["COMBO", {"options": ["std", "pro"], "default": "std"}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16", "1:1"], "default": "16:9"}], "duration": ["COMBO", {"options": ["5", "10"], "default": "5"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["start_frame", "prompt", "negative_prompt", "model_name", "cfg_scale", "mode", "aspect_ratio", "duration"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingImage2VideoNode", "display_name": "Kling Image to Video", "description": "Kling Image to Video Node", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingCameraControlI2VNode": {"input": {"required": {"start_frame": ["IMAGE", {"default": null, "tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."}], "prompt": ["STRING", {"default": null, "tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16", "1:1"], "default": "16:9"}], "camera_control": ["CAMERA_CONTROL", {"tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["start_frame", "prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "camera_control"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingCameraControlI2VNode", "display_name": "Kling Image to Video (Camera Control)", "description": "Transform still images into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original image.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingCameraControlT2VNode": {"input": {"required": {"prompt": ["STRING", {"default": null, "tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16", "1:1"], "default": "16:9"}], "camera_control": ["CAMERA_CONTROL", {"tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "camera_control"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingCameraControlT2VNode", "display_name": "Kling Text to Video (Camera Control)", "description": "Transform text into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original text.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingStartEndFrameNode": {"input": {"required": {"start_frame": ["IMAGE", {"default": null, "tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."}], "end_frame": ["IMAGE", {"default": null, "tooltip": "Reference Image - End frame control. URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px. Base64 should not include data:image prefix."}], "prompt": ["STRING", {"default": null, "tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16", "1:1"], "default": "16:9"}], "mode": [["standard mode / 5s duration / kling-v1", "pro mode / 5s duration / kling-v1", "pro mode / 5s duration / kling-v1-5", "pro mode / 10s duration / kling-v1-5", "pro mode / 5s duration / kling-v1-6", "pro mode / 10s duration / kling-v1-6"], {"default": "pro mode / 5s duration / kling-v1-5", "tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["start_frame", "end_frame", "prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "mode"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingStartEndFrameNode", "display_name": "Kling Start-End Frame to Video", "description": "Generate a video sequence that transitions between your provided start and end images. The node creates all frames in between, producing a smooth transformation from the first frame to the last.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingVideoExtendNode": {"input": {"required": {"prompt": ["STRING", {"default": null, "tooltip": "Positive text prompt for guiding the video extension", "multiline": true}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt for elements to avoid in the extended video", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0}], "video_id": ["STRING", {"default": null, "tooltip": "The ID of the video to be extended. Supports videos generated by text-to-video, image-to-video, and previous video extension operations. Cannot exceed 3 minutes total duration after extension.", "forceInput": true}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "video_id"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingVideoExtendNode", "display_name": "Kling Video Extend", "description": "Kling Video Extend Node. Extend videos made by other Kling nodes. The video_id is created by using other Kling Nodes.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingLipSyncAudioToVideoNode": {"input": {"required": {"video": ["VIDEO", {}], "audio": ["AUDIO", {}], "voice_language": ["COMBO", {"options": ["zh", "en"], "default": "en"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["video", "audio", "voice_language"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingLipSyncAudioToVideoNode", "display_name": "Kling Lip Sync Video with Audio", "description": "Kling Lip Sync Audio to Video Node. Syncs mouth movements in a video file to the audio content of an audio file.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingLipSyncTextToVideoNode": {"input": {"required": {"video": ["VIDEO", {}], "text": ["STRING", {"default": null, "tooltip": "Text Content for Lip-Sync Video Generation. Required when mode is text2video. Maximum length is 120 characters.", "multiline": true}], "voice": [["Melody", "Sunny", "Sage", "Ace", "Blossom", "Peppy", "Dove", "Shine", "Anchor", "Lyric", "Tender", "Siren", "Zippy", "Bud", "Sprite", "Candy", "Beacon", "Rock", "Titan", "Grace", "Helen", "Lore", "Crag", "Prattle", "Hearth", "The Reader", "Commercial Lady", "\u9633\u5149\u5c11\u5e74", "\u61c2\u4e8b\u5c0f\u5f1f", "\u8fd0\u52a8\u5c11\u5e74", "\u9752\u6625\u5c11\u5973", "\u6e29\u67d4\u5c0f\u59b9", "\u5143\u6c14\u5c11\u5973", "\u9633\u5149\u7537\u751f", "\u5e7d\u9ed8\u5c0f\u54e5", "\u6587\u827a\u5c0f\u54e5", "\u751c\u7f8e\u90bb\u5bb6", "\u6e29\u67d4\u59d0\u59d0", "\u804c\u573a\u5973\u9752", "\u6d3b\u6cfc\u7537\u7ae5", "\u4fcf\u76ae\u5973\u7ae5", "\u7a33\u91cd\u8001\u7238", "\u6e29\u67d4\u5988\u5988", "\u4e25\u8083\u4e0a\u53f8", "\u4f18\u96c5\u8d35\u5987", "\u6148\u7965\u7237\u7237", "\u5520\u53e8\u7237\u7237", "\u5520\u53e8\u5976\u5976", "\u548c\u853c\u5976\u5976", "\u4e1c\u5317\u8001\u94c1", "\u91cd\u5e86\u5c0f\u4f19", "\u56db\u5ddd\u59b9\u5b50", "\u6f6e\u6c55\u5927\u53d4", "\u53f0\u6e7e\u7537\u751f", "\u897f\u5b89\u638c\u67dc", "\u5929\u6d25\u59d0\u59d0", "\u65b0\u95fb\u64ad\u62a5\u7537", "\u8bd1\u5236\u7247\u7537", "\u6492\u5a07\u5973\u53cb", "\u5200\u7247\u70df\u55d3", "\u4e56\u5de7\u6b63\u592a"], {"default": "Melody"}], "voice_speed": ["FLOAT", {"default": 1, "tooltip": "Speech Rate. Valid range: 0.8~2.0, accurate to one decimal place.", "min": 0.8, "max": 2.0, "slider": true}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["video", "text", "voice", "voice_speed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingLipSyncTextToVideoNode", "display_name": "Kling Lip Sync Video with Text", "description": "Kling Lip Sync Text to Video Node. Syncs mouth movements in a video file to a text prompt.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingVirtualTryOnNode": {"input": {"required": {"human_image": ["IMAGE", {}], "cloth_image": ["IMAGE", {}], "model_name": ["COMBO", {"options": ["kolors-virtual-try-on-v1", "kolors-virtual-try-on-v1-5"], "default": "kolors-virtual-try-on-v1"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["human_image", "cloth_image", "model_name"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "KlingVirtualTryOnNode", "display_name": "Kling Virtual Try On", "description": "Kling Virtual Try On Node. Input a human image and a cloth image to try on the cloth on the human.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/image/Kling", "output_node": false, "api_node": true}, "KlingImageGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true, "max_length": 500}], "negative_prompt": ["STRING", {"default": null, "tooltip": "Negative text prompt", "multiline": true}], "image_type": ["COMBO", {"options": ["subject", "face"], "default": null}], "image_fidelity": ["FLOAT", {"default": 0.5, "tooltip": "Reference intensity for user-uploaded images", "min": 0.0, "max": 1.0, "slider": true, "step": 0.01}], "human_fidelity": ["FLOAT", {"default": 0.45, "tooltip": "Subject reference similarity", "min": 0.0, "max": 1.0, "slider": true, "step": 0.01}], "model_name": ["COMBO", {"options": ["kling-v1", "kling-v1-5", "kling-v2"], "default": "kling-v1"}], "aspect_ratio": ["COMBO", {"options": ["16:9", "9:16", "1:1", "4:3", "3:4", "3:2", "2:3", "21:9"], "default": "16:9"}], "n": ["INT", {"default": 1, "tooltip": "Number of generated images", "min": 1, "max": 9}]}, "optional": {"image": ["IMAGE", {}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "negative_prompt", "image_type", "image_fidelity", "human_fidelity", "model_name", "aspect_ratio", "n"], "optional": ["image"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "KlingImageGenerationNode", "display_name": "Kling Image Generation", "description": "Kling Image Generation Node. Generate an image from a text prompt with an optional reference image.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/image/Kling", "output_node": false, "api_node": true}, "KlingSingleImageVideoEffectNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": " Reference Image. URL or Base64 encoded string (without data:image prefix). File size cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1"}], "effect_scene": ["COMBO", {"options": ["bloombloom", "dizzydizzy", "fuzzyfuzzy", "squish", "expansion"]}], "model_name": ["COMBO", {"options": ["kling-v1-6"]}], "duration": ["COMBO", {"options": ["5", "10"]}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "effect_scene", "model_name", "duration"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "name": "KlingSingleImageVideoEffectNode", "display_name": "Kling Video Effects", "description": "Achieve different special effects when generating a video based on the effect_scene.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "KlingDualCharacterVideoEffectNode": {"input": {"required": {"image_left": ["IMAGE", {"tooltip": "Left side image"}], "image_right": ["IMAGE", {"tooltip": "Right side image"}], "effect_scene": ["COMBO", {"options": ["hug", "kiss", "heart_gesture"]}], "model_name": ["COMBO", {"options": ["kling-v1", "kling-v1-5", "kling-v1-6"], "default": "kling-v1"}], "mode": ["COMBO", {"options": ["std", "pro"], "default": "std"}], "duration": ["COMBO", {"options": ["5", "10"]}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image_left", "image_right", "effect_scene", "model_name", "mode", "duration"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO", "STRING"], "output_is_list": [false, false], "output_name": ["VIDEO", "duration"], "name": "KlingDualCharacterVideoEffectNode", "display_name": "Kling Dual Character Video Effects", "description": "Achieve different special effects when generating a video based on the effect_scene. First image will be positioned on left side, second on right side of the composite.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "api_node": true}, "FluxProUltraImageNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "prompt_upsampling": ["BOOLEAN", {"default": false, "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result)."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}], "aspect_ratio": ["STRING", {"default": "16:9", "tooltip": "Aspect ratio of image; must be between 1:4 and 4:1."}], "raw": ["BOOLEAN", {"default": false, "tooltip": "When True, generate less processed, more natural-looking images."}]}, "optional": {"image_prompt": ["IMAGE"], "image_prompt_strength": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Blend between the prompt and the image prompt."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "prompt_upsampling", "seed", "aspect_ratio", "raw"], "optional": ["image_prompt", "image_prompt_strength"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxProUltraImageNode", "display_name": "Flux 1.1 [pro] Ultra Image", "description": "Generates images using Flux Pro 1.1 Ultra via api based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "api_node": true}, "FluxProExpandNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "prompt_upsampling": ["BOOLEAN", {"default": false, "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result)."}], "top": ["INT", {"default": 0, "min": 0, "max": 2048, "tooltip": "Number of pixels to expand at the top of the image"}], "bottom": ["INT", {"default": 0, "min": 0, "max": 2048, "tooltip": "Number of pixels to expand at the bottom of the image"}], "left": ["INT", {"default": 0, "min": 0, "max": 2048, "tooltip": "Number of pixels to expand at the left side of the image"}], "right": ["INT", {"default": 0, "min": 0, "max": 2048, "tooltip": "Number of pixels to expand at the right side of the image"}], "guidance": ["FLOAT", {"default": 60, "min": 1.5, "max": 100, "tooltip": "Guidance strength for the image generation process"}], "steps": ["INT", {"default": 50, "min": 15, "max": 50, "tooltip": "Number of steps for the image generation process"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "prompt_upsampling", "top", "bottom", "left", "right", "guidance", "steps", "seed"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxProExpandNode", "display_name": "Flux.1 Expand Image", "description": "Outpaints image based on prompt.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "api_node": true}, "FluxProFillNode": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "prompt_upsampling": ["BOOLEAN", {"default": false, "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result)."}], "guidance": ["FLOAT", {"default": 60, "min": 1.5, "max": 100, "tooltip": "Guidance strength for the image generation process"}], "steps": ["INT", {"default": 50, "min": 15, "max": 50, "tooltip": "Number of steps for the image generation process"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "mask", "prompt", "prompt_upsampling", "guidance", "steps", "seed"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxProFillNode", "display_name": "Flux.1 Fill Image", "description": "Inpaints image based on mask and prompt.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "api_node": true}, "FluxProCannyNode": {"input": {"required": {"control_image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "prompt_upsampling": ["BOOLEAN", {"default": false, "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result)."}], "canny_low_threshold": ["FLOAT", {"default": 0.1, "min": 0.01, "max": 0.99, "step": 0.01, "tooltip": "Low threshold for Canny edge detection; ignored if skip_processing is True"}], "canny_high_threshold": ["FLOAT", {"default": 0.4, "min": 0.01, "max": 0.99, "step": 0.01, "tooltip": "High threshold for Canny edge detection; ignored if skip_processing is True"}], "skip_preprocessing": ["BOOLEAN", {"default": false, "tooltip": "Whether to skip preprocessing; set to True if control_image already is canny-fied, False if it is a raw image."}], "guidance": ["FLOAT", {"default": 30, "min": 1, "max": 100, "tooltip": "Guidance strength for the image generation process"}], "steps": ["INT", {"default": 50, "min": 15, "max": 50, "tooltip": "Number of steps for the image generation process"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["control_image", "prompt", "prompt_upsampling", "canny_low_threshold", "canny_high_threshold", "skip_preprocessing", "guidance", "steps", "seed"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxProCannyNode", "display_name": "Flux.1 Canny Control Image", "description": "Generate image using a control image (canny).", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "api_node": true}, "FluxProDepthNode": {"input": {"required": {"control_image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "prompt_upsampling": ["BOOLEAN", {"default": false, "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result)."}], "skip_preprocessing": ["BOOLEAN", {"default": false, "tooltip": "Whether to skip preprocessing; set to True if control_image already is depth-ified, False if it is a raw image."}], "guidance": ["FLOAT", {"default": 15, "min": 1, "max": 100, "tooltip": "Guidance strength for the image generation process"}], "steps": ["INT", {"default": 50, "min": 15, "max": 50, "tooltip": "Number of steps for the image generation process"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["control_image", "prompt", "prompt_upsampling", "skip_preprocessing", "guidance", "steps", "seed"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxProDepthNode", "display_name": "Flux.1 Depth Control Image", "description": "Generate image using a control image (depth).", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "api_node": true}, "LumaImageNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "model": [["photon-1", "photon-flash-1"]], "aspect_ratio": [["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"], {"default": "16:9"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}], "style_image_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Weight of style image. Ignored if no style_image provided."}]}, "optional": {"image_luma_ref": ["LUMA_REF", {"tooltip": "Luma Reference node connection to influence generation with input images; up to 4 images can be considered."}], "style_image": ["IMAGE", {"tooltip": "Style reference image; only 1 image will be used."}], "character_image": ["IMAGE", {"tooltip": "Character reference images; can be a batch of multiple, up to 4 images can be considered."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "seed", "style_image_weight"], "optional": ["image_luma_ref", "style_image", "character_image"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LumaImageNode", "display_name": "Luma Text to Image", "description": "Generates images synchronously based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "api_node": true}, "LumaImageModifyNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation"}], "image_weight": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 0.98, "step": 0.01, "tooltip": "Weight of the image; the closer to 1.0, the less the image will be modified."}], "model": [["photon-1", "photon-flash-1"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "image_weight", "model", "seed"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LumaImageModifyNode", "display_name": "Luma Image to Image", "description": "Modifies images synchronously based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "api_node": true}, "LumaVideoNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the video generation"}], "model": [["ray-2", "ray-flash-2", "ray-1-6"]], "aspect_ratio": [["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"], {"default": "16:9"}], "resolution": [["540p", "720p", "1080p", "4k"], {"default": "540p"}], "duration": [["5s", "9s"]], "loop": ["BOOLEAN", {"default": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "resolution", "duration", "loop", "seed"], "optional": ["luma_concepts"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "LumaVideoNode", "display_name": "Luma Text to Video", "description": "Generates videos synchronously based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "api_node": true}, "LumaImageToVideoNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the video generation"}], "model": [["ray-2", "ray-flash-2", "ray-1-6"]], "resolution": [["540p", "720p", "1080p", "4k"], {"default": "540p"}], "duration": [["5s", "9s"]], "loop": ["BOOLEAN", {"default": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"first_image": ["IMAGE", {"tooltip": "First frame of generated video."}], "last_image": ["IMAGE", {"tooltip": "Last frame of generated video."}], "luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "model", "resolution", "duration", "loop", "seed"], "optional": ["first_image", "last_image", "luma_concepts"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "LumaImageToVideoNode", "display_name": "Luma Image to Video", "description": "Generates videos synchronously based on prompt, input images, and output_size.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "api_node": true}, "LumaReferenceNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "Image to use as reference."}], "weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Weight of image reference."}]}, "optional": {"luma_ref": ["LUMA_REF"]}}, "input_order": {"required": ["image", "weight"], "optional": ["luma_ref"]}, "output": ["LUMA_REF"], "output_is_list": [false], "output_name": ["luma_ref"], "name": "LumaReferenceNode", "display_name": "Luma Reference", "description": "Holds an image and weight for use with Luma Generate Image node.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false}, "LumaConceptsNode": {"input": {"required": {"concept1": [["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]], "concept2": [["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]], "concept3": [["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]], "concept4": [["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]]}, "optional": {"luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to add to the ones chosen here."}]}}, "input_order": {"required": ["concept1", "concept2", "concept3", "concept4"], "optional": ["luma_concepts"]}, "output": ["LUMA_CONCEPTS"], "output_is_list": [false], "output_name": ["luma_concepts"], "name": "LumaConceptsNode", "display_name": "Luma Concepts", "description": "Holds one or more Camera Concepts for use with Luma Text to Video and Luma Image to Video nodes.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false}, "RecraftTextToImageNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation."}], "size": [["1024x1024", "1365x1024", "1024x1365", "1536x1024", "1024x1536", "1820x1024", "1024x1820", "1024x2048", "2048x1024", "1434x1024", "1024x1434", "1024x1280", "1280x1024", "1024x1707", "1707x1024"], {"default": "1024x1024", "tooltip": "The size of the generated image."}], "n": ["INT", {"default": 1, "min": 1, "max": 6, "tooltip": "The number of images to generate."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE"], "negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "size", "n", "seed"], "optional": ["recraft_style", "negative_prompt", "recraft_controls"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RecraftTextToImageNode", "display_name": "Recraft Text to Image", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftImageToImageNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation."}], "n": ["INT", {"default": 1, "min": 1, "max": 6, "tooltip": "The number of images to generate."}], "strength": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE"], "negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "n", "strength", "seed"], "optional": ["recraft_style", "negative_prompt", "recraft_controls"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RecraftImageToImageNode", "display_name": "Recraft Image to Image", "description": "Modify image based on prompt and strength.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftImageInpaintingNode": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation."}], "n": ["INT", {"default": 1, "min": 1, "max": 6, "tooltip": "The number of images to generate."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE"], "negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "mask", "prompt", "n", "seed"], "optional": ["recraft_style", "negative_prompt"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RecraftImageInpaintingNode", "display_name": "Recraft Image Inpainting", "description": "Modify image based on prompt and mask.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftTextToVectorNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation."}], "substyle": [["None", "bold_stroke", "chemistry", "colored_stencil", "contour_pop_art", "cosmics", "cutout", "depressive", "editorial", "emotional_flat", "engraving", "infographical", "line_art", "line_circuit", "linocut", "marker_outline", "mosaic", "naivector", "roundish_flat", "seamless", "segmented_colors", "sharp_contrast", "thin", "vector_photo", "vivid_shapes"]], "size": [["1024x1024", "1365x1024", "1024x1365", "1536x1024", "1024x1536", "1820x1024", "1024x1820", "1024x2048", "2048x1024", "1434x1024", "1024x1434", "1024x1280", "1280x1024", "1024x1707", "1707x1024"], {"default": "1024x1024", "tooltip": "The size of the generated image."}], "n": ["INT", {"default": 1, "min": 1, "max": 6, "tooltip": "The number of images to generate."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "substyle", "size", "n", "seed"], "optional": ["negative_prompt", "recraft_controls"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["SVG"], "output_is_list": [false], "output_name": ["SVG"], "name": "RecraftTextToVectorNode", "display_name": "Recraft Text to Vector", "description": "Generates SVG synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftVectorizeImageNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["SVG"], "output_is_list": [false], "output_name": ["SVG"], "name": "RecraftVectorizeImageNode", "display_name": "Recraft Vectorize Image", "description": "Generates SVG synchronously from an input image.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftRemoveBackgroundNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "RecraftRemoveBackgroundNode", "display_name": "Recraft Remove Background", "description": "Remove background from image, and return processed image and mask.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftReplaceBackgroundNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the image generation."}], "n": ["INT", {"default": 1, "min": 1, "max": 6, "tooltip": "The number of images to generate."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed."}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE"], "negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "n", "seed"], "optional": ["recraft_style", "negative_prompt"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RecraftReplaceBackgroundNode", "display_name": "Recraft Replace Background", "description": "Replace background on image, based on provided prompt.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftCrispUpscaleNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RecraftCrispUpscaleNode", "display_name": "Recraft Crisp Upscale Image", "description": "Upscale image synchronously.\nEnhances a given raster image using \u2018crisp upscale\u2019 tool, increasing image resolution, making the image sharper and cleaner.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftCreativeUpscaleNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RecraftCreativeUpscaleNode", "display_name": "Recraft Creative Upscale Image", "description": "Upscale image synchronously.\nEnhances a given raster image using \u2018creative upscale\u2019 tool, boosting resolution with a focus on refining small details and faces.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "api_node": true}, "RecraftStyleV3RealisticImage": {"input": {"required": {"substyle": [["None", "b_and_w", "enterprise", "evening_light", "faded_nostalgia", "forest_life", "hard_flash", "hdr", "motion_blur", "mystic_naturalism", "natural_light", "natural_tones", "organic_calm", "real_life_glow", "retro_realism", "retro_snapshot", "studio_portrait", "urban_drama", "village_realism", "warm_folk"]]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "name": "RecraftStyleV3RealisticImage", "display_name": "Recraft Style - Realistic Image", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false}, "RecraftStyleV3DigitalIllustration": {"input": {"required": {"substyle": [["None", "2d_art_poster", "2d_art_poster_2", "antiquarian", "bold_fantasy", "child_book", "child_books", "cover", "crosshatch", "digital_engraving", "engraving_color", "expressionism", "freehand_details", "grain", "grain_20", "graphic_intensity", "hand_drawn", "hand_drawn_outline", "handmade_3d", "hard_comics", "infantile_sketch", "long_shadow", "modern_folk", "multicolor", "neon_calm", "noir", "nostalgic_pastel", "outline_details", "pastel_gradient", "pastel_sketch", "pixel_art", "plastic", "pop_art", "pop_renaissance", "seamless", "street_art", "tablet_sketch", "urban_glow", "urban_sketching", "vanilla_dreams", "young_adult_book", "young_adult_book_2"]]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "name": "RecraftStyleV3DigitalIllustration", "display_name": "Recraft Style - Digital Illustration", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false}, "RecraftStyleV3LogoRaster": {"input": {"required": {"substyle": [["emblem_graffiti", "emblem_pop_art", "emblem_punk", "emblem_stamp", "emblem_vintage"]]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "name": "RecraftStyleV3LogoRaster", "display_name": "Recraft Style - Logo Raster", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false}, "RecraftStyleV3InfiniteStyleLibrary": {"input": {"required": {"style_id": ["STRING", {"default": "", "tooltip": "UUID of style from Infinite Style Library."}]}}, "input_order": {"required": ["style_id"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "name": "RecraftStyleV3InfiniteStyleLibrary", "display_name": "Recraft Style - Infinite Style Library", "description": "Select style based on preexisting UUID from Recraft's Infinite Style Library.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false}, "RecraftColorRGB": {"input": {"required": {"r": ["INT", {"default": 0, "min": 0, "max": 255, "tooltip": "Red value of color."}], "g": ["INT", {"default": 0, "min": 0, "max": 255, "tooltip": "Green value of color."}], "b": ["INT", {"default": 0, "min": 0, "max": 255, "tooltip": "Blue value of color."}]}, "optional": {"recraft_color": ["RECRAFT_COLOR"]}}, "input_order": {"required": ["r", "g", "b"], "optional": ["recraft_color"]}, "output": ["RECRAFT_COLOR"], "output_is_list": [false], "output_name": ["recraft_color"], "name": "RecraftColorRGB", "display_name": "Recraft Color RGB", "description": "Create Recraft Color by choosing specific RGB values.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false}, "RecraftControls": {"input": {"required": {}, "optional": {"colors": ["RECRAFT_COLOR"], "background_color": ["RECRAFT_COLOR"]}}, "input_order": {"required": [], "optional": ["colors", "background_color"]}, "output": ["RECRAFT_CONTROLS"], "output_is_list": [false], "output_name": ["recraft_controls"], "name": "RecraftControls", "display_name": "Recraft Controls", "description": "Create Recraft Controls for customizing Recraft generation.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false}, "PixverseTextToVideoNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the video generation"}], "aspect_ratio": [["16:9", "4:3", "1:1", "3:4", "9:16"]], "quality": [["360p", "540p", "720p", "1080p"], {"default": "540p"}], "duration_seconds": [[5, 8]], "motion_mode": [["normal", "fast"]], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "control_after_generate": true, "tooltip": "Seed for video generation."}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}], "pixverse_template": ["PIXVERSE_TEMPLATE", {"tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "aspect_ratio", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt", "pixverse_template"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PixverseTextToVideoNode", "display_name": "PixVerse Text to Video", "description": "Generates videos synchronously based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "api_node": true}, "PixverseImageToVideoNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the video generation"}], "quality": [["360p", "540p", "720p", "1080p"], {"default": "540p"}], "duration_seconds": [[5, 8]], "motion_mode": [["normal", "fast"]], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "control_after_generate": true, "tooltip": "Seed for video generation."}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}], "pixverse_template": ["PIXVERSE_TEMPLATE", {"tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt", "pixverse_template"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PixverseImageToVideoNode", "display_name": "PixVerse Image to Video", "description": "Generates videos synchronously based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "api_node": true}, "PixverseTransitionVideoNode": {"input": {"required": {"first_frame": ["IMAGE"], "last_frame": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Prompt for the video generation"}], "quality": [["360p", "540p", "720p", "1080p"], {"default": "540p"}], "duration_seconds": [[5, 8]], "motion_mode": [["normal", "fast"]], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "control_after_generate": true, "tooltip": "Seed for video generation."}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "An optional text description of undesired elements on an image."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["first_frame", "last_frame", "prompt", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PixverseTransitionVideoNode", "display_name": "PixVerse Transition Video", "description": "Generates videos synchronously based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "api_node": true}, "PixverseTemplateNode": {"input": {"required": {"template": [["Microwave", "Suit Swagger", "Anything, Robot", "Subject 3 Fever", "kiss kiss"]]}}, "input_order": {"required": ["template"]}, "output": ["PIXVERSE_TEMPLATE"], "output_is_list": [false], "output_name": ["pixverse_template"], "name": "PixverseTemplateNode", "display_name": "PixVerse Template", "description": "", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false}, "StabilityStableImageUltraNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly definesWhat you wish to see in the output image. A strong, descriptive prompt that clearly defineselements, colors, and subjects will lead to better results. To control the weight of a given word use the format `(word:weight)`,where `word` is the word you'd like to control the weight of and `weight`is a value between 0 and 1. For example: `The sky was a crisp (blue:0.3) and (green:0.8)`would convey a sky that was blue and green, but more green than blue."}], "aspect_ratio": [["1:1", "16:9", "9:16", "3:2", "2:3", "5:4", "4:5", "21:9", "9:21"], {"default": "1:1", "tooltip": "Aspect ratio of generated image."}], "style_preset": [["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"], {"tooltip": "Optional desired style of generated image."}], "seed": ["INT", {"default": 0, "min": 0, "max": 4294967294, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {"image": ["IMAGE"], "negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "A blurb of text describing what you do not wish to see in the output image. This is an advanced feature."}], "image_denoise": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "aspect_ratio", "style_preset", "seed"], "optional": ["image", "negative_prompt", "image_denoise"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityStableImageUltraNode", "display_name": "Stability AI Stable Image Ultra", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "api_node": true}, "StabilityStableImageSD_3_5Node": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results."}], "model": [["sd3.5-large", "sd3.5-medium"]], "aspect_ratio": [["1:1", "16:9", "9:16", "3:2", "2:3", "5:4", "4:5", "21:9", "9:21"], {"default": "1:1", "tooltip": "Aspect ratio of generated image."}], "style_preset": [["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"], {"tooltip": "Optional desired style of generated image."}], "cfg_scale": ["FLOAT", {"default": 4.0, "min": 1.0, "max": 10.0, "step": 0.1, "tooltip": "How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt)"}], "seed": ["INT", {"default": 0, "min": 0, "max": 4294967294, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {"image": ["IMAGE"], "negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature."}], "image_denoise": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "style_preset", "cfg_scale", "seed"], "optional": ["image", "negative_prompt", "image_denoise"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityStableImageSD_3_5Node", "display_name": "Stability AI Stable Diffusion 3.5 Image", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "api_node": true}, "StabilityUpscaleConservativeNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results."}], "creativity": ["FLOAT", {"default": 0.35, "min": 0.2, "max": 0.5, "step": 0.01, "tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image."}], "seed": ["INT", {"default": 0, "min": 0, "max": 4294967294, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "creativity", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityUpscaleConservativeNode", "display_name": "Stability AI Upscale Conservative", "description": "Upscale image with minimal alterations to 4K resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "api_node": true}, "StabilityUpscaleCreativeNode": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results."}], "creativity": ["FLOAT", {"default": 0.3, "min": 0.1, "max": 0.5, "step": 0.01, "tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image."}], "style_preset": [["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"], {"tooltip": "Optional desired style of generated image."}], "seed": ["INT", {"default": 0, "min": 0, "max": 4294967294, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "forceInput": true, "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt", "creativity", "style_preset", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityUpscaleCreativeNode", "display_name": "Stability AI Upscale Creative", "description": "Upscale image with minimal alterations to 4K resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "api_node": true}, "StabilityUpscaleFastNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image"], "optional": [], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityUpscaleFastNode", "display_name": "Stability AI Upscale Fast", "description": "Quickly upscales an image via Stability API call to 4x its original size; intended for upscaling low-quality/compressed images.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "api_node": true}, "PikaImageToVideoNode2_2": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The image to convert to video"}], "prompt_text": ["STRING", {"default": null, "multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"options": ["1080p", "720p"], "default": "1080p"}], "duration": ["COMBO", {"options": [5, 10], "default": 5}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "prompt_text", "negative_prompt", "seed", "resolution", "duration"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PikaImageToVideoNode2_2", "display_name": "Pika Image to Video", "description": "Sends an image and prompt to the Pika API v2.2 to generate a video.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "PikaTextToVideoNode2_2": {"input": {"required": {"prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"options": ["1080p", "720p"], "default": "1080p"}], "duration": ["COMBO", {"options": [5, 10], "default": 5}], "aspect_ratio": ["FLOAT", {"default": 1.7777777777777777, "tooltip": "Aspect ratio (width / height)", "min": 0.4, "max": 2.5, "step": 0.001}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt_text", "negative_prompt", "seed", "resolution", "duration", "aspect_ratio"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PikaTextToVideoNode2_2", "display_name": "Pika Text to Video", "description": "Sends a text prompt to the Pika API v2.2 to generate a video.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "PikaScenesV2_2": {"input": {"required": {"prompt_text": ["STRING", {"default": null, "multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"options": ["1080p", "720p"], "default": "1080p"}], "duration": ["COMBO", {"options": [5, 10], "default": 5}], "ingredients_mode": ["COMBO", {"options": ["creative", "precise"], "default": "creative"}], "aspect_ratio": ["FLOAT", {"default": 1.7777777777777777, "tooltip": "Aspect ratio (width / height)", "step": 0.001, "min": 0.4, "max": 2.5}]}, "optional": {"image_ingredient_1": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_2": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_3": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_4": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_5": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["prompt_text", "negative_prompt", "seed", "resolution", "duration", "ingredients_mode", "aspect_ratio"], "optional": ["image_ingredient_1", "image_ingredient_2", "image_ingredient_3", "image_ingredient_4", "image_ingredient_5"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PikaScenesV2_2", "display_name": "Pika Scenes (Video Image Composition)", "description": "Combine your images to create a video with the objects in them. Upload multiple images as ingredients and generate a high-quality video that incorporates all of them.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "Pikadditions": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to add an image to."}], "image": ["IMAGE", {"tooltip": "The image to add to the video."}], "prompt_text": ["STRING", {"default": null, "multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["video", "image", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "Pikadditions", "display_name": "Pikadditions (Video Object Insertion)", "description": "Add any object or image into your video. Upload a video and specify what you\u2019d like to add to create a seamlessly integrated result.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "Pikaswaps": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to swap an object in."}], "image": ["IMAGE", {"tooltip": "The image used to replace the masked object in the video."}], "mask": ["MASK", {"tooltip": "Use the mask to define areas in the video to replace"}], "prompt_text": ["STRING", {"default": null, "multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["video", "image", "mask", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "Pikaswaps", "display_name": "Pika Swaps (Video Object Replacement)", "description": "Swap out any object or region of your video with a new image or object. Define areas to replace either with a mask or coordinates.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "Pikaffects": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The reference image to apply the Pikaffect to."}], "pikaffect": ["COMBO", {"options": ["Cake-ify", "Crumble", "Crush", "Decapitate", "Deflate", "Dissolve", "Explode", "Eye-pop", "Inflate", "Levitate", "Melt", "Peel", "Poke", "Squish", "Ta-da", "Tear"], "default": "Cake-ify"}], "prompt_text": ["STRING", {"default": null, "multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image", "pikaffect", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "Pikaffects", "display_name": "Pikaffects (Video Effects)", "description": "Generate a video with a specific Pikaffect. Supported Pikaffects: Cake-ify, Crumble, Crush, Decapitate, Deflate, Dissolve, Explode, Eye-pop, Inflate, Levitate, Melt, Peel, Poke, Squish, Ta-da, Tear", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "PikaStartEndFrameNode2_2": {"input": {"required": {"image_start": ["IMAGE", {"tooltip": "The first image to combine."}], "image_end": ["IMAGE", {"tooltip": "The last image to combine."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"default": null, "multiline": true}], "seed": ["INT", {"default": null, "min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"options": ["1080p", "720p"], "default": "1080p"}], "duration": ["COMBO", {"options": [5, 10], "default": null}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG"}}, "input_order": {"required": ["image_start", "image_end", "prompt_text", "negative_prompt", "seed", "resolution", "duration"], "hidden": ["auth_token", "comfy_api_key"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "name": "PikaStartEndFrameNode2_2", "display_name": "Pika Start and End Frame to Video", "description": "Generate a video by combining your first and last frame. Upload two images to define the start and end points, and let the AI create a smooth transition between them.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "api_node": true}, "FluxLoraLoader": {"input": {"required": {"model": ["MODEL"], "lora_name": [[]], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "lora_name", "strength_model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FluxLoraLoader", "display_name": "Load Flux LoRA", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "LoadFluxControlNet": {"input": {"required": {"model_name": [["flux-dev", "flux-dev-fp8", "flux-schnell"]], "controlnet_path": [["flux-depth-controlnet-v3.safetensors"]]}}, "input_order": {"required": ["model_name", "controlnet_path"]}, "output": ["FluxControlNet"], "output_is_list": [false], "output_name": ["ControlNet"], "name": "LoadFluxControlNet", "display_name": "Load Flux ControlNet", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "ApplyFluxControlNet": {"input": {"required": {"controlnet": ["FluxControlNet"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}, "optional": {"controlnet_condition": ["ControlNetCondition", {"default": null}]}}, "input_order": {"required": ["controlnet", "image", "strength"], "optional": ["controlnet_condition"]}, "output": ["ControlNetCondition"], "output_is_list": [false], "output_name": ["controlnet_condition"], "name": "ApplyFluxControlNet", "display_name": "Apply Flux ControlNet", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "ApplyAdvancedFluxControlNet": {"input": {"required": {"controlnet": ["FluxControlNet"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"controlnet_condition": ["ControlNetCondition", {"default": null}]}}, "input_order": {"required": ["controlnet", "image", "strength", "start", "end"], "optional": ["controlnet_condition"]}, "output": ["ControlNetCondition"], "output_is_list": [false], "output_name": ["controlnet_condition"], "name": "ApplyAdvancedFluxControlNet", "display_name": "Apply Advanced Flux ControlNet", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "XlabsSampler": {"input": {"required": {"model": ["MODEL"], "conditioning": ["CONDITIONING"], "neg_conditioning": ["CONDITIONING"], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 100}], "timestep_to_start_cfg": ["INT", {"default": 20, "min": 0, "max": 100}], "true_gs": ["FLOAT", {"default": 3, "min": 0, "max": 100}], "image_to_image_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "denoise_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"latent_image": ["LATENT", {"default": null}], "controlnet_condition": ["ControlNetCondition", {"default": null}]}}, "input_order": {"required": ["model", "conditioning", "neg_conditioning", "noise_seed", "steps", "timestep_to_start_cfg", "true_gs", "image_to_image_strength", "denoise_strength"], "optional": ["latent_image", "controlnet_condition"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["latent"], "name": "XlabsSampler", "display_name": "Xlabs Sampler", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "ApplyFluxIPAdapter": {"input": {"required": {"model": ["MODEL"], "ip_adapter_flux": ["IP_ADAPTER_FLUX"], "image": ["IMAGE"], "ip_scale": ["FLOAT", {"default": 0.93, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "ip_adapter_flux", "image", "ip_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyFluxIPAdapter", "display_name": "Apply Flux IPAdapter", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "LoadFluxIPAdapter": {"input": {"required": {"ipadatper": [[]], "clip_vision": [["CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors", "CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors", "SD1.5/pytorch_model.bin", "clip_vision_g.safetensors", "sdxl_clip.safetensors", "sigclip_vision_patch14_384_F1.safetensors"]], "provider": [["CPU", "GPU"]]}}, "input_order": {"required": ["ipadatper", "clip_vision", "provider"]}, "output": ["IP_ADAPTER_FLUX"], "output_is_list": [false], "output_name": ["ipadapterFlux"], "name": "LoadFluxIPAdapter", "display_name": "Load Flux IPAdatpter", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "ApplyAdvancedFluxIPAdapter": {"input": {"required": {"model": ["MODEL"], "ip_adapter_flux": ["IP_ADAPTER_FLUX"], "image": ["IMAGE"], "begin_strength": ["FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 0.01}], "end_strength": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "smothing_type": [["Linear", "First half", "Second half", "Sigmoid"]]}}, "input_order": {"required": ["model", "ip_adapter_flux", "image", "begin_strength", "end_strength", "smothing_type"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyAdvancedFluxIPAdapter", "display_name": "Apply Advanced Flux IPAdapter", "description": "", "python_module": "custom_nodes.x-flux-comfyui", "category": "XLabsNodes", "output_node": false}, "BLIP Model Loader": {"input": {"required": {"blip_model": ["STRING", {"default": "Salesforce/blip-image-captioning-base"}], "vqa_model_id": ["STRING", {"default": "Salesforce/blip-vqa-base"}], "device": [["cuda", "cpu"]]}}, "input_order": {"required": ["blip_model", "vqa_model_id", "device"]}, "output": ["BLIP_MODEL"], "output_is_list": [false], "output_name": ["BLIP_MODEL"], "name": "BLIP Model Loader", "display_name": "BLIP Model Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "Blend Latents": {"input": {"required": {"latent_a": ["LATENT"], "latent_b": ["LATENT"], "operation": [["add", "multiply", "divide", "subtract", "overlay", "hard_light", "soft_light", "screen", "linear_dodge", "difference", "exclusion", "random"]], "blend": ["FLOAT", {"default": 0.5, "min": 0.01, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["latent_a", "latent_b", "operation", "blend"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "Blend Latents", "display_name": "Blend Latents", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Latent", "output_node": false}, "Bus Node": {"input": {"required": {}, "optional": {"bus": ["BUS"], "model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"]}}, "input_order": {"required": [], "optional": ["bus", "model", "clip", "vae", "positive", "negative"]}, "output": ["BUS", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING"], "output_is_list": [false, false, false, false, false, false], "output_name": ["bus", "model", "clip", "vae", "positive", "negative"], "name": "Bus Node", "display_name": "Bus Node", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Utilities", "output_node": false}, "Cache Node": {"input": {"required": {"latent_suffix": ["STRING", {"default": "21268508_cache", "multiline": false}], "image_suffix": ["STRING", {"default": "30971509_cache", "multiline": false}], "conditioning_suffix": ["STRING", {"default": "25128061_cache", "multiline": false}]}, "optional": {"output_path": ["STRING", {"default": "/ComfyUI/custom_nodes/was-node-suite-comfyui/cache", "multiline": false}], "latent": ["LATENT"], "image": ["IMAGE"], "conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["latent_suffix", "image_suffix", "conditioning_suffix"], "optional": ["output_path", "latent", "image", "conditioning"]}, "output": ["STRING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["latent_filename", "image_filename", "conditioning_filename"], "name": "Cache Node", "display_name": "Cache Node", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": true}, "Checkpoint Loader": {"input": {"required": {"config_name": [["anything_v3.yaml", "v1-inference.yaml", "v1-inference_clip_skip_2.yaml", "v1-inference_clip_skip_2_fp16.yaml", "v1-inference_fp16.yaml", "v1-inpainting-inference.yaml", "v2-inference-v.yaml", "v2-inference-v_fp32.yaml", "v2-inference.yaml", "v2-inference_fp32.yaml", "v2-inpainting-inference.yaml"]], "ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["config_name", "ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "NAME_STRING"], "name": "Checkpoint Loader", "display_name": "Checkpoint Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders/Advanced", "output_node": false}, "Checkpoint Loader (Simple)": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "NAME_STRING"], "name": "Checkpoint Loader (Simple)", "display_name": "Checkpoint Loader (Simple)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "CLIPTextEncode (NSP)": {"input": {"required": {"mode": [["Noodle Soup Prompts", "Wildcards"]], "noodle_key": ["STRING", {"default": "__", "multiline": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "text": ["STRING", {"multiline": true}], "clip": ["CLIP"]}}, "input_order": {"required": ["mode", "noodle_key", "seed", "text", "clip"]}, "output": ["CONDITIONING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["conditioning", "parsed_text", "raw_text"], "name": "CLIPTextEncode (NSP)", "display_name": "CLIPTextEncode (NSP)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Conditioning", "output_node": true}, "CLIP Input Switch": {"input": {"required": {"clip_a": ["CLIP"], "clip_b": ["CLIP"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["clip_a", "clip_b", "boolean"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIP Input Switch", "display_name": "CLIP Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "CLIP Vision Input Switch": {"input": {"required": {"clip_vision_a": ["CLIP_VISION"], "clip_vision_b": ["CLIP_VISION"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["clip_vision_a", "clip_vision_b", "boolean"]}, "output": ["CLIP_VISION"], "output_is_list": [false], "output_name": ["CLIP_VISION"], "name": "CLIP Vision Input Switch", "display_name": "CLIP Vision Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Conditioning Input Switch": {"input": {"required": {"conditioning_a": ["CONDITIONING"], "conditioning_b": ["CONDITIONING"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["conditioning_a", "conditioning_b", "boolean"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "Conditioning Input Switch", "display_name": "Conditioning Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Constant Number": {"input": {"required": {"number_type": [["integer", "float", "bool"]], "number": ["FLOAT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.01}]}, "optional": {"number_as_text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["number_type", "number"], "optional": ["number_as_text"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "Constant Number", "display_name": "Constant Number", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number", "output_node": false}, "Create Grid Image": {"input": {"required": {"images_path": ["STRING", {"default": "./ComfyUI/input/", "multiline": false}], "pattern_glob": ["STRING", {"default": "*", "multiline": false}], "include_subfolders": [["false", "true"]], "border_width": ["INT", {"default": 3, "min": 0, "max": 100, "step": 1}], "number_of_columns": ["INT", {"default": 6, "min": 1, "max": 24, "step": 1}], "max_cell_size": ["INT", {"default": 256, "min": 32, "max": 1280, "step": 1}], "border_red": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "border_green": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "border_blue": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["images_path", "pattern_glob", "include_subfolders", "border_width", "number_of_columns", "max_cell_size", "border_red", "border_green", "border_blue"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Create Grid Image", "display_name": "Create Grid Image", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Create Grid Image from Batch": {"input": {"required": {"images": ["IMAGE"], "border_width": ["INT", {"default": 3, "min": 0, "max": 100, "step": 1}], "number_of_columns": ["INT", {"default": 6, "min": 1, "max": 24, "step": 1}], "max_cell_size": ["INT", {"default": 256, "min": 32, "max": 2048, "step": 1}], "border_red": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "border_green": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "border_blue": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["images", "border_width", "number_of_columns", "max_cell_size", "border_red", "border_green", "border_blue"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Create Grid Image from Batch", "display_name": "Create Grid Image from Batch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Create Morph Image": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "transition_frames": ["INT", {"default": 30, "min": 2, "max": 60, "step": 1}], "still_image_delay_ms": ["FLOAT", {"default": 2500.0, "min": 0.1, "max": 60000.0, "step": 0.1}], "duration_ms": ["FLOAT", {"default": 0.1, "min": 0.1, "max": 60000.0, "step": 0.1}], "loops": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "max_size": ["INT", {"default": 512, "min": 128, "max": 1280, "step": 1}], "output_path": ["STRING", {"default": "./ComfyUI/output", "multiline": false}], "filename": ["STRING", {"default": "morph", "multiline": false}], "filetype": [["GIF", "APNG"]]}}, "input_order": {"required": ["image_a", "image_b", "transition_frames", "still_image_delay_ms", "duration_ms", "loops", "max_size", "output_path", "filename", "filetype"]}, "output": ["IMAGE", "IMAGE", "STRING", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["image_a_pass", "image_b_pass", "filepath_text", "filename_text"], "name": "Create Morph Image", "display_name": "Create Morph Image", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Animation", "output_node": false}, "Create Morph Image from Path": {"input": {"required": {"transition_frames": ["INT", {"default": 30, "min": 2, "max": 60, "step": 1}], "still_image_delay_ms": ["FLOAT", {"default": 2500.0, "min": 0.1, "max": 60000.0, "step": 0.1}], "duration_ms": ["FLOAT", {"default": 0.1, "min": 0.1, "max": 60000.0, "step": 0.1}], "loops": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "max_size": ["INT", {"default": 512, "min": 128, "max": 1280, "step": 1}], "input_path": ["STRING", {"default": "./ComfyUI", "multiline": false}], "input_pattern": ["STRING", {"default": "*", "multiline": false}], "output_path": ["STRING", {"default": "./ComfyUI/output", "multiline": false}], "filename": ["STRING", {"default": "morph", "multiline": false}], "filetype": [["GIF", "APNG"]]}}, "input_order": {"required": ["transition_frames", "still_image_delay_ms", "duration_ms", "loops", "max_size", "input_path", "input_pattern", "output_path", "filename", "filetype"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["filepath_text", "filename_text"], "name": "Create Morph Image from Path", "display_name": "Create Morph Image from Path", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Animation", "output_node": false}, "Create Video from Path": {"input": {"required": {"transition_frames": ["INT", {"default": 30, "min": 0, "max": 120, "step": 1}], "image_delay_sec": ["FLOAT", {"default": 2.5, "min": 0.01, "max": 60000.0, "step": 0.01}], "fps": ["INT", {"default": 30, "min": 1, "max": 60.0, "step": 1}], "max_size": ["INT", {"default": 512, "min": 128, "max": 1920, "step": 1}], "input_path": ["STRING", {"default": "./ComfyUI/input", "multiline": false}], "output_path": ["STRING", {"default": "./ComfyUI/output", "multiline": false}], "filename": ["STRING", {"default": "comfy_video", "multiline": false}], "codec": [["AVC1", "FFV1", "H264", "MP4V"]]}}, "input_order": {"required": ["transition_frames", "image_delay_sec", "fps", "max_size", "input_path", "output_path", "filename", "codec"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["filepath_text", "filename_text"], "name": "Create Video from Path", "display_name": "Create Video from Path", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Animation", "output_node": false}, "CLIPSeg Masking": {"input": {"required": {"image": ["IMAGE"], "text": ["STRING", {"default": "", "multiline": false}]}, "optional": {"clipseg_model": ["CLIPSEG_MODEL"]}}, "input_order": {"required": ["image", "text"], "optional": ["clipseg_model"]}, "output": ["MASK", "IMAGE"], "output_is_list": [false, false], "output_name": ["MASK", "MASK_IMAGE"], "name": "CLIPSeg Masking", "display_name": "CLIPSeg Masking", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "CLIPSeg Model Loader": {"input": {"required": {"model": ["STRING", {"default": "CIDAS/clipseg-rd64-refined", "multiline": false}]}}, "input_order": {"required": ["model"]}, "output": ["CLIPSEG_MODEL"], "output_is_list": [false], "output_name": ["clipseg_model"], "name": "CLIPSeg Model Loader", "display_name": "CLIPSeg Model Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "CLIPSeg Batch Masking": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "text_a": ["STRING", {"default": "", "multiline": false}], "text_b": ["STRING", {"default": "", "multiline": false}]}, "optional": {"image_c": ["IMAGE"], "image_d": ["IMAGE"], "image_e": ["IMAGE"], "image_f": ["IMAGE"], "text_c": ["STRING", {"default": "", "multiline": false}], "text_d": ["STRING", {"default": "", "multiline": false}], "text_e": ["STRING", {"default": "", "multiline": false}], "text_f": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["image_a", "image_b", "text_a", "text_b"], "optional": ["image_c", "image_d", "image_e", "image_f", "text_c", "text_d", "text_e", "text_f"]}, "output": ["IMAGE", "MASK", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["IMAGES_BATCH", "MASKS_BATCH", "MASK_IMAGES_BATCH"], "name": "CLIPSeg Batch Masking", "display_name": "CLIPSeg Batch Masking", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Convert Masks to Images": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGES"], "name": "Convert Masks to Images", "display_name": "Convert Masks to Images", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Control Net Model Input Switch": {"input": {"required": {"control_net_a": ["CONTROL_NET"], "control_net_b": ["CONTROL_NET"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["control_net_a", "control_net_b", "boolean"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "Control Net Model Input Switch", "display_name": "Control Net Model Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Debug Number to Console": {"input": {"required": {"number": ["NUMBER"], "label": ["STRING", {"default": "Debug to Console", "multiline": false}]}}, "input_order": {"required": ["number", "label"]}, "output": ["NUMBER"], "output_is_list": [false], "output_name": ["NUMBER"], "name": "Debug Number to Console", "display_name": "Debug Number to Console", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Debug", "output_node": true}, "Dictionary to Console": {"input": {"required": {"dictionary": ["DICT"], "label": ["STRING", {"default": "Dictionary Output", "multiline": false}]}}, "input_order": {"required": ["dictionary", "label"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "Dictionary to Console", "display_name": "Dictionary to Console", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Debug", "output_node": true}, "Diffusers Model Loader": {"input": {"required": {"model_path": [[]]}}, "input_order": {"required": ["model_path"]}, "output": ["MODEL", "CLIP", "VAE", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "NAME_STRING"], "name": "Diffusers Model Loader", "display_name": "Diffusers Model Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders/Advanced", "output_node": false}, "Diffusers Hub Model Down-Loader": {"input": {"required": {"repo_id": ["STRING", {"multiline": false}], "revision": ["STRING", {"default": "None", "multiline": false}]}}, "input_order": {"required": ["repo_id", "revision"]}, "output": ["MODEL", "CLIP", "VAE", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "NAME_STRING"], "name": "Diffusers Hub Model Down-Loader", "display_name": "Diffusers Hub Model Down-Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders/Advanced", "output_node": false}, "Export API": {"input": {"required": {"save_prompt_api": [["true", "true"]], "output_path": ["STRING", {"default": "./ComfyUI/output/", "multiline": false}], "filename_prefix": ["STRING", {"default": "ComfyUI_Prompt"}], "filename_delimiter": ["STRING", {"default": "_"}], "filename_number_padding": ["INT", {"default": 4, "min": 2, "max": 9, "step": 1}], "parse_text_tokens": ["BOOLEAN", {"default": false}]}, "hidden": {"prompt": "PROMPT"}}, "input_order": {"required": ["save_prompt_api", "output_path", "filename_prefix", "filename_delimiter", "filename_number_padding", "parse_text_tokens"], "hidden": ["prompt"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Export API", "display_name": "Export API", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Debug", "output_node": true}, "Latent Input Switch": {"input": {"required": {"latent_a": ["LATENT"], "latent_b": ["LATENT"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["latent_a", "latent_b", "boolean"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "Latent Input Switch", "display_name": "Latent Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Load Cache": {"input": {"required": {"latent_path": ["STRING", {"default": "", "multiline": false}], "image_path": ["STRING", {"default": "", "multiline": false}], "conditioning_path": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["latent_path", "image_path", "conditioning_path"]}, "output": ["LATENT", "IMAGE", "CONDITIONING"], "output_is_list": [false, false, false], "output_name": ["LATENT", "IMAGE", "CONDITIONING"], "name": "Load Cache", "display_name": "Load Cache", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": false}, "Logic Boolean": {"input": {"required": {"boolean": ["FLOAT", {"default": 1, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["boolean"]}, "output": ["BOOLEAN", "NUMBER", "INT", "FLOAT"], "output_is_list": [false, false, false, false], "output_name": ["BOOLEAN", "NUMBER", "INT", "FLOAT"], "name": "Logic Boolean", "display_name": "Logic Boolean", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Logic Boolean Primitive": {"input": {"required": {"boolean": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["boolean"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "Logic Boolean Primitive", "display_name": "Logic Boolean Primitive", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Logic Comparison OR": {"input": {"required": {"boolean_a": ["BOOLEAN", {"default": false}], "boolean_b": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["boolean_a", "boolean_b"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "Logic Comparison OR", "display_name": "Logic Comparison OR", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Logic Comparison AND": {"input": {"required": {"boolean_a": ["BOOLEAN", {"default": false}], "boolean_b": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["boolean_a", "boolean_b"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "Logic Comparison AND", "display_name": "Logic Comparison AND", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Logic Comparison XOR": {"input": {"required": {"boolean_a": ["BOOLEAN", {"default": false}], "boolean_b": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["boolean_a", "boolean_b"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "Logic Comparison XOR", "display_name": "Logic Comparison XOR", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Logic NOT": {"input": {"required": {"boolean": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["boolean"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "Logic NOT", "display_name": "Logic NOT", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Lora Loader": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_name": [["None", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"]}, "output": ["MODEL", "CLIP", "STRING"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "NAME_STRING"], "name": "Lora Loader", "display_name": "Lora Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "Hex to HSL": {"input": {"required": {"hex_color": ["STRING", {"default": "#FF0000"}]}, "optional": {"include_alpha": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["hex_color"], "optional": ["include_alpha"]}, "output": ["INT", "INT", "INT", "FLOAT", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["hue", "saturation", "lightness", "alpha", "hsl"], "name": "Hex to HSL", "display_name": "Hex to HSL", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Utilities", "output_node": false}, "HSL to Hex": {"input": {"required": {"hsl_color": ["STRING", {"default": "hsl(0, 100%, 50%)"}]}}, "input_order": {"required": ["hsl_color"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["hex_color"], "name": "HSL to Hex", "display_name": "HSL to Hex", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Utilities", "output_node": false}, "Image SSAO (Ambient Occlusion)": {"input": {"required": {"images": ["IMAGE"], "depth_images": ["IMAGE"], "strength": ["FLOAT", {"min": 0.0, "max": 5.0, "default": 1.0, "step": 0.01}], "radius": ["FLOAT", {"min": 0.01, "max": 1024, "default": 30, "step": 0.01}], "ao_blur": ["FLOAT", {"min": 0.01, "max": 1024, "default": 2.5, "step": 0.01}], "specular_threshold": ["INT", {"min": 0, "max": 255, "default": 25, "step": 1}], "enable_specular_masking": [["True", "False"]], "tile_size": ["INT", {"min": 1, "max": 512, "default": 1, "step": 1}]}}, "input_order": {"required": ["images", "depth_images", "strength", "radius", "ao_blur", "specular_threshold", "enable_specular_masking", "tile_size"]}, "output": ["IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["composited_images", "ssao_images", "specular_mask_images"], "name": "Image SSAO (Ambient Occlusion)", "display_name": "Image SSAO (Ambient Occlusion)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image SSDO (Direct Occlusion)": {"input": {"required": {"images": ["IMAGE"], "depth_images": ["IMAGE"], "strength": ["FLOAT", {"min": 0.0, "max": 5.0, "default": 1.0, "step": 0.01}], "radius": ["FLOAT", {"min": 0.01, "max": 1024, "default": 30, "step": 0.01}], "specular_threshold": ["INT", {"min": 0, "max": 255, "default": 128, "step": 1}], "colored_occlusion": [["True", "False"]]}}, "input_order": {"required": ["images", "depth_images", "strength", "radius", "specular_threshold", "colored_occlusion"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false, false], "output_name": ["composited_images", "ssdo_images", "ssdo_image_masks", "light_source_image_masks"], "name": "Image SSDO (Direct Occlusion)", "display_name": "Image SSDO (Direct Occlusion)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Analyze": {"input": {"required": {"image": ["IMAGE"], "mode": [["Black White Levels", "RGB Levels"]]}}, "input_order": {"required": ["image", "mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Analyze", "display_name": "Image Analyze", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Analyze", "output_node": false}, "Image Aspect Ratio": {"input": {"required": {}, "optional": {"image": ["IMAGE"], "width": ["NUMBER"], "height": ["NUMBER"]}}, "input_order": {"required": [], "optional": ["image", "width", "height"]}, "output": ["NUMBER", "FLOAT", "NUMBER", "STRING", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["aspect_number", "aspect_float", "is_landscape_bool", "aspect_ratio_common", "aspect_type"], "name": "Image Aspect Ratio", "display_name": "Image Aspect Ratio", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Image Batch": {"input": {"required": {}, "optional": {"images_a": ["IMAGE"], "images_b": ["IMAGE"], "images_c": ["IMAGE"], "images_d": ["IMAGE"]}}, "input_order": {"required": [], "optional": ["images_a", "images_b", "images_c", "images_d"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Batch", "display_name": "Image Batch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Image Blank": {"input": {"required": {"width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 1}], "red": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "green": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "blue": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["width", "height", "red", "green", "blue"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Blank", "display_name": "Image Blank", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Image Blend by Mask": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "mask": ["IMAGE"], "blend_percentage": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image_a", "image_b", "mask", "blend_percentage"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Blend by Mask", "display_name": "Image Blend by Mask", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Image Blend": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "blend_percentage": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image_a", "image_b", "blend_percentage"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Blend", "display_name": "Image Blend", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Image Blending Mode": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "mode": [["add", "color", "color_burn", "color_dodge", "darken", "difference", "exclusion", "hard_light", "hue", "lighten", "multiply", "overlay", "screen", "soft_light"]], "blend_percentage": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image_a", "image_b", "mode", "blend_percentage"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Blending Mode", "display_name": "Image Blending Mode", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Image Bloom Filter": {"input": {"required": {"image": ["IMAGE"], "radius": ["FLOAT", {"default": 10, "min": 0.0, "max": 1024, "step": 0.1}], "intensity": ["FLOAT", {"default": 1, "min": 0.0, "max": 1.0, "step": 0.1}]}}, "input_order": {"required": ["image", "radius", "intensity"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Bloom Filter", "display_name": "Image Bloom Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Canny Filter": {"input": {"required": {"images": ["IMAGE"], "enable_threshold": [["false", "true"]], "threshold_low": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "threshold_high": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["images", "enable_threshold", "threshold_low", "threshold_high"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Canny Filter", "display_name": "Image Canny Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Chromatic Aberration": {"input": {"required": {"image": ["IMAGE"], "red_offset": ["INT", {"default": 2, "min": -255, "max": 255, "step": 1}], "green_offset": ["INT", {"default": -1, "min": -255, "max": 255, "step": 1}], "blue_offset": ["INT", {"default": 1, "min": -255, "max": 255, "step": 1}], "intensity": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "fade_radius": ["INT", {"default": 12, "min": 0, "max": 1024, "step": 1}]}}, "input_order": {"required": ["image", "red_offset", "green_offset", "blue_offset", "intensity", "fade_radius"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Chromatic Aberration", "display_name": "Image Chromatic Aberration", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Color Palette": {"input": {"required": {"image": ["IMAGE"], "colors": ["INT", {"default": 16, "min": 8, "max": 256, "step": 1}], "mode": [["Chart", "back_to_back"]]}}, "input_order": {"required": ["image", "colors", "mode"]}, "output": ["IMAGE", "LIST"], "output_is_list": [false, false], "output_name": ["image", "color_palettes"], "name": "Image Color Palette", "display_name": "Image Color Palette", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Analyze", "output_node": false}, "Image Crop Face": {"input": {"required": {"image": ["IMAGE"], "crop_padding_factor": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 2.0, "step": 0.01}], "cascade_xml": [["lbpcascade_animeface.xml", "haarcascade_frontalface_default.xml", "haarcascade_frontalface_alt.xml", "haarcascade_frontalface_alt2.xml", "haarcascade_frontalface_alt_tree.xml", "haarcascade_profileface.xml", "haarcascade_upperbody.xml", "haarcascade_eye.xml"]]}}, "input_order": {"required": ["image", "crop_padding_factor", "cascade_xml"]}, "output": ["IMAGE", "CROP_DATA"], "output_is_list": [false, false], "output_name": ["IMAGE", "CROP_DATA"], "name": "Image Crop Face", "display_name": "Image Crop Face", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Crop Location": {"input": {"required": {"image": ["IMAGE"], "top": ["INT", {"default": 0, "max": 10000000, "min": 0, "step": 1}], "left": ["INT", {"default": 0, "max": 10000000, "min": 0, "step": 1}], "right": ["INT", {"default": 256, "max": 10000000, "min": 0, "step": 1}], "bottom": ["INT", {"default": 256, "max": 10000000, "min": 0, "step": 1}]}}, "input_order": {"required": ["image", "top", "left", "right", "bottom"]}, "output": ["IMAGE", "CROP_DATA"], "output_is_list": [false, false], "output_name": ["IMAGE", "CROP_DATA"], "name": "Image Crop Location", "display_name": "Image Crop Location", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Crop Square Location": {"input": {"required": {"image": ["IMAGE"], "x": ["INT", {"default": 0, "max": 24576, "min": 0, "step": 1}], "y": ["INT", {"default": 0, "max": 24576, "min": 0, "step": 1}], "size": ["INT", {"default": 256, "max": 4096, "min": 5, "step": 1}]}}, "input_order": {"required": ["image", "x", "y", "size"]}, "output": ["IMAGE", "CROP_DATA"], "output_is_list": [false, false], "output_name": ["IMAGE", "CROP_DATA"], "name": "Image Crop Square Location", "display_name": "Image Crop Square Location", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Displacement Warp": {"input": {"required": {"images": ["IMAGE"], "displacement_maps": ["IMAGE"], "amplitude": ["FLOAT", {"default": 25.0, "min": -4096, "max": 4096, "step": 0.1}]}}, "input_order": {"required": ["images", "displacement_maps", "amplitude"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Displacement Warp", "display_name": "Image Displacement Warp", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image Lucy Sharpen": {"input": {"required": {"images": ["IMAGE"], "iterations": ["INT", {"default": 2, "min": 1, "max": 12, "step": 1}], "kernel_size": ["INT", {"default": 3, "min": 1, "max": 16, "step": 1}]}}, "input_order": {"required": ["images", "iterations", "kernel_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Lucy Sharpen", "display_name": "Image Lucy Sharpen", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Paste Face": {"input": {"required": {"image": ["IMAGE"], "crop_image": ["IMAGE"], "crop_data": ["CROP_DATA"], "crop_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_sharpening": ["INT", {"default": 0, "min": 0, "max": 3, "step": 1}]}}, "input_order": {"required": ["image", "crop_image", "crop_data", "crop_blending", "crop_sharpening"]}, "output": ["IMAGE", "IMAGE"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK_IMAGE"], "name": "Image Paste Face", "display_name": "Image Paste Face", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Paste Crop": {"input": {"required": {"image": ["IMAGE"], "crop_image": ["IMAGE"], "crop_data": ["CROP_DATA"], "crop_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_sharpening": ["INT", {"default": 0, "min": 0, "max": 3, "step": 1}]}}, "input_order": {"required": ["image", "crop_image", "crop_data", "crop_blending", "crop_sharpening"]}, "output": ["IMAGE", "IMAGE"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "Image Paste Crop", "display_name": "Image Paste Crop", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Paste Crop by Location": {"input": {"required": {"image": ["IMAGE"], "crop_image": ["IMAGE"], "top": ["INT", {"default": 0, "max": 10000000, "min": 0, "step": 1}], "left": ["INT", {"default": 0, "max": 10000000, "min": 0, "step": 1}], "right": ["INT", {"default": 256, "max": 10000000, "min": 0, "step": 1}], "bottom": ["INT", {"default": 256, "max": 10000000, "min": 0, "step": 1}], "crop_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_sharpening": ["INT", {"default": 0, "min": 0, "max": 3, "step": 1}]}}, "input_order": {"required": ["image", "crop_image", "top", "left", "right", "bottom", "crop_blending", "crop_sharpening"]}, "output": ["IMAGE", "IMAGE"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "Image Paste Crop by Location", "display_name": "Image Paste Crop by Location", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Pixelate": {"input": {"required": {"images": ["IMAGE"], "pixelation_size": ["FLOAT", {"default": 164, "min": 16, "max": 480, "step": 1}], "num_colors": ["FLOAT", {"default": 16, "min": 2, "max": 256, "step": 1}], "init_mode": [["k-means++", "random", "none"]], "max_iterations": ["FLOAT", {"default": 100, "min": 1, "max": 256, "step": 1}], "dither": [["False", "True"]], "dither_mode": [["FloydSteinberg", "Ordered"]]}, "optional": {"color_palettes": ["LIST", {"forceInput": true}], "color_palette_mode": [["Brightness", "BrightnessAndTonal", "Linear", "Tonal"]], "reverse_palette": [["False", "True"]]}}, "input_order": {"required": ["images", "pixelation_size", "num_colors", "init_mode", "max_iterations", "dither", "dither_mode"], "optional": ["color_palettes", "color_palette_mode", "reverse_palette"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Pixelate", "display_name": "Image Pixelate", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Power Noise": {"input": {"required": {"width": ["INT", {"default": 512, "max": 4096, "min": 64, "step": 1}], "height": ["INT", {"default": 512, "max": 4096, "min": 64, "step": 1}], "frequency": ["FLOAT", {"default": 0.5, "max": 10.0, "min": 0.0, "step": 0.01}], "attenuation": ["FLOAT", {"default": 0.5, "max": 10.0, "min": 0.0, "step": 0.01}], "noise_type": [["grey", "white", "pink", "blue", "green", "mix"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["width", "height", "frequency", "attenuation", "noise_type", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Power Noise", "display_name": "Image Power Noise", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Generate/Noise", "output_node": false}, "Image Dragan Photography Filter": {"input": {"required": {"image": ["IMAGE"], "saturation": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 16.0, "step": 0.01}], "contrast": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 16.0, "step": 0.01}], "brightness": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 16.0, "step": 0.01}], "sharpness": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 6.0, "step": 0.01}], "highpass_radius": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 255.0, "step": 0.01}], "highpass_samples": ["INT", {"default": 1, "min": 0, "max": 6.0, "step": 1}], "highpass_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 3.0, "step": 0.01}], "colorize": [["true", "false"]]}}, "input_order": {"required": ["image", "saturation", "contrast", "brightness", "sharpness", "highpass_radius", "highpass_samples", "highpass_strength", "colorize"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Dragan Photography Filter", "display_name": "Image Dragan Photography Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Edge Detection Filter": {"input": {"required": {"image": ["IMAGE"], "mode": [["normal", "laplacian"]]}}, "input_order": {"required": ["image", "mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Edge Detection Filter", "display_name": "Image Edge Detection Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Film Grain": {"input": {"required": {"image": ["IMAGE"], "density": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 1.0, "step": 0.01}], "intensity": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 1.0, "step": 0.01}], "highlights": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 255.0, "step": 0.01}], "supersample_factor": ["INT", {"default": 4, "min": 1, "max": 8, "step": 1}]}}, "input_order": {"required": ["image", "density", "intensity", "highlights", "supersample_factor"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Film Grain", "display_name": "Image Film Grain", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Filter Adjustments": {"input": {"required": {"image": ["IMAGE"], "brightness": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}], "contrast": ["FLOAT", {"default": 1.0, "min": -1.0, "max": 2.0, "step": 0.01}], "saturation": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 5.0, "step": 0.01}], "sharpness": ["FLOAT", {"default": 1.0, "min": -5.0, "max": 5.0, "step": 0.01}], "blur": ["INT", {"default": 0, "min": 0, "max": 16, "step": 1}], "gaussian_blur": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1024.0, "step": 0.1}], "edge_enhance": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "detail_enhance": [["false", "true"]]}}, "input_order": {"required": ["image", "brightness", "contrast", "saturation", "sharpness", "blur", "gaussian_blur", "edge_enhance", "detail_enhance"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Filter Adjustments", "display_name": "Image Filter Adjustments", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Flip": {"input": {"required": {"images": ["IMAGE"], "mode": [["horizontal", "vertical"]]}}, "input_order": {"required": ["images", "mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Flip", "display_name": "Image Flip", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image Gradient Map": {"input": {"required": {"image": ["IMAGE"], "gradient_image": ["IMAGE"], "flip_left_right": [["false", "true"]]}}, "input_order": {"required": ["image", "gradient_image", "flip_left_right"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Gradient Map", "display_name": "Image Gradient Map", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Generate Gradient": {"input": {"required": {"width": ["INT", {"default": 512, "max": 4096, "min": 64, "step": 1}], "height": ["INT", {"default": 512, "max": 4096, "min": 64, "step": 1}], "direction": [["horizontal", "vertical"]], "tolerance": ["INT", {"default": 0, "max": 255, "min": 0, "step": 1}], "gradient_stops": ["STRING", {"default": "0:255,0,0\n25:255,255,255\n50:0,255,0\n75:0,0,255", "multiline": true}]}}, "input_order": {"required": ["width", "height", "direction", "tolerance", "gradient_stops"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Generate Gradient", "display_name": "Image Generate Gradient", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Generate", "output_node": false}, "Image High Pass Filter": {"input": {"required": {"images": ["IMAGE"], "radius": ["INT", {"default": 10, "min": 1, "max": 500, "step": 1}], "strength": ["FLOAT", {"default": 1.5, "min": 0.0, "max": 255.0, "step": 0.1}], "color_output": [["true", "false"]], "neutral_background": [["true", "false"]]}}, "input_order": {"required": ["images", "radius", "strength", "color_output", "neutral_background"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image High Pass Filter", "display_name": "Image High Pass Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image History Loader": {"input": {"required": {"image": [["No History"]]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["image", "filename_text"], "name": "Image History Loader", "display_name": "Image History Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/History", "output_node": false}, "Image Input Switch": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["image_a", "image_b", "boolean"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Input Switch", "display_name": "Image Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Image Levels Adjustment": {"input": {"required": {"image": ["IMAGE"], "black_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 255.0, "step": 0.1}], "mid_level": ["FLOAT", {"default": 127.5, "min": 0.0, "max": 255.0, "step": 0.1}], "white_level": ["FLOAT", {"default": 255, "min": 0.0, "max": 255.0, "step": 0.1}]}}, "input_order": {"required": ["image", "black_level", "mid_level", "white_level"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Levels Adjustment", "display_name": "Image Levels Adjustment", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Adjustment", "output_node": false}, "Image Load": {"input": {"required": {"image_path": ["STRING", {"default": "./ComfyUI/input/example.png", "multiline": false}], "RGBA": [["false", "true"]]}, "optional": {"filename_text_extension": [["true", "false"]]}}, "input_order": {"required": ["image_path", "RGBA"], "optional": ["filename_text_extension"]}, "output": ["IMAGE", "MASK", "STRING"], "output_is_list": [false, false, false], "output_name": ["image", "mask", "filename_text"], "name": "Image Load", "display_name": "Image Load", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": false}, "Image Median Filter": {"input": {"required": {"image": ["IMAGE"], "diameter": ["INT", {"default": 2.0, "min": 0.1, "max": 255, "step": 1}], "sigma_color": ["FLOAT", {"default": 10.0, "min": -255.0, "max": 255.0, "step": 0.1}], "sigma_space": ["FLOAT", {"default": 10.0, "min": -255.0, "max": 255.0, "step": 0.1}]}}, "input_order": {"required": ["image", "diameter", "sigma_color", "sigma_space"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Median Filter", "display_name": "Image Median Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Mix RGB Channels": {"input": {"required": {"red_channel": ["IMAGE"], "green_channel": ["IMAGE"], "blue_channel": ["IMAGE"]}}, "input_order": {"required": ["red_channel", "green_channel", "blue_channel"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Mix RGB Channels", "display_name": "Image Mix RGB Channels", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Monitor Effects Filter": {"input": {"required": {"image": ["IMAGE"], "mode": [["Digital Distortion", "Signal Distortion", "TV Distortion"]], "amplitude": ["INT", {"default": 5, "min": 1, "max": 255, "step": 1}], "offset": ["INT", {"default": 10, "min": 1, "max": 255, "step": 1}]}}, "input_order": {"required": ["image", "mode", "amplitude", "offset"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Monitor Effects Filter", "display_name": "Image Monitor Effects Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Nova Filter": {"input": {"required": {"image": ["IMAGE"], "amplitude": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.001}], "frequency": ["FLOAT", {"default": 3.14, "min": 0.0, "max": 100.0, "step": 0.001}]}}, "input_order": {"required": ["image", "amplitude", "frequency"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Nova Filter", "display_name": "Image Nova Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Padding": {"input": {"required": {"image": ["IMAGE"], "feathering": ["INT", {"default": 120, "min": 0, "max": 2048, "step": 1}], "feather_second_pass": [["true", "false"]], "left_padding": ["INT", {"default": 512, "min": 8, "max": 48000, "step": 1}], "right_padding": ["INT", {"default": 512, "min": 8, "max": 48000, "step": 1}], "top_padding": ["INT", {"default": 512, "min": 8, "max": 48000, "step": 1}], "bottom_padding": ["INT", {"default": 512, "min": 8, "max": 48000, "step": 1}]}}, "input_order": {"required": ["image", "feathering", "feather_second_pass", "left_padding", "right_padding", "top_padding", "bottom_padding"]}, "output": ["IMAGE", "IMAGE"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "Image Padding", "display_name": "Image Padding", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image Perlin Noise": {"input": {"required": {"width": ["INT", {"default": 512, "max": 2048, "min": 64, "step": 1}], "height": ["INT", {"default": 512, "max": 2048, "min": 64, "step": 1}], "scale": ["INT", {"default": 100, "max": 2048, "min": 2, "step": 1}], "octaves": ["INT", {"default": 4, "max": 8, "min": 0, "step": 1}], "persistence": ["FLOAT", {"default": 0.5, "max": 100.0, "min": 0.01, "step": 0.01}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["width", "height", "scale", "octaves", "persistence", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Perlin Noise", "display_name": "Image Perlin Noise", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Generate/Noise", "output_node": false}, "Image Rembg (Remove Background)": {"input": {"required": {"images": ["IMAGE"], "transparency": ["BOOLEAN", {"default": true}], "model": [["u2net", "u2netp", "u2net_human_seg", "silueta", "isnet-general-use", "isnet-anime"]], "post_processing": ["BOOLEAN", {"default": false}], "only_mask": ["BOOLEAN", {"default": false}], "alpha_matting": ["BOOLEAN", {"default": false}], "alpha_matting_foreground_threshold": ["INT", {"default": 240, "min": 0, "max": 255}], "alpha_matting_background_threshold": ["INT", {"default": 10, "min": 0, "max": 255}], "alpha_matting_erode_size": ["INT", {"default": 10, "min": 0, "max": 255}], "background_color": [["none", "black", "white", "magenta", "chroma green", "chroma blue"]]}}, "input_order": {"required": ["images", "transparency", "model", "post_processing", "only_mask", "alpha_matting", "alpha_matting_foreground_threshold", "alpha_matting_background_threshold", "alpha_matting_erode_size", "background_color"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Rembg (Remove Background)", "display_name": "Image Rembg (Remove Background)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/AI", "output_node": false}, "Image Perlin Power Fractal": {"input": {"required": {"width": ["INT", {"default": 512, "max": 8192, "min": 64, "step": 1}], "height": ["INT", {"default": 512, "max": 8192, "min": 64, "step": 1}], "scale": ["INT", {"default": 100, "max": 2048, "min": 2, "step": 1}], "octaves": ["INT", {"default": 4, "max": 8, "min": 0, "step": 1}], "persistence": ["FLOAT", {"default": 0.5, "max": 100.0, "min": 0.01, "step": 0.01}], "lacunarity": ["FLOAT", {"default": 2.0, "max": 100.0, "min": 0.01, "step": 0.01}], "exponent": ["FLOAT", {"default": 2.0, "max": 100.0, "min": 0.01, "step": 0.01}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["width", "height", "scale", "octaves", "persistence", "lacunarity", "exponent", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Perlin Power Fractal", "display_name": "Image Perlin Power Fractal", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Generate/Noise", "output_node": false}, "Image Remove Background (Alpha)": {"input": {"required": {"images": ["IMAGE"], "mode": [["background", "foreground"]], "threshold": ["INT", {"default": 127, "min": 0, "max": 255, "step": 1}], "threshold_tolerance": ["INT", {"default": 2, "min": 1, "max": 24, "step": 1}]}}, "input_order": {"required": ["images", "mode", "threshold", "threshold_tolerance"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Remove Background (Alpha)", "display_name": "Image Remove Background (Alpha)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Remove Color": {"input": {"required": {"image": ["IMAGE"], "target_red": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "target_green": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "target_blue": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "replace_red": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "replace_green": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "replace_blue": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "clip_threshold": ["INT", {"default": 10, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["image", "target_red", "target_green", "target_blue", "replace_red", "replace_green", "replace_blue", "clip_threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Remove Color", "display_name": "Image Remove Color", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Resize": {"input": {"required": {"image": ["IMAGE"], "mode": [["rescale", "resize"]], "supersample": [["true", "false"]], "resampling": [["lanczos", "nearest", "bilinear", "bicubic"]], "rescale_factor": ["FLOAT", {"default": 2, "min": 0.01, "max": 16.0, "step": 0.01}], "resize_width": ["INT", {"default": 1024, "min": 1, "max": 48000, "step": 1}], "resize_height": ["INT", {"default": 1536, "min": 1, "max": 48000, "step": 1}]}}, "input_order": {"required": ["image", "mode", "supersample", "resampling", "rescale_factor", "resize_width", "resize_height"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Resize", "display_name": "Image Resize", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image Rotate": {"input": {"required": {"images": ["IMAGE"], "mode": [["transpose", "internal"]], "rotation": ["INT", {"default": 0, "min": 0, "max": 360, "step": 90}], "sampler": [["nearest", "bilinear", "bicubic"]]}}, "input_order": {"required": ["images", "mode", "rotation", "sampler"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Rotate", "display_name": "Image Rotate", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image Rotate Hue": {"input": {"required": {"image": ["IMAGE"], "hue_shift": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["image", "hue_shift"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Rotate Hue", "display_name": "Image Rotate Hue", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Adjustment", "output_node": false}, "Image Send HTTP": {"input": {"required": {"images": ["IMAGE"], "url": ["STRING", {"default": "example.com"}], "method_type": [["post", "put", "patch"], {"default": "post"}], "request_field_name": ["STRING", {"default": "image"}]}, "optional": {"additional_request_headers": ["DICT"]}}, "input_order": {"required": ["images", "url", "method_type", "request_field_name"], "optional": ["additional_request_headers"]}, "output": ["INT", "STRING"], "output_is_list": [false, false], "output_name": ["status_code", "result_text"], "name": "Image Send HTTP", "display_name": "Image Send HTTP", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": true}, "Image Save": {"input": {"required": {"images": ["IMAGE"], "output_path": ["STRING", {"default": "[time(%Y-%m-%d)]", "multiline": false}], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "filename_delimiter": ["STRING", {"default": "_"}], "filename_number_padding": ["INT", {"default": 4, "min": 1, "max": 9, "step": 1}], "filename_number_start": [["false", "true"]], "extension": [["png", "jpg", "jpeg", "gif", "tiff", "webp", "bmp"]], "dpi": ["INT", {"default": 300, "min": 1, "max": 2400, "step": 1}], "quality": ["INT", {"default": 100, "min": 1, "max": 100, "step": 1}], "optimize_image": [["true", "false"]], "lossless_webp": [["false", "true"]], "overwrite_mode": [["false", "prefix_as_filename"]], "show_history": [["false", "true"]], "show_history_by_prefix": [["true", "false"]], "embed_workflow": [["true", "false"]], "show_previews": [["true", "false"]]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "output_path", "filename_prefix", "filename_delimiter", "filename_number_padding", "filename_number_start", "extension", "dpi", "quality", "optimize_image", "lossless_webp", "overwrite_mode", "show_history", "show_history_by_prefix", "embed_workflow", "show_previews"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["images", "files"], "name": "Image Save", "display_name": "Image Save", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": true}, "Image Seamless Texture": {"input": {"required": {"images": ["IMAGE"], "blending": ["FLOAT", {"default": 0.4, "max": 1.0, "min": 0.0, "step": 0.01}], "tiled": [["true", "false"]], "tiles": ["INT", {"default": 2, "max": 6, "min": 2, "step": 2}]}}, "input_order": {"required": ["images", "blending", "tiled", "tiles"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Image Seamless Texture", "display_name": "Image Seamless Texture", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Select Channel": {"input": {"required": {"image": ["IMAGE"], "channel": [["red", "green", "blue"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Select Channel", "display_name": "Image Select Channel", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Select Color": {"input": {"required": {"image": ["IMAGE"], "red": ["INT", {"default": 255.0, "min": 0.0, "max": 255.0, "step": 0.1}], "green": ["INT", {"default": 255.0, "min": 0.0, "max": 255.0, "step": 0.1}], "blue": ["INT", {"default": 255.0, "min": 0.0, "max": 255.0, "step": 0.1}], "variance": ["INT", {"default": 10, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["image", "red", "green", "blue", "variance"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Select Color", "display_name": "Image Select Color", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Shadows and Highlights": {"input": {"required": {"image": ["IMAGE"], "shadow_threshold": ["FLOAT", {"default": 75, "min": 0.0, "max": 255.0, "step": 0.1}], "shadow_factor": ["FLOAT", {"default": 1.5, "min": -12.0, "max": 12.0, "step": 0.1}], "shadow_smoothing": ["FLOAT", {"default": 0.25, "min": -255.0, "max": 255.0, "step": 0.1}], "highlight_threshold": ["FLOAT", {"default": 175, "min": 0.0, "max": 255.0, "step": 0.1}], "highlight_factor": ["FLOAT", {"default": 0.5, "min": -12.0, "max": 12.0, "step": 0.1}], "highlight_smoothing": ["FLOAT", {"default": 0.25, "min": -255.0, "max": 255.0, "step": 0.1}], "simplify_isolation": ["FLOAT", {"default": 0, "min": -255.0, "max": 255.0, "step": 0.1}]}}, "input_order": {"required": ["image", "shadow_threshold", "shadow_factor", "shadow_smoothing", "highlight_threshold", "highlight_factor", "highlight_smoothing", "simplify_isolation"]}, "output": ["IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["image", "shadow_map", "highlight_map"], "name": "Image Shadows and Highlights", "display_name": "Image Shadows and Highlights", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Adjustment", "output_node": false}, "Image Size to Number": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["NUMBER", "NUMBER", "FLOAT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["width_num", "height_num", "width_float", "height_float", "width_int", "height_int"], "name": "Image Size to Number", "display_name": "Image Size to Number", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Image Stitch": {"input": {"required": {"image_a": ["IMAGE"], "image_b": ["IMAGE"], "stitch": [["top", "left", "bottom", "right"]], "feathering": ["INT", {"default": 50, "min": 0, "max": 2048, "step": 1}]}}, "input_order": {"required": ["image_a", "image_b", "stitch", "feathering"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Stitch", "display_name": "Image Stitch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image Style Filter": {"input": {"required": {"image": ["IMAGE"], "style": [["1977", "aden", "brannan", "brooklyn", "clarendon", "earlybird", "fairy tale", "gingham", "hudson", "inkwell", "kelvin", "lark", "lofi", "maven", "mayfair", "moon", "nashville", "perpetua", "reyes", "rise", "slumber", "stinson", "toaster", "valencia", "walden", "willow", "xpro2"]]}}, "input_order": {"required": ["image", "style"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Style Filter", "display_name": "Image Style Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image Threshold": {"input": {"required": {"image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image", "threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Threshold", "display_name": "Image Threshold", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Tiled": {"input": {"required": {"image": ["IMAGE"], "num_tiles": ["INT", {"default": 4, "max": 64, "min": 2, "step": 1}]}}, "input_order": {"required": ["image", "num_tiles"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGES"], "name": "Image Tiled", "display_name": "Image Tiled", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Process", "output_node": false}, "Image Transpose": {"input": {"required": {"image": ["IMAGE"], "image_overlay": ["IMAGE"], "width": ["INT", {"default": 512, "min": -48000, "max": 48000, "step": 1}], "height": ["INT", {"default": 512, "min": -48000, "max": 48000, "step": 1}], "X": ["INT", {"default": 0, "min": -48000, "max": 48000, "step": 1}], "Y": ["INT", {"default": 0, "min": -48000, "max": 48000, "step": 1}], "rotation": ["INT", {"default": 0, "min": -360, "max": 360, "step": 1}], "feathering": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["image", "image_overlay", "width", "height", "X", "Y", "rotation", "feathering"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Transpose", "display_name": "Image Transpose", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Transform", "output_node": false}, "Image fDOF Filter": {"input": {"required": {"image": ["IMAGE"], "depth": ["IMAGE"], "mode": [["mock", "gaussian", "box"]], "radius": ["INT", {"default": 8, "min": 1, "max": 128, "step": 1}], "samples": ["INT", {"default": 1, "min": 1, "max": 3, "step": 1}]}}, "input_order": {"required": ["image", "depth", "mode", "radius", "samples"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image fDOF Filter", "display_name": "Image fDOF Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Filter", "output_node": false}, "Image to Latent Mask": {"input": {"required": {"images": ["IMAGE"], "channel": [["alpha", "red", "green", "blue"]]}}, "input_order": {"required": ["images", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Image to Latent Mask", "display_name": "Image to Latent Mask", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Image to Noise": {"input": {"required": {"images": ["IMAGE"], "num_colors": ["INT", {"default": 16, "max": 256, "min": 2, "step": 2}], "black_mix": ["INT", {"default": 0, "max": 20, "min": 0, "step": 1}], "gaussian_mix": ["FLOAT", {"default": 0.0, "max": 1024, "min": 0, "step": 0.1}], "brightness": ["FLOAT", {"default": 1.0, "max": 2.0, "min": 0.0, "step": 0.01}], "output_mode": [["batch", "list"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["images", "num_colors", "black_mix", "gaussian_mix", "brightness", "output_mode", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image to Noise", "display_name": "Image to Noise", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Generate/Noise", "output_node": false}, "Image to Seed": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["INT"], "output_is_list": [true], "output_name": ["INT"], "name": "Image to Seed", "display_name": "Image to Seed", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Analyze", "output_node": false}, "Images to RGB": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Images to RGB", "display_name": "Images to RGB", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Images to Linear": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Images to Linear", "display_name": "Images to Linear", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image", "output_node": false}, "Integer place counter": {"input": {"required": {"int_input": ["INT", {"default": 0, "min": 0, "max": 10000000, "step": 1}]}}, "input_order": {"required": ["int_input"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT_PLACES"], "name": "Integer place counter", "display_name": "Integer place counter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Integer", "output_node": false}, "Image Voronoi Noise Filter": {"input": {"required": {"width": ["INT", {"default": 512, "max": 4096, "min": 64, "step": 1}], "height": ["INT", {"default": 512, "max": 4096, "min": 64, "step": 1}], "density": ["INT", {"default": 50, "max": 256, "min": 10, "step": 2}], "modulator": ["INT", {"default": 0, "max": 8, "min": 0, "step": 1}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}, "optional": {"flat": [["False", "True"]], "RGB_output": [["True", "False"]]}}, "input_order": {"required": ["width", "height", "density", "modulator", "seed"], "optional": ["flat", "RGB_output"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Image Voronoi Noise Filter", "display_name": "Image Voronoi Noise Filter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Generate/Noise", "output_node": false}, "KSampler (WAS)": {"input": {"required": {"model": ["MODEL"], "seed": ["SEED"], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSampler (WAS)", "display_name": "KSampler (WAS)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Sampling", "output_node": false}, "KSampler Cycle": {"input": {"required": {"model": ["MODEL"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "tiled_vae": [["disable", "enable"]], "latent_upscale": [["disable", "nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "upscale_factor": ["FLOAT", {"default": 2.0, "min": 0.1, "max": 8.0, "step": 0.1}], "upscale_cycles": ["INT", {"default": 2, "min": 2, "max": 12, "step": 1}], "starting_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cycle_denoise": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "scale_denoise": [["enable", "disable"]], "scale_sampling": [["bilinear", "bicubic", "nearest", "lanczos"]], "vae": ["VAE"]}, "optional": {"secondary_model": ["MODEL"], "secondary_start_cycle": ["INT", {"default": 2, "min": 2, "max": 16, "step": 1}], "upscale_model": ["UPSCALE_MODEL"], "processor_model": ["UPSCALE_MODEL"], "pos_additive": ["CONDITIONING"], "neg_additive": ["CONDITIONING"], "pos_add_mode": [["increment", "decrement"]], "pos_add_strength": ["FLOAT", {"default": 0.25, "min": 0.01, "max": 1.0, "step": 0.01}], "pos_add_strength_scaling": [["enable", "disable"]], "pos_add_strength_cutoff": ["FLOAT", {"default": 2.0, "min": 0.01, "max": 10.0, "step": 0.01}], "neg_add_mode": [["increment", "decrement"]], "neg_add_strength": ["FLOAT", {"default": 0.25, "min": 0.01, "max": 1.0, "step": 0.01}], "neg_add_strength_scaling": [["enable", "disable"]], "neg_add_strength_cutoff": ["FLOAT", {"default": 2.0, "min": 0.01, "max": 10.0, "step": 0.01}], "sharpen_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}], "sharpen_radius": ["INT", {"default": 2, "min": 1, "max": 12, "step": 1}], "steps_scaling": [["enable", "disable"]], "steps_control": [["decrement", "increment"]], "steps_scaling_value": ["INT", {"default": 10, "min": 1, "max": 20, "step": 1}], "steps_cutoff": ["INT", {"default": 20, "min": 4, "max": 1000, "step": 1}], "denoise_cutoff": ["FLOAT", {"default": 0.25, "min": 0.01, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "tiled_vae", "latent_upscale", "upscale_factor", "upscale_cycles", "starting_denoise", "cycle_denoise", "scale_denoise", "scale_sampling", "vae"], "optional": ["secondary_model", "secondary_start_cycle", "upscale_model", "processor_model", "pos_additive", "neg_additive", "pos_add_mode", "pos_add_strength", "pos_add_strength_scaling", "pos_add_strength_cutoff", "neg_add_mode", "neg_add_strength", "neg_add_strength_scaling", "neg_add_strength_cutoff", "sharpen_strength", "sharpen_radius", "steps_scaling", "steps_control", "steps_scaling_value", "steps_cutoff", "denoise_cutoff"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["latent(s)"], "name": "KSampler Cycle", "display_name": "KSampler Cycle", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Sampling", "output_node": false}, "Latent Batch": {"input": {"required": {}, "optional": {"latent_a": ["LATENT"], "latent_b": ["LATENT"], "latent_c": ["LATENT"], "latent_d": ["LATENT"]}}, "input_order": {"required": [], "optional": ["latent_a", "latent_b", "latent_c", "latent_d"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["latent"], "name": "Latent Batch", "display_name": "Latent Batch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Latent", "output_node": false}, "Latent Noise Injection": {"input": {"required": {"samples": ["LATENT"], "noise_std": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "noise_std"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "Latent Noise Injection", "display_name": "Latent Noise Injection", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Latent/Generate", "output_node": false}, "Latent Size to Number": {"input": {"required": {"samples": ["LATENT"]}}, "input_order": {"required": ["samples"]}, "output": ["NUMBER", "NUMBER", "FLOAT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["tensor_w_num", "tensor_h_num", "tensor_w_float", "tensor_h_float", "tensor_w_int", "tensor_h_int"], "name": "Latent Size to Number", "display_name": "Latent Size to Number", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Latent Upscale by Factor (WAS)": {"input": {"required": {"samples": ["LATENT"], "mode": [["area", "bicubic", "bilinear", "nearest"]], "factor": ["FLOAT", {"default": 2.0, "min": 0.1, "max": 8.0, "step": 0.01}], "align": [["true", "false"]]}}, "input_order": {"required": ["samples", "mode", "factor", "align"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "Latent Upscale by Factor (WAS)", "display_name": "Latent Upscale by Factor (WAS)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Latent/Transform", "output_node": false}, "Load Image Batch": {"input": {"required": {"mode": [["single_image", "incremental_image", "random"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "index": ["INT", {"default": 0, "min": 0, "max": 150000, "step": 1}], "label": ["STRING", {"default": "Batch 001", "multiline": false}], "path": ["STRING", {"default": "", "multiline": false}], "pattern": ["STRING", {"default": "*", "multiline": false}], "allow_RGBA_output": [["false", "true"]]}, "optional": {"filename_text_extension": [["true", "false"]]}}, "input_order": {"required": ["mode", "seed", "index", "label", "path", "pattern", "allow_RGBA_output"], "optional": ["filename_text_extension"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["image", "filename_text"], "name": "Load Image Batch", "display_name": "Load Image Batch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": false}, "Load Text File": {"input": {"required": {"file_path": ["STRING", {"default": "", "multiline": false}], "dictionary_name": ["STRING", {"default": "[filename]", "multiline": false}]}}, "input_order": {"required": ["file_path", "dictionary_name"]}, "output": ["STRING", "DICT"], "output_is_list": [false, false], "output_name": ["STRING", "DICT"], "name": "Load Text File", "display_name": "Load Text File", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": false}, "Load Lora": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_name": [["None", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"]}, "output": ["MODEL", "CLIP", "STRING"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "NAME_STRING"], "name": "Load Lora", "display_name": "Load Lora", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "Lora Input Switch": {"input": {"required": {"model_a": ["MODEL"], "clip_a": ["CLIP"], "model_b": ["MODEL"], "clip_b": ["CLIP"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["model_a", "clip_a", "model_b", "clip_b", "boolean"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "Lora Input Switch", "display_name": "Lora Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Masks Add": {"input": {"required": {"masks_a": ["MASK"], "masks_b": ["MASK"]}}, "input_order": {"required": ["masks_a", "masks_b"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Masks Add", "display_name": "Masks Add", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Masks Subtract": {"input": {"required": {"masks_a": ["MASK"], "masks_b": ["MASK"]}}, "input_order": {"required": ["masks_a", "masks_b"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Masks Subtract", "display_name": "Masks Subtract", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Arbitrary Region": {"input": {"required": {"masks": ["MASK"], "size": ["INT", {"default": 256, "min": 1, "max": 4096, "step": 1}], "threshold": ["INT", {"default": 128, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["masks", "size", "threshold"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Arbitrary Region", "display_name": "Mask Arbitrary Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Batch to Mask": {"input": {"required": {"masks": ["MASK"], "batch_number": ["INT", {"default": 0, "min": 0, "max": 64, "step": 1}]}}, "input_order": {"required": ["masks", "batch_number"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "Mask Batch to Mask", "display_name": "Mask Batch to Mask", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Batch": {"input": {"optional": {"masks_a": ["MASK"], "masks_b": ["MASK"], "masks_c": ["MASK"], "masks_d": ["MASK"]}}, "input_order": {"optional": ["masks_a", "masks_b", "masks_c", "masks_d"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["masks"], "name": "Mask Batch", "display_name": "Mask Batch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Ceiling Region": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Ceiling Region", "display_name": "Mask Ceiling Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Crop Dominant Region": {"input": {"required": {"masks": ["MASK"], "padding": ["INT", {"default": 24, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["masks", "padding"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Crop Dominant Region", "display_name": "Mask Crop Dominant Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Crop Minority Region": {"input": {"required": {"masks": ["MASK"], "padding": ["INT", {"default": 24, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["masks", "padding"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Crop Minority Region", "display_name": "Mask Crop Minority Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Crop Region": {"input": {"required": {"mask": ["MASK"], "padding": ["INT", {"default": 24, "min": 0, "max": 4096, "step": 1}], "region_type": [["dominant", "minority"]]}}, "input_order": {"required": ["mask", "padding", "region_type"]}, "output": ["MASK", "CROP_DATA", "INT", "INT", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false, false, false], "output_name": ["cropped_mask", "crop_data", "top_int", "left_int", "right_int", "bottom_int", "width_int", "height_int"], "name": "Mask Crop Region", "display_name": "Mask Crop Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Paste Region": {"input": {"required": {"mask": ["MASK"], "crop_mask": ["MASK"], "crop_data": ["CROP_DATA"], "crop_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_sharpening": ["INT", {"default": 0, "min": 0, "max": 3, "step": 1}]}}, "input_order": {"required": ["mask", "crop_mask", "crop_data", "crop_blending", "crop_sharpening"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["RESULT_MASK", "CROP_MASK"], "name": "Mask Paste Region", "display_name": "Mask Paste Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Dilate Region": {"input": {"required": {"masks": ["MASK"], "iterations": ["INT", {"default": 5, "min": 1, "max": 64, "step": 1}]}}, "input_order": {"required": ["masks", "iterations"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Dilate Region", "display_name": "Mask Dilate Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Dominant Region": {"input": {"required": {"masks": ["MASK"], "threshold": ["INT", {"default": 128, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["masks", "threshold"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Dominant Region", "display_name": "Mask Dominant Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Erode Region": {"input": {"required": {"masks": ["MASK"], "iterations": ["INT", {"default": 5, "min": 1, "max": 64, "step": 1}]}}, "input_order": {"required": ["masks", "iterations"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Erode Region", "display_name": "Mask Erode Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Fill Holes": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Fill Holes", "display_name": "Mask Fill Holes", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Floor Region": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Floor Region", "display_name": "Mask Floor Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Gaussian Region": {"input": {"required": {"masks": ["MASK"], "radius": ["FLOAT", {"default": 5.0, "min": 0.0, "max": 1024, "step": 0.1}]}}, "input_order": {"required": ["masks", "radius"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Gaussian Region", "display_name": "Mask Gaussian Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Invert": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Invert", "display_name": "Mask Invert", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Minority Region": {"input": {"required": {"masks": ["MASK"], "threshold": ["INT", {"default": 128, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["masks", "threshold"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Minority Region", "display_name": "Mask Minority Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Rect Area": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "width": ["INT", {"default": 50, "min": 0, "max": 100, "step": 1}], "height": ["INT", {"default": 50, "min": 0, "max": 100, "step": 1}], "blur_radius": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}]}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["x", "y", "width", "height", "blur_radius"], "hidden": ["extra_pnginfo", "unique_id"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Rect Area", "display_name": "Mask Rect Area", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Rect Area (Advanced)": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 64}], "y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 64}], "width": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 64}], "height": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 64}], "image_width": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "image_height": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "blur_radius": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}]}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["x", "y", "width", "height", "image_width", "image_height", "blur_radius"], "hidden": ["extra_pnginfo", "unique_id"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Rect Area (Advanced)", "display_name": "Mask Rect Area (Advanced)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Smooth Region": {"input": {"required": {"masks": ["MASK"], "sigma": ["FLOAT", {"default": 5.0, "min": 0.0, "max": 128.0, "step": 0.1}]}}, "input_order": {"required": ["masks", "sigma"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Smooth Region", "display_name": "Mask Smooth Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Mask Threshold Region": {"input": {"required": {"masks": ["MASK"], "black_threshold": ["INT", {"default": 75, "min": 0, "max": 255, "step": 1}], "white_threshold": ["INT", {"default": 175, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["masks", "black_threshold", "white_threshold"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASKS"], "name": "Mask Threshold Region", "display_name": "Mask Threshold Region", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Masks Combine Regions": {"input": {"required": {"mask_a": ["MASK"], "mask_b": ["MASK"]}, "optional": {"mask_c": ["MASK"], "mask_d": ["MASK"], "mask_e": ["MASK"], "mask_f": ["MASK"]}}, "input_order": {"required": ["mask_a", "mask_b"], "optional": ["mask_c", "mask_d", "mask_e", "mask_f"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "Masks Combine Regions", "display_name": "Masks Combine Regions", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Masks Combine Batch": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "Masks Combine Batch", "display_name": "Masks Combine Batch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "MiDaS Model Loader": {"input": {"required": {"midas_model": [["DPT_Large", "DPT_Hybrid"]]}}, "input_order": {"required": ["midas_model"]}, "output": ["MIDAS_MODEL"], "output_is_list": [false], "output_name": ["midas_model"], "name": "MiDaS Model Loader", "display_name": "MiDaS Model Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "MiDaS Depth Approximation": {"input": {"required": {"image": ["IMAGE"], "use_cpu": [["false", "true"]], "midas_type": [["DPT_Large", "DPT_Hybrid"]], "invert_depth": [["false", "true"]]}, "optional": {"midas_model": ["MIDAS_MODEL"]}}, "input_order": {"required": ["image", "use_cpu", "midas_type", "invert_depth"], "optional": ["midas_model"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "MiDaS Depth Approximation", "display_name": "MiDaS Depth Approximation", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/AI", "output_node": false}, "MiDaS Mask Image": {"input": {"required": {"image": ["IMAGE"], "use_cpu": [["false", "true"]], "midas_model": [["DPT_Large", "DPT_Hybrid", "DPT_Small"]], "remove": [["background", "foregroud"]], "threshold": [["false", "true"]], "threshold_low": ["FLOAT", {"default": 10, "min": 0, "max": 255, "step": 1}], "threshold_mid": ["FLOAT", {"default": 200, "min": 0, "max": 255, "step": 1}], "threshold_high": ["FLOAT", {"default": 210, "min": 0, "max": 255, "step": 1}], "smoothing": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 16.0, "step": 0.01}], "background_red": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "background_green": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "background_blue": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["image", "use_cpu", "midas_model", "remove", "threshold", "threshold_low", "threshold_mid", "threshold_high", "smoothing", "background_red", "background_green", "background_blue"]}, "output": ["IMAGE", "IMAGE"], "output_is_list": [false, false], "output_name": ["RESULT", "DEPTH"], "name": "MiDaS Mask Image", "display_name": "MiDaS Mask Image", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/AI", "output_node": false}, "Model Input Switch": {"input": {"required": {"model_a": ["MODEL"], "model_b": ["MODEL"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["model_a", "model_b", "boolean"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "Model Input Switch", "display_name": "Model Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Number Counter": {"input": {"required": {"number_type": [["integer", "float"]], "mode": [["increment", "decrement", "increment_to_stop", "decrement_to_stop", "reset_after_stop"]], "start": ["FLOAT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.01}], "stop": ["FLOAT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.01}], "step": ["FLOAT", {"default": 1, "min": 0, "max": 99999, "step": 0.01}]}, "optional": {"reset_bool": ["NUMBER"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["number_type", "mode", "start", "stop", "step"], "optional": ["reset_bool"], "hidden": ["unique_id"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["number", "float", "int"], "name": "Number Counter", "display_name": "Number Counter", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number", "output_node": false}, "Number Operation": {"input": {"required": {"number_a": ["NUMBER"], "number_b": ["NUMBER"], "operation": [["addition", "subtraction", "division", "floor division", "multiplication", "exponentiation", "modulus", "greater-than", "greater-than or equals", "less-than", "less-than or equals", "equals", "does not equal"]]}}, "input_order": {"required": ["number_a", "number_b", "operation"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "Number Operation", "display_name": "Number Operation", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Number to Float": {"input": {"required": {"number": ["NUMBER"]}}, "input_order": {"required": ["number"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "Number to Float", "display_name": "Number to Float", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Number Input Switch": {"input": {"required": {"number_a": ["NUMBER"], "number_b": ["NUMBER"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["number_a", "number_b", "boolean"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "Number Input Switch", "display_name": "Number Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Number Input Condition": {"input": {"required": {"number_a": ["NUMBER"], "number_b": ["NUMBER"], "return_boolean": [["false", "true"]], "comparison": [["and", "or", "greater-than", "greater-than or equals", "less-than", "less-than or equals", "equals", "does not equal", "divisible by", "if A odd", "if A even", "if A prime", "factor of"]]}}, "input_order": {"required": ["number_a", "number_b", "return_boolean", "comparison"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "Number Input Condition", "display_name": "Number Input Condition", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Number Multiple Of": {"input": {"required": {"number": ["NUMBER"], "multiple": ["INT", {"default": 8, "min": -18446744073709551615, "max": 18446744073709551615}]}}, "input_order": {"required": ["number", "multiple"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "Number Multiple Of", "display_name": "Number Multiple Of", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Functions", "output_node": false}, "Number PI": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["NUMBER", "FLOAT"], "output_is_list": [false, false], "output_name": ["NUMBER", "FLOAT"], "name": "Number PI", "display_name": "Number PI", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number", "output_node": false}, "Number to Int": {"input": {"required": {"number": ["NUMBER"]}}, "input_order": {"required": ["number"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "Number to Int", "display_name": "Number to Int", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Number to Seed": {"input": {"required": {"number": ["NUMBER"]}}, "input_order": {"required": ["number"]}, "output": ["SEED"], "output_is_list": [false], "output_name": ["SEED"], "name": "Number to Seed", "display_name": "Number to Seed", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Number to String": {"input": {"required": {"number": ["NUMBER"]}}, "input_order": {"required": ["number"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Number to String", "display_name": "Number to String", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Number to Text": {"input": {"required": {"number": ["NUMBER"]}}, "input_order": {"required": ["number"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Number to Text", "display_name": "Number to Text", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number/Operations", "output_node": false}, "Boolean To Text": {"input": {"required": {"boolean": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["boolean"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Boolean To Text", "display_name": "Boolean To Text", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Prompt Styles Selector": {"input": {"required": {"style": [["None"]]}}, "input_order": {"required": ["style"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["positive_string", "negative_string"], "name": "Prompt Styles Selector", "display_name": "Prompt Styles Selector", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Prompt Multiple Styles Selector": {"input": {"required": {"style1": [["None"]], "style2": [["None"]], "style3": [["None"]], "style4": [["None"]]}}, "input_order": {"required": ["style1", "style2", "style3", "style4"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["positive_string", "negative_string"], "name": "Prompt Multiple Styles Selector", "display_name": "Prompt Multiple Styles Selector", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Random Number": {"input": {"required": {"number_type": [["integer", "float", "bool"]], "minimum": ["FLOAT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615}], "maximum": ["FLOAT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["number_type", "minimum", "maximum", "seed"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "Random Number", "display_name": "Random Number", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number", "output_node": false}, "Save Text File": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "path": ["STRING", {"default": "./ComfyUI/output/[time(%Y-%m-%d)]", "multiline": false}], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "filename_delimiter": ["STRING", {"default": "_"}], "filename_number_padding": ["INT", {"default": 4, "min": 0, "max": 9, "step": 1}]}, "optional": {"file_extension": ["STRING", {"default": ".txt"}], "encoding": ["STRING", {"default": "utf-8"}], "filename_suffix": ["STRING", {"default": ""}]}}, "input_order": {"required": ["text", "path", "filename_prefix", "filename_delimiter", "filename_number_padding"], "optional": ["file_extension", "encoding", "filename_suffix"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Save Text File", "display_name": "Save Text File", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/IO", "output_node": true}, "Seed": {"input": {"required": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["seed"]}, "output": ["SEED", "NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["seed", "number", "float", "int"], "name": "Seed", "display_name": "Seed", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number", "output_node": false}, "Tensor Batch to Image": {"input": {"required": {"images_batch": ["IMAGE"], "batch_image_number": ["INT", {"default": 0, "min": 0, "max": 64, "step": 1}]}}, "input_order": {"required": ["images_batch", "batch_image_number"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Tensor Batch to Image", "display_name": "Tensor Batch to Image", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Latent/Transform", "output_node": false}, "BLIP Analyze Image": {"input": {"required": {"images": ["IMAGE"], "mode": [["caption", "interrogate"]], "question": ["STRING", {"default": "What does the background consist of?", "multiline": true, "dynamicPrompts": false}], "blip_model": ["BLIP_MODEL"]}, "optional": {"min_length": ["INT", {"min": 1, "max": 1024, "default": 24}], "max_length": ["INT", {"min": 2, "max": 1024, "default": 64}], "num_beams": ["INT", {"min": 1, "max": 12, "default": 5}], "no_repeat_ngram_size": ["INT", {"min": 1, "max": 12, "default": 3}], "early_stopping": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["images", "mode", "question", "blip_model"], "optional": ["min_length", "max_length", "num_beams", "no_repeat_ngram_size", "early_stopping"]}, "output": ["STRING", "STRING"], "output_is_list": [false, true], "output_name": ["FULL_CAPTIONS", "CAPTIONS"], "name": "BLIP Analyze Image", "display_name": "BLIP Analyze Image", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/AI", "output_node": false}, "SAM Model Loader": {"input": {"required": {"model_size": [["ViT-H", "ViT-L", "ViT-B"]]}}, "input_order": {"required": ["model_size"]}, "output": ["SAM_MODEL"], "output_is_list": [false], "output_name": ["SAM_MODEL"], "name": "SAM Model Loader", "display_name": "SAM Model Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "SAM Parameters": {"input": {"required": {"points": ["STRING", {"default": "[128, 128]; [0, 0]", "multiline": false}], "labels": ["STRING", {"default": "[1, 0]", "multiline": false}]}}, "input_order": {"required": ["points", "labels"]}, "output": ["SAM_PARAMETERS"], "output_is_list": [false], "output_name": ["SAM_PARAMETERS"], "name": "SAM Parameters", "display_name": "SAM Parameters", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "SAM Parameters Combine": {"input": {"required": {"sam_parameters_a": ["SAM_PARAMETERS"], "sam_parameters_b": ["SAM_PARAMETERS"]}}, "input_order": {"required": ["sam_parameters_a", "sam_parameters_b"]}, "output": ["SAM_PARAMETERS"], "output_is_list": [false], "output_name": ["SAM_PARAMETERS"], "name": "SAM Parameters Combine", "display_name": "SAM Parameters Combine", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "SAM Image Mask": {"input": {"required": {"sam_model": ["SAM_MODEL"], "sam_parameters": ["SAM_PARAMETERS"], "image": ["IMAGE"]}}, "input_order": {"required": ["sam_model", "sam_parameters", "image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "SAM Image Mask", "display_name": "SAM Image Mask", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Masking", "output_node": false}, "Samples Passthrough (Stat System)": {"input": {"required": {"samples": ["LATENT"]}}, "input_order": {"required": ["samples"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "Samples Passthrough (Stat System)", "display_name": "Samples Passthrough (Stat System)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Debug", "output_node": false}, "String to Text": {"input": {"required": {"string": ["STRING", {}]}}, "input_order": {"required": ["string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "String to Text", "display_name": "String to Text", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "Image Bounds": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE_BOUNDS"], "output_is_list": [false], "output_name": ["IMAGE_BOUNDS"], "name": "Image Bounds", "display_name": "Image Bounds", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Bound", "output_node": false}, "Inset Image Bounds": {"input": {"required": {"image_bounds": ["IMAGE_BOUNDS"], "inset_left": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}], "inset_right": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}], "inset_top": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}], "inset_bottom": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["image_bounds", "inset_left", "inset_right", "inset_top", "inset_bottom"]}, "output": ["IMAGE_BOUNDS"], "output_is_list": [false], "output_name": ["IMAGE_BOUNDS"], "name": "Inset Image Bounds", "display_name": "Inset Image Bounds", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Bound", "output_node": false}, "Bounded Image Blend": {"input": {"required": {"target": ["IMAGE"], "target_bounds": ["IMAGE_BOUNDS"], "source": ["IMAGE"], "blend_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}], "feathering": ["INT", {"default": 16, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["target", "target_bounds", "source", "blend_factor", "feathering"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Bounded Image Blend", "display_name": "Bounded Image Blend", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Bound", "output_node": false}, "Bounded Image Blend with Mask": {"input": {"required": {"target": ["IMAGE"], "target_mask": ["MASK"], "target_bounds": ["IMAGE_BOUNDS"], "source": ["IMAGE"], "blend_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}], "feathering": ["INT", {"default": 16, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["target", "target_mask", "target_bounds", "source", "blend_factor", "feathering"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Bounded Image Blend with Mask", "display_name": "Bounded Image Blend with Mask", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Bound", "output_node": false}, "Bounded Image Crop": {"input": {"required": {"image": ["IMAGE"], "image_bounds": ["IMAGE_BOUNDS"]}}, "input_order": {"required": ["image", "image_bounds"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Bounded Image Crop", "display_name": "Bounded Image Crop", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Bound", "output_node": false}, "Bounded Image Crop with Mask": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "padding_left": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}], "padding_right": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}], "padding_top": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}], "padding_bottom": ["INT", {"default": 64, "min": 0, "max": 18446744073709551615}]}, "optional": {"return_list": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "mask", "padding_left", "padding_right", "padding_top", "padding_bottom"], "optional": ["return_list"]}, "output": ["IMAGE", "IMAGE_BOUNDS"], "output_is_list": [false, false], "output_name": ["IMAGE", "IMAGE_BOUNDS"], "name": "Bounded Image Crop with Mask", "display_name": "Bounded Image Crop with Mask", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Image/Bound", "output_node": false}, "Image Bounds to Console": {"input": {"required": {"image_bounds": ["IMAGE_BOUNDS"], "label": ["STRING", {"default": "Debug to Console", "multiline": false}]}}, "input_order": {"required": ["image_bounds", "label"]}, "output": ["IMAGE_BOUNDS"], "output_is_list": [false], "output_name": ["IMAGE_BOUNDS"], "name": "Image Bounds to Console", "display_name": "Image Bounds to Console", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Debug", "output_node": true}, "Text Dictionary Update": {"input": {"required": {"dictionary_a": ["DICT"], "dictionary_b": ["DICT"]}, "optional": {"dictionary_c": ["DICT"], "dictionary_d": ["DICT"]}}, "input_order": {"required": ["dictionary_a", "dictionary_b"], "optional": ["dictionary_c", "dictionary_d"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "Text Dictionary Update", "display_name": "Text Dictionary Update", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Dictionary Get": {"input": {"required": {"dictionary": ["DICT"], "key": ["STRING", {"default": "", "multiline": false}]}, "optional": {"default_value": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["dictionary", "key"], "optional": ["default_value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Dictionary Get", "display_name": "Text Dictionary Get", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Dictionary Convert": {"input": {"required": {"dictionary_text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["dictionary_text"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "Text Dictionary Convert", "display_name": "Text Dictionary Convert", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Dictionary New": {"input": {"required": {"key_1": ["STRING", {"default": "", "multiline": false}], "value_1": ["STRING", {"default": "", "multiline": false}]}, "optional": {"key_2": ["STRING", {"default": "", "multiline": false}], "value_2": ["STRING", {"default": "", "multiline": false}], "key_3": ["STRING", {"default": "", "multiline": false}], "value_3": ["STRING", {"default": "", "multiline": false}], "key_4": ["STRING", {"default": "", "multiline": false}], "value_4": ["STRING", {"default": "", "multiline": false}], "key_5": ["STRING", {"default": "", "multiline": false}], "value_5": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["key_1", "value_1"], "optional": ["key_2", "value_2", "key_3", "value_3", "key_4", "value_4", "key_5", "value_5"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "Text Dictionary New", "display_name": "Text Dictionary New", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Dictionary Keys": {"input": {"required": {"dictionary": ["DICT"]}, "optional": {}}, "input_order": {"required": ["dictionary"], "optional": []}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "Text Dictionary Keys", "display_name": "Text Dictionary Keys", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Dictionary To Text": {"input": {"required": {"dictionary": ["DICT"]}, "optional": {}}, "input_order": {"required": ["dictionary"], "optional": []}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Dictionary To Text", "display_name": "Text Dictionary To Text", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Add Tokens": {"input": {"required": {"tokens": ["STRING", {"default": "[hello]: world", "multiline": true}], "print_current_tokens": [["false", "true"]]}}, "input_order": {"required": ["tokens", "print_current_tokens"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Text Add Tokens", "display_name": "Text Add Tokens", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Tokens", "output_node": true}, "Text Add Token by Input": {"input": {"required": {"token_name": ["STRING", {"forceInput": true}], "token_value": ["STRING", {"forceInput": true}], "print_current_tokens": [["false", "true"]]}}, "input_order": {"required": ["token_name", "token_value", "print_current_tokens"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Text Add Token by Input", "display_name": "Text Add Token by Input", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Tokens", "output_node": true}, "Text Compare": {"input": {"required": {"text_a": ["STRING", {"forceInput": true}], "text_b": ["STRING", {"forceInput": true}], "mode": [["similarity", "difference"]], "tolerance": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["text_a", "text_b", "mode", "tolerance"]}, "output": ["STRING", "STRING", "BOOLEAN", "NUMBER", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["TEXT_A_PASS", "TEXT_B_PASS", "BOOLEAN", "SCORE_NUMBER", "COMPARISON_TEXT"], "name": "Text Compare", "display_name": "Text Compare", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Search", "output_node": false}, "Text Concatenate": {"input": {"required": {"delimiter": ["STRING", {"default": ", "}], "clean_whitespace": [["true", "false"]]}, "optional": {"text_a": ["STRING", {"forceInput": true}], "text_b": ["STRING", {"forceInput": true}], "text_c": ["STRING", {"forceInput": true}], "text_d": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["delimiter", "clean_whitespace"], "optional": ["text_a", "text_b", "text_c", "text_d"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Concatenate", "display_name": "Text Concatenate", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text File History Loader": {"input": {"required": {"file": [["No History"]], "dictionary_name": ["STRING", {"default": "[filename]", "multiline": true}]}}, "input_order": {"required": ["file", "dictionary_name"]}, "output": ["STRING", "DICT"], "output_is_list": [false, false], "output_name": ["STRING", "DICT"], "name": "Text File History Loader", "display_name": "Text File History Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/History", "output_node": false}, "Text Find and Replace by Dictionary": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "dictionary": ["DICT"], "replacement_key": ["STRING", {"default": "__", "multiline": false}], "seed": ["INT", {"default": 1, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["text", "dictionary", "replacement_key", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Find and Replace by Dictionary", "display_name": "Text Find and Replace by Dictionary", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Search", "output_node": false}, "Text Find and Replace Input": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "find": ["STRING", {"forceInput": true}], "replace": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["text", "find", "replace"]}, "output": ["STRING", "NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["result_text", "replacement_count_number", "replacement_count_float", "replacement_count_int"], "name": "Text Find and Replace Input", "display_name": "Text Find and Replace Input", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Search", "output_node": false}, "Text Find and Replace": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "find": ["STRING", {"default": "", "multiline": false}], "replace": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["text", "find", "replace"]}, "output": ["STRING", "NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["result_text", "replacement_count_number", "replacement_count_float", "replacement_count_int"], "name": "Text Find and Replace", "display_name": "Text Find and Replace", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Search", "output_node": false}, "Text Find": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "substring": ["STRING", {"default": "", "multiline": false}], "pattern": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["text", "substring", "pattern"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["found"], "name": "Text Find", "display_name": "Text Find", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Search", "output_node": false}, "Text Input Switch": {"input": {"required": {"text_a": ["STRING", {"forceInput": true}], "text_b": ["STRING", {"forceInput": true}], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["text_a", "text_b", "boolean"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Input Switch", "display_name": "Text Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Text List": {"input": {"required": {}, "optional": {"text_a": ["STRING", {"forceInput": true}], "text_b": ["STRING", {"forceInput": true}], "text_c": ["STRING", {"forceInput": true}], "text_d": ["STRING", {"forceInput": true}], "text_e": ["STRING", {"forceInput": true}], "text_f": ["STRING", {"forceInput": true}], "text_g": ["STRING", {"forceInput": true}]}}, "input_order": {"required": [], "optional": ["text_a", "text_b", "text_c", "text_d", "text_e", "text_f", "text_g"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "Text List", "display_name": "Text List", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text List Concatenate": {"input": {"required": {}, "optional": {"list_a": ["LIST", {"forceInput": true}], "list_b": ["LIST", {"forceInput": true}], "list_c": ["LIST", {"forceInput": true}], "list_d": ["LIST", {"forceInput": true}]}}, "input_order": {"required": [], "optional": ["list_a", "list_b", "list_c", "list_d"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "Text List Concatenate", "display_name": "Text List Concatenate", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text List to Text": {"input": {"required": {"delimiter": ["STRING", {"default": ", "}], "text_list": ["LIST", {"forceInput": true}]}}, "input_order": {"required": ["delimiter", "text_list"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text List to Text", "display_name": "Text List to Text", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Load Line From File": {"input": {"required": {"file_path": ["STRING", {"default": "", "multiline": false}], "dictionary_name": ["STRING", {"default": "[filename]", "multiline": false}], "label": ["STRING", {"default": "TextBatch", "multiline": false}], "mode": [["automatic", "index"]], "index": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"multiline_text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["file_path", "dictionary_name", "label", "mode", "index"], "optional": ["multiline_text"]}, "output": ["STRING", "DICT"], "output_is_list": [false, false], "output_name": ["line_text", "dictionary"], "name": "Text Load Line From File", "display_name": "Text Load Line From File", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Multiline": {"input": {"required": {"text": ["STRING", {"default": "", "multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Multiline", "display_name": "Text Multiline", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Multiline (Code Compatible)": {"input": {"required": {"text": ["STRING", {"default": "", "multiline": true, "dynamicPrompts": false}]}}, "input_order": {"required": ["text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Multiline (Code Compatible)", "display_name": "Text Multiline (Code Compatible)", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Parse A1111 Embeddings": {"input": {"required": {"text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Parse A1111 Embeddings", "display_name": "Text Parse A1111 Embeddings", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Parse", "output_node": false}, "Text Parse Noodle Soup Prompts": {"input": {"required": {"mode": [["Noodle Soup Prompts", "Wildcards"]], "noodle_key": ["STRING", {"default": "__", "multiline": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["mode", "noodle_key", "seed", "text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Parse Noodle Soup Prompts", "display_name": "Text Parse Noodle Soup Prompts", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Parse", "output_node": true}, "Text Parse Tokens": {"input": {"required": {"text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Parse Tokens", "display_name": "Text Parse Tokens", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Tokens", "output_node": false}, "Text Random Line": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["text", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Random Line", "display_name": "Text Random Line", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Random Prompt": {"input": {"required": {"search_seed": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["search_seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Random Prompt", "display_name": "Text Random Prompt", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text String": {"input": {"required": {"text": ["STRING", {"default": "", "multiline": false}]}, "optional": {"text_b": ["STRING", {"default": "", "multiline": false}], "text_c": ["STRING", {"default": "", "multiline": false}], "text_d": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["text"], "optional": ["text_b", "text_c", "text_d"]}, "output": ["STRING", "STRING", "STRING", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["TEXT", "TEXT_B", "TEXT_C", "TEXT_D"], "name": "Text String", "display_name": "Text String", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text", "output_node": false}, "Text Contains": {"input": {"required": {"text": ["STRING", {"default": "", "multiline": false}], "sub_text": ["STRING", {"default": "", "multiline": false}]}, "optional": {"case_insensitive": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "sub_text"], "optional": ["case_insensitive"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "Text Contains", "display_name": "Text Contains", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Text Shuffle": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "separator": ["STRING", {"default": ",", "multiline": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["text", "separator", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Shuffle", "display_name": "Text Shuffle", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "Text Sort": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "separator": ["STRING", {"default": ", ", "multiline": false}]}}, "input_order": {"required": ["text", "separator"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text Sort", "display_name": "Text Sort", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "Text to Conditioning": {"input": {"required": {"clip": ["CLIP"], "text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["clip", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "Text to Conditioning", "display_name": "Text to Conditioning", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "Text to Console": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "label": ["STRING", {"default": "Text Output", "multiline": false}]}}, "input_order": {"required": ["text", "label"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text to Console", "display_name": "Text to Console", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Debug", "output_node": true}, "Text to Number": {"input": {"required": {"text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["text"]}, "output": ["NUMBER"], "output_is_list": [false], "output_name": ["NUMBER"], "name": "Text to Number", "display_name": "Text to Number", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "Text to String": {"input": {"required": {"text": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Text to String", "display_name": "Text to String", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "Text String Truncate": {"input": {"required": {"text": ["STRING", {"forceInput": true}], "truncate_by": [["characters", "words"]], "truncate_from": [["end", "beginning"]], "truncate_to": ["INT", {"default": 10, "min": -99999999, "max": 99999999, "step": 1}]}, "optional": {"text_b": ["STRING", {"forceInput": true}], "text_c": ["STRING", {"forceInput": true}], "text_d": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["text", "truncate_by", "truncate_from", "truncate_to"], "optional": ["text_b", "text_c", "text_d"]}, "output": ["STRING", "STRING", "STRING", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["TEXT", "TEXT_B", "TEXT_C", "TEXT_D"], "name": "Text String Truncate", "display_name": "Text String Truncate", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Text/Operations", "output_node": false}, "True Random.org Number Generator": {"input": {"required": {"api_key": ["STRING", {"default": "00000000-0000-0000-0000-000000000000", "multiline": false}], "minimum": ["FLOAT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615}], "maximum": ["FLOAT", {"default": 10000000, "min": -18446744073709551615, "max": 18446744073709551615}], "mode": [["random", "fixed"]]}}, "input_order": {"required": ["api_key", "minimum", "maximum", "mode"]}, "output": ["NUMBER", "FLOAT", "INT"], "output_is_list": [false, false, false], "output_name": ["NUMBER", "FLOAT", "INT"], "name": "True Random.org Number Generator", "display_name": "True Random.org Number Generator", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Number", "output_node": false}, "unCLIP Checkpoint Loader": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE", "CLIP_VISION", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "CLIP_VISION", "NAME_STRING"], "name": "unCLIP Checkpoint Loader", "display_name": "unCLIP Checkpoint Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "Upscale Model Loader": {"input": {"required": {"model_name": [["4x-ClearRealityV1.pth"]]}}, "input_order": {"required": ["model_name"]}, "output": ["UPSCALE_MODEL", "STRING"], "output_is_list": [false, false], "output_name": ["UPSCALE_MODEL", "MODEL_NAME_TEXT"], "name": "Upscale Model Loader", "display_name": "Upscale Model Loader", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Loaders", "output_node": false}, "Upscale Model Switch": {"input": {"required": {"upscale_model_a": ["UPSCALE_MODEL"], "upscale_model_b": ["UPSCALE_MODEL"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["upscale_model_a", "upscale_model_b", "boolean"]}, "output": ["UPSCALE_MODEL"], "output_is_list": [false], "output_name": ["UPSCALE_MODEL"], "name": "Upscale Model Switch", "display_name": "Upscale Model Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Write to GIF": {"input": {"required": {"image": ["IMAGE"], "transition_frames": ["INT", {"default": 30, "min": 2, "max": 60, "step": 1}], "image_delay_ms": ["FLOAT", {"default": 2500.0, "min": 0.1, "max": 60000.0, "step": 0.1}], "duration_ms": ["FLOAT", {"default": 0.1, "min": 0.1, "max": 60000.0, "step": 0.1}], "loops": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "max_size": ["INT", {"default": 512, "min": 128, "max": 1280, "step": 1}], "output_path": ["STRING", {"default": "/ComfyUI/output", "multiline": false}], "filename": ["STRING", {"default": "morph_writer", "multiline": false}]}}, "input_order": {"required": ["image", "transition_frames", "image_delay_ms", "duration_ms", "loops", "max_size", "output_path", "filename"]}, "output": ["IMAGE", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["image_pass", "filepath_text", "filename_text"], "name": "Write to GIF", "display_name": "Write to GIF", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Animation/Writer", "output_node": false}, "Write to Video": {"input": {"required": {"image": ["IMAGE"], "transition_frames": ["INT", {"default": 30, "min": 0, "max": 120, "step": 1}], "image_delay_sec": ["FLOAT", {"default": 2.5, "min": 0.1, "max": 60000.0, "step": 0.1}], "fps": ["INT", {"default": 30, "min": 1, "max": 60.0, "step": 1}], "max_size": ["INT", {"default": 512, "min": 128, "max": 1920, "step": 1}], "output_path": ["STRING", {"default": "./ComfyUI/output", "multiline": false}], "filename": ["STRING", {"default": "comfy_writer", "multiline": false}], "codec": [["AVC1", "FFV1", "H264", "MP4V"]]}}, "input_order": {"required": ["image", "transition_frames", "image_delay_sec", "fps", "max_size", "output_path", "filename", "codec"]}, "output": ["IMAGE", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["IMAGE_PASS", "filepath_text", "filename_text"], "name": "Write to Video", "display_name": "Write to Video", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Animation/Writer", "output_node": false}, "VAE Input Switch": {"input": {"required": {"vae_a": ["VAE"], "vae_b": ["VAE"], "boolean": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["vae_a", "vae_b", "boolean"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "VAE Input Switch", "display_name": "VAE Input Switch", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Logic", "output_node": false}, "Video Dump Frames": {"input": {"required": {"video_path": ["STRING", {"default": "./ComfyUI/input/MyVideo.mp4", "multiline": false}], "output_path": ["STRING", {"default": "./ComfyUI/input/MyVideo", "multiline": false}], "prefix": ["STRING", {"default": "frame_", "multiline": false}], "filenumber_digits": ["INT", {"default": 4, "min": -1, "max": 8, "step": 1}], "extension": [["png", "jpg", "gif", "tiff"]]}}, "input_order": {"required": ["video_path", "output_path", "prefix", "filenumber_digits", "extension"]}, "output": ["STRING", "NUMBER"], "output_is_list": [false, false], "output_name": ["output_path", "processed_count"], "name": "Video Dump Frames", "display_name": "Video Dump Frames", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "WAS Suite/Animation", "output_node": false}, "CLIPSEG2": {"input": {"required": {"image": ["IMAGE"], "text": ["STRING", {"default": "", "multiline": false}], "use_cuda": ["BOOLEAN", {"default": false}]}, "optional": {"clipseg_model": ["CLIPSEG_MODEL"]}}, "input_order": {"required": ["image", "text", "use_cuda"], "optional": ["clipseg_model"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CLIPSEG2", "display_name": "CLIPSEG2", "description": "", "python_module": "custom_nodes.was-node-suite-comfyui", "category": "image/transformation", "output_node": false}, "Playbook Depth": {"input": {"required": {"api_key": ["STRING", {"multiline": false}]}, "optional": {"run_id": ["STRING", {"multiline": false}], "default_value": ["IMAGE"]}}, "input_order": {"required": ["api_key"], "optional": ["run_id", "default_value"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Image"], "name": "Playbook Depth", "display_name": "Playbook Depth Render Pass", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Depth Sequence": {"input": {"required": {"api_key": ["STRING", {"multiline": false}]}, "optional": {"run_id": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["api_key"], "optional": ["run_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Images"], "name": "Playbook Depth Sequence", "display_name": "Playbook Depth Render Pass Sequence", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Outline": {"input": {"required": {"api_key": ["STRING", {"multiline": false}]}, "optional": {"run_id": ["STRING", {"multiline": false}], "default_value": ["IMAGE"]}}, "input_order": {"required": ["api_key"], "optional": ["run_id", "default_value"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Image"], "name": "Playbook Outline", "display_name": "Playbook Outline Render Pass", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Outline Sequence": {"input": {"required": {"api_key": ["STRING", {"multiline": false}]}, "optional": {"run_id": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["api_key"], "optional": ["run_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Images"], "name": "Playbook Outline Sequence", "display_name": "Playbook Outline Render Pass Sequence", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Mask": {"input": {"required": {"api_key": ["STRING", {"multiline": false}], "blur_size": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 50.0}]}, "optional": {"run_id": ["STRING", {"multiline": false}], "default_value": ["IMAGE"]}}, "input_order": {"required": ["api_key", "blur_size"], "optional": ["run_id", "default_value"]}, "output": ["IMAGE", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["image", "mask_1", "mask_2", "mask_3", "mask_4", "mask_5", "mask_6", "mask_7", "mask_8"], "name": "Playbook Mask", "display_name": "Playbook Mask Render Pass", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Mask Sequence": {"input": {"required": {"api_key": ["STRING", {"multiline": false}], "blur_size": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 50.0}]}, "optional": {"run_id": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["api_key", "blur_size"], "optional": ["run_id"]}, "output": ["IMAGE", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["mask_pass", "mask_1", "mask_2", "mask_3", "mask_4", "mask_5", "mask_6", "mask_7", "mask_8"], "name": "Playbook Mask Sequence", "display_name": "Playbook Mask Render Pass Sequence", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Beauty": {"input": {"required": {"api_key": ["STRING", {"multiline": false}]}, "optional": {"run_id": ["STRING", {"multiline": false}], "default_value": ["IMAGE"]}}, "input_order": {"required": ["api_key"], "optional": ["run_id", "default_value"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Image"], "name": "Playbook Beauty", "display_name": "Playbook Beauty Render Pass", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Beauty Sequence": {"input": {"required": {"api_key": ["STRING", {"multiline": false}]}, "optional": {"run_id": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["api_key"], "optional": ["run_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Images"], "name": "Playbook Beauty Sequence", "display_name": "Playbook Beauty Render Pass Sequence", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Render Result": {"input": {"required": {"images": ["IMAGE"], "api_key": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["images", "api_key"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["URL"], "name": "Playbook Render Result", "display_name": "Playbook Render Result", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Boolean": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}], "default_value": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["id", "label", "default_value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["Boolean"], "name": "Playbook Boolean", "display_name": "Playbook Boolean (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Float": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}], "min": ["FLOAT", {"multiline": false, "default": 0, "display": "number", "step": 0.01}], "max": ["FLOAT", {"multiline": false, "default": 1.0, "display": "number", "step": 0.01}]}, "optional": {"default_value": ["FLOAT", {"multiline": true, "display": "number", "min": -2147483647, "max": 2147483647, "default": 0, "step": 0.01}]}}, "input_order": {"required": ["id", "label", "min", "max"], "optional": ["default_value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["float"], "name": "Playbook Float", "display_name": "Playbook Float (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Number": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}], "min": ["INT", {"multiline": false, "default": 0, "display": "number"}], "max": ["INT", {"multiline": false, "default": 100, "display": "number"}]}, "optional": {"default_value": ["INT", {"multiline": true, "display": "number", "min": -2147483647, "max": 2147483647, "default": 0}]}}, "input_order": {"required": ["id", "label", "min", "max"], "optional": ["default_value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["number"], "name": "Playbook Number", "display_name": "Playbook Number (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Text": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}]}, "optional": {"default_value": ["STRING", {"multiline": true}], "trigger_words": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["id", "label"], "optional": ["default_value", "trigger_words"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["text", "trigger_words"], "name": "Playbook Text", "display_name": "Playbook Text (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Image": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}]}, "optional": {"default_value": ["IMAGE"], "default_url": ["STRING", {"multiline": false, "default": ""}]}}, "input_order": {"required": ["id", "label"], "optional": ["default_value", "default_url"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Image"], "name": "Playbook Image", "display_name": "Playbook Image (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Video": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 1000, "step": 1}]}, "optional": {"default_value": ["IMAGE"], "default_url": ["STRING", {"multiline": false, "default": ""}]}}, "input_order": {"required": ["id", "label", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["default_value", "default_url"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "Playbook Video", "display_name": "Playbook Video (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Aspect Ratio Select": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}], "default_value": [["1:1", "16:9", "9:16", "4:3", "3:4"]]}}, "input_order": {"required": ["id", "label", "default_value"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["x", "y"], "name": "Playbook Aspect Ratio Select", "display_name": "Playbook Aspect Ratio Select (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook LoRA Select": {"input": {"required": {"default_value": ["STRING", {"default": "", "multiline": false, "tooltip": "LoRA name."}], "id": ["STRING", {"default": "Node ID", "multiline": false, "tooltip": "LoRA selection node identifier"}], "label": ["STRING", {"default": "Node Label", "multiline": false, "tooltip": "LoRA selection node's label"}], "base_model": [["SD1.5", "SDXL", "CogVideoX", "Flux"], {"default": "SD1.5", "tooltip": "Which base model is this LoRA meant for?"}]}}, "input_order": {"required": ["default_value", "id", "label", "base_model"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["lora_name"], "name": "Playbook LoRA Select", "display_name": "Playbook LoRA Select (External)", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "Playbook Seed": {"input": {"required": {"id": ["STRING", {"multiline": false, "default": "Node ID"}], "label": ["STRING", {"multiline": false, "default": "Node Label"}], "default_value": ["INT", {"multiline": false, "display": "number", "default": 0, "min": -999999999999999, "max": 999999999999999}], "setting": [["Fixed", "Random"], {"default": "Fixed"}]}}, "input_order": {"required": ["id", "label", "default_value", "setting"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["seed"], "name": "Playbook Seed", "display_name": "Playbook Seed", "description": "", "python_module": "custom_nodes.playbook3d-comfyui-nodes", "category": "Playbook 3D", "output_node": false}, "XY Input: Lora Block Weight //Inspire": {"input": {"required": {"category_filter": [["All", ""]], "lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "inverse": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "A": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "B": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "preset": [["Preset", "SD-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SD-INS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-IND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0", "SD-INALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0", "SD-MIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0", "SD-MIDD0.2:1,0,0,0,0,0,0.2,0.4,0.4,0.2,0,0,0,0,0,0,0", "SD-MIDD0.8:1,0,0,0,0,0.5,0.8,0.8,0.4,0,0,0,0,0,0,0,0", "SD-MOUT:1,0,0,0,0,0,1,1,1,1,1,1,1,1,0.5,0,0", "SD-OUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0", "SD-OUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1", "SD-OUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "SD-ROUT:1,1,1,1,1,1,1,1,R,R,R,R,R,R,R,R,R", "SD-AOUT:A,1,1,1,1,1,1,1,1,1,1,1,A,A,A,A,A", "SD-AB:A,B,B,B,B,B,B,B,B,B,B,B,A,A,A,A,A", "SD-ALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5", "SD-LyC-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SD-LyC-INALL:1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-MIDALL:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-OUTALL:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-NONE:0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-ALL:1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-INALL:1,1,1,1,1,0,0,0,0,0,0,0", "SDXL-MIDALL:1,0,0,0,0,1,0,0,0,0,0,0", "SDXL-OUTALL:1,0,0,0,0,0,1,1,1,1,1,1", "SDXL-LyC-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-LyC-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-LyC-INALL:1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-LyC-MIDALL:1,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0", "SDXL-LyC-OUTALL:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "FLUX-DBL-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "FLUX-DBL-FRONT7:1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-DBL-MID6:1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0", "FLUX-DBL-TAIL6:1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1", "FLUX-SINGLE-ALL:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "FLUX-SINGLE-1to10:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-SINGLE-11to20:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-SINGLE-21to30:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0", "FLUX-SINGLE-31to37:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1", "FLUX-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "@SD-FULL-TEST:17", "@SD-BLOCK1-TEST:17,12,1", "@SD-BLOCK2-TEST:17,12,2", "@SD-BLOCK3-TEST:17,12,3", "@SD-BLOCK4-TEST:17,12,4", "@SD-BLOCK5-TEST:17,12,5", "@SD-BLOCK6-TEST:17,12,6", "@SD-BLOCK7-TEST:17,12,7", "@SD-BLOCK8-TEST:17,12,8", "@SD-BLOCK9-TEST:17,12,9", "@SD-BLOCK10-TEST:17,12,10", "@SD-BLOCK11-TEST:17,12,11", "@SD-BLOCK12-TEST:17,12,12", "@SD-BLOCK13-TEST:17,12,13", "@SD-BLOCK14-TEST:17,12,14", "@SD-BLOCK15-TEST:17,12,15", "@SD-BLOCK16-TEST:17,12,16", "@SD-BLOCK17-TEST:17,12,17", "@SD-LyC-FULL-TEST:27", "@SDXL-FULL-TEST:12", "@SDXL-LyC-FULL-TEST:21", "@FLUX-DBL-FULL:19", "@FLUX-DBL-SGL-FULL:58", "@FLUX-DBL0-TEST:19,14,2", "@FLUX-DBL1-TEST:19,14,3", "@FLUX-DBL2-TEST:19,14,4", "@FLUX-DBL3-TEST:19,14,5", "@FLUX-DBL4-TEST:19,14,6", "@FLUX-DBL5-TEST:19,14,7", "@FLUX-DBL6-TEST:19,14,8", "@FLUX-DBL7-TEST:19,14,9", "@FLUX-DBL8-TEST:19,14,10", "@FLUX-DBL9-TEST:19,14,11", "@FLUX-DBL10-TEST:19,14,12", "@FLUX-DBL11-TEST:19,14,13", "@FLUX-DBL12-TEST:19,14,14", "@FLUX-DBL13-TEST:19,14,15", "@FLUX-DBL14-TEST:19,14,16", "@FLUX-DBL15-TEST:19,14,17", "@FLUX-DBL16-TEST:19,14,18", "@FLUX-DBL17-TEST:19,14,19", "@FLUX-DBL18-TEST:19,14,20", "@FLUX-SGL0-TEST:58,6,21", "@FLUX-SGL1-TEST:58,6,22", "@FLUX-SGL2-TEST:58,6,23", "@FLUX-SGL3-TEST:58,6,24", "@FLUX-SGL4-TEST:58,6,25", "@FLUX-SGL5-TEST:58,6,26", "@FLUX-SGL6-TEST:58,6,27", "@FLUX-SGL7-TEST:58,6,28", "@FLUX-SGL8-TEST:58,6,29", "@FLUX-SGL9-TEST:58,6,30", "@FLUX-SGL10-TEST:58,6,31", "@FLUX-SGL11-TEST:58,6,32", "@FLUX-SGL12-TEST:58,6,33", "@FLUX-SGL13-TEST:58,6,34", "@FLUX-SGL14-TEST:58,6,35", "@FLUX-SGL15-TEST:58,6,36", "@FLUX-SGL16-TEST:58,6,37", "@FLUX-SGL17-TEST:58,6,38", "@FLUX-SGL18-TEST:58,6,39", "@FLUX-SGL19-TEST:58,6,40", "@FLUX-SGL20-TEST:58,6,41", "@FLUX-SGL21-TEST:58,6,42", "@FLUX-SGL22-TEST:58,6,43", "@FLUX-SGL23-TEST:58,6,44", "@FLUX-SGL24-TEST:58,6,45", "@FLUX-SGL25-TEST:58,6,46", "@FLUX-SGL26-TEST:58,6,47", "@FLUX-SGL27-TEST:58,6,48", "@FLUX-SGL28-TEST:58,6,49", "@FLUX-SGL29-TEST:58,6,50", "@FLUX-SGL30-TEST:58,6,51", "@FLUX-SGL31-TEST:58,6,52", "@FLUX-SGL32-TEST:58,6,53", "@FLUX-SGL33-TEST:58,6,54", "@FLUX-SGL34-TEST:58,6,55", "@FLUX-SGL35-TEST:58,6,56", "@FLUX-SGL36-TEST:58,6,57", "@FLUX-SGL37-TEST:58,6,58", "@FLUX-SGL38-TEST:58,6,59"]], "block_vectors": ["STRING", {"multiline": true, "default": "SD-NONE/SD-ALL\nSD-ALL/SD-ALL\nSD-INS/SD-ALL\nSD-IND/SD-ALL\nSD-INALL/SD-ALL\nSD-MIDD/SD-ALL\nSD-MIDD0.2/SD-ALL\nSD-MIDD0.8/SD-ALL\nSD-MOUT/SD-ALL\nSD-OUTD/SD-ALL\nSD-OUTS/SD-ALL\nSD-OUTALL/SD-ALL", "placeholder": "{target vector}/{reference vector}", "pysssss.autocomplete": false}], "heatmap_palette": [["viridis", "magma", "plasma", "inferno", "cividis"]], "heatmap_alpha": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.01}], "heatmap_strength": ["FLOAT", {"default": 1.5, "min": 0.0, "max": 10.0, "step": 0.01}], "xyplot_mode": [["Simple", "Diff", "Diff+Heatmap"]]}}, "input_order": {"required": ["category_filter", "lora_name", "strength_model", "strength_clip", "inverse", "seed", "A", "B", "preset", "block_vectors", "heatmap_palette", "heatmap_alpha", "heatmap_strength", "xyplot_mode"]}, "output": ["XY", "XY"], "output_is_list": [false, false], "output_name": ["X (vectors)", "Y (effect_compares)"], "name": "XY Input: Lora Block Weight //Inspire", "display_name": "XY Input: LoRA Block Weight", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": false}, "LoraLoaderBlockWeight //Inspire": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "category_filter": [["All", ""]], "lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "inverse": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False", "tooltip": "Apply the following weights for each block:\nTrue: 1 - weight\nFalse: weight"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": ""}], "A": ["FLOAT", {"default": 4.0, "min": -10.0, "max": 10.0, "step": 0.01}], "B": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "preset": [["Preset", "SD-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SD-INS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-IND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0", "SD-INALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0", "SD-MIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0", "SD-MIDD0.2:1,0,0,0,0,0,0.2,0.4,0.4,0.2,0,0,0,0,0,0,0", "SD-MIDD0.8:1,0,0,0,0,0.5,0.8,0.8,0.4,0,0,0,0,0,0,0,0", "SD-MOUT:1,0,0,0,0,0,1,1,1,1,1,1,1,1,0.5,0,0", "SD-OUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0", "SD-OUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1", "SD-OUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "SD-ROUT:1,1,1,1,1,1,1,1,R,R,R,R,R,R,R,R,R", "SD-AOUT:A,1,1,1,1,1,1,1,1,1,1,1,A,A,A,A,A", "SD-AB:A,B,B,B,B,B,B,B,B,B,B,B,A,A,A,A,A", "SD-ALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5", "SD-LyC-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SD-LyC-INALL:1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-MIDALL:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-OUTALL:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-NONE:0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-ALL:1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-INALL:1,1,1,1,1,0,0,0,0,0,0,0", "SDXL-MIDALL:1,0,0,0,0,1,0,0,0,0,0,0", "SDXL-OUTALL:1,0,0,0,0,0,1,1,1,1,1,1", "SDXL-LyC-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-LyC-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-LyC-INALL:1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-LyC-MIDALL:1,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0", "SDXL-LyC-OUTALL:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "FLUX-DBL-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "FLUX-DBL-FRONT7:1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-DBL-MID6:1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0", "FLUX-DBL-TAIL6:1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1", "FLUX-SINGLE-ALL:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "FLUX-SINGLE-1to10:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-SINGLE-11to20:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-SINGLE-21to30:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0", "FLUX-SINGLE-31to37:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1", "FLUX-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1"]], "block_vector": ["STRING", {"multiline": true, "placeholder": "block weight vectors", "default": "1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "pysssss.autocomplete": false}], "bypass": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}]}}, "input_order": {"required": ["model", "clip", "category_filter", "lora_name", "strength_model", "strength_clip", "inverse", "seed", "A", "B", "preset", "block_vector", "bypass"]}, "output": ["MODEL", "CLIP", "STRING"], "output_is_list": [false, false, false], "output_name": ["model", "clip", "populated_vector"], "name": "LoraLoaderBlockWeight //Inspire", "display_name": "LoRA Loader (Block Weight)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": false}, "LoraBlockInfo //Inspire": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "block_info": ["STRING", {"multiline": true}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["model", "clip", "lora_name", "block_info"], "hidden": ["unique_id"]}, "output": [], "output_is_list": [], "output_name": [], "name": "LoraBlockInfo //Inspire", "display_name": "LoRA Block Info", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": true}, "MakeLBW //Inspire": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "category_filter": [["All", ""]], "lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "inverse": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False", "tooltip": "Apply the following weights for each block:\nTrue: 1 - weight\nFalse: weight"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": ""}], "A": ["FLOAT", {"default": 4.0, "min": -10.0, "max": 10.0, "step": 0.01}], "B": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "preset": [["Preset", "SD-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SD-INS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-IND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0", "SD-INALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0", "SD-MIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0", "SD-MIDD0.2:1,0,0,0,0,0,0.2,0.4,0.4,0.2,0,0,0,0,0,0,0", "SD-MIDD0.8:1,0,0,0,0,0.5,0.8,0.8,0.4,0,0,0,0,0,0,0,0", "SD-MOUT:1,0,0,0,0,0,1,1,1,1,1,1,1,1,0.5,0,0", "SD-OUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0", "SD-OUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1", "SD-OUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "SD-ROUT:1,1,1,1,1,1,1,1,R,R,R,R,R,R,R,R,R", "SD-AOUT:A,1,1,1,1,1,1,1,1,1,1,1,A,A,A,A,A", "SD-AB:A,B,B,B,B,B,B,B,B,B,B,B,A,A,A,A,A", "SD-ALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5", "SD-LyC-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SD-LyC-INALL:1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-MIDALL:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "SD-LyC-OUTALL:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-NONE:0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-ALL:1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-INALL:1,1,1,1,1,0,0,0,0,0,0,0", "SDXL-MIDALL:1,0,0,0,0,1,0,0,0,0,0,0", "SDXL-OUTALL:1,0,0,0,0,0,1,1,1,1,1,1", "SDXL-LyC-NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-LyC-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "SDXL-LyC-INALL:1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "SDXL-LyC-MIDALL:1,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0", "SDXL-LyC-OUTALL:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "FLUX-DBL-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "FLUX-DBL-FRONT7:1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-DBL-MID6:1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0", "FLUX-DBL-TAIL6:1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1", "FLUX-SINGLE-ALL:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", "FLUX-SINGLE-1to10:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-SINGLE-11to20:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0", "FLUX-SINGLE-21to30:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0", "FLUX-SINGLE-31to37:1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1", "FLUX-ALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1"]], "block_vector": ["STRING", {"multiline": true, "placeholder": "block weight vectors", "default": "1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1", "pysssss.autocomplete": false}], "bypass": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}]}}, "input_order": {"required": ["model", "clip", "category_filter", "lora_name", "inverse", "seed", "A", "B", "preset", "block_vector", "bypass"]}, "output": ["LBW_MODEL", "STRING"], "output_is_list": [false, false], "output_name": ["lbw_model", "populated_vector"], "name": "MakeLBW //Inspire", "display_name": "Make LoRA Block Weight", "description": "Instead of directly applying the LoRA Block Weight to the MODEL, it is generated in a separate LBW_MODEL form.", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": false}, "ApplyLBW //Inspire": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "strength_model": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lbw_model": ["LBW_MODEL"]}}, "input_order": {"required": ["model", "clip", "strength_model", "strength_clip", "lbw_model"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "ApplyLBW //Inspire", "display_name": "Apply LoRA Block Weight", "description": "Apply LBW_MODEL to MODEL and CLIP", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": false}, "SaveLBW //Inspire": {"input": {"required": {"lbw_model": ["LBW_MODEL"], "filename_prefix": ["STRING", {"default": "ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["lbw_model", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveLBW //Inspire", "display_name": "Save LoRA Block Weight", "description": "Save LBW_MODEL as a .lbw.safetensors file", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": true}, "LoadLBW //Inspire": {"input": {"required": {"lbw_model": [[]]}}, "input_order": {"required": ["lbw_model"]}, "output": ["LBW_MODEL"], "output_is_list": [false], "output_name": ["LBW_MODEL"], "name": "LoadLBW //Inspire", "display_name": "Load LoRA Block Weight", "description": "Load LBW_MODEL from .lbw.safetensors file", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/LoraBlockWeight", "output_node": false}, "OpenPose_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"detect_hand": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "detect_body": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "detect_face": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "resolution_upscale_by": ["FLOAT", {"default": 1.0, "min": 0.5, "max": 100, "step": 0.1}]}}, "input_order": {"required": ["detect_hand", "detect_body", "detect_face", "resolution_upscale_by"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "OpenPose_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "OpenPose Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "DWPreprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"detect_hand": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "detect_body": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "detect_face": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "resolution_upscale_by": ["FLOAT", {"default": 1.0, "min": 0.5, "max": 100, "step": 0.1}], "bbox_detector": [["yolox_l.torchscript.pt", "yolox_l.onnx", "yolo_nas_l_fp16.onnx", "yolo_nas_m_fp16.onnx", "yolo_nas_s_fp16.onnx"], {"default": "yolox_l.onnx"}], "pose_estimator": [["dw-ll_ucoco_384_bs5.torchscript.pt", "dw-ll_ucoco_384.onnx", "dw-ll_ucoco.onnx"], {"default": "dw-ll_ucoco_384_bs5.torchscript.pt"}]}}, "input_order": {"required": ["detect_hand", "detect_body", "detect_face", "resolution_upscale_by", "bbox_detector", "pose_estimator"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "DWPreprocessor_Provider_for_SEGS //Inspire", "display_name": "DWPreprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "MiDaS_DepthMap_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"a": ["FLOAT", {"default": 6.283185307179586, "min": 0.0, "max": 15.707963267948966, "step": 0.05}], "bg_threshold": ["FLOAT", {"default": 0.1, "min": 0, "max": 1, "step": 0.05}]}}, "input_order": {"required": ["a", "bg_threshold"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "MiDaS_DepthMap_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "MiDaS Depth Map Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "LeRes_DepthMap_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"rm_nearest": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100, "step": 0.1}], "rm_background": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100, "step": 0.1}]}, "optional": {"boost": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["rm_nearest", "rm_background"], "optional": ["boost"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "LeRes_DepthMap_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "LeReS Depth Map Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "Canny_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"low_threshold": ["FLOAT", {"default": 0.4, "min": 0.01, "max": 0.99, "step": 0.01}], "high_threshold": ["FLOAT", {"default": 0.8, "min": 0.01, "max": 0.99, "step": 0.01}]}}, "input_order": {"required": ["low_threshold", "high_threshold"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "Canny_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "Canny Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "MediaPipe_FaceMesh_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"max_faces": ["INT", {"default": 10, "min": 1, "max": 50, "step": 1}], "min_confidence": ["FLOAT", {"default": 0.5, "min": 0.01, "max": 1.0, "step": 0.01}], "resolution_upscale_by": ["FLOAT", {"default": 1.0, "min": 0.5, "max": 100, "step": 0.1}]}}, "input_order": {"required": ["max_faces", "min_confidence", "resolution_upscale_by"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "MediaPipe_FaceMesh_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "MediaPipe FaceMesh Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "HEDPreprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"safe": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["safe"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "HEDPreprocessor_Provider_for_SEGS //Inspire", "display_name": "HED Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "FakeScribblePreprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"safe": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["safe"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "FakeScribblePreprocessor_Provider_for_SEGS //Inspire", "display_name": "Fake Scribble Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "AnimeLineArt_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "AnimeLineArt_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "AnimeLineArt Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "Manga2Anime_LineArt_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "Manga2Anime_LineArt_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "Manga2Anime LineArt Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "LineArt_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"coarse": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["coarse"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "LineArt_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "LineArt Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "Color_Preprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "Color_Preprocessor_Provider_for_SEGS //Inspire", "display_name": "Color Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "InpaintPreprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {}, "optional": {"black_pixel_for_xinsir_cn": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": [], "optional": ["black_pixel_for_xinsir_cn"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "InpaintPreprocessor_Provider_for_SEGS //Inspire", "display_name": "Inpaint Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "TilePreprocessor_Provider_for_SEGS //Inspire": {"input": {"required": {"pyrUp_iters": ["INT", {"default": 3, "min": 1, "max": 10, "step": 1}]}}, "input_order": {"required": ["pyrUp_iters"]}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "TilePreprocessor_Provider_for_SEGS //Inspire", "display_name": "Tile Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "MeshGraphormerDepthMapPreprocessorProvider_for_SEGS //Inspire": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["SEGS_PREPROCESSOR"], "output_is_list": [false], "output_name": ["SEGS_PREPROCESSOR"], "name": "MeshGraphormerDepthMapPreprocessorProvider_for_SEGS //Inspire", "display_name": "MeshGraphormer Depth Map Preprocessor Provider (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/SEGS/ControlNet", "output_node": false}, "MediaPipeFaceMeshDetectorProvider //Inspire": {"input": {"required": {"max_faces": ["INT", {"default": 10, "min": 1, "max": 50, "step": 1}], "face": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "mouth": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "left_eyebrow": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "left_eye": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "left_pupil": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "right_eyebrow": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "right_eye": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "right_pupil": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["max_faces", "face", "mouth", "left_eyebrow", "left_eye", "left_pupil", "right_eyebrow", "right_eye", "right_pupil"]}, "output": ["BBOX_DETECTOR", "SEGM_DETECTOR"], "output_is_list": [false, false], "output_name": ["BBOX_DETECTOR", "SEGM_DETECTOR"], "name": "MediaPipeFaceMeshDetectorProvider //Inspire", "display_name": "MediaPipeFaceMesh Detector Provider", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Detector", "output_node": false}, "KSampler //Inspire": {"input": {"required": {"model": ["MODEL"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed for the initial noise applied to the latent."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_mode": [["GPU(=A1111)", "CPU", "GPU+internal_seed", "CPU+internal_seed"]], "batch_seed_mode": [["incremental", "comfy", "variation str inc:0.01", "variation str inc:0.05"]], "variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"variation_method": [["linear", "slerp"]], "scheduler_func_opt": ["SCHEDULER_FUNC"], "internal_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed used for generating noise in intermediate steps when using ancestral and SDE-based samplers.\nNOTE: If `noise_mode` is in GPU mode and `internal_seed` is the same as `seed`, the generated image may be distorted."}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise", "noise_mode", "batch_seed_mode", "variation_seed", "variation_strength"], "optional": ["variation_method", "scheduler_func_opt", "internal_seed"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSampler //Inspire", "display_name": "KSampler (inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/a1111_compat", "output_node": false}, "KSamplerAdvanced //Inspire": {"input": {"required": {"model": ["MODEL"], "add_noise": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed for the initial noise applied to the latent."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000}], "noise_mode": [["GPU(=A1111)", "CPU", "GPU+internal_seed", "CPU+internal_seed"]], "return_with_leftover_noise": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "batch_seed_mode": [["incremental", "comfy", "variation str inc:0.01", "variation str inc:0.05"]], "variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"variation_method": [["linear", "slerp"]], "noise_opt": ["NOISE_IMAGE"], "scheduler_func_opt": ["SCHEDULER_FUNC"], "internal_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed used for generating noise in intermediate steps when using ancestral and SDE-based samplers.\nNOTE: If `noise_mode` is in GPU mode and `internal_seed` is the same as `seed`, the generated image may be distorted."}]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "start_at_step", "end_at_step", "noise_mode", "return_with_leftover_noise", "batch_seed_mode", "variation_seed", "variation_strength"], "optional": ["variation_method", "noise_opt", "scheduler_func_opt", "internal_seed"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSamplerAdvanced //Inspire", "display_name": "KSamplerAdvanced (inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/a1111_compat", "output_node": false}, "KSamplerPipe //Inspire": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed for the initial noise applied to the latent."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "latent_image": ["LATENT"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_mode": [["GPU(=A1111)", "CPU", "GPU+internal_seed", "CPU+internal_seed"]], "batch_seed_mode": [["incremental", "comfy", "variation str inc:0.01", "variation str inc:0.05"]], "variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"scheduler_func_opt": ["SCHEDULER_FUNC"], "internal_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed used for generating noise in intermediate steps when using ancestral and SDE-based samplers.\nNOTE: If `noise_mode` is in GPU mode and `internal_seed` is the same as `seed`, the generated image may be distorted."}]}}, "input_order": {"required": ["basic_pipe", "seed", "steps", "cfg", "sampler_name", "scheduler", "latent_image", "denoise", "noise_mode", "batch_seed_mode", "variation_seed", "variation_strength"], "optional": ["scheduler_func_opt", "internal_seed"]}, "output": ["LATENT", "VAE"], "output_is_list": [false, false], "output_name": ["LATENT", "VAE"], "name": "KSamplerPipe //Inspire", "display_name": "KSampler [pipe] (inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/a1111_compat", "output_node": false}, "KSamplerAdvancedPipe //Inspire": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"], "add_noise": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed for the initial noise applied to the latent."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "latent_image": ["LATENT"], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000}], "noise_mode": [["GPU(=A1111)", "CPU", "GPU+internal_seed", "CPU+internal_seed"]], "return_with_leftover_noise": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "batch_seed_mode": [["incremental", "comfy", "variation str inc:0.01", "variation str inc:0.05"]], "variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"noise_opt": ["NOISE_IMAGE"], "scheduler_func_opt": ["SCHEDULER_FUNC"], "internal_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed used for generating noise in intermediate steps when using ancestral and SDE-based samplers.\nNOTE: If `noise_mode` is in GPU mode and `internal_seed` is the same as `seed`, the generated image may be distorted."}]}}, "input_order": {"required": ["basic_pipe", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "latent_image", "start_at_step", "end_at_step", "noise_mode", "return_with_leftover_noise", "batch_seed_mode", "variation_seed", "variation_strength"], "optional": ["noise_opt", "scheduler_func_opt", "internal_seed"]}, "output": ["LATENT", "VAE"], "output_is_list": [false, false], "output_name": ["LATENT", "VAE"], "name": "KSamplerAdvancedPipe //Inspire", "display_name": "KSamplerAdvanced [pipe] (inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/a1111_compat", "output_node": false}, "RandomNoise //Inspire": {"input": {"required": {"noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed for the initial noise applied to the latent."}], "noise_mode": [["GPU(=A1111)", "CPU"]], "batch_seed_mode": [["incremental", "comfy", "variation str inc:0.01", "variation str inc:0.05"]], "variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"variation_method": [["linear", "slerp"]], "internal_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "This is the seed used for generating noise in intermediate steps when using ancestral and SDE-based samplers.\nNOTE: If `noise_mode` is in GPU mode and `internal_seed` is the same as `seed`, the generated image may be distorted."}]}}, "input_order": {"required": ["noise_seed", "noise_mode", "batch_seed_mode", "variation_seed", "variation_strength"], "optional": ["variation_method", "internal_seed"]}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "RandomNoise //Inspire", "display_name": "RandomNoise (inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/a1111_compat", "output_node": false}, "HyperTile //Inspire": {"input": {"required": {"model": ["MODEL"], "tile_size": ["INT", {"default": 256, "min": 1, "max": 2048}], "swap_size": ["INT", {"default": 2, "min": 1, "max": 128}], "max_depth": ["INT", {"default": 0, "min": 0, "max": 10}], "scale_depth": ["BOOLEAN", {"default": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["model", "tile_size", "swap_size", "max_depth", "scale_depth", "seed"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "HyperTile //Inspire", "display_name": "HyperTile (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/__for_testing", "output_node": false}, "LoadPromptsFromDir //Inspire": {"input": {"required": {"prompt_dir": [["example"]]}, "optional": {"reload": ["BOOLEAN", {"default": false, "label_on": "if file changed", "label_off": "if value changed"}], "load_cap": ["INT", {"default": 0, "min": 0, "step": 1, "advanced": true, "tooltip": "The amount of prompts to load at once:\n0: Load all\n1 or higher: Load a specified number"}], "start_index": ["INT", {"default": 0, "min": -1, "step": 1, "max": 18446744073709551615, "advanced": true, "tooltip": "Starting index for loading prompts:\n-1: The last prompt\n0 or higher: Load from the specified index"}]}}, "input_order": {"required": ["prompt_dir"], "optional": ["reload", "load_cap", "start_index"]}, "output": ["ZIPPED_PROMPT", "INT", "INT"], "output_is_list": [true, false, false], "output_name": ["zipped_prompt", "count", "remaining_count"], "name": "LoadPromptsFromDir //Inspire", "display_name": "Load Prompts From Dir (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "LoadPromptsFromFile //Inspire": {"input": {"required": {"prompt_file": [["example/prompt2.txt", "example/prompt1.txt"]]}, "optional": {"text_data_opt": ["STRING", {"defaultInput": true}], "reload": ["BOOLEAN", {"default": false, "label_on": "if file changed", "label_off": "if value changed"}], "load_cap": ["INT", {"default": 0, "min": 0, "step": 1, "advanced": true, "tooltip": "The amount of prompts to load at once:\n0: Load all\n1 or higher: Load a specified number"}], "start_index": ["INT", {"default": 0, "min": -1, "max": 18446744073709551615, "step": 1, "advanced": true, "tooltip": "Starting index for loading prompts:\n-1: The last prompt\n0 or higher: Load from the specified index"}]}}, "input_order": {"required": ["prompt_file"], "optional": ["text_data_opt", "reload", "load_cap", "start_index"]}, "output": ["ZIPPED_PROMPT", "INT", "INT"], "output_is_list": [true, false, false], "output_name": ["zipped_prompt", "count", "remaining_count"], "name": "LoadPromptsFromFile //Inspire", "display_name": "Load Prompts From File (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "LoadSinglePromptFromFile //Inspire": {"input": {"required": {"prompt_file": [["example/prompt2.txt", "example/prompt1.txt"]], "index": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}, "optional": {"text_data_opt": ["STRING", {"defaultInput": true}]}}, "input_order": {"required": ["prompt_file", "index"], "optional": ["text_data_opt"]}, "output": ["ZIPPED_PROMPT"], "output_is_list": [true], "output_name": ["ZIPPED_PROMPT"], "name": "LoadSinglePromptFromFile //Inspire", "display_name": "Load Single Prompt From File (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "UnzipPrompt //Inspire": {"input": {"required": {"zipped_prompt": ["ZIPPED_PROMPT"]}}, "input_order": {"required": ["zipped_prompt"]}, "output": ["STRING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "name"], "name": "UnzipPrompt //Inspire", "display_name": "Unzip Prompt (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "ZipPrompt //Inspire": {"input": {"required": {"positive": ["STRING", {"forceInput": true, "multiline": true}], "negative": ["STRING", {"forceInput": true, "multiline": true}]}, "optional": {"name_opt": ["STRING", {"forceInput": true, "multiline": false}]}}, "input_order": {"required": ["positive", "negative"], "optional": ["name_opt"]}, "output": ["ZIPPED_PROMPT"], "output_is_list": [false], "output_name": ["ZIPPED_PROMPT"], "name": "ZipPrompt //Inspire", "display_name": "Zip Prompt (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "PromptExtractor //Inspire": {"input": {"required": {"image": [["example.png"], {"image_upload": true}], "positive_id": ["STRING", {}], "negative_id": ["STRING", {}], "info": ["STRING", {"multiline": true}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["image", "positive_id", "negative_id", "info"], "hidden": ["unique_id"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PromptExtractor //Inspire", "display_name": "Prompt Extractor (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": true}, "GlobalSeed //Inspire": {"input": {"required": {"value": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "mode": ["BOOLEAN", {"default": true, "label_on": "control_before_generate", "label_off": "control_after_generate"}], "action": [["fixed", "increment", "decrement", "randomize", "increment for each node", "decrement for each node", "randomize for each node"]], "last_seed": ["STRING", {"default": ""}]}}, "input_order": {"required": ["value", "mode", "action", "last_seed"]}, "output": [], "output_is_list": [], "output_name": [], "name": "GlobalSeed //Inspire", "display_name": "Global Seed (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": true}, "GlobalSampler //Inspire": {"input": {"required": {"sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]]}}, "input_order": {"required": ["sampler_name", "scheduler"]}, "output": [], "output_is_list": [], "output_name": [], "name": "GlobalSampler //Inspire", "display_name": "Global Sampler (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": true}, "BindImageListPromptList //Inspire": {"input": {"required": {"images": ["IMAGE"], "zipped_prompts": ["ZIPPED_PROMPT"], "default_positive": ["STRING", {"multiline": true, "placeholder": "default positive"}], "default_negative": ["STRING", {"multiline": true, "placeholder": "default negative"}]}}, "input_order": {"required": ["images", "zipped_prompts", "default_positive", "default_negative"]}, "output": ["IMAGE", "STRING", "STRING", "STRING"], "output_is_list": [true, true, true], "output_name": ["image", "positive", "negative", "prompt_label"], "name": "BindImageListPromptList //Inspire", "display_name": "Bind [ImageList, PromptList] (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "WildcardEncode //Inspire": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "token_normalization": [["none", "mean", "length", "length+mean"]], "weight_interpretation": [["comfy", "A1111", "compel", "comfy++", "down_weight"], {"default": "comfy++"}], "wildcard_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "Wildcard Prompt (User Input)"}], "populated_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "Populated Prompt (Will be generated automatically)"}], "mode": [["populate", "fixed", "reproduce"], {"default": "populate", "tooltip": "populate: Before running the workflow, it overwrites the existing value of 'populated_text' with the prompt processed from 'wildcard_text'. In this mode, 'populated_text' cannot be edited.\nfixed: Ignores wildcard_text and keeps 'populated_text' as is. You can edit 'populated_text' in this mode.\nreproduce: This mode operates as 'fixed' mode only once for reproduction, and then it switches to 'populate' mode."}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["model", "clip", "token_normalization", "weight_interpretation", "wildcard_text", "populated_text", "mode", "Select to add LoRA", "Select to add Wildcard", "seed"]}, "output": ["MODEL", "CLIP", "CONDITIONING", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["model", "clip", "conditioning", "populated_text"], "name": "WildcardEncode //Inspire", "display_name": "Wildcard Encode (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "PromptBuilder //Inspire": {"input": {"required": {"category": [["Angle of View", "Artists", "Character Types", "Colors", "Composition", "Composition Form", "Lighting", "Negative", "Picture Effect", "Picture Quality", "Setting", "Shot", "Style", "#PLACEHOLDER"]], "preset": [["#PRESET"]], "text": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["category", "preset", "text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "PromptBuilder //Inspire", "display_name": "Prompt Builder (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "SeedExplorer //Inspire": {"input": {"required": {"latent": ["LATENT"], "seed_prompt": ["STRING", {"multiline": true, "dynamicPrompts": false, "pysssss.autocomplete": false}], "enable_additional": ["BOOLEAN", {"default": true, "label_on": "true", "label_off": "false"}], "additional_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "additional_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_mode": [["GPU(=A1111)", "CPU"]], "initial_batch_seed_mode": [["incremental", "comfy"]]}, "optional": {"variation_method": [["linear", "slerp"]], "model": ["MODEL"]}}, "input_order": {"required": ["latent", "seed_prompt", "enable_additional", "additional_seed", "additional_strength", "noise_mode", "initial_batch_seed_mode"], "optional": ["variation_method", "model"]}, "output": ["NOISE_IMAGE"], "output_is_list": [false], "output_name": ["NOISE_IMAGE"], "name": "SeedExplorer //Inspire", "display_name": "Seed Explorer (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "ListCounter //Inspire": {"input": {"required": {"signal": ["*"], "base_value": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["signal", "base_value"], "hidden": ["unique_id"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "ListCounter //Inspire", "display_name": "List Counter (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "CLIPTextEncodeWithWeight //Inspire": {"input": {"required": {"text": ["STRING", {"multiline": true}], "clip": ["CLIP"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "add_weight": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["text", "clip", "strength", "add_weight"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeWithWeight //Inspire", "display_name": "CLIPTextEncodeWithWeight (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "RandomGeneratorForList //Inspire": {"input": {"required": {"signal": ["*"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["signal", "seed"], "hidden": ["unique_id"]}, "output": ["*", "INT"], "output_is_list": [false, false], "output_name": ["signal", "random_value"], "name": "RandomGeneratorForList //Inspire", "display_name": "Random Generator for List (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "MakeBasicPipe //Inspire": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]], "ckpt_key_opt": ["STRING", {"multiline": false, "placeholder": "If empty, use 'ckpt_name' as the key."}], "positive_wildcard_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "Positive Prompt (User Input)"}], "negative_wildcard_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "Negative Prompt (User Input)"}], "Add selection to": ["BOOLEAN", {"default": true, "label_on": "Positive", "label_off": "Negative"}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]], "wildcard_mode": [["populate", "fixed", "reproduce"], {"default": "populate", "tooltip": "populate: Before running the workflow, it overwrites the existing value of 'populated_text' with the prompt processed from 'wildcard_text'. In this mode, 'populated_text' cannot be edited.\nfixed: Ignores wildcard_text and keeps 'populated_text' as is. You can edit 'populated_text' in this mode.\nreproduce: This mode operates as 'fixed' mode only once for reproduction, and then it switches to 'populate' mode."}], "positive_populated_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "Populated Positive Prompt (Will be generated automatically)"}], "negative_populated_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "Populated Negative Prompt (Will be generated automatically)"}], "token_normalization": [["none", "mean", "length", "length+mean"]], "weight_interpretation": [["comfy", "A1111", "compel", "comfy++", "down_weight"], {"default": "comfy++"}], "stop_at_clip_layer": ["INT", {"default": -2, "min": -24, "max": -1, "step": 1}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}, "optional": {"vae_opt": ["VAE"]}}, "input_order": {"required": ["ckpt_name", "ckpt_key_opt", "positive_wildcard_text", "negative_wildcard_text", "Add selection to", "Select to add LoRA", "Select to add Wildcard", "wildcard_mode", "positive_populated_text", "negative_populated_text", "token_normalization", "weight_interpretation", "stop_at_clip_layer", "seed"], "optional": ["vae_opt"]}, "output": ["BASIC_PIPE", "STRING"], "output_is_list": [false, false], "output_name": ["basic_pipe", "cache_key"], "name": "MakeBasicPipe //Inspire", "display_name": "Make Basic Pipe (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "RemoveControlNet //Inspire": {"input": {"required": {"conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "RemoveControlNet //Inspire", "display_name": "Remove ControlNet (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "RemoveControlNetFromRegionalPrompts //Inspire": {"input": {"required": {"regional_prompts": ["REGIONAL_PROMPTS"]}}, "input_order": {"required": ["regional_prompts"]}, "output": ["REGIONAL_PROMPTS"], "output_is_list": [false], "output_name": ["REGIONAL_PROMPTS"], "name": "RemoveControlNetFromRegionalPrompts //Inspire", "display_name": "Remove ControlNet [RegionalPrompts] (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "CompositeNoise //Inspire": {"input": {"required": {"destination": ["NOISE_IMAGE"], "source": ["NOISE_IMAGE"], "mode": [["center", "left-top", "right-top", "left-bottom", "right-bottom", "xy"]], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["destination", "source", "mode", "x", "y"]}, "output": ["NOISE_IMAGE"], "output_is_list": [false], "output_name": ["NOISE_IMAGE"], "name": "CompositeNoise //Inspire", "display_name": "Composite Noise (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Prompt", "output_node": false}, "LoadImagesFromDir //Inspire": {"input": {"required": {"directory": ["STRING", {"default": ""}]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "step": 1}], "start_index": ["INT", {"default": 0, "min": -1, "max": 18446744073709551615, "step": 1}], "load_always": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "start_index", "load_always"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "INT"], "name": "LoadImagesFromDir //Inspire", "display_name": "Load Image Batch From Dir (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "image", "output_node": false}, "LoadImageListFromDir //Inspire": {"input": {"required": {"directory": ["STRING", {"default": ""}]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "step": 1}], "start_index": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "step": 1}], "load_always": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "start_index", "load_always"]}, "output": ["IMAGE", "MASK", "STRING"], "output_is_list": [true, true, true], "output_name": ["IMAGE", "MASK", "FILE PATH"], "name": "LoadImageListFromDir //Inspire", "display_name": "Load Image List From Dir (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "image", "output_node": false}, "LoadImage //Inspire": {"input": {"required": {"image": [["example.png", "#DATA"], {"image_upload": true}], "image_data": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["image", "image_data"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImage //Inspire", "display_name": "Load Image (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/image", "output_node": false}, "ChangeImageBatchSize //Inspire": {"input": {"required": {"image": ["IMAGE"], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "mode": [["simple"]]}}, "input_order": {"required": ["image", "batch_size", "mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ChangeImageBatchSize //Inspire", "display_name": "Change Image Batch Size (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "ChangeLatentBatchSize //Inspire": {"input": {"required": {"latent": ["LATENT"], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "mode": [["simple"]]}}, "input_order": {"required": ["latent", "batch_size", "mode"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ChangeLatentBatchSize //Inspire", "display_name": "Change Latent Batch Size (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "ImageBatchSplitter //Inspire": {"input": {"required": {"images": ["IMAGE"], "split_count": ["INT", {"default": 4, "min": 0, "max": 50, "step": 1}]}}, "input_order": {"required": ["images", "split_count"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatchSplitter //Inspire", "display_name": "Image Batch Splitter (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "LatentBatchSplitter //Inspire": {"input": {"required": {"latent": ["LATENT"], "split_count": ["INT", {"default": 4, "min": 0, "max": 50, "step": 1}]}}, "input_order": {"required": ["latent", "split_count"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentBatchSplitter //Inspire", "display_name": "Latent Batch Splitter (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "ColorMapToMasks //Inspire": {"input": {"required": {"color_map": ["IMAGE"], "min_pixels": ["INT", {"default": 500, "min": 1, "max": 18446744073709551615, "step": 1}], "max_count": ["INT", {"default": 5, "min": 0, "max": 1000, "step": 1}]}}, "input_order": {"required": ["color_map", "min_pixels", "max_count"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ColorMapToMasks //Inspire", "display_name": "Color Map To Masks (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "SelectNthMask //Inspire": {"input": {"required": {"masks": ["MASK"], "idx": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["masks", "idx"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SelectNthMask //Inspire", "display_name": "Select Nth Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "RegionalPromptSimple //Inspire": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"], "mask": ["MASK"], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "wildcard_prompt": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "wildcard prompt"}], "controlnet_in_pipe": ["BOOLEAN", {"default": false, "label_on": "Keep", "label_off": "Override"}], "sigma_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}, "optional": {"variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "variation_method": [["linear", "slerp"]], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["basic_pipe", "mask", "cfg", "sampler_name", "scheduler", "wildcard_prompt", "controlnet_in_pipe", "sigma_factor"], "optional": ["variation_seed", "variation_strength", "variation_method", "scheduler_func_opt"]}, "output": ["REGIONAL_PROMPTS"], "output_is_list": [false], "output_name": ["REGIONAL_PROMPTS"], "name": "RegionalPromptSimple //Inspire", "display_name": "Regional Prompt Simple (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalPromptColorMask //Inspire": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"], "color_mask": ["IMAGE"], "mask_color": ["STRING", {"multiline": false, "default": "#FFFFFF"}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "wildcard_prompt": ["STRING", {"multiline": true, "dynamicPrompts": false, "placeholder": "wildcard prompt"}], "controlnet_in_pipe": ["BOOLEAN", {"default": false, "label_on": "Keep", "label_off": "Override"}], "sigma_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}, "optional": {"variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "variation_method": [["linear", "slerp"]], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["basic_pipe", "color_mask", "mask_color", "cfg", "sampler_name", "scheduler", "wildcard_prompt", "controlnet_in_pipe", "sigma_factor"], "optional": ["variation_seed", "variation_strength", "variation_method", "scheduler_func_opt"]}, "output": ["REGIONAL_PROMPTS", "MASK"], "output_is_list": [false, false], "output_name": ["REGIONAL_PROMPTS", "MASK"], "name": "RegionalPromptColorMask //Inspire", "display_name": "Regional Prompt By Color Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalConditioningSimple //Inspire": {"input": {"required": {"clip": ["CLIP"], "mask": ["MASK"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]], "prompt": ["STRING", {"multiline": true, "placeholder": "prompt"}]}}, "input_order": {"required": ["clip", "mask", "strength", "set_cond_area", "prompt"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "RegionalConditioningSimple //Inspire", "display_name": "Regional Conditioning Simple (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalConditioningColorMask //Inspire": {"input": {"required": {"clip": ["CLIP"], "color_mask": ["IMAGE"], "mask_color": ["STRING", {"multiline": false, "default": "#FFFFFF"}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]], "prompt": ["STRING", {"multiline": true, "placeholder": "prompt"}]}, "optional": {"dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["clip", "color_mask", "mask_color", "strength", "set_cond_area", "prompt"], "optional": ["dilation"]}, "output": ["CONDITIONING", "MASK"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "MASK"], "name": "RegionalConditioningColorMask //Inspire", "display_name": "Regional Conditioning By Color Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalIPAdapterMask //Inspire": {"input": {"required": {"mask": ["MASK"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 0.7, "min": -1, "max": 3, "step": 0.05}], "noise": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "unfold_batch": ["BOOLEAN", {"default": false}]}, "optional": {"faceid_v2": ["BOOLEAN", {"default": false}], "weight_v2": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "neg_image": ["IMAGE"]}}, "input_order": {"required": ["mask", "image", "weight", "noise", "weight_type", "start_at", "end_at", "unfold_batch"], "optional": ["faceid_v2", "weight_v2", "combine_embeds", "neg_image"]}, "output": ["REGIONAL_IPADAPTER"], "output_is_list": [false], "output_name": ["REGIONAL_IPADAPTER"], "name": "RegionalIPAdapterMask //Inspire", "display_name": "Regional IPAdapter Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalIPAdapterColorMask //Inspire": {"input": {"required": {"color_mask": ["IMAGE"], "mask_color": ["STRING", {"multiline": false, "default": "#FFFFFF"}], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 0.7, "min": -1, "max": 3, "step": 0.05}], "noise": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "unfold_batch": ["BOOLEAN", {"default": false}]}, "optional": {"faceid_v2": ["BOOLEAN", {"default": false}], "weight_v2": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "neg_image": ["IMAGE"]}}, "input_order": {"required": ["color_mask", "mask_color", "image", "weight", "noise", "weight_type", "start_at", "end_at", "unfold_batch"], "optional": ["faceid_v2", "weight_v2", "combine_embeds", "neg_image"]}, "output": ["REGIONAL_IPADAPTER", "MASK"], "output_is_list": [false, false], "output_name": ["REGIONAL_IPADAPTER", "MASK"], "name": "RegionalIPAdapterColorMask //Inspire", "display_name": "Regional IPAdapter By Color Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalIPAdapterEncodedMask //Inspire": {"input": {"required": {"mask": ["MASK"], "embeds": ["EMBEDS"], "weight": ["FLOAT", {"default": 0.7, "min": -1, "max": 3, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "unfold_batch": ["BOOLEAN", {"default": false}]}, "optional": {"neg_embeds": ["EMBEDS"]}}, "input_order": {"required": ["mask", "embeds", "weight", "weight_type", "start_at", "end_at", "unfold_batch"], "optional": ["neg_embeds"]}, "output": ["REGIONAL_IPADAPTER"], "output_is_list": [false], "output_name": ["REGIONAL_IPADAPTER"], "name": "RegionalIPAdapterEncodedMask //Inspire", "display_name": "Regional IPAdapter Encoded Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalIPAdapterEncodedColorMask //Inspire": {"input": {"required": {"color_mask": ["IMAGE"], "mask_color": ["STRING", {"multiline": false, "default": "#FFFFFF"}], "embeds": ["EMBEDS"], "weight": ["FLOAT", {"default": 0.7, "min": -1, "max": 3, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "unfold_batch": ["BOOLEAN", {"default": false}]}, "optional": {"neg_embeds": ["EMBEDS"]}}, "input_order": {"required": ["color_mask", "mask_color", "embeds", "weight", "weight_type", "start_at", "end_at", "unfold_batch"], "optional": ["neg_embeds"]}, "output": ["REGIONAL_IPADAPTER", "MASK"], "output_is_list": [false, false], "output_name": ["REGIONAL_IPADAPTER", "MASK"], "name": "RegionalIPAdapterEncodedColorMask //Inspire", "display_name": "Regional IPAdapter Encoded By Color Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalSeedExplorerMask //Inspire": {"input": {"required": {"mask": ["MASK"], "noise": ["NOISE_IMAGE"], "seed_prompt": ["STRING", {"multiline": true, "dynamicPrompts": false, "pysssss.autocomplete": false}], "enable_additional": ["BOOLEAN", {"default": true, "label_on": "true", "label_off": "false"}], "additional_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "additional_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_mode": [["GPU(=A1111)", "CPU"]]}, "optional": {"variation_method": [["linear", "slerp"]]}}, "input_order": {"required": ["mask", "noise", "seed_prompt", "enable_additional", "additional_seed", "additional_strength", "noise_mode"], "optional": ["variation_method"]}, "output": ["NOISE_IMAGE"], "output_is_list": [false], "output_name": ["NOISE_IMAGE"], "name": "RegionalSeedExplorerMask //Inspire", "display_name": "Regional Seed Explorer By Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalSeedExplorerColorMask //Inspire": {"input": {"required": {"color_mask": ["IMAGE"], "mask_color": ["STRING", {"multiline": false, "default": "#FFFFFF"}], "noise": ["NOISE_IMAGE"], "seed_prompt": ["STRING", {"multiline": true, "dynamicPrompts": false, "pysssss.autocomplete": false}], "enable_additional": ["BOOLEAN", {"default": true, "label_on": "true", "label_off": "false"}], "additional_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "additional_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_mode": [["GPU(=A1111)", "CPU"]]}, "optional": {"variation_method": [["linear", "slerp"]]}}, "input_order": {"required": ["color_mask", "mask_color", "noise", "seed_prompt", "enable_additional", "additional_seed", "additional_strength", "noise_mode"], "optional": ["variation_method"]}, "output": ["NOISE_IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["NOISE_IMAGE", "MASK"], "name": "RegionalSeedExplorerColorMask //Inspire", "display_name": "Regional Seed Explorer By Color Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "ToIPAdapterPipe //Inspire": {"input": {"required": {"ipadapter": ["IPADAPTER"], "model": ["MODEL"]}, "optional": {"clip_vision": ["CLIP_VISION"], "insightface": ["INSIGHTFACE"]}}, "input_order": {"required": ["ipadapter", "model"], "optional": ["clip_vision", "insightface"]}, "output": ["IPADAPTER_PIPE"], "output_is_list": [false], "output_name": ["IPADAPTER_PIPE"], "name": "ToIPAdapterPipe //Inspire", "display_name": "ToIPAdapterPipe (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "FromIPAdapterPipe //Inspire": {"input": {"required": {"ipadapter_pipe": ["IPADAPTER_PIPE"]}}, "input_order": {"required": ["ipadapter_pipe"]}, "output": ["IPADAPTER", "MODEL", "CLIP_VISION", "INSIGHTFACE"], "output_is_list": [false, false, false, false], "output_name": ["ipadapter", "model", "clip_vision", "insight_face"], "name": "FromIPAdapterPipe //Inspire", "display_name": "FromIPAdapterPipe (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "ApplyRegionalIPAdapters //Inspire": {"input": {"required": {"ipadapter_pipe": ["IPADAPTER_PIPE"], "regional_ipadapter1": ["REGIONAL_IPADAPTER"]}}, "input_order": {"required": ["ipadapter_pipe", "regional_ipadapter1"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyRegionalIPAdapters //Inspire", "display_name": "Apply Regional IPAdapters (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "RegionalCFG //Inspire": {"input": {"required": {"model": ["MODEL"], "mask": ["MASK"]}}, "input_order": {"required": ["model", "mask"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "RegionalCFG //Inspire", "display_name": "Regional CFG (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "ColorMaskToDepthMask //Inspire": {"input": {"required": {"color_mask": ["IMAGE"], "spec": ["STRING", {"multiline": true, "default": "#FF0000:1.0\n#000000:1.0"}], "base_value": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0}], "dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "flatten_method": [["override", "sum", "max"]]}}, "input_order": {"required": ["color_mask", "spec", "base_value", "dilation", "flatten_method"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ColorMaskToDepthMask //Inspire", "display_name": "Color Mask To Depth Mask (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Regional", "output_node": false}, "KSamplerProgress //Inspire": {"input": {"required": {"model": ["MODEL"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_mode": [["GPU(=A1111)", "CPU", "GPU+internal_seed", "CPU+internal_seed"]], "interval": ["INT", {"default": 1, "min": 1, "max": 10000}], "omit_start_latent": ["BOOLEAN", {"default": true, "label_on": "True", "label_off": "False"}], "omit_final_latent": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}]}, "optional": {"scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise", "noise_mode", "interval", "omit_start_latent", "omit_final_latent"], "optional": ["scheduler_func_opt"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["latent", "progress_latent"], "name": "KSamplerProgress //Inspire", "display_name": "KSampler Progress (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/analysis", "output_node": false}, "KSamplerAdvancedProgress //Inspire": {"input": {"required": {"model": ["MODEL"], "add_noise": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000}], "noise_mode": [["GPU(=A1111)", "CPU", "GPU+internal_seed", "CPU+internal_seed"]], "return_with_leftover_noise": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}], "interval": ["INT", {"default": 1, "min": 1, "max": 10000}], "omit_start_latent": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}], "omit_final_latent": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}]}, "optional": {"prev_progress_latent_opt": ["LATENT"], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "start_at_step", "end_at_step", "noise_mode", "return_with_leftover_noise", "interval", "omit_start_latent", "omit_final_latent"], "optional": ["prev_progress_latent_opt", "scheduler_func_opt"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["latent", "progress_latent"], "name": "KSamplerAdvancedProgress //Inspire", "display_name": "KSampler Advanced Progress (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/analysis", "output_node": false}, "ScheduledCFGGuider //Inspire": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "sigmas": ["SIGMAS"], "from_cfg": ["FLOAT", {"default": 6.5, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "to_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "schedule": [["linear", "log", "exp", "cos"], {"default": "log"}]}}, "input_order": {"required": ["model", "positive", "negative", "sigmas", "from_cfg", "to_cfg", "schedule"]}, "output": ["GUIDER", "SIGMAS"], "output_is_list": [false, false], "output_name": ["GUIDER", "SIGMAS"], "name": "ScheduledCFGGuider //Inspire", "display_name": "Scheduled CFGGuider (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "sampling/custom_sampling/guiders", "output_node": false}, "ScheduledPerpNegCFGGuider //Inspire": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "empty_conditioning": ["CONDITIONING"], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}], "sigmas": ["SIGMAS"], "from_cfg": ["FLOAT", {"default": 6.5, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "to_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "schedule": [["linear", "log", "exp", "cos"], {"default": "log"}]}}, "input_order": {"required": ["model", "positive", "negative", "empty_conditioning", "neg_scale", "sigmas", "from_cfg", "to_cfg", "schedule"]}, "output": ["GUIDER", "SIGMAS"], "output_is_list": [false, false], "output_name": ["GUIDER", "SIGMAS"], "name": "ScheduledPerpNegCFGGuider //Inspire", "display_name": "Scheduled PerpNeg CFGGuider (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "sampling/custom_sampling/guiders", "output_node": false}, "CacheBackendData //Inspire": {"input": {"required": {"key": ["STRING", {"multiline": false, "placeholder": "Input data key (e.g. 'model a', 'chunli lora', 'girl latent 3', ...)"}], "tag": ["STRING", {"multiline": false, "placeholder": "Tag: short description"}], "data": ["*"]}}, "input_order": {"required": ["key", "tag", "data"]}, "output": ["*"], "output_is_list": [false], "output_name": ["data opt"], "name": "CacheBackendData //Inspire", "display_name": "Cache Backend Data (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "CacheBackendDataNumberKey //Inspire": {"input": {"required": {"key": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "tag": ["STRING", {"multiline": false, "placeholder": "Tag: short description"}], "data": ["*"]}}, "input_order": {"required": ["key", "tag", "data"]}, "output": ["*"], "output_is_list": [false], "output_name": ["data opt"], "name": "CacheBackendDataNumberKey //Inspire", "display_name": "Cache Backend Data [NumberKey] (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "CacheBackendDataList //Inspire": {"input": {"required": {"key": ["STRING", {"multiline": false, "placeholder": "Input data key (e.g. 'model a', 'chunli lora', 'girl latent 3', ...)"}], "tag": ["STRING", {"multiline": false, "placeholder": "Tag: short description"}], "data": ["*"]}}, "input_order": {"required": ["key", "tag", "data"]}, "output": ["*"], "output_is_list": [true], "output_name": ["data opt"], "name": "CacheBackendDataList //Inspire", "display_name": "Cache Backend Data List (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "CacheBackendDataNumberKeyList //Inspire": {"input": {"required": {"key": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "tag": ["STRING", {"multiline": false, "placeholder": "Tag: short description"}], "data": ["*"]}}, "input_order": {"required": ["key", "tag", "data"]}, "output": ["*"], "output_is_list": [true], "output_name": ["data opt"], "name": "CacheBackendDataNumberKeyList //Inspire", "display_name": "Cache Backend Data List [NumberKey] (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "RetrieveBackendData //Inspire": {"input": {"required": {"key": ["STRING", {"multiline": false, "placeholder": "Input data key (e.g. 'model a', 'chunli lora', 'girl latent 3', ...)"}]}}, "input_order": {"required": ["key"]}, "output": ["*"], "output_is_list": [true], "output_name": ["data"], "name": "RetrieveBackendData //Inspire", "display_name": "Retrieve Backend Data (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false}, "RetrieveBackendDataNumberKey //Inspire": {"input": {"required": {"key": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["key"]}, "output": ["*"], "output_is_list": [true], "output_name": ["data"], "name": "RetrieveBackendDataNumberKey //Inspire", "display_name": "Retrieve Backend Data [NumberKey] (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false}, "RemoveBackendData //Inspire": {"input": {"required": {"key": ["STRING", {"multiline": false, "placeholder": "Input data key ('*' = clear all)"}]}, "optional": {"signal_opt": ["*"]}}, "input_order": {"required": ["key"], "optional": ["signal_opt"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal"], "name": "RemoveBackendData //Inspire", "display_name": "Remove Backend Data (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "RemoveBackendDataNumberKey //Inspire": {"input": {"required": {"key": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}, "optional": {"signal_opt": ["*"]}}, "input_order": {"required": ["key"], "optional": ["signal_opt"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal"], "name": "RemoveBackendDataNumberKey //Inspire", "display_name": "Remove Backend Data [NumberKey] (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "ShowCachedInfo //Inspire": {"input": {"required": {"cache_info": ["STRING", {"multiline": true, "default": ""}], "key": ["STRING", {"multiline": false, "default": ""}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["cache_info", "key"], "hidden": ["unique_id"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ShowCachedInfo //Inspire", "display_name": "Show Cached Info (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": true}, "CheckpointLoaderSimpleShared //Inspire": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]], "key_opt": ["STRING", {"multiline": false, "placeholder": "If empty, use 'ckpt_name' as the key."}]}, "optional": {"mode": [["Auto", "Override Cache", "Read Only"]]}}, "input_order": {"required": ["ckpt_name", "key_opt"], "optional": ["mode"]}, "output": ["MODEL", "CLIP", "VAE", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["model", "clip", "vae", "cache key"], "name": "CheckpointLoaderSimpleShared //Inspire", "display_name": "Shared Checkpoint Loader (Inspire)", "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false, "output_tooltips": ["The model used for denoising latents.", "The CLIP model used for encoding text prompts.", "The VAE model used for encoding and decoding images to and from latent space."]}, "LoadDiffusionModelShared //Inspire": {"input": {"required": {"model_name": [["IC-Light/iclight_sd15_fc.safetensors", "flux-dev-de-distill.safetensors", "flux1-dev-fp8.safetensors", "flux1-dev.safetensors", "flux1-fill-dev.safetensors", "fluxmania_III.safetensors", "hunyuan_video_720_cfgdistill_fp8_e4m3fn.safetensors", "skyreels_hunyuan_i2v_fp8_e4m3fn.safetensors", "wan2.1_i2v_480p_14B_bf16.safetensors"], {"tooltip": "Diffusion Model Name"}], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"]], "key_opt": ["STRING", {"multiline": false, "placeholder": "If empty, use 'model_name' as the key."}], "mode": [["Auto", "Override Cache", "Read Only"]]}}, "input_order": {"required": ["model_name", "weight_dtype", "key_opt", "mode"]}, "output": ["MODEL", "STRING"], "output_is_list": [false, false], "output_name": ["model", "cache key"], "name": "LoadDiffusionModelShared //Inspire", "display_name": "Shared Diffusion Model Loader (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false}, "LoadTextEncoderShared //Inspire": {"input": {"required": {"model_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "model_name2": [["None", "Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "model_name3": [["None", "Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["stable_diffusion", "stable_cascade", "sd3", "stable_audio", "mochi", "ltxv", "pixart", "cosmos", "sdxl", "flux", "hunyuan_video"]], "key_opt": ["STRING", {"multiline": false, "placeholder": "If empty, use 'model_name' as the key."}], "mode": [["Auto", "Override Cache", "Read Only"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["model_name1", "model_name2", "model_name3", "type", "key_opt", "mode"], "optional": ["device"]}, "output": ["CLIP", "STRING"], "output_is_list": [false, false], "output_name": ["clip", "cache key"], "name": "LoadTextEncoderShared //Inspire", "display_name": "Shared Text Encoder Loader (Inspire)", "description": "[Recipes single]\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5 / clip-g / clip-l\nstable_audio: t5\nmochi: t5\ncosmos: old t5 xxl\n\n[Recipes dual]\nsdxl: clip-l, clip-g\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\nflux: clip-l, t5\n\n[Recipes triple]\nsd3: clip-l, clip-g, t5", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false}, "StableCascade_CheckpointLoader //Inspire": {"input": {"required": {"stage_b": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], {"default": "CRM.pth"}], "key_opt_b": ["STRING", {"multiline": false, "placeholder": "If empty, use 'stage_b' as the key."}], "stage_c": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], {"default": "CRM.pth"}], "key_opt_c": ["STRING", {"multiline": false, "placeholder": "If empty, use 'stage_c' as the key."}], "cache_mode": [["none", "stage_b", "stage_c", "all"], {"default": "none"}]}}, "input_order": {"required": ["stage_b", "key_opt_b", "stage_c", "key_opt_c", "cache_mode"]}, "output": ["MODEL", "VAE", "MODEL", "VAE", "CLIP_VISION", "CLIP", "STRING", "STRING"], "output_is_list": [false, false, false, false, false, false, false, false], "output_name": ["b_model", "b_vae", "c_model", "c_vae", "c_clip_vision", "clip", "key_b", "key_c"], "name": "StableCascade_CheckpointLoader //Inspire", "display_name": "Stable Cascade Checkpoint Loader (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false}, "IsCached //Inspire": {"input": {"required": {"key": ["STRING", {"multiline": false}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["key"], "hidden": ["unique_id"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "IsCached //Inspire", "display_name": "Is Cached (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Backend", "output_node": false}, "FloatRange //Inspire": {"input": {"required": {"start": ["FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1e-09}], "stop": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 1e-09}], "step": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 100.0, "step": 1e-09}], "limit": ["INT", {"default": 100, "min": 2, "max": 4096, "step": 1}], "ensure_end": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["start", "stop", "step", "limit", "ensure_end"]}, "output": ["FLOAT"], "output_is_list": [true], "output_name": ["FLOAT"], "name": "FloatRange //Inspire", "display_name": "Float Range (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/List", "output_node": false}, "WorklistToItemList //Inspire": {"input": {"required": {"item": ["*"]}}, "input_order": {"required": ["item"]}, "output": ["ITEM_LIST"], "output_is_list": [false], "output_name": ["item_list"], "name": "WorklistToItemList //Inspire", "display_name": "Worklist To Item List (Inspire)", "description": "The list in ComfyUI allows for repeated execution of a sub-workflow.\nThis groups these repetitions (a.k.a. list) into a single ITEM_LIST output.\nITEM_LIST can then be used in ForeachList.", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/List", "output_node": false}, "ForeachListBegin //Inspire": {"input": {"required": {"item_list": ["ITEM_LIST", {"tooltip": "ITEM_LIST containing items to be processed iteratively."}]}, "optional": {"initial_input": ["*", {"tooltip": "If initial_input is omitted, the first item in item_list is used as the initial value, and the processing starts from the second item in item_list."}]}}, "input_order": {"required": ["item_list"], "optional": ["initial_input"]}, "output": ["FOREACH_LIST_CONTROL", "ITEM_LIST", "*", "*"], "output_is_list": [false, false, false, false], "output_name": ["flow_control", "remained_list", "item", "intermediate_output"], "name": "ForeachListBegin //Inspire", "display_name": "\u25b6Foreach List (Inspire)", "description": "A starting node for performing iterative tasks by retrieving items one by one from the ITEM_LIST.\nGenerate a new intermediate_output using item and intermediate_output as inputs, then connect it to ForeachListEnd.\nNOTE:If initial_input is omitted, the first item in item_list is used as the initial value, and the processing starts from the second item in item_list.", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/List", "output_node": false, "output_tooltips": ["Pass ForeachListEnd as is to indicate the end of the iteration.", "Output the ITEM_LIST containing the remaining items during the iteration, passing ForeachListEnd as is to indicate the end of the iteration.", "Output the current item during the iteration.", "Output the intermediate results during the iteration."]}, "ForeachListEnd //Inspire": {"input": {"required": {"flow_control": ["FOREACH_LIST_CONTROL", {"rawLink": true, "tooltip": "Directly connect the output of ForeachListBegin, the starting node of the iteration."}], "remained_list": ["ITEM_LIST", {"tooltip": "Directly connect the output of ForeachListBegin, the starting node of the iteration."}], "intermediate_output": ["*", {"tooltip": "Connect the intermediate outputs processed within the iteration here."}]}, "hidden": {"dynprompt": "DYNPROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["flow_control", "remained_list", "intermediate_output"], "hidden": ["dynprompt", "unique_id"]}, "output": ["*"], "output_is_list": [false], "output_name": ["result"], "name": "ForeachListEnd //Inspire", "display_name": "Foreach List\u25c0 (Inspire)", "description": "A end node for performing iterative tasks by retrieving items one by one from the ITEM_LIST.\nNOTE:Directly connect the outputs of ForeachListBegin to 'flow_control' and 'remained_list'.", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/List", "output_node": false, "output_tooltips": ["This is the final output value."]}, "DropItems //Inspire": {"input": {"required": {"item_list": ["ITEM_LIST", {"tooltip": "Directly connect the output of ForeachListBegin, the starting node of the iteration."}]}}, "input_order": {"required": ["item_list"]}, "output": ["*"], "output_is_list": [false], "output_name": ["ITEM_LIST"], "name": "DropItems //Inspire", "display_name": "Drop Items (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/List", "output_node": false, "output_tooltips": ["This is the final output value."]}, "ConcatConditioningsWithMultiplier //Inspire": {"input": {"required": {"conditioning1": ["CONDITIONING"]}, "optional": {"multiplier1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning1"], "optional": ["multiplier1"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConcatConditioningsWithMultiplier //Inspire", "display_name": "Concat Conditionings with Multiplier (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/__for_testing", "output_node": false}, "ConditioningUpscale //Inspire": {"input": {"required": {"conditioning": ["CONDITIONING"], "scalar": ["INT", {"default": 2, "min": 1, "max": 100, "step": 0.5}]}}, "input_order": {"required": ["conditioning", "scalar"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningUpscale //Inspire", "display_name": "Conditioning Upscale (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/conditioning", "output_node": false}, "ConditioningStretch //Inspire": {"input": {"required": {"conditioning": ["CONDITIONING"], "resolutionX": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "resolutionY": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "newWidth": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "newHeight": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["conditioning", "resolutionX", "resolutionY", "newWidth", "newHeight"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningStretch //Inspire", "display_name": "Conditioning Stretch (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/conditioning", "output_node": false}, "IPAdapterModelHelper //Inspire": {"input": {"required": {"model": ["MODEL"], "preset": [["SD1.5", "SD1.5 Light v11", "SD1.5 Light", "SD1.5 Plus", "SD1.5 Plus Face", "SD1.5 Full Face", "SD1.5 ViT-G", "SDXL", "SDXL ViT-H", "SDXL Plus ViT-H", "SDXL Plus Face ViT-H", "Kolors Plus", "SD1.5 FaceID", "SD1.5 FaceID Plus v2", "SD1.5 FaceID Plus", "SD1.5 FaceID Portrait v11", "SD1.5 FaceID Portrait", "SDXL FaceID", "SDXL FaceID Plus v2", "SDXL FaceID Portrait", "SDXL FaceID Portrait unnorm", "Kolors FaceID Plus", "SD1.5 Plus Composition", "SDXL Plus Composition"]], "lora_strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "lora_strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "insightface_provider": [["CPU", "CUDA", "ROCM"]], "cache_mode": [["insightface only", "clip_vision only", "all", "none"], {"default": "insightface only"}]}, "optional": {"clip": ["CLIP"], "insightface_model_name": [["buffalo_l", "antelopev2"]]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["model", "preset", "lora_strength_model", "lora_strength_clip", "insightface_provider", "cache_mode"], "optional": ["clip", "insightface_model_name"], "hidden": ["unique_id"]}, "output": ["IPADAPTER_PIPE", "IPADAPTER", "CLIP_VISION", "INSIGHTFACE", "MODEL", "CLIP", "STRING", "STRING"], "output_is_list": [false, false, false, false, false, false, false, false], "output_name": ["IPADAPTER_PIPE", "IPADAPTER", "CLIP_VISION", "INSIGHTFACE", "MODEL", "CLIP", "insightface_cache_key", "clip_vision_cache_key"], "name": "IPAdapterModelHelper //Inspire", "display_name": "IPAdapter Model Helper (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/models", "output_node": false}, "RGB_HexToHSV //Inspire": {"input": {"required": {"rgb_hex": ["STRING", {"defaultInput": true}]}}, "input_order": {"required": ["rgb_hex"]}, "output": ["FLOAT", "FLOAT", "FLOAT"], "output_is_list": [false, false, false], "output_name": ["hue", "saturation", "value"], "name": "RGB_HexToHSV //Inspire", "display_name": "RGB Hex To HSV (Inspire)", "description": "", "python_module": "custom_nodes.ComfyUI-Inspire-Pack", "category": "InspirePack/Util", "output_node": false}, "CLIPTextEncodeSDXL+": {"input": {"required": {"width": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024.0, "min": 0, "max": 16384}], "size_cond_factor": ["INT", {"default": 4, "min": 1, "max": 16}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true, "default": ""}], "clip": ["CLIP"]}}, "input_order": {"required": ["width", "height", "size_cond_factor", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncodeSDXL+", "display_name": "\ud83d\udd27 SDXL CLIPTextEncode", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "ConditioningCombineMultiple+": {"input": {"required": {"conditioning_1": ["CONDITIONING"], "conditioning_2": ["CONDITIONING"]}, "optional": {"conditioning_3": ["CONDITIONING"], "conditioning_4": ["CONDITIONING"], "conditioning_5": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_1", "conditioning_2"], "optional": ["conditioning_3", "conditioning_4", "conditioning_5"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningCombineMultiple+", "display_name": "\ud83d\udd27 Cond Combine Multiple", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "SD3NegativeConditioning+": {"input": {"required": {"conditioning": ["CONDITIONING"], "end": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["conditioning", "end"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "SD3NegativeConditioning+", "display_name": "\ud83d\udd27 SD3 Negative Conditioning", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "FluxAttentionSeeker+": {"input": {"required": {"clip": ["CLIP"], "apply_to_query": ["BOOLEAN", {"default": true}], "apply_to_key": ["BOOLEAN", {"default": true}], "apply_to_value": ["BOOLEAN", {"default": true}], "apply_to_out": ["BOOLEAN", {"default": true}], "clip_l_0": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_1": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_2": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_3": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_4": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_5": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_6": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_7": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_8": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_9": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_10": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_11": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_0": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_1": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_2": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_3": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_4": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_5": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_6": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_7": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_8": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_9": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_10": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_11": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_12": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_13": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_14": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_15": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_16": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_17": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_18": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_19": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_20": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_21": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_22": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_23": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}]}}, "input_order": {"required": ["clip", "apply_to_query", "apply_to_key", "apply_to_value", "apply_to_out", "clip_l_0", "clip_l_1", "clip_l_2", "clip_l_3", "clip_l_4", "clip_l_5", "clip_l_6", "clip_l_7", "clip_l_8", "clip_l_9", "clip_l_10", "clip_l_11", "t5xxl_0", "t5xxl_1", "t5xxl_2", "t5xxl_3", "t5xxl_4", "t5xxl_5", "t5xxl_6", "t5xxl_7", "t5xxl_8", "t5xxl_9", "t5xxl_10", "t5xxl_11", "t5xxl_12", "t5xxl_13", "t5xxl_14", "t5xxl_15", "t5xxl_16", "t5xxl_17", "t5xxl_18", "t5xxl_19", "t5xxl_20", "t5xxl_21", "t5xxl_22", "t5xxl_23"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "FluxAttentionSeeker+", "display_name": "\ud83d\udd27 Flux Attention Seeker", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "SD3AttentionSeekerLG+": {"input": {"required": {"clip": ["CLIP"], "apply_to_query": ["BOOLEAN", {"default": true}], "apply_to_key": ["BOOLEAN", {"default": true}], "apply_to_value": ["BOOLEAN", {"default": true}], "apply_to_out": ["BOOLEAN", {"default": true}], "clip_l_0": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_1": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_2": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_3": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_4": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_5": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_6": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_7": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_8": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_9": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_10": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_l_11": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_0": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_1": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_2": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_3": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_4": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_5": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_6": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_7": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_8": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_9": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_10": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_11": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_12": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_13": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_14": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_15": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_16": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_17": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_18": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_19": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_20": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_21": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_22": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_23": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_24": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_25": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_26": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_27": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_28": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_29": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_30": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "clip_g_31": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}]}}, "input_order": {"required": ["clip", "apply_to_query", "apply_to_key", "apply_to_value", "apply_to_out", "clip_l_0", "clip_l_1", "clip_l_2", "clip_l_3", "clip_l_4", "clip_l_5", "clip_l_6", "clip_l_7", "clip_l_8", "clip_l_9", "clip_l_10", "clip_l_11", "clip_g_0", "clip_g_1", "clip_g_2", "clip_g_3", "clip_g_4", "clip_g_5", "clip_g_6", "clip_g_7", "clip_g_8", "clip_g_9", "clip_g_10", "clip_g_11", "clip_g_12", "clip_g_13", "clip_g_14", "clip_g_15", "clip_g_16", "clip_g_17", "clip_g_18", "clip_g_19", "clip_g_20", "clip_g_21", "clip_g_22", "clip_g_23", "clip_g_24", "clip_g_25", "clip_g_26", "clip_g_27", "clip_g_28", "clip_g_29", "clip_g_30", "clip_g_31"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "SD3AttentionSeekerLG+", "display_name": "\ud83d\udd27 SD3 Attention Seeker L/G", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "SD3AttentionSeekerT5+": {"input": {"required": {"clip": ["CLIP"], "apply_to_query": ["BOOLEAN", {"default": true}], "apply_to_key": ["BOOLEAN", {"default": true}], "apply_to_value": ["BOOLEAN", {"default": true}], "apply_to_out": ["BOOLEAN", {"default": true}], "t5xxl_0": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_1": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_2": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_3": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_4": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_5": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_6": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_7": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_8": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_9": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_10": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_11": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_12": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_13": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_14": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_15": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_16": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_17": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_18": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_19": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_20": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_21": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_22": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}], "t5xxl_23": ["FLOAT", {"display": "slider", "default": 1.0, "min": 0, "max": 5, "step": 0.05}]}}, "input_order": {"required": ["clip", "apply_to_query", "apply_to_key", "apply_to_value", "apply_to_out", "t5xxl_0", "t5xxl_1", "t5xxl_2", "t5xxl_3", "t5xxl_4", "t5xxl_5", "t5xxl_6", "t5xxl_7", "t5xxl_8", "t5xxl_9", "t5xxl_10", "t5xxl_11", "t5xxl_12", "t5xxl_13", "t5xxl_14", "t5xxl_15", "t5xxl_16", "t5xxl_17", "t5xxl_18", "t5xxl_19", "t5xxl_20", "t5xxl_21", "t5xxl_22", "t5xxl_23"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "SD3AttentionSeekerT5+", "display_name": "\ud83d\udd27 SD3 Attention Seeker T5", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "FluxBlocksBuster+": {"input": {"required": {"model": ["MODEL"], "blocks": ["STRING", {"default": "## 0 = 1.0\n## 1 = 1.0\n## 2 = 1.0\n## 3 = 1.0\n## 4 = 1.0\n## 5 = 1.0\n## 6 = 1.0\n## 7 = 1.0\n## 8 = 1.0\n## 9 = 1.0\n## 10 = 1.0\n## 11 = 1.0\n## 12 = 1.0\n## 13 = 1.0\n## 14 = 1.0\n## 15 = 1.0\n## 16 = 1.0\n## 17 = 1.0\n## 18 = 1.0\n# 0 = 1.0\n# 1 = 1.0\n# 2 = 1.0\n# 3 = 1.0\n# 4 = 1.0\n# 5 = 1.0\n# 6 = 1.0\n# 7 = 1.0\n# 8 = 1.0\n# 9 = 1.0\n# 10 = 1.0\n# 11 = 1.0\n# 12 = 1.0\n# 13 = 1.0\n# 14 = 1.0\n# 15 = 1.0\n# 16 = 1.0\n# 17 = 1.0\n# 18 = 1.0\n# 19 = 1.0\n# 20 = 1.0\n# 21 = 1.0\n# 22 = 1.0\n# 23 = 1.0\n# 24 = 1.0\n# 25 = 1.0\n# 26 = 1.0\n# 27 = 1.0\n# 28 = 1.0\n# 29 = 1.0\n# 30 = 1.0\n# 31 = 1.0\n# 32 = 1.0\n# 33 = 1.0\n# 34 = 1.0\n# 35 = 1.0\n# 36 = 1.0\n# 37 = 1.0", "multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["model", "blocks"]}, "output": ["MODEL", "STRING"], "output_is_list": [false, false], "output_name": ["MODEL", "patched_blocks"], "name": "FluxBlocksBuster+", "display_name": "\ud83d\udd27 Flux Model Blocks Buster", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/conditioning", "output_node": false}, "ImageEnhanceDifference+": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "exponent": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0, "step": 0.05}]}}, "input_order": {"required": ["image1", "image2", "exponent"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageEnhanceDifference+", "display_name": "\ud83d\udd27 Image Enhance Difference", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image analysis", "output_node": false}, "ImageBatchMultiple+": {"input": {"required": {"image_1": ["IMAGE"], "method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"], {"default": "lanczos"}]}, "optional": {"image_2": ["IMAGE"], "image_3": ["IMAGE"], "image_4": ["IMAGE"], "image_5": ["IMAGE"]}}, "input_order": {"required": ["image_1", "method"], "optional": ["image_2", "image_3", "image_4", "image_5"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatchMultiple+", "display_name": "\ud83d\udd27 Images Batch Multiple", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image batch", "output_node": false}, "ImageExpandBatch+": {"input": {"required": {"image": ["IMAGE"], "size": ["INT", {"default": 16, "min": 1, "step": 1}], "method": [["expand", "repeat all", "repeat first", "repeat last"]]}}, "input_order": {"required": ["image", "size", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageExpandBatch+", "display_name": "\ud83d\udd27 Image Expand Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image batch", "output_node": false}, "ImageFromBatch+": {"input": {"required": {"image": ["IMAGE"], "start": ["INT", {"default": 0, "min": 0, "step": 1}], "length": ["INT", {"default": -1, "min": -1, "step": 1}]}}, "input_order": {"required": ["image", "start", "length"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFromBatch+", "display_name": "\ud83d\udd27 Image From Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image batch", "output_node": false}, "ImageListToBatch+": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageListToBatch+", "display_name": "\ud83d\udd27 Image List To Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image batch", "output_node": false}, "ImageBatchToList+": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "ImageBatchToList+", "display_name": "\ud83d\udd27 Image Batch To List", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image batch", "output_node": false}, "ImageCompositeFromMaskBatch+": {"input": {"required": {"image_from": ["IMAGE"], "image_to": ["IMAGE"], "mask": ["MASK"]}}, "input_order": {"required": ["image_from", "image_to", "mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCompositeFromMaskBatch+", "display_name": "\ud83d\udd27 Image Composite From Mask Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageComposite+": {"input": {"required": {"destination": ["IMAGE"], "source": ["IMAGE"], "x": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "offset_x": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "offset_y": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "offset_x", "offset_y"], "optional": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageComposite+", "display_name": "\ud83d\udd27 Image Composite", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageCrop+": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 256, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 0, "max": 16384, "step": 8}], "position": [["top-left", "top-center", "top-right", "right-center", "bottom-right", "bottom-center", "bottom-left", "left-center", "center"]], "x_offset": ["INT", {"default": 0, "min": -99999, "step": 1}], "y_offset": ["INT", {"default": 0, "min": -99999, "step": 1}]}}, "input_order": {"required": ["image", "width", "height", "position", "x_offset", "y_offset"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "x", "y"], "name": "ImageCrop+", "display_name": "\ud83d\udd27 Image Crop", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageFlip+": {"input": {"required": {"image": ["IMAGE"], "axis": [["x", "y", "xy"]]}}, "input_order": {"required": ["image", "axis"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFlip+", "display_name": "\ud83d\udd27 Image Flip", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageRandomTransform+": {"input": {"required": {"image": ["IMAGE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "repeat": ["INT", {"default": 1, "min": 1, "max": 256, "step": 1}], "variation": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.05}]}}, "input_order": {"required": ["image", "seed", "repeat", "variation"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageRandomTransform+", "display_name": "\ud83d\udd27 Image Random Transform", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageRemoveAlpha+": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageRemoveAlpha+", "display_name": "\ud83d\udd27 Image Remove Alpha", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image utils", "output_node": false}, "ImageRemoveBackground+": {"input": {"required": {"rembg_session": ["REMBG_SESSION"], "image": ["IMAGE"]}}, "input_order": {"required": ["rembg_session", "image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImageRemoveBackground+", "display_name": "\ud83d\udd27 Image Remove Background", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageResize+": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "interpolation": [["nearest", "bilinear", "bicubic", "area", "nearest-exact", "lanczos"]], "method": [["stretch", "keep proportion", "fill / crop", "pad"]], "condition": [["always", "downscale if bigger", "upscale if smaller", "if bigger area", "if smaller area"]], "multiple_of": ["INT", {"default": 0, "min": 0, "max": 512, "step": 1}]}}, "input_order": {"required": ["image", "width", "height", "interpolation", "method", "condition", "multiple_of"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "width", "height"], "name": "ImageResize+", "display_name": "\ud83d\udd27 Image Resize", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageSeamCarving+": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "energy": [["backward", "forward"]], "order": [["width-first", "height-first"]]}, "optional": {"keep_mask": ["MASK"], "drop_mask": ["MASK"]}}, "input_order": {"required": ["image", "width", "height", "energy", "order"], "optional": ["keep_mask", "drop_mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageSeamCarving+", "display_name": "\ud83d\udd27 Image Seam Carving", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageTile+": {"input": {"required": {"image": ["IMAGE"], "rows": ["INT", {"default": 2, "min": 1, "max": 256, "step": 1}], "cols": ["INT", {"default": 2, "min": 1, "max": 256, "step": 1}], "overlap": ["FLOAT", {"default": 0, "min": 0, "max": 0.5, "step": 0.01}], "overlap_x": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 1}], "overlap_y": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 1}]}}, "input_order": {"required": ["image", "rows", "cols", "overlap", "overlap_x", "overlap_y"]}, "output": ["IMAGE", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["IMAGE", "tile_width", "tile_height", "overlap_x", "overlap_y"], "name": "ImageTile+", "display_name": "\ud83d\udd27 Image Tile", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageUntile+": {"input": {"required": {"tiles": ["IMAGE"], "overlap_x": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 1}], "overlap_y": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 1}], "rows": ["INT", {"default": 2, "min": 1, "max": 256, "step": 1}], "cols": ["INT", {"default": 2, "min": 1, "max": 256, "step": 1}]}}, "input_order": {"required": ["tiles", "overlap_x", "overlap_y", "rows", "cols"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageUntile+", "display_name": "\ud83d\udd27 Image Untile", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "RemBGSession+": {"input": {"required": {"model": [["u2net: general purpose", "u2netp: lightweight general purpose", "u2net_human_seg: human segmentation", "u2net_cloth_seg: cloths Parsing", "silueta: very small u2net", "isnet-general-use: general purpose", "isnet-anime: anime illustrations", "sam: general purpose"]], "providers": [["CPU", "CUDA", "ROCM", "DirectML", "OpenVINO", "CoreML", "Tensorrt", "Azure"]]}}, "input_order": {"required": ["model", "providers"]}, "output": ["REMBG_SESSION"], "output_is_list": [false], "output_name": ["REMBG_SESSION"], "name": "RemBGSession+", "display_name": "\ud83d\udd27 RemBG Session", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "TransparentBGSession+": {"input": {"required": {"mode": [["base", "fast", "base-nightly"]], "use_jit": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mode", "use_jit"]}, "output": ["REMBG_SESSION"], "output_is_list": [false], "output_name": ["REMBG_SESSION"], "name": "TransparentBGSession+", "display_name": "\ud83d\udd27 InSPyReNet TransparentBG", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image manipulation", "output_node": false}, "ImageApplyLUT+": {"input": {"required": {"image": ["IMAGE"], "lut_file": [["put_luts_files_here.txt"]], "gamma_correction": ["BOOLEAN", {"default": true}], "clip_values": ["BOOLEAN", {"default": true}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.1}]}}, "input_order": {"required": ["image", "lut_file", "gamma_correction", "clip_values", "strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageApplyLUT+", "display_name": "\ud83d\udd27 Image Apply LUT", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImageCASharpening+": {"input": {"required": {"image": ["IMAGE"], "amount": ["FLOAT", {"default": 0.8, "min": 0, "max": 1, "step": 0.05}]}}, "input_order": {"required": ["image", "amount"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCASharpening+", "display_name": "\ud83d\udd27 Image Contrast Adaptive Sharpening", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImageDesaturate+": {"input": {"required": {"image": ["IMAGE"], "factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}], "method": [["luminance (Rec.709)", "luminance (Rec.601)", "average", "lightness"]]}}, "input_order": {"required": ["image", "factor", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageDesaturate+", "display_name": "\ud83d\udd27 Image Desaturate", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "PixelOEPixelize+": {"input": {"required": {"image": ["IMAGE"], "downscale_mode": [["contrast", "bicubic", "nearest", "center", "k-centroid"]], "target_size": ["INT", {"default": 128, "min": 0, "max": 16384, "step": 8}], "patch_size": ["INT", {"default": 16, "min": 4, "max": 32, "step": 2}], "thickness": ["INT", {"default": 2, "min": 1, "max": 16, "step": 1}], "color_matching": ["BOOLEAN", {"default": true}], "upscale": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "downscale_mode", "target_size", "patch_size", "thickness", "color_matching", "upscale"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PixelOEPixelize+", "display_name": "\ud83d\udd27 Pixelize", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImagePosterize+": {"input": {"required": {"image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.05}]}}, "input_order": {"required": ["image", "threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImagePosterize+", "display_name": "\ud83d\udd27 Image Posterize", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImageColorMatch+": {"input": {"required": {"image": ["IMAGE"], "reference": ["IMAGE"], "color_space": [["LAB", "YCbCr", "RGB", "LUV", "YUV", "XYZ"]], "factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}], "device": [["auto", "cpu", "gpu"]], "batch_size": ["INT", {"default": 0, "min": 0, "max": 1024, "step": 1}]}, "optional": {"reference_mask": ["MASK"]}}, "input_order": {"required": ["image", "reference", "color_space", "factor", "device", "batch_size"], "optional": ["reference_mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageColorMatch+", "display_name": "\ud83d\udd27 Image Color Match", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImageColorMatchAdobe+": {"input": {"required": {"image": ["IMAGE"], "reference": ["IMAGE"], "color_space": [["RGB", "LAB"]], "luminance_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}], "color_intensity_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}], "fade_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}], "neutralization_factor": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.05}], "device": [["auto", "cpu", "gpu"]]}, "optional": {"reference_mask": ["MASK"]}}, "input_order": {"required": ["image", "reference", "color_space", "luminance_factor", "color_intensity_factor", "fade_factor", "neutralization_factor", "device"], "optional": ["reference_mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageColorMatchAdobe+", "display_name": "\ud83d\udd27 Image Color Match Adobe", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImageHistogramMatch+": {"input": {"required": {"image": ["IMAGE"], "reference": ["IMAGE"], "method": [["pytorch", "skimage"]], "factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}], "device": [["auto", "cpu", "gpu"]]}}, "input_order": {"required": ["image", "reference", "method", "factor", "device"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageHistogramMatch+", "display_name": "\ud83d\udd27 Image Histogram Match", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "ImageSmartSharpen+": {"input": {"required": {"image": ["IMAGE"], "noise_radius": ["INT", {"default": 7, "min": 1, "max": 25, "step": 1}], "preserve_edges": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0, "step": 0.05}], "sharpen": ["FLOAT", {"default": 5.0, "min": 0.0, "max": 25.0, "step": 0.5}], "ratio": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.1}]}}, "input_order": {"required": ["image", "noise_radius", "preserve_edges", "sharpen", "ratio"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageSmartSharpen+", "display_name": "\ud83d\udd27 Image Smart Sharpen", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image processing", "output_node": false}, "GetImageSize+": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["INT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["width", "height", "count"], "name": "GetImageSize+", "display_name": "\ud83d\udd27 Get Image Size", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image utils", "output_node": false}, "ImageToDevice+": {"input": {"required": {"image": ["IMAGE"], "device": [["auto", "cpu", "gpu"]]}}, "input_order": {"required": ["image", "device"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageToDevice+", "display_name": "\ud83d\udd27 Image To Device", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image utils", "output_node": false}, "ImagePreviewFromLatent+": {"input": {"required": {"latent": ["LATENT"], "vae": ["VAE"], "tile_size": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 64}]}, "optional": {"image": [["none"], {"image_upload": false}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["latent", "vae", "tile_size"], "optional": ["image"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["IMAGE", "MASK", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "MASK", "width", "height"], "name": "ImagePreviewFromLatent+", "display_name": "\ud83d\udd27 Image Preview From Latent", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image utils", "output_node": true}, "NoiseFromImage+": {"input": {"required": {"image": ["IMAGE"], "noise_strenght": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "noise_size": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "color_noise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "mask_strength": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "mask_scale_diff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "mask_contrast": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "saturation": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 100.0, "step": 0.1}], "contrast": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "blur": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.1}]}, "optional": {"noise_mask": ["IMAGE"]}}, "input_order": {"required": ["image", "noise_strenght", "noise_size", "color_noise", "mask_strength", "mask_scale_diff", "mask_contrast", "saturation", "contrast", "blur"], "optional": ["noise_mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "NoiseFromImage+", "display_name": "\ud83d\udd27 Noise From Image", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/image utils", "output_node": false}, "MaskBlur+": {"input": {"required": {"mask": ["MASK"], "amount": ["INT", {"default": 6, "min": 0, "max": 256, "step": 1}], "device": [["auto", "cpu", "gpu"]]}}, "input_order": {"required": ["mask", "amount", "device"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskBlur+", "display_name": "\ud83d\udd27 Mask Blur", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskBoundingBox+": {"input": {"required": {"mask": ["MASK"], "padding": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "blur": ["INT", {"default": 0, "min": 0, "max": 256, "step": 1}]}, "optional": {"image_optional": ["IMAGE"]}}, "input_order": {"required": ["mask", "padding", "blur"], "optional": ["image_optional"]}, "output": ["MASK", "IMAGE", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["MASK", "IMAGE", "x", "y", "width", "height"], "name": "MaskBoundingBox+", "display_name": "\ud83d\udd27 Mask Bounding Box", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskFix+": {"input": {"required": {"mask": ["MASK"], "erode_dilate": ["INT", {"default": 0, "min": -256, "max": 256, "step": 1}], "fill_holes": ["INT", {"default": 0, "min": 0, "max": 128, "step": 1}], "remove_isolated_pixels": ["INT", {"default": 0, "min": 0, "max": 32, "step": 1}], "smooth": ["INT", {"default": 0, "min": 0, "max": 256, "step": 1}], "blur": ["INT", {"default": 0, "min": 0, "max": 256, "step": 1}]}}, "input_order": {"required": ["mask", "erode_dilate", "fill_holes", "remove_isolated_pixels", "smooth", "blur"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskFix+", "display_name": "\ud83d\udd27 Mask Fix", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskFlip+": {"input": {"required": {"mask": ["MASK"], "axis": [["x", "y", "xy"]]}}, "input_order": {"required": ["mask", "axis"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskFlip+", "display_name": "\ud83d\udd27 Mask Flip", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskFromColor+": {"input": {"required": {"image": ["IMAGE"], "red": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "green": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "blue": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}], "threshold": ["INT", {"default": 0, "min": 0, "max": 127, "step": 1}]}}, "input_order": {"required": ["image", "red", "green", "blue", "threshold"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskFromColor+", "display_name": "\ud83d\udd27 Mask From Color", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskFromList+": {"input": {"required": {"width": ["INT", {"default": 32, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 32, "min": 0, "max": 16384, "step": 8}]}, "optional": {"values": ["*", {"default": 0.0, "min": 0.0, "max": 1.0}], "str_values": ["STRING", {"default": "", "multiline": true, "placeholder": "0.0, 0.5, 1.0"}]}}, "input_order": {"required": ["width", "height"], "optional": ["values", "str_values"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskFromList+", "display_name": "\ud83d\udd27 Mask From List", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskFromRGBCMYBW+": {"input": {"required": {"image": ["IMAGE"], "threshold_r": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1, "step": 0.01}], "threshold_g": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1, "step": 0.01}], "threshold_b": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["image", "threshold_r", "threshold_g", "threshold_b"]}, "output": ["MASK", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK", "MASK"], "output_is_list": [false, false, false, false, false, false, false, false], "output_name": ["red", "green", "blue", "cyan", "magenta", "yellow", "black", "white"], "name": "MaskFromRGBCMYBW+", "display_name": "\ud83d\udd27 Mask From RGB/CMY/BW", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskFromSegmentation+": {"input": {"required": {"image": ["IMAGE"], "segments": ["INT", {"default": 6, "min": 1, "max": 16, "step": 1}], "remove_isolated_pixels": ["INT", {"default": 0, "min": 0, "max": 32, "step": 1}], "remove_small_masks": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "fill_holes": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "segments", "remove_isolated_pixels", "remove_small_masks", "fill_holes"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskFromSegmentation+", "display_name": "\ud83d\udd27 Mask From Segmentation", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskPreview+": {"input": {"required": {"mask": ["MASK"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mask"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "MaskPreview+", "display_name": "\ud83d\udd27 Mask Preview", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": true}, "MaskSmooth+": {"input": {"required": {"mask": ["MASK"], "amount": ["INT", {"default": 0, "min": 0, "max": 127, "step": 1}]}}, "input_order": {"required": ["mask", "amount"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskSmooth+", "display_name": "\ud83d\udd27 Mask Smooth", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "TransitionMask+": {"input": {"required": {"width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "frames": ["INT", {"default": 16, "min": 1, "max": 9999, "step": 1}], "start_frame": ["INT", {"default": 0, "min": 0, "step": 1}], "end_frame": ["INT", {"default": 9999, "min": 0, "step": 1}], "transition_type": [["horizontal slide", "vertical slide", "horizontal bar", "vertical bar", "center box", "horizontal door", "vertical door", "circle", "fade"]], "timing_function": [["linear", "in", "out", "in-out"]]}}, "input_order": {"required": ["width", "height", "frames", "start_frame", "end_frame", "transition_type", "timing_function"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "TransitionMask+", "display_name": "\ud83d\udd27 Transition Mask", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask", "output_node": false}, "MaskBatch+": {"input": {"required": {"mask1": ["MASK"], "mask2": ["MASK"]}}, "input_order": {"required": ["mask1", "mask2"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskBatch+", "display_name": "\ud83d\udd27 Mask Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask batch", "output_node": false}, "MaskExpandBatch+": {"input": {"required": {"mask": ["MASK"], "size": ["INT", {"default": 16, "min": 1, "step": 1}], "method": [["expand", "repeat all", "repeat first", "repeat last"]]}}, "input_order": {"required": ["mask", "size", "method"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskExpandBatch+", "display_name": "\ud83d\udd27 Mask Expand Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask batch", "output_node": false}, "MaskFromBatch+": {"input": {"required": {"mask": ["MASK"], "start": ["INT", {"default": 0, "min": 0, "step": 1}], "length": ["INT", {"default": 1, "min": 1, "step": 1}]}}, "input_order": {"required": ["mask", "start", "length"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskFromBatch+", "display_name": "\ud83d\udd27 Mask From Batch", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/mask batch", "output_node": false}, "KSamplerVariationsStochastic+": {"input": {"required": {"model": ["MODEL"], "latent_image": ["LATENT"], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 25, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 7.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "sampler": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "variation_seed": ["INT:seed", {"default": 0, "min": 0, "max": 18446744073709551615}], "variation_strength": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.05, "round": 0.01}], "cfg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05, "round": 0.01}]}}, "input_order": {"required": ["model", "latent_image", "noise_seed", "steps", "cfg", "sampler", "scheduler", "positive", "negative", "variation_seed", "variation_strength", "cfg_scale"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSamplerVariationsStochastic+", "display_name": "\ud83d\udd27 KSampler Stochastic Variations", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "KSamplerVariationsWithNoise+": {"input": {"required": {"model": ["MODEL"], "latent_image": ["LATENT"], "main_seed": ["INT:seed", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "variation_strength": ["FLOAT", {"default": 0.17, "min": 0.0, "max": 1.0, "step": 0.01, "round": 0.01}], "variation_seed": ["INT:seed", {"default": 12345, "min": 0, "max": 18446744073709551615}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "round": 0.01}]}}, "input_order": {"required": ["model", "latent_image", "main_seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "variation_strength", "variation_seed", "denoise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSamplerVariationsWithNoise+", "display_name": "\ud83d\udd27 KSampler Variations with Noise Injection", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "InjectLatentNoise+": {"input": {"required": {"latent": ["LATENT"], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "noise_strength": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01, "round": 0.01}], "normalize": [["false", "true"], {"default": "false"}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["latent", "noise_seed", "noise_strength", "normalize"], "optional": ["mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "InjectLatentNoise+", "display_name": "\ud83d\udd27 Inject Latent Noise", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "FluxSamplerParams+": {"input": {"required": {"model": ["MODEL"], "conditioning": ["CONDITIONING"], "latent_image": ["LATENT"], "seed": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "?"}], "sampler": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "euler"}], "scheduler": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "simple"}], "steps": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "20"}], "guidance": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "3.5"}], "max_shift": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": ""}], "base_shift": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": ""}], "denoise": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "1.0"}]}, "optional": {"loras": ["LORA_PARAMS"]}}, "input_order": {"required": ["model", "conditioning", "latent_image", "seed", "sampler", "scheduler", "steps", "guidance", "max_shift", "base_shift", "denoise"], "optional": ["loras"]}, "output": ["LATENT", "SAMPLER_PARAMS"], "output_is_list": [false, false], "output_name": ["latent", "params"], "name": "FluxSamplerParams+", "display_name": "\ud83d\udd27 Flux Sampler Parameters", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "GuidanceTimestepping+": {"input": {"required": {"model": ["MODEL"], "value": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 100.0, "step": 0.05}], "start_at": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "end_at": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "value", "start_at", "end_at"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "GuidanceTimestepping+", "display_name": "\ud83d\udd27 Guidance Timestep (experimental)", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "PlotParameters+": {"input": {"required": {"images": ["IMAGE"], "params": ["SAMPLER_PARAMS"], "order_by": [["none", "time", "seed", "steps", "denoise", "sampler", "scheduler", "guidance", "max_shift", "base_shift", "lora_strength"]], "cols_value": [["none", "time", "seed", "steps", "denoise", "sampler", "scheduler", "guidance", "max_shift", "base_shift", "lora_strength"]], "cols_num": ["INT", {"default": -1, "min": -1, "max": 1024}], "add_prompt": [["false", "true", "excerpt"]], "add_params": [["false", "true", "changes only"], {"default": "true"}]}}, "input_order": {"required": ["images", "params", "order_by", "cols_value", "cols_num", "add_prompt", "add_params"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PlotParameters+", "display_name": "\ud83d\udd27 Plot Sampler Parameters", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "TextEncodeForSamplerParams+": {"input": {"required": {"text": ["STRING", {"multiline": true, "dynamicPrompts": true, "default": "Separate prompts with at least three dashes\n---\nLike so"}], "clip": ["CLIP"]}}, "input_order": {"required": ["text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "TextEncodeForSamplerParams+", "display_name": "\ud83d\udd27Text Encode for Sampler Params", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "SamplerSelectHelper+": {"input": {"required": {"euler": ["BOOLEAN", {"default": false}], "euler_cfg_pp": ["BOOLEAN", {"default": false}], "euler_ancestral": ["BOOLEAN", {"default": false}], "euler_ancestral_cfg_pp": ["BOOLEAN", {"default": false}], "heun": ["BOOLEAN", {"default": false}], "heunpp2": ["BOOLEAN", {"default": false}], "dpm_2": ["BOOLEAN", {"default": false}], "dpm_2_ancestral": ["BOOLEAN", {"default": false}], "lms": ["BOOLEAN", {"default": false}], "dpm_fast": ["BOOLEAN", {"default": false}], "dpm_adaptive": ["BOOLEAN", {"default": false}], "dpmpp_2s_ancestral": ["BOOLEAN", {"default": false}], "dpmpp_2s_ancestral_cfg_pp": ["BOOLEAN", {"default": false}], "dpmpp_sde": ["BOOLEAN", {"default": false}], "dpmpp_sde_gpu": ["BOOLEAN", {"default": false}], "dpmpp_2m": ["BOOLEAN", {"default": false}], "dpmpp_2m_cfg_pp": ["BOOLEAN", {"default": false}], "dpmpp_2m_sde": ["BOOLEAN", {"default": false}], "dpmpp_2m_sde_gpu": ["BOOLEAN", {"default": false}], "dpmpp_3m_sde": ["BOOLEAN", {"default": false}], "dpmpp_3m_sde_gpu": ["BOOLEAN", {"default": false}], "ddpm": ["BOOLEAN", {"default": false}], "lcm": ["BOOLEAN", {"default": false}], "ipndm": ["BOOLEAN", {"default": false}], "ipndm_v": ["BOOLEAN", {"default": false}], "deis": ["BOOLEAN", {"default": false}], "res_multistep": ["BOOLEAN", {"default": false}], "res_multistep_cfg_pp": ["BOOLEAN", {"default": false}], "res_multistep_ancestral": ["BOOLEAN", {"default": false}], "res_multistep_ancestral_cfg_pp": ["BOOLEAN", {"default": false}], "gradient_estimation": ["BOOLEAN", {"default": false}], "gradient_estimation_cfg_pp": ["BOOLEAN", {"default": false}], "er_sde": ["BOOLEAN", {"default": false}], "seeds_2": ["BOOLEAN", {"default": false}], "seeds_3": ["BOOLEAN", {"default": false}], "ddim": ["BOOLEAN", {"default": false}], "uni_pc": ["BOOLEAN", {"default": false}], "uni_pc_bh2": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SamplerSelectHelper+", "display_name": "\ud83d\udd27 Sampler Select Helper", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "SchedulerSelectHelper+": {"input": {"required": {"normal": ["BOOLEAN", {"default": false}], "karras": ["BOOLEAN", {"default": false}], "exponential": ["BOOLEAN", {"default": false}], "sgm_uniform": ["BOOLEAN", {"default": false}], "simple": ["BOOLEAN", {"default": false}], "ddim_uniform": ["BOOLEAN", {"default": false}], "beta": ["BOOLEAN", {"default": false}], "linear_quadratic": ["BOOLEAN", {"default": false}], "kl_optimal": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SchedulerSelectHelper+", "display_name": "\ud83d\udd27 Scheduler Select Helper", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "LorasForFluxParams+": {"input": {"required": {"lora_1": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"], {"tooltip": "The name of the LoRA."}], "strength_model_1": ["STRING", {"multiline": false, "dynamicPrompts": false, "default": "1.0"}]}}, "input_order": {"required": ["lora_1", "strength_model_1"]}, "output": ["LORA_PARAMS"], "output_is_list": [false], "output_name": ["LORA_PARAMS"], "name": "LorasForFluxParams+", "display_name": "\ud83d\udd27 LoRA for Flux Parameters", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "ModelSamplingSD3Advanced+": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01}], "cut_off": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.05}], "shift_multiplier": ["FLOAT", {"default": 2, "min": 0, "max": 10, "step": 0.05}]}}, "input_order": {"required": ["model", "shift", "cut_off", "shift_multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingSD3Advanced+", "display_name": "\ud83d\udd27 Model Sampling SD3 Advanced", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/sampling", "output_node": false}, "ApplyCLIPSeg+": {"input": {"required": {"clip_seg": ["CLIP_SEG"], "image": ["IMAGE"], "prompt": ["STRING", {"multiline": false, "default": ""}], "threshold": ["FLOAT", {"default": 0.4, "min": 0.0, "max": 1.0, "step": 0.05}], "smooth": ["INT", {"default": 9, "min": 0, "max": 32, "step": 1}], "dilate": ["INT", {"default": 0, "min": -32, "max": 32, "step": 1}], "blur": ["INT", {"default": 0, "min": 0, "max": 64, "step": 1}]}}, "input_order": {"required": ["clip_seg", "image", "prompt", "threshold", "smooth", "dilate", "blur"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ApplyCLIPSeg+", "display_name": "\ud83d\udd27 Apply CLIPSeg", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/segmentation", "output_node": false}, "LoadCLIPSegModels+": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["CLIP_SEG"], "output_is_list": [false], "output_name": ["CLIP_SEG"], "name": "LoadCLIPSegModels+", "display_name": "\ud83d\udd27 Load CLIPSeg Models", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/segmentation", "output_node": false}, "DrawText+": {"input": {"required": {"text": ["STRING", {"multiline": true, "dynamicPrompts": true, "default": "Hello, World!"}], "font": [["ShareTechMono-Regular.ttf"]], "size": ["INT", {"default": 56, "min": 1, "max": 9999, "step": 1}], "color": ["STRING", {"multiline": false, "default": "#FFFFFF"}], "background_color": ["STRING", {"multiline": false, "default": "#00000000"}], "shadow_distance": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "shadow_blur": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "shadow_color": ["STRING", {"multiline": false, "default": "#000000"}], "horizontal_align": [["left", "center", "right"]], "vertical_align": [["top", "center", "bottom"]], "offset_x": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "offset_y": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "direction": [["ltr", "rtl"]]}, "optional": {"img_composite": ["IMAGE"]}}, "input_order": {"required": ["text", "font", "size", "color", "background_color", "shadow_distance", "shadow_blur", "shadow_color", "horizontal_align", "vertical_align", "offset_x", "offset_y", "direction"], "optional": ["img_composite"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "DrawText+", "display_name": "\ud83d\udd27 Draw Text", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/text", "output_node": false}, "BatchCount+": {"input": {"required": {"batch": ["*", {}]}}, "input_order": {"required": ["batch"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "BatchCount+", "display_name": "\ud83d\udd27 Batch Count", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "ConsoleDebug+": {"input": {"required": {"value": ["*", {}]}, "optional": {"prefix": ["STRING", {"multiline": false, "default": "Value:"}]}}, "input_order": {"required": ["value"], "optional": ["prefix"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ConsoleDebug+", "display_name": "\ud83d\udd27 Console Debug", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": true}, "DebugTensorShape+": {"input": {"required": {"tensor": ["*", {}]}}, "input_order": {"required": ["tensor"]}, "output": [], "output_is_list": [], "output_name": [], "name": "DebugTensorShape+", "display_name": "\ud83d\udd27 Debug Tensor Shape", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": true}, "DisplayAny": {"input": {"required": {"input": ["*", {}], "mode": [["raw value", "tensor shape"]]}}, "input_order": {"required": ["input", "mode"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "DisplayAny", "display_name": "\ud83d\udd27 Display Any", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": true}, "ModelCompile+": {"input": {"required": {"model": ["MODEL"], "fullgraph": ["BOOLEAN", {"default": false}], "dynamic": ["BOOLEAN", {"default": false}], "mode": [["default", "reduce-overhead", "max-autotune", "max-autotune-no-cudagraphs"]]}}, "input_order": {"required": ["model", "fullgraph", "dynamic", "mode"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelCompile+", "display_name": "\ud83d\udd27 Model Compile", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "RemoveLatentMask+": {"input": {"required": {"samples": ["LATENT"]}}, "input_order": {"required": ["samples"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RemoveLatentMask+", "display_name": "\ud83d\udd27 Remove Latent Mask", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SDXLEmptyLatentSizePicker+": {"input": {"required": {"resolution": [["704x1408 (0.5)", "704x1344 (0.52)", "768x1344 (0.57)", "768x1280 (0.6)", "832x1216 (0.68)", "832x1152 (0.72)", "896x1152 (0.78)", "896x1088 (0.82)", "960x1088 (0.88)", "960x1024 (0.94)", "1024x1024 (1.0)", "1024x960 (1.07)", "1088x960 (1.13)", "1088x896 (1.21)", "1152x896 (1.29)", "1152x832 (1.38)", "1216x832 (1.46)", "1280x768 (1.67)", "1344x768 (1.75)", "1344x704 (1.91)", "1408x704 (2.0)", "1472x704 (2.09)", "1536x640 (2.4)", "1600x640 (2.5)", "1664x576 (2.89)", "1728x576 (3.0)"], {"default": "1024x1024 (1.0)"}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "width_override": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "height_override": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["resolution", "batch_size", "width_override", "height_override"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["LATENT", "width", "height"], "name": "SDXLEmptyLatentSizePicker+", "display_name": "\ud83d\udd27 Empty Latent Size Picker", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleComparison+": {"input": {"required": {"a": ["*", {"default": 0}], "b": ["*", {"default": 0}], "comparison": [["==", "!=", "<", "<=", ">", ">="]]}}, "input_order": {"required": ["a", "b", "comparison"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "SimpleComparison+", "display_name": "\ud83d\udd27 Simple Comparison", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleCondition+": {"input": {"required": {"evaluate": ["*", {"default": 0}], "on_true": ["*", {"default": 0}]}, "optional": {"on_false": ["*", {"default": null}]}}, "input_order": {"required": ["evaluate", "on_true"], "optional": ["on_false"]}, "output": ["*"], "output_is_list": [false], "output_name": ["result"], "name": "SimpleCondition+", "display_name": "\ud83d\udd27 Simple Condition", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMath+": {"input": {"optional": {"a": ["*", {"default": 0.0}], "b": ["*", {"default": 0.0}], "c": ["*", {"default": 0.0}]}, "required": {"value": ["STRING", {"multiline": false, "default": ""}]}}, "input_order": {"optional": ["a", "b", "c"], "required": ["value"]}, "output": ["INT", "FLOAT"], "output_is_list": [false, false], "output_name": ["INT", "FLOAT"], "name": "SimpleMath+", "display_name": "\ud83d\udd27 Simple Math", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathDual+": {"input": {"optional": {"a": ["*", {"default": 0.0}], "b": ["*", {"default": 0.0}], "c": ["*", {"default": 0.0}], "d": ["*", {"default": 0.0}]}, "required": {"value_1": ["STRING", {"multiline": false, "default": ""}], "value_2": ["STRING", {"multiline": false, "default": ""}]}}, "input_order": {"optional": ["a", "b", "c", "d"], "required": ["value_1", "value_2"]}, "output": ["INT", "FLOAT", "INT", "FLOAT"], "output_is_list": [false, false, false, false], "output_name": ["int_1", "float_1", "int_2", "float_2"], "name": "SimpleMathDual+", "display_name": "\ud83d\udd27 Simple Math Dual", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathCondition+": {"input": {"optional": {"a": ["*", {"default": 0.0}], "b": ["*", {"default": 0.0}], "c": ["*", {"default": 0.0}]}, "required": {"evaluate": ["*", {"default": 0}], "on_true": ["STRING", {"multiline": false, "default": ""}], "on_false": ["STRING", {"multiline": false, "default": ""}]}}, "input_order": {"optional": ["a", "b", "c"], "required": ["evaluate", "on_true", "on_false"]}, "output": ["INT", "FLOAT"], "output_is_list": [false, false], "output_name": ["INT", "FLOAT"], "name": "SimpleMathCondition+", "display_name": "\ud83d\udd27 Simple Math Condition", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathBoolean+": {"input": {"required": {"value": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "SimpleMathBoolean+", "display_name": "\ud83d\udd27 Simple Math Boolean", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathFloat+": {"input": {"required": {"value": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.05}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "SimpleMathFloat+", "display_name": "\ud83d\udd27 Simple Math Float", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathInt+": {"input": {"required": {"value": ["INT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "SimpleMathInt+", "display_name": "\ud83d\udd27 Simple Math Int", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathPercent+": {"input": {"required": {"value": ["FLOAT", {"default": 0.0, "min": 0, "max": 1, "step": 0.05}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "SimpleMathPercent+", "display_name": "\ud83d\udd27 Simple Math Percent", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathSlider+": {"input": {"required": {"value": ["FLOAT", {"display": "slider", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}], "min": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.001}], "max": ["FLOAT", {"default": 1.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.001}], "rounding": ["INT", {"default": 0, "min": 0, "max": 10, "step": 1}]}}, "input_order": {"required": ["value", "min", "max", "rounding"]}, "output": ["FLOAT", "INT"], "output_is_list": [false, false], "output_name": ["FLOAT", "INT"], "name": "SimpleMathSlider+", "display_name": "\ud83d\udd27 Simple Math Slider", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SimpleMathSliderLowRes+": {"input": {"required": {"value": ["INT", {"display": "slider", "default": 5, "min": 0, "max": 10, "step": 1}], "min": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.001}], "max": ["FLOAT", {"default": 1.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.001}], "rounding": ["INT", {"default": 0, "min": 0, "max": 10, "step": 1}]}}, "input_order": {"required": ["value", "min", "max", "rounding"]}, "output": ["FLOAT", "INT"], "output_is_list": [false, false], "output_name": ["FLOAT", "INT"], "name": "SimpleMathSliderLowRes+", "display_name": "\ud83d\udd27 Simple Math Slider low-res", "description": "", "python_module": "custom_nodes.ComfyUI_essentials", "category": "essentials/utilities", "output_node": false}, "SAMLoader": {"input": {"required": {"model_name": [["mobile_sam.pt", "sam_vit_b_01ec64.pth", "sam_vit_h_4b8939.pth", "sam_vit_l_0b3195.pth"], {"tooltip": "The detection accuracy varies depending on the SAM model. ESAM can only be used if ComfyUI-YoloWorld-EfficientSAM is installed."}], "device_mode": [["AUTO", "Prefer GPU", "CPU"], {"tooltip": "AUTO: Only applicable when a GPU is available. It temporarily loads the SAM_MODEL into VRAM only when the detection function is used.\nPrefer GPU: Tries to keep the SAM_MODEL on the GPU whenever possible. This can be used when there is sufficient VRAM available.\nCPU: Always loads only on the CPU."}]}}, "input_order": {"required": ["model_name", "device_mode"]}, "output": ["SAM_MODEL"], "output_is_list": [false], "output_name": ["SAM_MODEL"], "name": "SAMLoader", "display_name": "SAMLoader (Impact)", "description": "Load the SAM (Segment Anything) model. This can be used in places that utilize SAM detection functionality, such as SAMDetector or SimpleDetector.\nThe SAM detection functionality in Impact Pack must use the SAM_MODEL loaded through this node.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack", "output_node": false}, "CLIPSegDetectorProvider": {"input": {"required": {"text": ["STRING", {"multiline": false, "tooltip": "Enter the targets to be detected, separated by commas"}], "blur": ["FLOAT", {"min": 0, "max": 15, "step": 0.1, "default": 7, "tooltip": "Blurs the detected mask"}], "threshold": ["FLOAT", {"min": 0, "max": 1, "step": 0.05, "default": 0.4, "tooltip": "Detects only areas that are certain above the threshold."}], "dilation_factor": ["INT", {"min": 0, "max": 10, "step": 1, "default": 4, "tooltip": "Dilates the detected mask."}]}}, "input_order": {"required": ["text", "blur", "threshold", "dilation_factor"]}, "output": ["BBOX_DETECTOR"], "output_is_list": [false], "output_name": ["BBOX_DETECTOR"], "name": "CLIPSegDetectorProvider", "display_name": "CLIPSegDetectorProvider", "description": "Provides a detection function using CLIPSeg, which generates masks based on text prompts.\nTo use this node, the CLIPSeg custom node must be installed.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ONNXDetectorProvider": {"input": {"required": {"model_name": [[]]}}, "input_order": {"required": ["model_name"]}, "output": ["BBOX_DETECTOR"], "output_is_list": [false], "output_name": ["BBOX_DETECTOR"], "name": "ONNXDetectorProvider", "display_name": "ONNXDetectorProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack", "output_node": false}, "BitwiseAndMaskForEach": {"input": {"required": {"base_segs": ["SEGS"], "mask_segs": ["SEGS"]}}, "input_order": {"required": ["base_segs", "mask_segs"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "BitwiseAndMaskForEach", "display_name": "Pixelwise(SEGS & SEGS)", "description": "Retains only the overlapping areas between the masks included in base_segs and the mask regions of mask_segs. SEGS with no overlapping mask areas are filtered out.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "SubtractMaskForEach": {"input": {"required": {"base_segs": ["SEGS"], "mask_segs": ["SEGS"]}}, "input_order": {"required": ["base_segs", "mask_segs"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "SubtractMaskForEach", "display_name": "Pixelwise(SEGS - SEGS)", "description": "Removes only the overlapping areas between the masks included in base_segs and the mask regions of mask_segs. SEGS with no overlapping mask areas are filtered out.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "DetailerForEach": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "model": ["MODEL", {"tooltip": "If the `ImpactDummyInput` is connected to the model, the inference stage is skipped."}], "clip": ["CLIP"], "vae": ["VAE"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "segs", "model", "clip", "vae", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "feather", "noise_mask", "force_inpaint", "wildcard", "cycle"], "optional": ["detailer_hook", "inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DetailerForEach", "display_name": "Detailer (SEGS)", "description": "It enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "DetailerForEachDebug": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "model": ["MODEL", {"tooltip": "If the `ImpactDummyInput` is connected to the model, the inference stage is skipped."}], "clip": ["CLIP"], "vae": ["VAE"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "segs", "model", "clip", "vae", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "feather", "noise_mask", "force_inpaint", "wildcard", "cycle"], "optional": ["detailer_hook", "inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, true, true, true, true], "output_name": ["image", "cropped", "cropped_refined", "cropped_refined_alpha", "cnet_images"], "name": "DetailerForEachDebug", "display_name": "DetailerDebug (SEGS)", "description": "It enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "DetailerForEachPipe": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "If the `ImpactDummyInput` is connected to the model in the basic_pipe, the inference stage is skipped."}], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"], "refiner_basic_pipe_opt": ["BASIC_PIPE"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "segs", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "feather", "noise_mask", "force_inpaint", "basic_pipe", "wildcard", "refiner_ratio", "cycle"], "optional": ["detailer_hook", "refiner_basic_pipe_opt", "inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE", "SEGS", "BASIC_PIPE", "IMAGE"], "output_is_list": [false, false, false, true], "output_name": ["image", "segs", "basic_pipe", "cnet_images"], "name": "DetailerForEachPipe", "display_name": "Detailer (SEGS/pipe)", "description": "It enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "DetailerForEachDebugPipe": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "If the `ImpactDummyInput` is connected to the model in the basic_pipe, the inference stage is skipped."}], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"], "refiner_basic_pipe_opt": ["BASIC_PIPE"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "segs", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "feather", "noise_mask", "force_inpaint", "basic_pipe", "wildcard", "refiner_ratio", "cycle"], "optional": ["detailer_hook", "refiner_basic_pipe_opt", "inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE", "SEGS", "BASIC_PIPE", "IMAGE", "IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false, true, true, true, true], "output_name": ["image", "segs", "basic_pipe", "cropped", "cropped_refined", "cropped_refined_alpha", "cnet_images"], "name": "DetailerForEachDebugPipe", "display_name": "DetailerDebug (SEGS/pipe)", "description": "It enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "DetailerForEachPipeForAnimateDiff": {"input": {"required": {"image_frames": ["IMAGE"], "segs": ["SEGS"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "If the `ImpactDummyInput` is connected to the model in the basic_pipe, the inference stage is skipped."}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"], "refiner_basic_pipe_opt": ["BASIC_PIPE"], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["image_frames", "segs", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "feather", "basic_pipe", "refiner_ratio"], "optional": ["detailer_hook", "refiner_basic_pipe_opt", "noise_mask_feather", "scheduler_func_opt"]}, "output": ["IMAGE", "SEGS", "BASIC_PIPE", "IMAGE"], "output_is_list": [false, false, false, true], "output_name": ["image", "segs", "basic_pipe", "cnet_images"], "name": "DetailerForEachPipeForAnimateDiff", "display_name": "Detailer For AnimateDiff (SEGS/pipe)", "description": "This node enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.\nThis node is a specialized detailer node for enhancing video details, such as in AnimateDiff. It can handle cases where the masks contained in SEGS serve as batch masks spanning multiple frames.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "SAMDetectorCombined": {"input": {"required": {"sam_model": ["SAM_MODEL", {"tooltip": "Segment Anything Model for Silhouette Detection.\nBe sure to use the SAM_MODEL loaded through the SAMLoader (Impact) node as input."}], "segs": ["SEGS", {"tooltip": "This is the segment information detected by the detector.\nIt refines the Mask through the SAM (Segment Anything) detector for all areas pointed to by SEGS, and combines all Masks to return as a single Mask."}], "image": ["IMAGE", {"tooltip": "It is assumed that segs contains only the information about the detected areas, and does not include the image. SAM (Segment Anything) operates by referencing this image."}], "detection_hint": [["center-1", "horizontal-2", "vertical-2", "rect-4", "diamond-4", "mask-area", "mask-points", "mask-point-bbox", "none"], {"tooltip": "It is recommended to use only center-1.\nWhen refining the mask of SEGS with the SAM (Segment Anything) model, center-1 uses only the rectangular area of SEGS and a single point at the exact center as hints.\nOther options were added during the experimental stage and do not work well."}], "dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1, "tooltip": "Set the value to dilate the result mask. If the value is negative, it erodes the mask."}], "threshold": ["FLOAT", {"default": 0.93, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Set the sensitivity threshold for the mask detected by SAM (Segment Anything). A higher value generates a more specific mask with a narrower range. For example, when pointing to a person's area, it might detect clothes, which is a narrower range, instead of the entire person."}], "bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1, "tooltip": "When performing SAM (Segment Anything) detection within the SEGS area, the rectangular area of SEGS is expanded and used as a hint."}], "mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "When detection_hint is mask-area, the mask of SEGS is used as a point hint for SAM (Segment Anything).\nIn this case, only the areas of the mask with brightness values equal to or greater than mask_hint_threshold are used as hints."}], "mask_hint_use_negative": [["False", "Small", "Outter"], {"tooltip": "When detecting with SAM (Segment Anything), negative hints are applied as follows:\nSmall: When the SEGS is smaller than 10 pixels in size\nOuter: Sampling the image area outside the SEGS region at regular intervals"}]}}, "input_order": {"required": ["sam_model", "segs", "image", "detection_hint", "dilation", "threshold", "bbox_expansion", "mask_hint_threshold", "mask_hint_use_negative"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SAMDetectorCombined", "display_name": "SAMDetector (combined)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "SAMDetectorSegmented": {"input": {"required": {"sam_model": ["SAM_MODEL", {"tooltip": "Segment Anything Model for Silhouette Detection.\nBe sure to use the SAM_MODEL loaded through the SAMLoader (Impact) node as input."}], "segs": ["SEGS", {"tooltip": "This is the segment information detected by the detector.\nFor the SEGS region, the masks detected by SAM (Segment Anything) are created as a unified mask and a batch of individual masks."}], "image": ["IMAGE", {"tooltip": "It is assumed that segs contains only the information about the detected areas, and does not include the image. SAM (Segment Anything) operates by referencing this image."}], "detection_hint": [["center-1", "horizontal-2", "vertical-2", "rect-4", "diamond-4", "mask-area", "mask-points", "mask-point-bbox", "none"], {"tooltip": "It is recommended to use only center-1.\nWhen refining the mask of SEGS with the SAM (Segment Anything) model, center-1 uses only the rectangular area of SEGS and a single point at the exact center as hints.\nOther options were added during the experimental stage and do not work well."}], "dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1, "tooltip": "Set the value to dilate the result mask. If the value is negative, it erodes the mask."}], "threshold": ["FLOAT", {"default": 0.93, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1, "tooltip": "When performing SAM (Segment Anything) detection within the SEGS area, the rectangular area of SEGS is expanded and used as a hint."}], "mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "When detection_hint is mask-area, the mask of SEGS is used as a point hint for SAM (Segment Anything).\nIn this case, only the areas of the mask with brightness values equal to or greater than mask_hint_threshold are used as hints."}], "mask_hint_use_negative": [["False", "Small", "Outter"], {"tooltip": "When detecting with SAM (Segment Anything), negative hints are applied as follows:\nSmall: When the SEGS is smaller than 10 pixels in size\nOuter: Sampling the image area outside the SEGS region at regular intervals"}]}}, "input_order": {"required": ["sam_model", "segs", "image", "detection_hint", "dilation", "threshold", "bbox_expansion", "mask_hint_threshold", "mask_hint_use_negative"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["combined_mask", "batch_masks"], "name": "SAMDetectorSegmented", "display_name": "SAMDetector (segmented)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "FaceDetailer": {"input": {"required": {"image": ["IMAGE"], "model": ["MODEL", {"tooltip": "If the `ImpactDummyInput` is connected to the model, the inference stage is skipped."}], "clip": ["CLIP"], "vae": ["VAE"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "bbox_crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10, "step": 0.1}], "sam_detection_hint": [["center-1", "horizontal-2", "vertical-2", "rect-4", "diamond-4", "mask-area", "mask-points", "mask-point-bbox", "none"]], "sam_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "sam_threshold": ["FLOAT", {"default": 0.93, "min": 0.0, "max": 1.0, "step": 0.01}], "sam_bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "sam_mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}], "sam_mask_hint_use_negative": [["False", "Small", "Outter"]], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "bbox_detector": ["BBOX_DETECTOR"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"sam_model_opt": ["SAM_MODEL"], "segm_detector_opt": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "model", "clip", "vae", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "feather", "noise_mask", "force_inpaint", "bbox_threshold", "bbox_dilation", "bbox_crop_factor", "sam_detection_hint", "sam_dilation", "sam_threshold", "sam_bbox_expansion", "sam_mask_hint_threshold", "sam_mask_hint_use_negative", "drop_size", "bbox_detector", "wildcard", "cycle"], "optional": ["sam_model_opt", "segm_detector_opt", "detailer_hook", "inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "MASK", "DETAILER_PIPE", "IMAGE"], "output_is_list": [false, true, true, false, false, true], "output_name": ["image", "cropped_refined", "cropped_enhanced_alpha", "mask", "detailer_pipe", "cnet_images"], "name": "FaceDetailer", "display_name": "FaceDetailer", "description": "This node enhances details by automatically detecting specific objects in the input image using detection models (bbox, segm, sam) and regenerating the image by enlarging the detected area based on the guide size.\nAlthough this node is specialized to simplify the commonly used facial detail enhancement workflow, it can also be used for various automatic inpainting purposes depending on the detection model.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Simple", "output_node": false}, "FaceDetailerPipe": {"input": {"required": {"image": ["IMAGE"], "detailer_pipe": ["DETAILER_PIPE", {"tooltip": "If the `ImpactDummyInput` is connected to the model in the detailer_pipe, the inference stage is skipped."}], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "bbox_crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10, "step": 0.1}], "sam_detection_hint": [["center-1", "horizontal-2", "vertical-2", "rect-4", "diamond-4", "mask-area", "mask-points", "mask-point-bbox", "none"]], "sam_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "sam_threshold": ["FLOAT", {"default": 0.93, "min": 0.0, "max": 1.0, "step": 0.01}], "sam_bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "sam_mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}], "sam_mask_hint_use_negative": [["False", "Small", "Outter"]], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tiled_encode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tiled_decode": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["image", "detailer_pipe", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "feather", "noise_mask", "force_inpaint", "bbox_threshold", "bbox_dilation", "bbox_crop_factor", "sam_detection_hint", "sam_dilation", "sam_threshold", "sam_bbox_expansion", "sam_mask_hint_threshold", "sam_mask_hint_use_negative", "drop_size", "refiner_ratio", "cycle"], "optional": ["inpaint_model", "noise_mask_feather", "scheduler_func_opt", "tiled_encode", "tiled_decode"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "MASK", "DETAILER_PIPE", "IMAGE"], "output_is_list": [false, true, true, false, false, true], "output_name": ["image", "cropped_refined", "cropped_enhanced_alpha", "mask", "detailer_pipe", "cnet_images"], "name": "FaceDetailerPipe", "display_name": "FaceDetailer (pipe)", "description": "This node enhances details by automatically detecting specific objects in the input image using detection models (bbox, segm, sam) and regenerating the image by enlarging the detected area based on the guide size.\nAlthough this node is specialized to simplify the commonly used facial detail enhancement workflow, it can also be used for various automatic inpainting purposes depending on the detection model.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Simple", "output_node": false}, "MaskDetailerPipe": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "basic_pipe": ["BASIC_PIPE"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "mask bbox", "label_off": "crop region"}], "max_size": ["FLOAT", {"default": 1024, "min": 64, "max": 16384, "step": 8}], "mask_mode": ["BOOLEAN", {"default": true, "label_on": "masked only", "label_off": "whole"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 100}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"refiner_basic_pipe_opt": ["BASIC_PIPE"], "detailer_hook": ["DETAILER_HOOK"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "bbox_fill": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "contour_fill": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["image", "mask", "basic_pipe", "guide_size", "guide_size_for", "max_size", "mask_mode", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "feather", "crop_factor", "drop_size", "refiner_ratio", "batch_size", "cycle"], "optional": ["refiner_basic_pipe_opt", "detailer_hook", "inpaint_model", "noise_mask_feather", "bbox_fill", "contour_fill", "scheduler_func_opt"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "BASIC_PIPE", "BASIC_PIPE"], "output_is_list": [false, true, true, false, false], "output_name": ["image", "cropped_refined", "cropped_enhanced_alpha", "basic_pipe", "refiner_basic_pipe_opt"], "name": "MaskDetailerPipe", "display_name": "MaskDetailer (pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "ToDetailerPipe": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "bbox_detector": ["BBOX_DETECTOR"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}, "optional": {"sam_model_opt": ["SAM_MODEL"], "segm_detector_opt": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["model", "clip", "vae", "positive", "negative", "bbox_detector", "wildcard", "Select to add LoRA", "Select to add Wildcard"], "optional": ["sam_model_opt", "segm_detector_opt", "detailer_hook"]}, "output": ["DETAILER_PIPE"], "output_is_list": [false], "output_name": ["detailer_pipe"], "name": "ToDetailerPipe", "display_name": "ToDetailerPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "ToDetailerPipeSDXL": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "refiner_model": ["MODEL"], "refiner_clip": ["CLIP"], "refiner_positive": ["CONDITIONING"], "refiner_negative": ["CONDITIONING"], "bbox_detector": ["BBOX_DETECTOR"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}, "optional": {"sam_model_opt": ["SAM_MODEL"], "segm_detector_opt": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["model", "clip", "vae", "positive", "negative", "refiner_model", "refiner_clip", "refiner_positive", "refiner_negative", "bbox_detector", "wildcard", "Select to add LoRA", "Select to add Wildcard"], "optional": ["sam_model_opt", "segm_detector_opt", "detailer_hook"]}, "output": ["DETAILER_PIPE"], "output_is_list": [false], "output_name": ["detailer_pipe"], "name": "ToDetailerPipeSDXL", "display_name": "ToDetailerPipeSDXL", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "FromDetailerPipe": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"]}}, "input_order": {"required": ["detailer_pipe"]}, "output": ["MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "BBOX_DETECTOR", "SAM_MODEL", "SEGM_DETECTOR", "DETAILER_HOOK"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["model", "clip", "vae", "positive", "negative", "bbox_detector", "sam_model_opt", "segm_detector_opt", "detailer_hook"], "name": "FromDetailerPipe", "display_name": "FromDetailerPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "FromDetailerPipe_v2": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"]}}, "input_order": {"required": ["detailer_pipe"]}, "output": ["DETAILER_PIPE", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "BBOX_DETECTOR", "SAM_MODEL", "SEGM_DETECTOR", "DETAILER_HOOK"], "output_is_list": [false, false, false, false, false, false, false, false, false, false], "output_name": ["detailer_pipe", "model", "clip", "vae", "positive", "negative", "bbox_detector", "sam_model_opt", "segm_detector_opt", "detailer_hook"], "name": "FromDetailerPipe_v2", "display_name": "FromDetailerPipe_v2", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "FromDetailerPipeSDXL": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"]}}, "input_order": {"required": ["detailer_pipe"]}, "output": ["DETAILER_PIPE", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "BBOX_DETECTOR", "SAM_MODEL", "SEGM_DETECTOR", "DETAILER_HOOK", "MODEL", "CLIP", "CONDITIONING", "CONDITIONING"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["detailer_pipe", "model", "clip", "vae", "positive", "negative", "bbox_detector", "sam_model_opt", "segm_detector_opt", "detailer_hook", "refiner_model", "refiner_clip", "refiner_positive", "refiner_negative"], "name": "FromDetailerPipeSDXL", "display_name": "FromDetailer (SDXL/pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "AnyPipeToBasic": {"input": {"required": {"any_pipe": ["*"]}}, "input_order": {"required": ["any_pipe"]}, "output": ["BASIC_PIPE"], "output_is_list": [false], "output_name": ["basic_pipe"], "name": "AnyPipeToBasic", "display_name": "Any PIPE -> BasicPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "ToBasicPipe": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"]}}, "input_order": {"required": ["model", "clip", "vae", "positive", "negative"]}, "output": ["BASIC_PIPE"], "output_is_list": [false], "output_name": ["basic_pipe"], "name": "ToBasicPipe", "display_name": "ToBasicPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "FromBasicPipe": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"]}}, "input_order": {"required": ["basic_pipe"]}, "output": ["MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING"], "output_is_list": [false, false, false, false, false], "output_name": ["model", "clip", "vae", "positive", "negative"], "name": "FromBasicPipe", "display_name": "FromBasicPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "FromBasicPipe_v2": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"]}}, "input_order": {"required": ["basic_pipe"]}, "output": ["BASIC_PIPE", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING"], "output_is_list": [false, false, false, false, false, false], "output_name": ["basic_pipe", "model", "clip", "vae", "positive", "negative"], "name": "FromBasicPipe_v2", "display_name": "FromBasicPipe_v2", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "BasicPipeToDetailerPipe": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"], "bbox_detector": ["BBOX_DETECTOR"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}, "optional": {"sam_model_opt": ["SAM_MODEL"], "segm_detector_opt": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["basic_pipe", "bbox_detector", "wildcard", "Select to add LoRA", "Select to add Wildcard"], "optional": ["sam_model_opt", "segm_detector_opt", "detailer_hook"]}, "output": ["DETAILER_PIPE"], "output_is_list": [false], "output_name": ["detailer_pipe"], "name": "BasicPipeToDetailerPipe", "display_name": "BasicPipe -> DetailerPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "BasicPipeToDetailerPipeSDXL": {"input": {"required": {"base_basic_pipe": ["BASIC_PIPE"], "refiner_basic_pipe": ["BASIC_PIPE"], "bbox_detector": ["BBOX_DETECTOR"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}, "optional": {"sam_model_opt": ["SAM_MODEL"], "segm_detector_opt": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["base_basic_pipe", "refiner_basic_pipe", "bbox_detector", "wildcard", "Select to add LoRA", "Select to add Wildcard"], "optional": ["sam_model_opt", "segm_detector_opt", "detailer_hook"]}, "output": ["DETAILER_PIPE"], "output_is_list": [false], "output_name": ["detailer_pipe"], "name": "BasicPipeToDetailerPipeSDXL", "display_name": "BasicPipe -> DetailerPipe (SDXL)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "DetailerPipeToBasicPipe": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"]}}, "input_order": {"required": ["detailer_pipe"]}, "output": ["BASIC_PIPE", "BASIC_PIPE"], "output_is_list": [false, false], "output_name": ["base_basic_pipe", "refiner_basic_pipe"], "name": "DetailerPipeToBasicPipe", "display_name": "DetailerPipe -> BasicPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "EditBasicPipe": {"input": {"required": {"basic_pipe": ["BASIC_PIPE"]}, "optional": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"]}}, "input_order": {"required": ["basic_pipe"], "optional": ["model", "clip", "vae", "positive", "negative"]}, "output": ["BASIC_PIPE"], "output_is_list": [false], "output_name": ["basic_pipe"], "name": "EditBasicPipe", "display_name": "Edit BasicPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "EditDetailerPipe": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}, "optional": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "bbox_detector": ["BBOX_DETECTOR"], "sam_model": ["SAM_MODEL"], "segm_detector": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["detailer_pipe", "wildcard", "Select to add LoRA", "Select to add Wildcard"], "optional": ["model", "clip", "vae", "positive", "negative", "bbox_detector", "sam_model", "segm_detector", "detailer_hook"]}, "output": ["DETAILER_PIPE"], "output_is_list": [false], "output_name": ["detailer_pipe"], "name": "EditDetailerPipe", "display_name": "Edit DetailerPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "EditDetailerPipeSDXL": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"], "wildcard": ["STRING", {"multiline": true, "dynamicPrompts": false}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}, "optional": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "refiner_model": ["MODEL"], "refiner_clip": ["CLIP"], "refiner_positive": ["CONDITIONING"], "refiner_negative": ["CONDITIONING"], "bbox_detector": ["BBOX_DETECTOR"], "sam_model": ["SAM_MODEL"], "segm_detector": ["SEGM_DETECTOR"], "detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["detailer_pipe", "wildcard", "Select to add LoRA", "Select to add Wildcard"], "optional": ["model", "clip", "vae", "positive", "negative", "refiner_model", "refiner_clip", "refiner_positive", "refiner_negative", "bbox_detector", "sam_model", "segm_detector", "detailer_hook"]}, "output": ["DETAILER_PIPE"], "output_is_list": [false], "output_name": ["detailer_pipe"], "name": "EditDetailerPipeSDXL", "display_name": "Edit DetailerPipe (SDXL)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Pipe", "output_node": false}, "LatentPixelScale": {"input": {"required": {"samples": ["LATENT"], "scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "scale_factor": ["FLOAT", {"default": 1.5, "min": 0.1, "max": 10000, "step": 0.1}], "vae": ["VAE"], "use_tiled_vae": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"]}}, "input_order": {"required": ["samples", "scale_method", "scale_factor", "vae", "use_tiled_vae"], "optional": ["upscale_model_opt"]}, "output": ["LATENT", "IMAGE"], "output_is_list": [false, false], "output_name": ["LATENT", "IMAGE"], "name": "LatentPixelScale", "display_name": "Latent Scale (on Pixel Space)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "PixelKSampleUpscalerProvider": {"input": {"required": {"scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "model": ["MODEL"], "vae": ["VAE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "use_tiled_vae": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "tile_size": ["INT", {"default": 512, "min": 320, "max": 4096, "step": 64}]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"], "pk_hook_opt": ["PK_HOOK"], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["scale_method", "model", "vae", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "use_tiled_vae", "tile_size"], "optional": ["upscale_model_opt", "pk_hook_opt", "scheduler_func_opt"]}, "output": ["UPSCALER"], "output_is_list": [false], "output_name": ["UPSCALER"], "name": "PixelKSampleUpscalerProvider", "display_name": "PixelKSampleUpscalerProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "PixelKSampleUpscalerProviderPipe": {"input": {"required": {"scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "use_tiled_vae": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "basic_pipe": ["BASIC_PIPE"], "tile_size": ["INT", {"default": 512, "min": 320, "max": 4096, "step": 64}]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"], "pk_hook_opt": ["PK_HOOK"], "scheduler_func_opt": ["SCHEDULER_FUNC"], "tile_cnet_opt": ["CONTROL_NET"], "tile_cnet_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["scale_method", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "use_tiled_vae", "basic_pipe", "tile_size"], "optional": ["upscale_model_opt", "pk_hook_opt", "scheduler_func_opt", "tile_cnet_opt", "tile_cnet_strength"]}, "output": ["UPSCALER"], "output_is_list": [false], "output_name": ["UPSCALER"], "name": "PixelKSampleUpscalerProviderPipe", "display_name": "PixelKSampleUpscalerProviderPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "IterativeLatentUpscale": {"input": {"required": {"samples": ["LATENT"], "upscale_factor": ["FLOAT", {"default": 1.5, "min": 1, "max": 10000, "step": 0.1}], "steps": ["INT", {"default": 3, "min": 1, "max": 10000, "step": 1}], "temp_prefix": ["STRING", {"default": ""}], "upscaler": ["UPSCALER"], "step_mode": [["simple", "geometric"], {"default": "simple"}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["samples", "upscale_factor", "steps", "temp_prefix", "upscaler", "step_mode"], "hidden": ["unique_id"]}, "output": ["LATENT", "VAE"], "output_is_list": [false, false], "output_name": ["latent", "vae"], "name": "IterativeLatentUpscale", "display_name": "Iterative Upscale (Latent/on Pixel Space)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "IterativeImageUpscale": {"input": {"required": {"pixels": ["IMAGE"], "upscale_factor": ["FLOAT", {"default": 1.5, "min": 1, "max": 10000, "step": 0.1}], "steps": ["INT", {"default": 3, "min": 1, "max": 10000, "step": 1}], "temp_prefix": ["STRING", {"default": ""}], "upscaler": ["UPSCALER"], "vae": ["VAE"], "step_mode": [["simple", "geometric"], {"default": "simple"}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["pixels", "upscale_factor", "steps", "temp_prefix", "upscaler", "vae", "step_mode"], "hidden": ["unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "IterativeImageUpscale", "display_name": "Iterative Upscale (Image)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "PixelTiledKSampleUpscalerProvider": {"input": {"required": {"scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "model": ["MODEL"], "vae": ["VAE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "tile_width": ["INT", {"default": 512, "min": 320, "max": 16384, "step": 64}], "tile_height": ["INT", {"default": 512, "min": 320, "max": 16384, "step": 64}], "tiling_strategy": [["random", "padded", "simple"]]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"], "pk_hook_opt": ["PK_HOOK"], "tile_cnet_opt": ["CONTROL_NET"], "tile_cnet_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}]}}, "input_order": {"required": ["scale_method", "model", "vae", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "tile_width", "tile_height", "tiling_strategy"], "optional": ["upscale_model_opt", "pk_hook_opt", "tile_cnet_opt", "tile_cnet_strength", "overlap"]}, "output": ["UPSCALER"], "output_is_list": [false], "output_name": ["UPSCALER"], "name": "PixelTiledKSampleUpscalerProvider", "display_name": "PixelTiledKSampleUpscalerProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "PixelTiledKSampleUpscalerProviderPipe": {"input": {"required": {"scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "tile_width": ["INT", {"default": 512, "min": 320, "max": 16384, "step": 64}], "tile_height": ["INT", {"default": 512, "min": 320, "max": 16384, "step": 64}], "tiling_strategy": [["random", "padded", "simple"]], "basic_pipe": ["BASIC_PIPE"]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"], "pk_hook_opt": ["PK_HOOK"], "tile_cnet_opt": ["CONTROL_NET"], "tile_cnet_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["scale_method", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "tile_width", "tile_height", "tiling_strategy", "basic_pipe"], "optional": ["upscale_model_opt", "pk_hook_opt", "tile_cnet_opt", "tile_cnet_strength"]}, "output": ["UPSCALER"], "output_is_list": [false], "output_name": ["UPSCALER"], "name": "PixelTiledKSampleUpscalerProviderPipe", "display_name": "PixelTiledKSampleUpscalerProviderPipe", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "TwoSamplersForMaskUpscalerProvider": {"input": {"required": {"scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "full_sample_schedule": [["none", "interleave1", "interleave2", "interleave3", "last1", "last2", "interleave1+last1", "interleave2+last1", "interleave3+last1"]], "use_tiled_vae": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "base_sampler": ["KSAMPLER"], "mask_sampler": ["KSAMPLER"], "mask": ["MASK"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 320, "max": 4096, "step": 64}]}, "optional": {"full_sampler_opt": ["KSAMPLER"], "upscale_model_opt": ["UPSCALE_MODEL"], "pk_hook_base_opt": ["PK_HOOK"], "pk_hook_mask_opt": ["PK_HOOK"], "pk_hook_full_opt": ["PK_HOOK"]}}, "input_order": {"required": ["scale_method", "full_sample_schedule", "use_tiled_vae", "base_sampler", "mask_sampler", "mask", "vae", "tile_size"], "optional": ["full_sampler_opt", "upscale_model_opt", "pk_hook_base_opt", "pk_hook_mask_opt", "pk_hook_full_opt"]}, "output": ["UPSCALER"], "output_is_list": [false], "output_name": ["UPSCALER"], "name": "TwoSamplersForMaskUpscalerProvider", "display_name": "TwoSamplersForMask Upscaler Provider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "TwoSamplersForMaskUpscalerProviderPipe": {"input": {"required": {"scale_method": [["nearest-exact", "bilinear", "lanczos", "area"]], "full_sample_schedule": [["none", "interleave1", "interleave2", "interleave3", "last1", "last2", "interleave1+last1", "interleave2+last1", "interleave3+last1"]], "use_tiled_vae": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "base_sampler": ["KSAMPLER"], "mask_sampler": ["KSAMPLER"], "mask": ["MASK"], "basic_pipe": ["BASIC_PIPE"], "tile_size": ["INT", {"default": 512, "min": 320, "max": 4096, "step": 64}]}, "optional": {"full_sampler_opt": ["KSAMPLER"], "upscale_model_opt": ["UPSCALE_MODEL"], "pk_hook_base_opt": ["PK_HOOK"], "pk_hook_mask_opt": ["PK_HOOK"], "pk_hook_full_opt": ["PK_HOOK"]}}, "input_order": {"required": ["scale_method", "full_sample_schedule", "use_tiled_vae", "base_sampler", "mask_sampler", "mask", "basic_pipe", "tile_size"], "optional": ["full_sampler_opt", "upscale_model_opt", "pk_hook_base_opt", "pk_hook_mask_opt", "pk_hook_full_opt"]}, "output": ["UPSCALER"], "output_is_list": [false], "output_name": ["UPSCALER"], "name": "TwoSamplersForMaskUpscalerProviderPipe", "display_name": "TwoSamplersForMask Upscaler Provider (pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "PixelKSampleHookCombine": {"input": {"required": {"hook1": ["PK_HOOK"], "hook2": ["PK_HOOK"]}}, "input_order": {"required": ["hook1", "hook2"]}, "output": ["PK_HOOK"], "output_is_list": [false], "output_name": ["PK_HOOK"], "name": "PixelKSampleHookCombine", "display_name": "PixelKSampleHookCombine", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "DenoiseScheduleHookProvider": {"input": {"required": {"schedule_for_iteration": [["simple"]], "target_denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["schedule_for_iteration", "target_denoise"]}, "output": ["PK_HOOK"], "output_is_list": [false], "output_name": ["PK_HOOK"], "name": "DenoiseScheduleHookProvider", "display_name": "DenoiseScheduleHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "StepsScheduleHookProvider": {"input": {"required": {"schedule_for_iteration": [["simple"]], "target_steps": ["INT", {"default": 20, "min": 1, "max": 10000}]}}, "input_order": {"required": ["schedule_for_iteration", "target_steps"]}, "output": ["PK_HOOK"], "output_is_list": [false], "output_name": ["PK_HOOK"], "name": "StepsScheduleHookProvider", "display_name": "StepsScheduleHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "CfgScheduleHookProvider": {"input": {"required": {"schedule_for_iteration": [["simple"]], "target_cfg": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0}]}}, "input_order": {"required": ["schedule_for_iteration", "target_cfg"]}, "output": ["PK_HOOK"], "output_is_list": [false], "output_name": ["PK_HOOK"], "name": "CfgScheduleHookProvider", "display_name": "CfgScheduleHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "NoiseInjectionHookProvider": {"input": {"required": {"schedule_for_iteration": [["simple"]], "source": [["CPU", "GPU"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "start_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 200.0, "step": 0.01}], "end_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 200.0, "step": 0.01}]}}, "input_order": {"required": ["schedule_for_iteration", "source", "seed", "start_strength", "end_strength"]}, "output": ["PK_HOOK"], "output_is_list": [false], "output_name": ["PK_HOOK"], "name": "NoiseInjectionHookProvider", "display_name": "NoiseInjectionHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "UnsamplerHookProvider": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 25, "min": 1, "max": 10000}], "start_end_at_step": ["INT", {"default": 21, "min": 0, "max": 10000}], "end_end_at_step": ["INT", {"default": 24, "min": 0, "max": 10000}], "cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "normalize": [["disable", "enable"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "schedule_for_iteration": [["simple"]]}}, "input_order": {"required": ["model", "steps", "start_end_at_step", "end_end_at_step", "cfg", "sampler_name", "scheduler", "normalize", "positive", "negative", "schedule_for_iteration"]}, "output": ["PK_HOOK"], "output_is_list": [false], "output_name": ["PK_HOOK"], "name": "UnsamplerHookProvider", "display_name": "UnsamplerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "CoreMLDetailerHookProvider": {"input": {"required": {"mode": [["512x512", "768x768", "512x768", "768x512"]]}}, "input_order": {"required": ["mode"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "CoreMLDetailerHookProvider", "display_name": "CoreMLDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "PreviewDetailerHookProvider": {"input": {"required": {"quality": ["INT", {"default": 95, "min": 20, "max": 100}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["quality"], "hidden": ["unique_id"]}, "output": ["DETAILER_HOOK", "UPSCALER_HOOK"], "output_is_list": [false, false], "output_name": ["DETAILER_HOOK", "UPSCALER_HOOK"], "name": "PreviewDetailerHookProvider", "display_name": "PreviewDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "DetailerHookCombine": {"input": {"required": {"hook1": ["DETAILER_HOOK"], "hook2": ["DETAILER_HOOK"]}}, "input_order": {"required": ["hook1", "hook2"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "DetailerHookCombine", "display_name": "DetailerHookCombine", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "NoiseInjectionDetailerHookProvider": {"input": {"required": {"schedule_for_cycle": [["skip_start", "from_start"]], "source": [["CPU", "GPU"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "start_strength": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 200.0, "step": 0.01}], "end_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 200.0, "step": 0.01}]}}, "input_order": {"required": ["schedule_for_cycle", "source", "seed", "start_strength", "end_strength"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "NoiseInjectionDetailerHookProvider", "display_name": "NoiseInjectionDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "UnsamplerDetailerHookProvider": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 25, "min": 1, "max": 10000}], "start_end_at_step": ["INT", {"default": 21, "min": 0, "max": 10000}], "end_end_at_step": ["INT", {"default": 24, "min": 0, "max": 10000}], "cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "normalize": [["disable", "enable"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "schedule_for_cycle": [["skip_start", "from_start"]]}}, "input_order": {"required": ["model", "steps", "start_end_at_step", "end_end_at_step", "cfg", "sampler_name", "scheduler", "normalize", "positive", "negative", "schedule_for_cycle"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "UnsamplerDetailerHookProvider", "display_name": "UnsamplerDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "DenoiseSchedulerDetailerHookProvider": {"input": {"required": {"schedule_for_cycle": [["simple"]], "target_denoise": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["schedule_for_cycle", "target_denoise"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "DenoiseSchedulerDetailerHookProvider", "display_name": "DenoiseSchedulerDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "SEGSOrderedFilterDetailerHookProvider": {"input": {"required": {"target": [["area(=w*h)", "width", "height", "x1", "y1", "x2", "y2"]], "order": ["BOOLEAN", {"default": true, "label_on": "descending", "label_off": "ascending"}], "take_start": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "take_count": ["INT", {"default": 1, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["target", "order", "take_start", "take_count"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "SEGSOrderedFilterDetailerHookProvider", "display_name": "SEGSOrderedFilterDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "SEGSRangeFilterDetailerHookProvider": {"input": {"required": {"target": [["area(=w*h)", "width", "height", "x1", "y1", "x2", "y2", "length_percent"]], "mode": ["BOOLEAN", {"default": true, "label_on": "inside", "label_off": "outside"}], "min_value": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "max_value": ["INT", {"default": 67108864, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["target", "mode", "min_value", "max_value"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "SEGSRangeFilterDetailerHookProvider", "display_name": "SEGSRangeFilterDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "SEGSLabelFilterDetailerHookProvider": {"input": {"required": {"segs": ["SEGS"], "preset": [["all", "hand", "face", "mouth", "eyes", "eyebrows", "pupils", "left_eyebrow", "left_eye", "left_pupil", "right_eyebrow", "right_eye", "right_pupil", "short_sleeved_shirt", "long_sleeved_shirt", "short_sleeved_outwear", "long_sleeved_outwear", "vest", "sling", "shorts", "trousers", "skirt", "short_sleeved_dress", "long_sleeved_dress", "vest_dress", "sling_dress", "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]], "labels": ["STRING", {"multiline": true, "placeholder": "List the types of segments to be allowed, separated by commas"}]}}, "input_order": {"required": ["segs", "preset", "labels"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "SEGSLabelFilterDetailerHookProvider", "display_name": "SEGSLabelFilterDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "VariationNoiseDetailerHookProvider": {"input": {"required": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["seed", "strength"]}, "output": ["DETAILER_HOOK"], "output_is_list": [false], "output_name": ["DETAILER_HOOK"], "name": "VariationNoiseDetailerHookProvider", "display_name": "VariationNoiseDetailerHookProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "BitwiseAndMask": {"input": {"required": {"mask1": ["MASK"], "mask2": ["MASK"]}}, "input_order": {"required": ["mask1", "mask2"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "BitwiseAndMask", "display_name": "Pixelwise(MASK & MASK)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "SubtractMask": {"input": {"required": {"mask1": ["MASK"], "mask2": ["MASK"]}}, "input_order": {"required": ["mask1", "mask2"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SubtractMask", "display_name": "Pixelwise(MASK - MASK)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "AddMask": {"input": {"required": {"mask1": ["MASK"], "mask2": ["MASK"]}}, "input_order": {"required": ["mask1", "mask2"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "AddMask", "display_name": "Pixelwise(MASK + MASK)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MaskRectArea": {"input": {"required": {}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": [], "hidden": ["extra_pnginfo", "unique_id"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskRectArea", "display_name": "Mask Rect Area", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MaskRectAreaAdvanced": {"input": {"required": {}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": [], "hidden": ["extra_pnginfo", "unique_id"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskRectAreaAdvanced", "display_name": "Mask Rect Area (Advanced)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "ImpactSegsAndMask": {"input": {"required": {"segs": ["SEGS"], "mask": ["MASK"]}}, "input_order": {"required": ["segs", "mask"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSegsAndMask", "display_name": "Pixelwise(SEGS & MASK)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "ImpactSegsAndMaskForEach": {"input": {"required": {"segs": ["SEGS"], "masks": ["MASK"]}}, "input_order": {"required": ["segs", "masks"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSegsAndMaskForEach", "display_name": "Pixelwise(SEGS & MASKS ForEach)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "EmptySegs": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "EmptySegs", "display_name": "EmptySegs", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactFlattenMask": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImpactFlattenMask", "display_name": "Flatten Mask Batch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MediaPipeFaceMeshToSEGS": {"input": {"required": {"image": ["IMAGE"], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "bbox_fill": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "crop_min_size": ["INT", {"min": 10, "max": 16384, "step": 1, "default": 50}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 1}], "dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "face": ["BOOLEAN", {"default": true, "label_on": "Enabled", "label_off": "Disabled"}], "mouth": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}], "left_eyebrow": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}], "left_eye": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}], "left_pupil": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}], "right_eyebrow": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}], "right_eye": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}], "right_pupil": ["BOOLEAN", {"default": false, "label_on": "Enabled", "label_off": "Disabled"}]}}, "input_order": {"required": ["image", "crop_factor", "bbox_fill", "crop_min_size", "drop_size", "dilation", "face", "mouth", "left_eyebrow", "left_eye", "left_pupil", "right_eyebrow", "right_eye", "right_pupil"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "MediaPipeFaceMeshToSEGS", "display_name": "MediaPipe FaceMesh to SEGS", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MaskToSEGS": {"input": {"required": {"mask": ["MASK"], "combined": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "bbox_fill": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "contour_fill": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["mask", "combined", "crop_factor", "bbox_fill", "drop_size", "contour_fill"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "MaskToSEGS", "display_name": "MASK to SEGS", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MaskToSEGS_for_AnimateDiff": {"input": {"required": {"mask": ["MASK"], "combined": ["BOOLEAN", {"default": false, "label_on": "True", "label_off": "False"}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "bbox_fill": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "contour_fill": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}]}}, "input_order": {"required": ["mask", "combined", "crop_factor", "bbox_fill", "drop_size", "contour_fill"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "MaskToSEGS_for_AnimateDiff", "display_name": "MASK to SEGS for AnimateDiff", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "ToBinaryMask": {"input": {"required": {"mask": ["MASK"], "threshold": ["INT", {"default": 20, "min": 1, "max": 255}]}}, "input_order": {"required": ["mask", "threshold"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ToBinaryMask", "display_name": "ToBinaryMask", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MasksToMaskList": {"input": {"required": {"masks": ["MASK"]}}, "input_order": {"required": ["masks"]}, "output": ["MASK"], "output_is_list": [true], "output_name": ["MASK"], "name": "MasksToMaskList", "display_name": "Mask Batch to Mask List", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "MaskListToMaskBatch": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskListToMaskBatch", "display_name": "Mask List to Mask Batch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "ImageListToImageBatch": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageListToImageBatch", "display_name": "Image List to Image Batch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "SetDefaultImageForSEGS": {"input": {"required": {"segs": ["SEGS"], "image": ["IMAGE"], "override": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["segs", "image", "override"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "SetDefaultImageForSEGS", "display_name": "Set Default Image for SEGS", "description": "If the SEGS have not passed through the detailer, they contain only detection area information without an image. This node sets a default image for the SEGS.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "RemoveImageFromSEGS": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "RemoveImageFromSEGS", "display_name": "Remove Image from SEGS", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "BboxDetectorSEGS": {"input": {"required": {"bbox_detector": ["BBOX_DETECTOR"], "image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "labels": ["STRING", {"multiline": true, "default": "all", "placeholder": "List the types of segments to be allowed, separated by commas"}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["bbox_detector", "image", "threshold", "dilation", "crop_factor", "drop_size", "labels"], "optional": ["detailer_hook"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "BboxDetectorSEGS", "display_name": "BBOX Detector (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "SegmDetectorSEGS": {"input": {"required": {"segm_detector": ["SEGM_DETECTOR"], "image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "labels": ["STRING", {"multiline": true, "default": "all", "placeholder": "List the types of segments to be allowed, separated by commas"}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["segm_detector", "image", "threshold", "dilation", "crop_factor", "drop_size", "labels"], "optional": ["detailer_hook"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "SegmDetectorSEGS", "display_name": "SEGM Detector (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "ONNXDetectorSEGS": {"input": {"required": {"bbox_detector": ["BBOX_DETECTOR"], "image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "labels": ["STRING", {"multiline": true, "default": "all", "placeholder": "List the types of segments to be allowed, separated by commas"}]}, "optional": {"detailer_hook": ["DETAILER_HOOK"]}}, "input_order": {"required": ["bbox_detector", "image", "threshold", "dilation", "crop_factor", "drop_size", "labels"], "optional": ["detailer_hook"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ONNXDetectorSEGS", "display_name": "ONNX Detector (SEGS/legacy) - use BBOXDetector", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "ImpactSimpleDetectorSEGS_for_AD": {"input": {"required": {"bbox_detector": ["BBOX_DETECTOR"], "image_frames": ["IMAGE"], "bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_dilation": ["INT", {"default": 0, "min": -255, "max": 255, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "sub_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "sub_dilation": ["INT", {"default": 0, "min": -255, "max": 255, "step": 1}], "sub_bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "sam_mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"masking_mode": [["Pivot SEGS", "Combine neighboring frames", "Don't combine"]], "segs_pivot": [["Combined mask", "1st frame mask"]], "sam_model_opt": ["SAM_MODEL", {"tooltip": "[OPTIONAL]\nSegment Anything Model for Silhouette Detection.\nBe sure to use the SAM_MODEL loaded through the SAMLoader (Impact) node as input.\nGiven this input, it refines the rectangular areas detected by BBOX_DETECTOR into silhouette shapes through SAM.\nsam_model_opt takes priority over segm_detector_opt."}], "segm_detector_opt": ["SEGM_DETECTOR"]}}, "input_order": {"required": ["bbox_detector", "image_frames", "bbox_threshold", "bbox_dilation", "crop_factor", "drop_size", "sub_threshold", "sub_dilation", "sub_bbox_expansion", "sam_mask_hint_threshold"], "optional": ["masking_mode", "segs_pivot", "sam_model_opt", "segm_detector_opt"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSimpleDetectorSEGS_for_AD", "display_name": "Simple Detector for AnimateDiff (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "ImpactSimpleDetectorSEGS": {"input": {"required": {"bbox_detector": ["BBOX_DETECTOR"], "image": ["IMAGE"], "bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "sub_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "sub_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "sub_bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "sam_mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"post_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "sam_model_opt": ["SAM_MODEL", {"tooltip": "[OPTIONAL]\nSegment Anything Model for Silhouette Detection.\nBe sure to use the SAM_MODEL loaded through the SAMLoader (Impact) node as input.\nGiven this input, it refines the rectangular areas detected by BBOX_DETECTOR into silhouette shapes through SAM.\nsam_model_opt takes priority over segm_detector_opt."}], "segm_detector_opt": ["SEGM_DETECTOR"]}}, "input_order": {"required": ["bbox_detector", "image", "bbox_threshold", "bbox_dilation", "crop_factor", "drop_size", "sub_threshold", "sub_dilation", "sub_bbox_expansion", "sam_mask_hint_threshold"], "optional": ["post_dilation", "sam_model_opt", "segm_detector_opt"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSimpleDetectorSEGS", "display_name": "Simple Detector (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "ImpactSimpleDetectorSEGSPipe": {"input": {"required": {"detailer_pipe": ["DETAILER_PIPE"], "image": ["IMAGE"], "bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "bbox_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 100, "step": 0.1}], "drop_size": ["INT", {"min": 1, "max": 16384, "step": 1, "default": 10}], "sub_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "sub_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "sub_bbox_expansion": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1}], "sam_mask_hint_threshold": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"post_dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["detailer_pipe", "image", "bbox_threshold", "bbox_dilation", "crop_factor", "drop_size", "sub_threshold", "sub_dilation", "sub_bbox_expansion", "sam_mask_hint_threshold"], "optional": ["post_dilation"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSimpleDetectorSEGSPipe", "display_name": "Simple Detector (SEGS/pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "ImpactControlNetApplySEGS": {"input": {"required": {"segs": ["SEGS"], "control_net": ["CONTROL_NET"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}, "optional": {"segs_preprocessor": ["SEGS_PREPROCESSOR"], "control_image": ["IMAGE"]}}, "input_order": {"required": ["segs", "control_net", "strength"], "optional": ["segs_preprocessor", "control_image"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactControlNetApplySEGS", "display_name": "ControlNetApply (SEGS) - DEPRECATED", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "deprecated": true}, "ImpactControlNetApplyAdvancedSEGS": {"input": {"required": {"segs": ["SEGS"], "control_net": ["CONTROL_NET"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"segs_preprocessor": ["SEGS_PREPROCESSOR"], "control_image": ["IMAGE"], "vae": ["VAE"]}}, "input_order": {"required": ["segs", "control_net", "strength", "start_percent", "end_percent"], "optional": ["segs_preprocessor", "control_image", "vae"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactControlNetApplyAdvancedSEGS", "display_name": "ControlNetApply (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactControlNetClearSEGS": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactControlNetClearSEGS", "display_name": "ImpactControlNetClearSEGS", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactIPAdapterApplySEGS": {"input": {"required": {"segs": ["SEGS"], "ipadapter_pipe": ["IPADAPTER_PIPE"], "weight": ["FLOAT", {"default": 0.7, "min": -1, "max": 3, "step": 0.05}], "noise": ["FLOAT", {"default": 0.4, "min": 0.0, "max": 1.0, "step": 0.01}], "weight_type": [["original", "linear", "channel penalty"], {"default": "channel penalty"}], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 1.0, "step": 0.001}], "unfold_batch": ["BOOLEAN", {"default": false}], "faceid_v2": ["BOOLEAN", {"default": false}], "weight_v2": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "context_crop_factor": ["FLOAT", {"default": 1.2, "min": 1.0, "max": 100, "step": 0.1}], "reference_image": ["IMAGE"]}, "optional": {"combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "neg_image": ["IMAGE"]}}, "input_order": {"required": ["segs", "ipadapter_pipe", "weight", "noise", "weight_type", "start_at", "end_at", "unfold_batch", "faceid_v2", "weight_v2", "context_crop_factor", "reference_image"], "optional": ["combine_embeds", "neg_image"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactIPAdapterApplySEGS", "display_name": "IPAdapterApply (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactDecomposeSEGS": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["SEGS_HEADER", "SEG_ELT"], "output_is_list": [false, true], "output_name": ["SEGS_HEADER", "SEG_ELT"], "name": "ImpactDecomposeSEGS", "display_name": "Decompose (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactAssembleSEGS": {"input": {"required": {"seg_header": ["SEGS_HEADER"], "seg_elt": ["SEG_ELT"]}}, "input_order": {"required": ["seg_header", "seg_elt"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactAssembleSEGS", "display_name": "Assemble (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactFrom_SEG_ELT": {"input": {"required": {"seg_elt": ["SEG_ELT"]}}, "input_order": {"required": ["seg_elt"]}, "output": ["SEG_ELT", "IMAGE", "MASK", "SEG_ELT_crop_region", "SEG_ELT_bbox", "SEG_ELT_control_net_wrapper", "FLOAT", "STRING"], "output_is_list": [false, false, false, false, false, false, false, false], "output_name": ["seg_elt", "cropped_image", "cropped_mask", "crop_region", "bbox", "control_net_wrapper", "confidence", "label"], "name": "ImpactFrom_SEG_ELT", "display_name": "From SEG_ELT", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactEdit_SEG_ELT": {"input": {"required": {"seg_elt": ["SEG_ELT"]}, "optional": {"cropped_image_opt": ["IMAGE"], "cropped_mask_opt": ["MASK"], "crop_region_opt": ["SEG_ELT_crop_region"], "bbox_opt": ["SEG_ELT_bbox"], "control_net_wrapper_opt": ["SEG_ELT_control_net_wrapper"], "confidence_opt": ["FLOAT", {"min": 0, "max": 1.0, "step": 0.1, "forceInput": true}], "label_opt": ["STRING", {"multiline": false, "forceInput": true}]}}, "input_order": {"required": ["seg_elt"], "optional": ["cropped_image_opt", "cropped_mask_opt", "crop_region_opt", "bbox_opt", "control_net_wrapper_opt", "confidence_opt", "label_opt"]}, "output": ["SEG_ELT"], "output_is_list": [false], "output_name": ["SEG_ELT"], "name": "ImpactEdit_SEG_ELT", "display_name": "Edit SEG_ELT", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactDilate_Mask_SEG_ELT": {"input": {"required": {"seg_elt": ["SEG_ELT"], "dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["seg_elt", "dilation"]}, "output": ["SEG_ELT"], "output_is_list": [false], "output_name": ["SEG_ELT"], "name": "ImpactDilate_Mask_SEG_ELT", "display_name": "Dilate Mask (SEG_ELT)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactDilateMask": {"input": {"required": {"mask": ["MASK"], "dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["mask", "dilation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImpactDilateMask", "display_name": "Dilate Mask", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactGaussianBlurMask": {"input": {"required": {"mask": ["MASK"], "kernel_size": ["INT", {"default": 10, "min": 0, "max": 100, "step": 1}], "sigma": ["FLOAT", {"default": 10.0, "min": 0.1, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["mask", "kernel_size", "sigma"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImpactGaussianBlurMask", "display_name": "Gaussian Blur Mask", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactDilateMaskInSEGS": {"input": {"required": {"segs": ["SEGS"], "dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["segs", "dilation"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactDilateMaskInSEGS", "display_name": "Dilate Mask (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactGaussianBlurMaskInSEGS": {"input": {"required": {"segs": ["SEGS"], "kernel_size": ["INT", {"default": 10, "min": 0, "max": 100, "step": 1}], "sigma": ["FLOAT", {"default": 10.0, "min": 0.1, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["segs", "kernel_size", "sigma"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactGaussianBlurMaskInSEGS", "display_name": "Gaussian Blur Mask (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactScaleBy_BBOX_SEG_ELT": {"input": {"required": {"seg": ["SEG_ELT"], "scale_by": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["seg", "scale_by"]}, "output": ["SEG_ELT"], "output_is_list": [false], "output_name": ["SEG_ELT"], "name": "ImpactScaleBy_BBOX_SEG_ELT", "display_name": "ScaleBy BBOX (SEG_ELT)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactFrom_SEG_ELT_bbox": {"input": {"required": {"bbox": ["SEG_ELT_bbox"]}}, "input_order": {"required": ["bbox"]}, "output": ["INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["left", "top", "right", "bottom"], "name": "ImpactFrom_SEG_ELT_bbox", "display_name": "From SEG_ELT bbox", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactFrom_SEG_ELT_crop_region": {"input": {"required": {"crop_region": ["SEG_ELT_crop_region"]}}, "input_order": {"required": ["crop_region"]}, "output": ["INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["left", "top", "right", "bottom"], "name": "ImpactFrom_SEG_ELT_crop_region", "display_name": "From SEG_ELT crop_region", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactCount_Elts_in_SEGS": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "ImpactCount_Elts_in_SEGS", "display_name": "Count Elts in SEGS", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "BboxDetectorCombined_v2": {"input": {"required": {"bbox_detector": ["BBOX_DETECTOR"], "image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "dilation": ["INT", {"default": 4, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["bbox_detector", "image", "threshold", "dilation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "BboxDetectorCombined_v2", "display_name": "BBOX Detector (combined)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "SegmDetectorCombined_v2": {"input": {"required": {"segm_detector": ["SEGM_DETECTOR"], "image": ["IMAGE"], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "dilation": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}]}}, "input_order": {"required": ["segm_detector", "image", "threshold", "dilation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SegmDetectorCombined_v2", "display_name": "SEGM Detector (combined)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detector", "output_node": false}, "SegsToCombinedMask": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SegsToCombinedMask", "display_name": "SEGS to MASK (combined)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Operation", "output_node": false}, "KSamplerProvider": {"input": {"required": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "tooltip": "classifier free guidance value"}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "sampler"}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"], {"tooltip": "noise schedule"}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of noise to remove. This amount is the noise added at the start, and the higher it is, the more the input latent will be modified before being returned."}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "basic_pipe input for sampling"}]}, "optional": {"scheduler_func_opt": ["SCHEDULER_FUNC", {"tooltip": "[OPTIONAL] Noise schedule generation function. If this is set, the scheduler widget will be ignored."}]}}, "input_order": {"required": ["seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "basic_pipe"], "optional": ["scheduler_func_opt"]}, "output": ["KSAMPLER"], "output_is_list": [false], "output_name": ["KSAMPLER"], "name": "KSamplerProvider", "display_name": "KSamplerProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Sampler", "output_node": false, "output_tooltips": ["sampler wrapper. (Can be used when generating a regional_prompt.)"]}, "TwoSamplersForMask": {"input": {"required": {"latent_image": ["LATENT", {"tooltip": "input latent image"}], "base_sampler": ["KSAMPLER", {"tooltip": "Sampler to apply to the region outside the mask."}], "mask_sampler": ["KSAMPLER", {"tooltip": "Sampler to apply to the masked region."}], "mask": ["MASK", {"tooltip": "region mask"}]}}, "input_order": {"required": ["latent_image", "base_sampler", "mask_sampler", "mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "TwoSamplersForMask", "display_name": "TwoSamplersForMask", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Sampler", "output_node": false, "output_tooltips": ["result latent"]}, "TiledKSamplerProvider": {"input": {"required": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "tooltip": "classifier free guidance value"}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "sampler"}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], {"tooltip": "noise schedule"}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of noise to remove. This amount is the noise added at the start, and the higher it is, the more the input latent will be modified before being returned."}], "tile_width": ["INT", {"default": 512, "min": 320, "max": 16384, "step": 64, "tooltip": "Sets the width of the tile to be used in TiledKSampler."}], "tile_height": ["INT", {"default": 512, "min": 320, "max": 16384, "step": 64, "tooltip": "Sets the height of the tile to be used in TiledKSampler."}], "tiling_strategy": [["random", "padded", "simple"], {"tooltip": "Sets the tiling strategy for TiledKSampler."}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "basic_pipe input for sampling"}]}}, "input_order": {"required": ["seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "tile_width", "tile_height", "tiling_strategy", "basic_pipe"]}, "output": ["KSAMPLER"], "output_is_list": [false], "output_name": ["KSAMPLER"], "name": "TiledKSamplerProvider", "display_name": "TiledKSamplerProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Sampler", "output_node": false, "output_tooltips": ["sampler wrapper. (Can be used when generating a regional_prompt.)"]}, "KSamplerAdvancedProvider": {"input": {"required": {"cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "toolip": "classifier free guidance value"}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"toolip": "sampler"}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"], {"toolip": "noise schedule"}], "sigma_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "toolip": "Multiplier of noise schedule"}], "basic_pipe": ["BASIC_PIPE", {"toolip": "basic_pipe input for sampling"}]}, "optional": {"sampler_opt": ["SAMPLER", {"toolip": "[OPTIONAL] Uses the passed sampler instead of internal impact_sampler."}], "scheduler_func_opt": ["SCHEDULER_FUNC", {"toolip": "[OPTIONAL] Noise schedule generation function. If this is set, the scheduler widget will be ignored."}]}}, "input_order": {"required": ["cfg", "sampler_name", "scheduler", "sigma_factor", "basic_pipe"], "optional": ["sampler_opt", "scheduler_func_opt"]}, "output": ["KSAMPLER_ADVANCED"], "output_is_list": [false], "output_name": ["KSAMPLER_ADVANCED"], "name": "KSamplerAdvancedProvider", "display_name": "KSamplerAdvancedProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Sampler", "output_node": false, "output_tooltips": ["sampler wrapper. (Can be used when generating a regional_prompt.)"]}, "TwoAdvancedSamplersForMask": {"input": {"required": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of noise to remove. This amount is the noise added at the start, and the higher it is, the more the input latent will be modified before being returned."}], "samples": ["LATENT", {"tooltip": "input latent image"}], "base_sampler": ["KSAMPLER_ADVANCED", {"tooltip": "Sampler to apply to the region outside the mask."}], "mask_sampler": ["KSAMPLER_ADVANCED", {"tooltip": "Sampler to apply to the masked region."}], "mask": ["MASK", {"tooltip": "region mask"}], "overlap_factor": ["INT", {"default": 10, "min": 0, "max": 10000, "tooltip": "To smooth the seams of the region boundaries, expand the mask by the overlap_factor amount to overlap with other regions."}]}}, "input_order": {"required": ["seed", "steps", "denoise", "samples", "base_sampler", "mask_sampler", "mask", "overlap_factor"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "TwoAdvancedSamplersForMask", "display_name": "TwoAdvancedSamplersForMask", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Sampler", "output_node": false, "output_tooltips": ["result latent"]}, "ImpactNegativeConditioningPlaceholder": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ImpactNegativeConditioningPlaceholder", "display_name": "Negative Cond Placeholder", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/sampling", "output_node": false, "output_tooltips": ["This is a Placeholder for the FLUX model that does not use Negative Conditioning."]}, "PreviewBridge": {"input": {"required": {"images": ["IMAGE"], "image": ["STRING", {"default": ""}]}, "optional": {"block": ["BOOLEAN", {"default": false, "label_on": "if_empty_mask", "label_off": "never", "tooltip": "is_empty_mask: If the mask is empty, the execution is stopped.\nnever: The execution is never stopped."}], "restore_mask": [["never", "always", "if_same_size"], {"tooltip": "if_same_size: If the changed input image is the same size as the previous image, restore using the last saved mask\nalways: Whenever the input image changes, always restore using the last saved mask\nnever: Do not restore the mask.\n`restore_mask` has higher priority than `block`"}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "image"], "optional": ["block", "restore_mask"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "PreviewBridge", "display_name": "Preview Bridge (Image)", "description": "This is a feature that allows you to edit and send a Mask over a image.\nIf the block is set to 'is_empty_mask', the execution is stopped when the mask is empty.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "PreviewBridgeLatent": {"input": {"required": {"latent": ["LATENT"], "image": ["STRING", {"default": ""}], "preview_method": [["Latent2RGB-FLUX.1", "Latent2RGB-SDXL", "Latent2RGB-SD15", "Latent2RGB-SD3", "Latent2RGB-SD-X4", "Latent2RGB-Playground-2.5", "Latent2RGB-SC-Prior", "Latent2RGB-SC-B", "Latent2RGB-LTXV", "TAEF1", "TAESDXL", "TAESD15", "TAESD3"]]}, "optional": {"vae_opt": ["VAE"], "block": ["BOOLEAN", {"default": false, "label_on": "if_empty_mask", "label_off": "never", "tooltip": "is_empty_mask: If the mask is empty, the execution is stopped.\nnever: The execution is never stopped. Instead, it returns a white mask."}], "restore_mask": [["never", "always", "if_same_size"], {"tooltip": "if_same_size: If the changed input latent is the same size as the previous latent, restore using the last saved mask\nalways: Whenever the input latent changes, always restore using the last saved mask\nnever: Do not restore the mask.\n`restore_mask` has higher priority than `block`\nIf the input latent already has a mask, do not restore mask."}]}, "hidden": {"unique_id": "UNIQUE_ID", "prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["latent", "image", "preview_method"], "optional": ["vae_opt", "block", "restore_mask"], "hidden": ["unique_id", "prompt", "extra_pnginfo"]}, "output": ["LATENT", "MASK"], "output_is_list": [false, false], "output_name": ["LATENT", "MASK"], "name": "PreviewBridgeLatent", "display_name": "Preview Bridge (Latent)", "description": "This is a feature that allows you to edit and send a Mask over a latent image.\nIf the block is set to 'is_empty_mask', the execution is stopped when the mask is empty.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "ImageSender": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ImgSender"}], "link_id": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "link_id"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImageSender", "display_name": "Image Sender", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "ImageReceiver": {"input": {"required": {"image": [["example.png"]], "link_id": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "save_to_workflow": ["BOOLEAN", {"default": false}], "image_data": ["STRING", {"multiline": false}], "trigger_always": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["image", "link_id", "save_to_workflow", "image_data", "trigger_always"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImageReceiver", "display_name": "Image Receiver", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "LatentSender": {"input": {"required": {"samples": ["LATENT"], "filename_prefix": ["STRING", {"default": "latents/LatentSender"}], "link_id": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "preview_method": [["Latent2RGB-FLUX.1", "Latent2RGB-SDXL", "Latent2RGB-SD15", "Latent2RGB-SD3", "Latent2RGB-SD-X4", "Latent2RGB-Playground-2.5", "Latent2RGB-SC-Prior", "Latent2RGB-SC-B", "Latent2RGB-LTXV", "TAEF1", "TAESDXL", "TAESD15", "TAESD3"]]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["samples", "filename_prefix", "link_id", "preview_method"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "LatentSender", "display_name": "LatentSender", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "LatentReceiver": {"input": {"required": {"latent": [[]], "link_id": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "trigger_always": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable"}]}}, "input_order": {"required": ["latent", "link_id", "trigger_always"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentReceiver", "display_name": "LatentReceiver", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImageMaskSwitch": {"input": {"required": {"select": ["INT", {"default": 1, "min": 1, "max": 4, "step": 1}], "images1": ["IMAGE"]}, "optional": {"mask1_opt": ["MASK"], "images2_opt": ["IMAGE"], "mask2_opt": ["MASK"], "images3_opt": ["IMAGE"], "mask3_opt": ["MASK"], "images4_opt": ["IMAGE"], "mask4_opt": ["MASK"]}}, "input_order": {"required": ["select", "images1"], "optional": ["mask1_opt", "images2_opt", "mask2_opt", "images3_opt", "mask3_opt", "images4_opt", "mask4_opt"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImageMaskSwitch", "display_name": "Switch (images, mask)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "LatentSwitch": {"input": {"required": {"select": ["INT", {"default": 1, "min": 1, "max": 999999, "step": 1, "tooltip": "The input number you want to output among the inputs"}], "sel_mode": ["BOOLEAN", {"default": false, "label_on": "select_on_prompt", "label_off": "select_on_execution", "forceInput": false, "tooltip": "In the case of 'select_on_execution', the selection is dynamically determined at the time of workflow execution. 'select_on_prompt' is an option that exists for older versions of ComfyUI, and it makes the decision before the workflow execution."}]}, "optional": {"input1": ["*", {"lazy": true, "tooltip": "Any input. When connected, one more input slot is added."}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["select", "sel_mode"], "optional": ["input1"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": ["*", "STRING", "INT"], "output_is_list": [false, false, false], "output_name": ["selected_value", "selected_label", "selected_index"], "name": "LatentSwitch", "display_name": "Switch (latent/legacy)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "output_tooltips": ["Output is generated only from the input chosen by the 'select' value.", "Slot label of the selected input slot", "Outputs the select value as is"]}, "SEGSSwitch": {"input": {"required": {"select": ["INT", {"default": 1, "min": 1, "max": 999999, "step": 1, "tooltip": "The input number you want to output among the inputs"}], "sel_mode": ["BOOLEAN", {"default": false, "label_on": "select_on_prompt", "label_off": "select_on_execution", "forceInput": false, "tooltip": "In the case of 'select_on_execution', the selection is dynamically determined at the time of workflow execution. 'select_on_prompt' is an option that exists for older versions of ComfyUI, and it makes the decision before the workflow execution."}]}, "optional": {"input1": ["*", {"lazy": true, "tooltip": "Any input. When connected, one more input slot is added."}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["select", "sel_mode"], "optional": ["input1"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": ["*", "STRING", "INT"], "output_is_list": [false, false, false], "output_name": ["selected_value", "selected_label", "selected_index"], "name": "SEGSSwitch", "display_name": "Switch (SEGS/legacy)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "output_tooltips": ["Output is generated only from the input chosen by the 'select' value.", "Slot label of the selected input slot", "Outputs the select value as is"]}, "ImpactSwitch": {"input": {"required": {"select": ["INT", {"default": 1, "min": 1, "max": 999999, "step": 1, "tooltip": "The input number you want to output among the inputs"}], "sel_mode": ["BOOLEAN", {"default": false, "label_on": "select_on_prompt", "label_off": "select_on_execution", "forceInput": false, "tooltip": "In the case of 'select_on_execution', the selection is dynamically determined at the time of workflow execution. 'select_on_prompt' is an option that exists for older versions of ComfyUI, and it makes the decision before the workflow execution."}]}, "optional": {"input1": ["*", {"lazy": true, "tooltip": "Any input. When connected, one more input slot is added."}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["select", "sel_mode"], "optional": ["input1"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": ["*", "STRING", "INT"], "output_is_list": [false, false, false], "output_name": ["selected_value", "selected_label", "selected_index"], "name": "ImpactSwitch", "display_name": "Switch (Any)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "output_tooltips": ["Output is generated only from the input chosen by the 'select' value.", "Slot label of the selected input slot", "Outputs the select value as is"]}, "ImpactInversedSwitch": {"input": {"required": {"select": ["INT", {"default": 1, "min": 1, "max": 999999, "step": 1, "tooltip": "The output number you want to send from the input"}], "input": ["*", {"tooltip": "Any input. When connected, one more input slot is added."}]}, "optional": {"sel_mode": ["BOOLEAN", {"default": false, "label_on": "select_on_prompt", "label_off": "select_on_execution", "forceInput": false, "tooltip": "In the case of 'select_on_execution', the selection is dynamically determined at the time of workflow execution. 'select_on_prompt' is an option that exists for older versions of ComfyUI, and it makes the decision before the workflow execution."}]}, "hidden": {"prompt": "PROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["select", "input"], "optional": ["sel_mode"], "hidden": ["prompt", "unique_id"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ImpactInversedSwitch", "display_name": "Inversed Switch (Any)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "output_tooltips": ["Output occurs only from the output selected by the 'select' value.\nWhen slots are connected, additional slots are created."]}, "ImpactWildcardProcessor": {"input": {"required": {"wildcard_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "tooltip": "Enter a prompt using wildcard syntax."}], "populated_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "tooltip": "The actual value passed during the execution of 'ImpactWildcardProcessor' is what is shown here. The behavior varies slightly depending on the mode. Wildcard syntax can also be used in 'populated_text'."}], "mode": [["populate", "fixed", "reproduce"], {"default": "populate", "tooltip": "populate: Before running the workflow, it overwrites the existing value of 'populated_text' with the prompt processed from 'wildcard_text'. In this mode, 'populated_text' cannot be edited.\nfixed: Ignores wildcard_text and keeps 'populated_text' as is. You can edit 'populated_text' in this mode.\nreproduce: This mode operates as 'fixed' mode only once for reproduction, and then it switches to 'populate' mode."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Determines the random seed to be used for wildcard processing."}], "Select to add Wildcard": [["Select the Wildcard to add to the text"]]}}, "input_order": {"required": ["wildcard_text", "populated_text", "mode", "seed", "Select to add Wildcard"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["processed text"], "name": "ImpactWildcardProcessor", "display_name": "ImpactWildcardProcessor", "description": "The 'ImpactWildcardProcessor' processes text prompts written in wildcard syntax and outputs the processed text prompt.\n\nTIP: Before the workflow is executed, the processing result of 'wildcard_text' is displayed in 'populated_text', and the populated text is saved along with the workflow. If you want to use a seed converted as input, write the prompt directly in 'populated_text' instead of 'wildcard_text', and set the mode to 'fixed'.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Prompt", "output_node": false}, "ImpactWildcardEncode": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "wildcard_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "tooltip": "Enter a prompt using wildcard syntax."}], "populated_text": ["STRING", {"multiline": true, "dynamicPrompts": false, "tooltip": "The actual value passed during the execution of 'ImpactWildcardEncode' is what is shown here. The behavior varies slightly depending on the mode. Wildcard syntax can also be used in 'populated_text'."}], "mode": [["populate", "fixed", "reproduce"], {"tooltip": "populate: Before running the workflow, it overwrites the existing value of 'populated_text' with the prompt processed from 'wildcard_text'. In this mode, 'populated_text' cannot be edited.\nfixed: Ignores wildcard_text and keeps 'populated_text' as is. You can edit 'populated_text' in this mode\n.reproduce: This mode operates as 'fixed' mode only once for reproduction, and then it switches to 'populate' mode."}], "Select to add LoRA": [["Select the LoRA to add to the text", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "Select to add Wildcard": [["Select the Wildcard to add to the text"]], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Determines the random seed to be used for wildcard processing."}]}}, "input_order": {"required": ["model", "clip", "wildcard_text", "populated_text", "mode", "Select to add LoRA", "Select to add Wildcard", "seed"]}, "output": ["MODEL", "CLIP", "CONDITIONING", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["model", "clip", "conditioning", "populated_text"], "name": "ImpactWildcardEncode", "display_name": "ImpactWildcardEncode", "description": "The 'ImpactWildcardEncode' node processes text prompts written in wildcard syntax and outputs them as conditioning. It also supports LoRA syntax, with the applied LoRA reflected in the model's output.\n\nTIP1: Before the workflow is executed, the processing result of 'wildcard_text' is displayed in 'populated_text', and the populated text is saved along with the workflow. If you want to use a seed converted as input, write the prompt directly in 'populated_text' instead of 'wildcard_text', and set the mode to 'fixed'.\nTIP2: If the 'Inspire Pack' is installed, LBW(LoRA Block Weight) syntax can also be applied.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Prompt", "output_node": false}, "SEGSUpscaler": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "rescale_factor": ["FLOAT", {"default": 2, "min": 0.01, "max": 100.0, "step": 0.01}], "resampling_method": [["lanczos", "nearest", "bilinear", "bicubic"]], "supersample": [["true", "false"]], "rounding_modulus": ["INT", {"default": 8, "min": 8, "max": 1024, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"], "upscaler_hook_opt": ["UPSCALER_HOOK"], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["image", "segs", "model", "clip", "vae", "rescale_factor", "resampling_method", "supersample", "rounding_modulus", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "denoise", "feather", "inpaint_model", "noise_mask_feather"], "optional": ["upscale_model_opt", "upscaler_hook_opt", "scheduler_func_opt"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SEGSUpscaler", "display_name": "Upscaler (SEGS)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "SEGSUpscalerPipe": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "basic_pipe": ["BASIC_PIPE"], "rescale_factor": ["FLOAT", {"default": 2, "min": 0.01, "max": 100.0, "step": 0.01}], "resampling_method": [["lanczos", "nearest", "bilinear", "bicubic"]], "supersample": [["true", "false"]], "rounding_modulus": ["INT", {"default": 8, "min": 8, "max": 1024, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}]}, "optional": {"upscale_model_opt": ["UPSCALE_MODEL"], "upscaler_hook_opt": ["UPSCALER_HOOK"], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["image", "segs", "basic_pipe", "rescale_factor", "resampling_method", "supersample", "rounding_modulus", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "feather", "inpaint_model", "noise_mask_feather"], "optional": ["upscale_model_opt", "upscaler_hook_opt", "scheduler_func_opt"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SEGSUpscalerPipe", "display_name": "Upscaler (SEGS/pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Upscale", "output_node": false}, "SEGSDetailer": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 768, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "noise_mask": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "force_inpaint": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled"}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "If the `ImpactDummyInput` is connected to the model in the basic_pipe, the inference stage is skipped."}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 100}], "cycle": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}, "optional": {"refiner_basic_pipe_opt": ["BASIC_PIPE"], "inpaint_model": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["image", "segs", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "noise_mask", "force_inpaint", "basic_pipe", "refiner_ratio", "batch_size", "cycle"], "optional": ["refiner_basic_pipe_opt", "inpaint_model", "noise_mask_feather", "scheduler_func_opt"]}, "output": ["SEGS", "IMAGE"], "output_is_list": [false, true], "output_name": ["segs", "cnet_images"], "name": "SEGSDetailer", "display_name": "SEGSDetailer", "description": "This node enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.\nThis node is applied specifically to SEGS rather than the entire image. To apply it to the entire image, use the 'SEGS Paste' node.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "SEGSPaste": {"input": {"required": {"image": ["IMAGE"], "segs": ["SEGS"], "feather": ["INT", {"default": 5, "min": 0, "max": 100, "step": 1}], "alpha": ["INT", {"default": 255, "min": 0, "max": 255, "step": 1}]}, "optional": {"ref_image_opt": ["IMAGE"]}}, "input_order": {"required": ["image", "segs", "feather", "alpha"], "optional": ["ref_image_opt"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SEGSPaste", "display_name": "SEGSPaste", "description": "This node provides a function to paste the enhanced SEGS, improved through the SEGS detailer, back onto the original image.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "SEGSPreview": {"input": {"required": {"segs": ["SEGS"], "alpha_mode": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable"}], "min_alpha": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"fallback_image_opt": ["IMAGE"]}}, "input_order": {"required": ["segs", "alpha_mode", "min_alpha"], "optional": ["fallback_image_opt"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "SEGSPreview", "display_name": "SEGSPreview", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "SEGSPreviewCNet": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "SEGSPreviewCNet", "display_name": "SEGSPreview (CNET Image)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": true}, "SEGSToImageList": {"input": {"required": {"segs": ["SEGS"]}, "optional": {"fallback_image_opt": ["IMAGE"]}}, "input_order": {"required": ["segs"], "optional": ["fallback_image_opt"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "SEGSToImageList", "display_name": "SEGSToImageList", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSToMaskList": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["MASK"], "output_is_list": [true], "output_name": ["MASK"], "name": "ImpactSEGSToMaskList", "display_name": "SEGS to Mask List", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSToMaskBatch": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImpactSEGSToMaskBatch", "display_name": "SEGS to Mask Batch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSConcat": {"input": {"required": {"segs1": ["SEGS"]}}, "input_order": {"required": ["segs1"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSEGSConcat", "display_name": "SEGS Concat", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSPicker": {"input": {"required": {"picks": ["STRING", {"multiline": true, "dynamicPrompts": false, "pysssss.autocomplete": false}], "segs": ["SEGS"]}, "optional": {"fallback_image_opt": ["IMAGE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["picks", "segs"], "optional": ["fallback_image_opt"], "hidden": ["unique_id"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSEGSPicker", "display_name": "Picker (SEGS)", "description": "This node provides a function to select only the chosen SEGS from the input SEGS.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactMakeTileSEGS": {"input": {"required": {"images": ["IMAGE"], "bbox_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 8}], "crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10, "step": 0.01}], "min_overlap": ["INT", {"default": 5, "min": 0, "max": 512, "step": 1}], "filter_segs_dilation": ["INT", {"default": 20, "min": -255, "max": 255, "step": 1}], "mask_irregularity": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "irregular_mask_mode": [["Reuse fast", "Reuse quality", "All random fast", "All random quality"]]}, "optional": {"filter_in_segs_opt": ["SEGS"], "filter_out_segs_opt": ["SEGS"]}}, "input_order": {"required": ["images", "bbox_size", "crop_factor", "min_overlap", "filter_segs_dilation", "mask_irregularity", "irregular_mask_mode"], "optional": ["filter_in_segs_opt", "filter_out_segs_opt"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactMakeTileSEGS", "display_name": "Make Tile SEGS", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/__for_testing", "output_node": false}, "ImpactSEGSMerge": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSEGSMerge", "display_name": "SEGS Merge", "description": "SEGS contains multiple SEGs. SEGS Merge integrates several SEGs into a single merged SEG. The label is changed to `merged` and the confidence becomes the minimum confidence. The applied controlnet and cropped_image are removed.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "SEGSDetailerForAnimateDiff": {"input": {"required": {"image_frames": ["IMAGE"], "segs": ["SEGS"], "guide_size": ["FLOAT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "guide_size_for": ["BOOLEAN", {"default": true, "label_on": "bbox", "label_off": "crop_region"}], "max_size": ["FLOAT", {"default": 768, "min": 64, "max": 16384, "step": 8}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "denoise": ["FLOAT", {"default": 0.5, "min": 0.0001, "max": 1.0, "step": 0.01}], "basic_pipe": ["BASIC_PIPE", {"tooltip": "If the `ImpactDummyInput` is connected to the model in the basic_pipe, the inference stage is skipped."}], "refiner_ratio": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0}]}, "optional": {"refiner_basic_pipe_opt": ["BASIC_PIPE"], "noise_mask_feather": ["INT", {"default": 20, "min": 0, "max": 100, "step": 1}], "scheduler_func_opt": ["SCHEDULER_FUNC"]}}, "input_order": {"required": ["image_frames", "segs", "guide_size", "guide_size_for", "max_size", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "basic_pipe", "refiner_ratio"], "optional": ["refiner_basic_pipe_opt", "noise_mask_feather", "scheduler_func_opt"]}, "output": ["SEGS", "IMAGE"], "output_is_list": [false, true], "output_name": ["segs", "cnet_images"], "name": "SEGSDetailerForAnimateDiff", "display_name": "SEGSDetailer For AnimateDiff (SEGS/pipe)", "description": "This node enhances details by inpainting each region within the detected area bundle (SEGS) after enlarging them based on the guide size.\nThis node is applied specifically to SEGS rather than the entire image. To apply it to the entire image, use the 'SEGS Paste' node.\nAs a specialized detailer node for improving video details, such as in AnimateDiff, this node can handle cases where the masks contained in SEGS serve as batch masks spanning multiple frames.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Detailer", "output_node": false}, "ImpactKSamplerBasicPipe": {"input": {"required": {"basic_pipe": ["BASIC_PIPE", {"tooltip": "basic_pipe input for sampling"}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "tooltip": "classifier free guidance value"}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "sampler"}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"], {"tooltip": "noise schedule"}], "latent_image": ["LATENT", {"tooltip": "input latent image"}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of noise to remove. This amount is the noise added at the start, and the higher it is, the more the input latent will be modified before being returned."}]}, "optional": {"scheduler_func_opt": ["SCHEDULER_FUNC", {"tooltip": "[OPTIONAL] Noise schedule generation function. If this is set, the scheduler widget will be ignored."}]}}, "input_order": {"required": ["basic_pipe", "seed", "steps", "cfg", "sampler_name", "scheduler", "latent_image", "denoise"], "optional": ["scheduler_func_opt"]}, "output": ["BASIC_PIPE", "LATENT", "VAE"], "output_is_list": [false, false, false], "output_name": ["BASIC_PIPE", "LATENT", "VAE"], "name": "ImpactKSamplerBasicPipe", "display_name": "KSampler (pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/sampling", "output_node": false, "output_tooltips": ["passthrough input basic_pipe", "result latent", "VAE in basic_pipe"]}, "ImpactKSamplerAdvancedBasicPipe": {"input": {"required": {"basic_pipe": ["BASIC_PIPE", {"tooltip": "basic_pipe input for sampling"}], "add_noise": ["BOOLEAN", {"default": true, "label_on": "enable", "label_off": "disable", "tooltip": "Whether to add noise"}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "tooltip": "classifier free guidance value"}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "sampler"}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"], {"tooltip": "noise schedule"}], "latent_image": ["LATENT", {"tooltip": "input latent image"}], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000, "tooltip": "The starting step of the sampling to be applied at this node within the range of 'steps'."}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000, "tooltip": "The step at which sampling applied at this node will stop within the range of steps (if greater than steps, sampling will continue only up to steps)."}], "return_with_leftover_noise": ["BOOLEAN", {"default": false, "label_on": "enable", "label_off": "disable", "tooltip": "Whether to return the latent with noise remaining if the noise has not been completely removed according to the noise schedule, or to completely remove the noise before returning it."}]}, "optional": {"scheduler_func_opt": ["SCHEDULER_FUNC", {"tooltip": "[OPTIONAL] Noise schedule generation function. If this is set, the scheduler widget will be ignored."}]}}, "input_order": {"required": ["basic_pipe", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "latent_image", "start_at_step", "end_at_step", "return_with_leftover_noise"], "optional": ["scheduler_func_opt"]}, "output": ["BASIC_PIPE", "LATENT", "VAE"], "output_is_list": [false, false, false], "output_name": ["BASIC_PIPE", "LATENT", "VAE"], "name": "ImpactKSamplerAdvancedBasicPipe", "display_name": "KSampler (Advanced/pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/sampling", "output_node": false, "output_tooltips": ["passthrough input basic_pipe", "result latent", "VAE in basic_pipe"]}, "ReencodeLatent": {"input": {"required": {"samples": ["LATENT"], "tile_mode": [["None", "Both", "Decode(input) only", "Encode(output) only"]], "input_vae": ["VAE"], "output_vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 320, "max": 4096, "step": 64}]}, "optional": {"overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32, "tooltip": "This setting applies when 'tile_mode' is enabled."}]}}, "input_order": {"required": ["samples", "tile_mode", "input_vae", "output_vae", "tile_size"], "optional": ["overlap"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ReencodeLatent", "display_name": "Reencode Latent", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ReencodeLatentPipe": {"input": {"required": {"samples": ["LATENT"], "tile_mode": [["None", "Both", "Decode(input) only", "Encode(output) only"]], "input_basic_pipe": ["BASIC_PIPE"], "output_basic_pipe": ["BASIC_PIPE"]}}, "input_order": {"required": ["samples", "tile_mode", "input_basic_pipe", "output_basic_pipe"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ReencodeLatentPipe", "display_name": "Reencode Latent (pipe)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactImageBatchToImageList": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "ImpactImageBatchToImageList", "display_name": "Image Batch to Image List", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactMakeImageList": {"input": {"required": {"image1": ["IMAGE"]}}, "input_order": {"required": ["image1"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "ImpactMakeImageList", "display_name": "Make Image List", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactMakeImageBatch": {"input": {"required": {"image1": ["IMAGE"]}}, "input_order": {"required": ["image1"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImpactMakeImageBatch", "display_name": "Make Image Batch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactMakeAnyList": {"input": {"required": {}, "optional": {"value1": ["*"]}}, "input_order": {"required": [], "optional": ["value1"]}, "output": ["*"], "output_is_list": [true], "output_name": ["*"], "name": "ImpactMakeAnyList", "display_name": "Make List (Any)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactMakeMaskList": {"input": {"required": {"mask1": ["MASK"]}}, "input_order": {"required": ["mask1"]}, "output": ["MASK"], "output_is_list": [true], "output_name": ["MASK"], "name": "ImpactMakeMaskList", "display_name": "Make Mask List", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactMakeMaskBatch": {"input": {"required": {"mask1": ["MASK"]}}, "input_order": {"required": ["mask1"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImpactMakeMaskBatch", "display_name": "Make Mask Batch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSelectNthItemOfAnyList": {"input": {"required": {"any_list": ["*"], "index": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "tooltip": "The index of the item you want to select from the list."}]}}, "input_order": {"required": ["any_list", "index"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ImpactSelectNthItemOfAnyList", "display_name": "Select Nth Item (Any list)", "description": "Selects the Nth item from a list. If the index is out of range, it returns the last item in the list.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "RegionalSampler": {"input": {"required": {"seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "seed_2nd": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Additional noise seed. The behavior is determined by seed_2nd_mode."}], "seed_2nd_mode": [["ignore", "fixed", "seed+seed_2nd", "seed-seed_2nd", "increment", "decrement", "randomize"], {"tooltip": "application method of seed_2nd. 1) ignore: Do not use seed_2nd. In the base only sampling stage, the seed is applied as a noise seed, and in the regional sampling stage, denoising is performed as it is without additional noise. 2) Others: In the base only sampling stage, the seed is applied as a noise seed, and once it is closed so that there is no leftover noise, new noise is added with seed_2nd and the regional samping stage is performed. a) fixed: Use seed_2nd as it is as an additional noise seed. b) seed+seed_2nd: Apply the value of seed+seed_2nd as an additional noise seed. c) seed-seed_2nd: Apply the value of seed-seed_2nd as an additional noise seed. d) increment: Not implemented yet. Same with fixed. e) decrement: Not implemented yet. Same with fixed. f) randomize: Not implemented yet. Same with fixed."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "base_only_steps": ["INT", {"default": 2, "min": 0, "max": 10000, "tooltip": "total sampling steps"}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of noise to remove. This amount is the noise added at the start, and the higher it is, the more the input latent will be modified before being returned."}], "samples": ["LATENT", {"tooltip": "input latent image"}], "base_sampler": ["KSAMPLER_ADVANCED", {"tooltip": "The sampler applied outside the area set by the regional_prompt."}], "regional_prompts": ["REGIONAL_PROMPTS", {"tooltip": "The prompt applied to each region"}], "overlap_factor": ["INT", {"default": 10, "min": 0, "max": 10000, "tooltip": "To smooth the seams of the region boundaries, expand the mask set in regional_prompts by the overlap_factor amount to overlap with other regions."}], "restore_latent": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled", "tooltip": "At each step, restore the noise outside the mask area to its original state, as per the principle of inpainting. This option is provided for backward compatibility, and it is recommended to always set it to true."}], "additional_mode": [["DISABLE", "ratio additional", "ratio between"], {"default": "ratio between", "tooltip": "..._sde or uni_pc and other special samplers are used, the region is not properly denoised, and it causes a phenomenon that destroys the overall harmony. To compensate for this, a recovery operation is performed using another sampler. This requires a longer time for sampling because a second sampling is performed at each step in each region using a special sampler. 1) DISABLE: Disable this feature. 2) ratio additional: After performing the denoise amount to be performed in the step with the sampler set in the region, the recovery sampler is additionally applied by the additional_sigma_ratio. If you use this option, the total denoise amount increases by additional_sigma_ratio. 3) ratio between: The denoise amount to be performed in the step with the sampler set in the region and the denoise amount to be applied to the recovery sampler are divided by additional_sigma_ratio, and denoise is performed for each denoise amount. If you use this option, the total denoise amount does not change."}], "additional_sampler": [["AUTO", "euler", "heun", "heunpp2", "dpm_2", "dpm_fast", "dpmpp_2m", "ddpm"], {"tooltip": "1) AUTO: Automatically set the recovery sampler. If the sampler is uni_pc, uni_pc_bh2, dpmpp_sde, dpmpp_sde_gpu, the dpm_fast sampler is selected If the sampler is dpmpp_2m_sde, dpmpp_2m_sde_gpu, dpmpp_3m_sde, dpmpp_3m_sde_gpu, the dpmpp_2m sampler is selected. 2) Others: Manually set the recovery sampler."}], "additional_sigma_ratio": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Multiplier of noise schedule to be applied according to additional_mode."}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["seed", "seed_2nd", "seed_2nd_mode", "steps", "base_only_steps", "denoise", "samples", "base_sampler", "regional_prompts", "overlap_factor", "restore_latent", "additional_mode", "additional_sampler", "additional_sigma_ratio"], "hidden": ["unique_id"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RegionalSampler", "display_name": "RegionalSampler", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Regional", "output_node": false, "output_tooltips": ["result latent"]}, "RegionalSamplerAdvanced": {"input": {"required": {"add_noise": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled", "tooltip": "Whether to add noise"}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Random seed to use for generating CPU noise for sampling."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "total sampling steps"}], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000, "tooltip": "The starting step of the sampling to be applied at this node within the range of 'steps'."}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000, "tooltip": "The step at which sampling applied at this node will stop within the range of steps (if greater than steps, sampling will continue only up to steps)."}], "overlap_factor": ["INT", {"default": 10, "min": 0, "max": 10000, "tooltip": "To smooth the seams of the region boundaries, expand the mask set in regional_prompts by the overlap_factor amount to overlap with other regions."}], "restore_latent": ["BOOLEAN", {"default": true, "label_on": "enabled", "label_off": "disabled", "tooltip": "At each step, restore the noise outside the mask area to its original state, as per the principle of inpainting. This option is provided for backward compatibility, and it is recommended to always set it to true."}], "return_with_leftover_noise": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled", "tooltip": "Whether to return the latent with noise remaining if the noise has not been completely removed according to the noise schedule, or to completely remove the noise before returning it."}], "latent_image": ["LATENT", {"tooltip": "input latent image"}], "base_sampler": ["KSAMPLER_ADVANCED", {"tooltip": "The sampler applied outside the area set by the regional_prompt."}], "regional_prompts": ["REGIONAL_PROMPTS", {"tooltip": "The prompt applied to each region"}], "additional_mode": [["DISABLE", "ratio additional", "ratio between"], {"default": "ratio between", "tooltip": "..._sde or uni_pc and other special samplers are used, the region is not properly denoised, and it causes a phenomenon that destroys the overall harmony. To compensate for this, a recovery operation is performed using another sampler. This requires a longer time for sampling because a second sampling is performed at each step in each region using a special sampler. 1) DISABLE: Disable this feature. 2) ratio additional: After performing the denoise amount to be performed in the step with the sampler set in the region, the recovery sampler is additionally applied by the additional_sigma_ratio. If you use this option, the total denoise amount increases by additional_sigma_ratio. 3) ratio between: The denoise amount to be performed in the step with the sampler set in the region and the denoise amount to be applied to the recovery sampler are divided by additional_sigma_ratio, and denoise is performed for each denoise amount. If you use this option, the total denoise amount does not change."}], "additional_sampler": [["AUTO", "euler", "heun", "heunpp2", "dpm_2", "dpm_fast", "dpmpp_2m", "ddpm"], {"tooltip": "1) AUTO: Automatically set the recovery sampler. If the sampler is uni_pc, uni_pc_bh2, dpmpp_sde, dpmpp_sde_gpu, the dpm_fast sampler is selected If the sampler is dpmpp_2m_sde, dpmpp_2m_sde_gpu, dpmpp_3m_sde, dpmpp_3m_sde_gpu, the dpmpp_2m sampler is selected. 2) Others: Manually set the recovery sampler."}], "additional_sigma_ratio": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Multiplier of noise schedule to be applied according to additional_mode."}]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["add_noise", "noise_seed", "steps", "start_at_step", "end_at_step", "overlap_factor", "restore_latent", "return_with_leftover_noise", "latent_image", "base_sampler", "regional_prompts", "additional_mode", "additional_sampler", "additional_sigma_ratio"], "hidden": ["unique_id"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RegionalSamplerAdvanced", "display_name": "RegionalSamplerAdvanced", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Regional", "output_node": false, "output_tooltips": ["result latent"]}, "CombineRegionalPrompts": {"input": {"required": {"regional_prompts1": ["REGIONAL_PROMPTS", {"tooltip": "input regional_prompts. (Connecting to the input slot increases the number of additional slots.)"}]}}, "input_order": {"required": ["regional_prompts1"]}, "output": ["REGIONAL_PROMPTS"], "output_is_list": [false], "output_name": ["REGIONAL_PROMPTS"], "name": "CombineRegionalPrompts", "display_name": "CombineRegionalPrompts", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Regional", "output_node": false, "output_tooltips": ["Combined REGIONAL_PROMPTS"]}, "RegionalPrompt": {"input": {"required": {"mask": ["MASK", {"tooltip": "region mask"}], "advanced_sampler": ["KSAMPLER_ADVANCED", {"tooltip": "sampler for specified region"}]}, "optional": {"variation_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "Sets the extra seed to be used for noise variation."}], "variation_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Sets the strength of the noise variation."}], "variation_method": [["linear", "slerp"], {"tooltip": "Sets how the original noise and extra noise are blended together."}]}}, "input_order": {"required": ["mask", "advanced_sampler"], "optional": ["variation_seed", "variation_strength", "variation_method"]}, "output": ["REGIONAL_PROMPTS"], "output_is_list": [false], "output_name": ["REGIONAL_PROMPTS"], "name": "RegionalPrompt", "display_name": "RegionalPrompt", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Regional", "output_node": false, "output_tooltips": ["regional prompts. (Can be used in the RegionalSampler.)"]}, "ImpactCombineConditionings": {"input": {"required": {"conditioning1": ["CONDITIONING", {"tooltip": "input conditionings. (Connecting to the input slot increases the number of additional slots.)"}]}}, "input_order": {"required": ["conditioning1"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ImpactCombineConditionings", "display_name": "Combine Conditionings", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "output_tooltips": ["Combined conditioning"]}, "ImpactConcatConditionings": {"input": {"required": {"conditioning1": ["CONDITIONING", {"tooltip": "input conditionings. (Connecting to the input slot increases the number of additional slots.)"}]}}, "input_order": {"required": ["conditioning1"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ImpactConcatConditionings", "display_name": "Concat Conditionings", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false, "output_tooltips": ["Concatenated conditioning"]}, "ImpactSEGSLabelAssign": {"input": {"required": {"segs": ["SEGS"], "labels": ["STRING", {"multiline": true, "placeholder": "List the label to be assigned in order of segs, separated by commas"}]}}, "input_order": {"required": ["segs", "labels"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["SEGS"], "name": "ImpactSEGSLabelAssign", "display_name": "SEGS Assign (label)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSLabelFilter": {"input": {"required": {"segs": ["SEGS"], "preset": [["all", "hand", "face", "mouth", "eyes", "eyebrows", "pupils", "left_eyebrow", "left_eye", "left_pupil", "right_eyebrow", "right_eye", "right_pupil", "short_sleeved_shirt", "long_sleeved_shirt", "short_sleeved_outwear", "long_sleeved_outwear", "vest", "sling", "shorts", "trousers", "skirt", "short_sleeved_dress", "long_sleeved_dress", "vest_dress", "sling_dress", "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"]], "labels": ["STRING", {"multiline": true, "placeholder": "List the types of segments to be allowed, separated by commas"}]}}, "input_order": {"required": ["segs", "preset", "labels"]}, "output": ["SEGS", "SEGS"], "output_is_list": [false, false], "output_name": ["filtered_SEGS", "remained_SEGS"], "name": "ImpactSEGSLabelFilter", "display_name": "SEGS Filter (label)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSRangeFilter": {"input": {"required": {"segs": ["SEGS"], "target": [["area(=w*h)", "width", "height", "x1", "y1", "x2", "y2", "length_percent", "confidence(0-100)"]], "mode": ["BOOLEAN", {"default": true, "label_on": "inside", "label_off": "outside"}], "min_value": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "max_value": ["INT", {"default": 67108864, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["segs", "target", "mode", "min_value", "max_value"]}, "output": ["SEGS", "SEGS"], "output_is_list": [false, false], "output_name": ["filtered_SEGS", "remained_SEGS"], "name": "ImpactSEGSRangeFilter", "display_name": "SEGS Filter (range)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSOrderedFilter": {"input": {"required": {"segs": ["SEGS"], "target": [["area(=w*h)", "width", "height", "x1", "y1", "x2", "y2", "confidence", "none"]], "order": ["BOOLEAN", {"default": true, "label_on": "descending", "label_off": "ascending"}], "take_start": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}], "take_count": ["INT", {"default": 1, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["segs", "target", "order", "take_start", "take_count"]}, "output": ["SEGS", "SEGS"], "output_is_list": [false, false], "output_name": ["filtered_SEGS", "remained_SEGS"], "name": "ImpactSEGSOrderedFilter", "display_name": "SEGS Filter (ordered)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSIntersectionFilter": {"input": {"required": {"segs1": ["SEGS"], "segs2": ["SEGS"], "ioa_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["segs1", "segs2", "ioa_threshold"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["filtered_SEGS"], "name": "ImpactSEGSIntersectionFilter", "display_name": "SEGS Filter (intersection)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactSEGSNMSFilter": {"input": {"required": {"segs": ["SEGS"], "iou_threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["segs", "iou_threshold"]}, "output": ["SEGS"], "output_is_list": [false], "output_name": ["filtered_SEGS"], "name": "ImpactSEGSNMSFilter", "display_name": "SEGS Filter (non max suppression)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactCompare": {"input": {"required": {"cmp": [["a = b", "a <> b", "a > b", "a < b", "a >= b", "a <= b", "tt", "ff"]], "a": ["*"], "b": ["*"]}}, "input_order": {"required": ["cmp", "a", "b"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ImpactCompare", "display_name": "ImpactCompare", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactConditionalBranch": {"input": {"required": {"cond": ["BOOLEAN"], "tt_value": ["*", {"lazy": true}], "ff_value": ["*", {"lazy": true}]}}, "input_order": {"required": ["cond", "tt_value", "ff_value"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ImpactConditionalBranch", "display_name": "ImpactConditionalBranch", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactConditionalBranchSelMode": {"input": {"required": {"cond": ["BOOLEAN"]}, "optional": {"tt_value": ["*"], "ff_value": ["*"]}}, "input_order": {"required": ["cond"], "optional": ["tt_value", "ff_value"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ImpactConditionalBranchSelMode", "display_name": "ImpactConditionalBranchSelMode", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactIfNone": {"input": {"required": {}, "optional": {"signal": ["*"], "any_input": ["*"]}}, "input_order": {"required": [], "optional": ["signal", "any_input"]}, "output": ["*", "BOOLEAN"], "output_is_list": [false, false], "output_name": ["signal_opt", "bool"], "name": "ImpactIfNone", "display_name": "ImpactIfNone", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactConvertDataType": {"input": {"required": {"value": ["*"]}}, "input_order": {"required": ["value"]}, "output": ["STRING", "FLOAT", "INT", "BOOLEAN"], "output_is_list": [false, false, false, false], "output_name": ["STRING", "FLOAT", "INT", "BOOLEAN"], "name": "ImpactConvertDataType", "display_name": "ImpactConvertDataType", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactLogicalOperators": {"input": {"required": {"operator": [["and", "or", "xor"]], "bool_a": ["BOOLEAN", {"forceInput": true}], "bool_b": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["operator", "bool_a", "bool_b"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ImpactLogicalOperators", "display_name": "ImpactLogicalOperators", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactInt": {"input": {"required": {"value": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "ImpactInt", "display_name": "ImpactInt", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactFloat": {"input": {"required": {"value": ["FLOAT", {"default": 1.0, "min": -3.402823466e+38, "max": 3.402823466e+38}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "ImpactFloat", "display_name": "ImpactFloat", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactBoolean": {"input": {"required": {"value": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ImpactBoolean", "display_name": "ImpactBoolean", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactValueSender": {"input": {"required": {"value": ["*"], "link_id": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}]}, "optional": {"signal_opt": ["*"]}}, "input_order": {"required": ["value", "link_id"], "optional": ["signal_opt"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal"], "name": "ImpactValueSender", "display_name": "ImpactValueSender", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": true}, "ImpactValueReceiver": {"input": {"required": {"typ": [["STRING", "INT", "FLOAT", "BOOLEAN"]], "value": ["STRING", {"default": ""}], "link_id": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["typ", "value", "link_id"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ImpactValueReceiver", "display_name": "ImpactValueReceiver", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactImageInfo": {"input": {"required": {"value": ["IMAGE"]}}, "input_order": {"required": ["value"]}, "output": ["INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["batch", "height", "width", "channel"], "name": "ImpactImageInfo", "display_name": "ImpactImageInfo", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": false}, "ImpactLatentInfo": {"input": {"required": {"value": ["LATENT"]}}, "input_order": {"required": ["value"]}, "output": ["INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["batch", "height", "width", "channel"], "name": "ImpactLatentInfo", "display_name": "ImpactLatentInfo", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": false}, "ImpactMinMax": {"input": {"required": {"mode": ["BOOLEAN", {"default": true, "label_on": "max", "label_off": "min"}], "a": ["*"], "b": ["*"]}}, "input_order": {"required": ["mode", "a", "b"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "ImpactMinMax", "display_name": "ImpactMinMax", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": false}, "ImpactNeg": {"input": {"required": {"value": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ImpactNeg", "display_name": "ImpactNeg", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactConditionalStopIteration": {"input": {"required": {"cond": ["BOOLEAN", {"forceInput": true}]}}, "input_order": {"required": ["cond"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImpactConditionalStopIteration", "display_name": "ImpactConditionalStopIteration", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": true}, "ImpactStringSelector": {"input": {"required": {"strings": ["STRING", {"multiline": true}], "multiline": ["BOOLEAN", {"default": false, "label_on": "enabled", "label_off": "disabled"}], "select": ["INT", {"min": 0, "max": 9223372036854775807, "step": 1, "default": 0}]}}, "input_order": {"required": ["strings", "multiline", "select"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ImpactStringSelector", "display_name": "String Selector", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "StringListToString": {"input": {"required": {"join_with": ["STRING", {"default": "\\n"}], "string_list": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["join_with", "string_list"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringListToString", "display_name": "String List to String", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "WildcardPromptFromString": {"input": {"required": {"string": ["STRING", {"forceInput": true}], "delimiter": ["STRING", {"multiline": false, "default": "\\n"}], "prefix_all": ["STRING", {"multiline": false}], "postfix_all": ["STRING", {"multiline": false}], "restrict_to_tags": ["STRING", {"multiline": false}], "exclude_tags": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["string", "delimiter", "prefix_all", "postfix_all", "restrict_to_tags", "exclude_tags"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["wildcard", "segs_labels"], "name": "WildcardPromptFromString", "display_name": "Wildcard Prompt from String", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactExecutionOrderController": {"input": {"required": {"signal": ["*"], "value": ["*"]}}, "input_order": {"required": ["signal", "value"]}, "output": ["*", "*"], "output_is_list": [false, false], "output_name": ["signal", "value"], "name": "ImpactExecutionOrderController", "display_name": "Execution Order Controller", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactListBridge": {"input": {"required": {"list_input": ["*"]}}, "input_order": {"required": ["list_input"]}, "output": ["*"], "output_is_list": [true], "output_name": ["list_output"], "name": "ImpactListBridge", "display_name": "List Bridge", "description": "When passing the list output through this node, it collects and organizes the data before forwarding it, which ensures that the previous stage's sub-workflow has been completed.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "RemoveNoiseMask": {"input": {"required": {"samples": ["LATENT"]}}, "input_order": {"required": ["samples"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RemoveNoiseMask", "display_name": "Remove Noise Mask", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "ImpactLogger": {"input": {"required": {"data": ["*"], "text": ["STRING", {"multiline": true}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["data", "text"], "hidden": ["prompt", "extra_pnginfo", "unique_id"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImpactLogger", "display_name": "ImpactLogger", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Debug", "output_node": true}, "ImpactDummyInput": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ImpactDummyInput", "display_name": "ImpactDummyInput", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Debug", "output_node": false}, "ImpactQueueTrigger": {"input": {"required": {"signal": ["*"], "mode": ["BOOLEAN", {"default": true, "label_on": "Trigger", "label_off": "Don't trigger"}]}}, "input_order": {"required": ["signal", "mode"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal_opt"], "name": "ImpactQueueTrigger", "display_name": "Queue Trigger", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactQueueTriggerCountdown": {"input": {"required": {"count": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "total": ["INT", {"default": 10, "min": 1, "max": 18446744073709551615}], "mode": ["BOOLEAN", {"default": true, "label_on": "Trigger", "label_off": "Don't trigger"}]}, "optional": {"signal": ["*"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["count", "total", "mode"], "optional": ["signal"], "hidden": ["unique_id"]}, "output": ["*", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["signal_opt", "count", "total"], "name": "ImpactQueueTriggerCountdown", "display_name": "Queue Trigger (Countdown)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactSetWidgetValue": {"input": {"required": {"signal": ["*"], "node_id": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "widget_name": ["STRING", {"multiline": false}]}, "optional": {"boolean_value": ["BOOLEAN", {"forceInput": true}], "int_value": ["INT", {"forceInput": true}], "float_value": ["FLOAT", {"forceInput": true}], "string_value": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["signal", "node_id", "widget_name"], "optional": ["boolean_value", "int_value", "float_value", "string_value"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal_opt"], "name": "ImpactSetWidgetValue", "display_name": "Set Widget Value", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactNodeSetMuteState": {"input": {"required": {"signal": ["*"], "node_id": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "set_state": ["BOOLEAN", {"default": true, "label_on": "active", "label_off": "mute"}]}}, "input_order": {"required": ["signal", "node_id", "set_state"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal_opt"], "name": "ImpactNodeSetMuteState", "display_name": "Set Mute State", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactControlBridge": {"input": {"required": {"value": ["*"], "mode": ["BOOLEAN", {"default": true, "label_on": "Active", "label_off": "Stop/Mute/Bypass"}], "behavior": [["Stop", "Mute", "Bypass"]]}, "hidden": {"unique_id": "UNIQUE_ID", "prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["value", "mode", "behavior"], "hidden": ["unique_id", "prompt", "extra_pnginfo"]}, "output": ["*"], "output_is_list": [false], "output_name": ["value"], "name": "ImpactControlBridge", "display_name": "Control Bridge", "description": "When behavior is Stop and mode is active, the input value is passed directly to the output.\nWhen behavior is Mute/Bypass and mode is active, the node connected to the output is changed to active state.\nWhen behavior is Stop and mode is Stop/Mute/Bypass, the workflow execution of the current node is halted.\nWhen behavior is Mute/Bypass and mode is Stop/Mute/Bypass, the node connected to the output is changed to Mute/Bypass state.", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": true}, "ImpactIsNotEmptySEGS": {"input": {"required": {"segs": ["SEGS"]}}, "input_order": {"required": ["segs"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ImpactIsNotEmptySEGS", "display_name": "SEGS isn't Empty", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic", "output_node": false}, "ImpactSleep": {"input": {"required": {"signal": ["*"], "seconds": ["FLOAT", {"default": 0.5, "min": 0, "max": 3600}]}}, "input_order": {"required": ["signal", "seconds"]}, "output": ["*"], "output_is_list": [false], "output_name": ["signal_opt"], "name": "ImpactSleep", "display_name": "Sleep", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactRemoteBoolean": {"input": {"required": {"node_id": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "widget_name": ["STRING", {"multiline": false}], "value": ["BOOLEAN", {"default": true, "label_on": "True", "label_off": "False"}]}}, "input_order": {"required": ["node_id", "widget_name", "value"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImpactRemoteBoolean", "display_name": "Remote Boolean (on prompt)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactRemoteInt": {"input": {"required": {"node_id": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "widget_name": ["STRING", {"multiline": false}], "value": ["INT", {"default": 0, "min": -18446744073709551615, "max": 18446744073709551615}]}}, "input_order": {"required": ["node_id", "widget_name", "value"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImpactRemoteInt", "display_name": "Remote Int (on prompt)", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Logic/_for_test", "output_node": true}, "ImpactHFTransformersClassifierProvider": {"input": {"required": {"preset_repo_id": [["rizvandwiki/gender-classification-2", "NTQAI/pedestrian_gender_recognition", "Leilab/gender_class", "ProjectPersonal/GenderClassifier", "crangana/trained-gender", "cledoux42/GenderNew_v002", "ivensamdh/genderage2", "Manual repo id"]], "manual_repo_id": ["STRING", {"multiline": false}], "device_mode": [["AUTO", "Prefer GPU", "CPU"]]}}, "input_order": {"required": ["preset_repo_id", "manual_repo_id", "device_mode"]}, "output": ["TRANSFORMERS_CLASSIFIER"], "output_is_list": [false], "output_name": ["TRANSFORMERS_CLASSIFIER"], "name": "ImpactHFTransformersClassifierProvider", "display_name": "HF Transformers Classifier Provider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/HuggingFace", "output_node": false}, "ImpactSEGSClassify": {"input": {"required": {"classifier": ["TRANSFORMERS_CLASSIFIER"], "segs": ["SEGS"], "preset_expr": [["#Female > #Male", "#Female < #Male", "female > 0.5", "male > 0.5", "Age16to25 > 0.1", "Age50to69 > 0.1", "Manual expr"]], "manual_expr": ["STRING", {"multiline": false}]}, "optional": {"ref_image_opt": ["IMAGE"]}}, "input_order": {"required": ["classifier", "segs", "preset_expr", "manual_expr"], "optional": ["ref_image_opt"]}, "output": ["SEGS", "SEGS", "STRING"], "output_is_list": [false, false, true], "output_name": ["filtered_SEGS", "remained_SEGS", "detected_labels"], "name": "ImpactSEGSClassify", "display_name": "SEGS Classify", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/HuggingFace", "output_node": false}, "ImpactSchedulerAdapter": {"input": {"required": {"scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], {"defaultInput": true}], "extra_scheduler": [["None", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]]}}, "input_order": {"required": ["scheduler", "extra_scheduler"]}, "output": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal", "AYS SDXL", "AYS SD1", "AYS SVD", "GITS[coeff=1.2]", "LTXV[default]", "OSS FLUX", "OSS Wan"]], "output_is_list": [false], "output_name": ["scheduler"], "name": "ImpactSchedulerAdapter", "display_name": "Impact Scheduler Adapter", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/Util", "output_node": false}, "GITSSchedulerFuncProvider": {"input": {"required": {"coeff": ["FLOAT", {"default": 1.2, "min": 0.8, "max": 1.5, "step": 0.05, "tooltip": "coeff factor of GITS Scheduler"}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "denoise amount for noise schedule"}]}}, "input_order": {"required": ["coeff", "denoise"]}, "output": ["SCHEDULER_FUNC"], "output_is_list": [false], "output_name": ["SCHEDULER_FUNC"], "name": "GITSSchedulerFuncProvider", "display_name": "GITSScheduler Func Provider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Pack", "category": "ImpactPack/sampling", "output_node": false, "output_tooltips": ["Returns a function that generates a noise schedule using GITSScheduler. This can be used in place of a predetermined noise schedule to dynamically generate a noise schedule based on the steps."]}, "SaveImageWebsocket": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImageWebsocket", "display_name": "SaveImageWebsocket", "description": "", "python_module": "custom_nodes.websocket_image_save", "category": "api/image", "output_node": true}, "iToolsLoadImagePlus": {"input": {"required": {"image": [["example.png"], {"image_upload": true}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK", "STRING", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "MASK", "possible prompt", "image name"], "name": "iToolsLoadImagePlus", "display_name": "iTools Load Image \ud83c\udfd5\ufe0f", "description": "An enhancement of the original ComfyUI ImageLoader node. It attempts to return the possible prompt used to create an image.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsPromptLoader": {"input": {"required": {"file_path": ["STRING", {"default": "prompts.txt", "multiline": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 65535}]}}, "input_order": {"required": ["file_path", "seed"]}, "output": ["STRING", "INT"], "output_is_list": [false, false], "output_name": ["prompt", "count"], "name": "iToolsPromptLoader", "display_name": "iTools Prompt Loader", "description": "Will return a prompt (line number) from txt file at given index, note that count start from zero.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsPromptSaver": {"input": {"required": {"prompt": ["STRING", {"forceInput": true}], "file_path": ["STRING", {"default": "prompts.txt", "multiline": false}]}}, "input_order": {"required": ["prompt", "file_path"]}, "output": [], "output_is_list": [], "output_name": [], "name": "iToolsPromptSaver", "display_name": "iTools Prompt Saver", "description": "Will append the given prompt as a new line to the given txt file", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsAddOverlay": {"input": {"required": {"image": ["IMAGE", {}], "text": ["STRING", {"default": "img info:", "multiline": false}], "background_color": ["STRING", {"default": "#000000AA", "multiline": false}], "font_size": ["INT", {"default": 40, "min": 10, "max": 1000}], "overlay_mode": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "text", "background_color", "font_size", "overlay_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "iToolsAddOverlay", "display_name": "iTools Add Text Overlay", "description": "Will add an overlay bottom bar to show a given text, you may change the background color of the overlay bar and the font size.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsLoadImages": {"input": {"required": {"images_directory": ["STRING", {"default": "/ComfyUI/output", "multiline": false}], "start_index": ["INT", {"default": 0, "min": 0, "max": 200}], "load_limit": ["INT", {"default": 4, "min": 2, "max": 200}]}}, "input_order": {"required": ["images_directory", "start_index", "load_limit"]}, "output": ["IMAGE", "STRING", "INT"], "output_is_list": [true, true, false], "output_name": ["images", "images names", "count"], "name": "iToolsLoadImages", "display_name": "iTools Load Images \ud83d\udce6", "description": "Will return list of images from a given directory with a given limit, for example if the limit is 4 it will return first 4 images in that directory. it will also return the list of these images names.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsPromptStyler": {"input": {"required": {"text_positive": ["STRING", {"default": "", "multiline": true}], "text_negative": ["STRING", {"default": "", "multiline": false}], "style_file": [["mood.yaml", "artist.yaml", "basic.yaml", "camera.yaml", "original.yaml"], {"default": "basic.yaml"}], "template_name": [["none", "random", "3D Model", "Abstract", "Analog", "Anime", "Arcade", "Architectural", "Art Deco", "Automotive", "Biomechanics", "Child's Drawing", "Cinematic", "Clay", "Comic Book", "Constructivist", "Corporate", "Cubist", "Cute", "Cyber Punk", "Cybernetic", "Digital Painting", "Dreamscape", "Dystopian", "Expressionist", "Fantasy", "Fashion", "Film Noir", "Food", "Food (Gourmet)", "Futuristic", "Glamour", "Gothic", "Horror", "Hyperreal", "Impressionist", "Isometric", "Kirigami", "Line art", "Long Exposure", "Lovecraftian", "Low Poly", "Luxury", "Manga", "Minimalist", "Monochrome", "Neon Punk", "Origami", "Paper Mache", "Papercraft", "Papercut", "Papercut (Stacked)", "Pixel art", "Pointillism", "Pop", "Product", "Professional", "Psychedelic", "Real Estate", "Renaissance", "Retro Futurism", "Robotics", "Sci-fi", "Steampunk", "Surreal", "Tilt Shift", "Vaporwave", "Watercolor"]]}}, "input_order": {"required": ["text_positive", "text_negative", "style_file", "template_name"]}, "output": ["STRING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["positive_prompt", "negative_prompt", "used_template"], "name": "iToolsPromptStyler", "display_name": "iTools Prompt Styler \ud83d\udd8c\ufe0f", "description": "Helps you quickly populate your prompt using a template stored in YAML file.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsPromptStylerExtra": {"input": {"required": {"text_positive": ["STRING", {"default": "", "multiline": true}], "text_negative": ["STRING", {"default": "", "multiline": false}], "base_file": [["mood.yaml", "artist.yaml", "basic.yaml", "camera.yaml", "original.yaml"], {"default": "basic.yaml"}], "base_style": [["none", "random", "3D Model", "Abstract", "Analog", "Anime", "Arcade", "Architectural", "Art Deco", "Automotive", "Biomechanics", "Child's Drawing", "Cinematic", "Clay", "Comic Book", "Constructivist", "Corporate", "Cubist", "Cute", "Cyber Punk", "Cybernetic", "Digital Painting", "Dreamscape", "Dystopian", "Expressionist", "Fantasy", "Fashion", "Film Noir", "Food", "Food (Gourmet)", "Futuristic", "Glamour", "Gothic", "Horror", "Hyperreal", "Impressionist", "Isometric", "Kirigami", "Line art", "Long Exposure", "Lovecraftian", "Low Poly", "Luxury", "Manga", "Minimalist", "Monochrome", "Neon Punk", "Origami", "Paper Mache", "Papercraft", "Papercut", "Papercut (Stacked)", "Pixel art", "Pointillism", "Pop", "Product", "Professional", "Psychedelic", "Real Estate", "Renaissance", "Retro Futurism", "Robotics", "Sci-fi", "Steampunk", "Surreal", "Tilt Shift", "Vaporwave", "Watercolor"]], "second_file": [["mood.yaml", "artist.yaml", "basic.yaml", "camera.yaml", "original.yaml"], {"default": "camera.yaml"}], "second_style": [["none", "random", "Canon EOS 90D", "Canon EOS M50", "Canon EOS M50 Mark II", "Canon EOS M6 Mark II", "Canon EOS R5", "Canon EOS R5 (Unique Variant)", "Canon EOS RP", "Canon EOS Rebel T8i", "Canon EOS Rebel T8i (Unique Variant)", "Canon EOS-1D X Mark III", "Canon EOS-1D X Mark III (Unique Dynamic Capture Variant)", "Canon EOS-1D X Mark III (Unique Dynamic Scenes Variant)", "Canon PowerShot G7 X Mark III", "Canon PowerShot G7 X Mark III (Unique Specific Variant)", "Canon PowerShot G7 X Mark III (Unique Variant)", "Fujifilm FinePix XP140", "Fujifilm GFX 100", "Fujifilm GFX 100 (Unique Specific Variant)", "Fujifilm GFX 100 (Unique Variant)", "Fujifilm GFX 50S", "Fujifilm Instax Mini 11", "Fujifilm X-E4", "Fujifilm X-E4 (Unique Variant)", "Fujifilm X-Pro3", "Fujifilm X-Pro3 (Unique Variant)", "Fujifilm X-T200", "Fujifilm X-T4", "Fujifilm X-T4 (Unique Strong Stabilization)", "Fujifilm X100V", "Fujifilm X100V (Unique Variant)", "GoPro HERO9 Black", "Hasselblad 907X 50C", "Hasselblad 907X 50C (Unique Large Format)", "Hasselblad H5D-50c", "Hasselblad H6D-100c", "Hasselblad X1D II 50C", "Hasselblad X1D II 50C (Unique High Resolution)", "Hasselblad XCD 4/45P", "Leica CL", "Leica M-D", "Leica M10 Monochrom", "Leica M10 Monochrom (Unique Variant)", "Leica M10-R", "Leica M11", "Leica Q-P", "Leica Q2", "Leica Q2 Monochrom", "Leica S3", "Leica SL2", "Leica SL2 (Unique Variant)", "Leica SL2-S", "Nikon Coolpix P950", "Nikon Coolpix P950 (Unique Variant)", "Nikon Coolpix W300", "Nikon D3500", "Nikon D6", "Nikon D780", "Nikon D850", "Nikon D850 (Unique High Resolution)", "Nikon Z5", "Nikon Z50", "Nikon Z50 (Unique Variant)", "Nikon Z6", "Nikon Z6 II", "Nikon Z7 II", "Nikon Z7 II (Unique Variant)", "Olympus E-M1X", "Olympus OM-D E-M1 Mark II", "Olympus OM-D E-M10 Mark IV", "Olympus OM-D E-M10 Mark IV (Unique Variant)", "Olympus OM-D E-M1X", "Olympus OM-D E-M5 Mark III", "Olympus OM-D E-M5 Mark III (Unique Variant)", "Olympus PEN E-PL10", "Olympus PEN-F", "Olympus PEN-F (Unique Specific Variant)", "Olympus PEN-F (Unique Variant)", "Olympus Tough TG-6", "Olympus Tough TG-6 (Unique Variant)", "Panasonic Lumix DC-G100", "Panasonic Lumix DC-G9", "Panasonic Lumix DC-GH5", "Panasonic Lumix DC-S1R", "Panasonic Lumix DC-S5", "Panasonic Lumix DC-S5 (Unique Variant)", "Panasonic Lumix DMC-FZ300", "Panasonic Lumix DMC-FZ300 (Unique Variant)", "Panasonic Lumix DMC-LX100 II", "Panasonic Lumix FZ1000 II", "Panasonic Lumix G100", "Panasonic Lumix GH5 II", "Panasonic Lumix S1", "Panasonic Lumix S1R", "Panasonic Lumix S5", "Pentax 645Z", "Pentax 645Z (Unique Large Format)", "Pentax K-1 Mark II", "Pentax KP", "Phase One XF IQ4 150MP", "Phase One XT", "Ricoh GR III", "Ricoh GR III (Unique Steady Focus)", "Ricoh GR III (Unique Variant)", "Ricoh Theta Z1", "Ricoh Theta Z1 (Unique Variant)", "Sigma SD Quattro H", "Sigma fp", "Sigma fp (Unique Specific Variant)", "Sigma fp (Unique Variant)", "Sigma fp L", "Sony A6000", "Sony A6400", "Sony A7R IV", "Sony A7S III", "Sony A9 II", "Sony Alpha 1", "Sony Alpha 1 (Unique Variant)", "Sony Alpha A7 III", "Sony Alpha A9 II", "Sony Cyber-shot DSC-RX10 IV", "Sony Cyber-shot DSC-W800", "Sony Cyber-shot RX100 VII", "Sony RX10 IV", "Sony RX100 VII", "Sony RX100 VII (Unique Fast Capture)", "Sony ZV-1"]], "third_file": [["mood.yaml", "artist.yaml", "basic.yaml", "camera.yaml", "original.yaml"], {"default": "artist.yaml"}], "third_style": [["none", "random", "A.J.Casson", "Aaron Douglas", "Aaron Horkey", "Aaron Jasinski", "Aaron Siskind", "Abbott Fuller Graves", "Abbott Handerson Thayer", "Abdel Hadi Al Gazzar", "Abed Abdi", "Abigail Larson", "Abraham Mintchine", "Abraham Pether", "Abram Efimovich Arkhipov", "Adam Elsheimer", "Adam Hughes", "Adam Martinakis", "Adam Paquette", "Adi Granov", "Adolf Hir\u00e9my-Hirschl", "Adolph Gottlieb", "Adolph Menzel", "Adonna Khare", "Adriaen van Ostade", "Adriaen van Outrecht", "Adrian Donoghue", "Adrian Ghenie", "Adrian Paul Allinson", "Adrian Smith", "Adrian Tomine", "Adrianus Eversen", "Afarin Sajedi", "Affandi", "Aggi Erguna", "Agnes Cecile", "Agnes Lawrence Pelton", "Agnes Martin", "Agostino Arrivabene", "Agostino Tassi", "Ai Weiwei", "Ai Yazawa", "Akihiko Yoshida", "Akira Toriyama", "Akos Major", "Akseli Gallen-Kallela", "Al Capp", "Al Feldstein", "Al Williamson", "Alain Laboile", "Alan Bean", "Alan Davis", "Alan Kenny", "Alan Lee", "Alan Moore", "Alan Parry", "Alan Schaller", "Alasdair McLellan", "Alastair Magnaldo", "Alayna Lemmer", "Albert Benois", "Albert Bierstadt", "Albert Bloch", "Albert Dubois-Pillet", "Albert Eckhout", "Albert Edelfelt", "Albert Gleizes", "Albert Goodwin", "Albert Joseph Moore", "Albert Koetsier", "Albert Kotin", "Albert Lynch", "Albert Marquet", "Albert Pinkham Ryder", "Albert Robida", "Albert Servaes", "Albert Tucker", "Albert Watson", "Alberto Biasi", "Alberto Burri", "Alberto Giacometti", "Alberto Magnelli", "Alberto Seveso", "Alberto Sughi", "Alberto Vargas", "Albrecht Anker", "Albrecht Durer", "Alec Soth", "Alejandro Burdisio", "Alejandro Jodorowsky", "Aleksey Savrasov", "Aleksi Briclot", "Alena Aenami", "Alessandro Allori", "Alessandro Barbucci", "Alessandro Gottardo", "Alessio Albi", "Alex Alemany", "Alex Andreev", "Alex Colville", "Alex Figini", "Alex Garant", "Alex Grey", "Alex Gross", "Alex Hirsch", "Alex Horley", "Alex Howitt", "Alex Katz", "Alex Maleev", "Alex Petruk", "Alex Prager", "Alex Ross", "Alex Russell Flint", "Alex Schomburg", "Alex Timmermans", "Alex Toth", "Alexander Archipenko", "Alexander Bogen", "Alexander Fedosav", "Alexander Jansson", "Alexander Kanoldt", "Alexander McQueen", "Alexander Millar", "Alexander Milne Calder", "Alexandr Averin", "Alexandre Antigna", "Alexandre Benois", "Alexandre Cabanel", "Alexandre Calame", "Alexandre Jacovleff", "Alexandre-E\u0301variste Fragonard", "Alexei Harlamoff", "Alexej von Jawlensky", "Alexey Kurbatov", "Alexis Gritchenko", "Alfred Augustus Glendening", "Alfred Cheney Johnston", "Alfred Eisenstaedt", "Alfred Guillou", "Alfred Heber Hutty", "Alfred Henry Maurer", "Alfred Kelsner", "Alfred Kubin", "Alfred Munnings", "Alfred Parsons", "Alfred Sisley", "Alfred Stevens", "Alfredo Jaar", "Algernon Blackwood", "Alice Bailly", "Alice Neel", "Alice Pasquini", "Alice Rahon", "Alison Bechdel", "Aliza Razell", "Allen Williams", "Allie Brosh", "Allison Bechdel", "Alma Thomas", "Alois Arnegger", "Alphonse Mucha", "Alphonse Osbert", "Alpo Jaakola", "Alson Skinner Clark", "Alvar Aalto", "Alvaro Siza", "Alvin Langdon Coburn", "Alyssa Monks", "Amadou Opa Bathily", "Amanda Clark", "Amanda Sage", "Amandine Van Ray", "Ambrosius Benson", "Ambrosius Bosschaert", "Amedee Ozenfant", "Amedeo Modigliani", "Amiet Cuno", "Aminollah Rezaei", "Amir Zand", "Amy Earles", "Amy Judd", "Amy Sillman", "Am\u00e9d\u00e9e Guillemin", "Anato Finnstark", "Anatoly Metlan", "Anders Zorn", "Ando Fuchs", "Andre De Dienes", "Andre Derain", "Andre Kertesz", "Andre Kohn", "Andre Norton", "Andre-Charles Boulle", "Andrea Kowch", "Andrea Mantegna", "Andreas Achenbach", "Andreas Franke", "Andreas Gursky", "Andreas Levers", "Andreas Rocha", "Andreas Vesalius", "Andrei Markin", "Andrew Atroshenko", "Andrew Ferez", "Andrew Macara", "Andrew Robinson", "Andrew Whem", "Andrew Wyeth", "Andrey Remnev", "Andre\u0301i Arinouchkine", "Android Jones", "Andrzej Sykut", "Andr\u00e9 Lhote", "Andr\u00e9 Masson", "Andy Fairhurst", "Andy Goldsworthy", "Andy Kehoe", "Andy Warhol", "Angela Barrett", "Angela Sung", "Angus McKie", "Anish Kapoor", "Anita Malfatti", "Anja Millen", "Anja Percival", "Anka Zhuravleva", "Ann Stookey", "Anna Ancher", "Anna Bocek", "Anna Dittmann", "Anna Razumovskaya", "Anna and Elena Balbusso", "Anne Bachelier", "Anne Brigman", "Anne Dewailly", "Anne Mccaffrey", "Anne Packard", "Anne Rothenstein", "Anne Stokes", "Anne Sudworth", "Anne Truitt", "Anne-Louis Girodet", "Anni Albers", "Annibale Carracci", "Annick Bouvattier", "Annie Soudain", "Annie Swynnerton", "Ansel Adams", "Anselm Kiefer", "Antanas Sutkus", "Anthony Gerace", "Anthony Thieme", "Anthony van Dyck", "Anto Carte", "Antoine Blanchard", "Antoine Verney-Carron", "Anton Corbijn", "Anton Domenico Gabbiani", "Anton Fadeev", "Anton Mauve", "Anton Otto Fischer", "Anton Pieck", "Anton Raphael Mengs", "Anton Semenov", "Antonello da Messina", "Antoni Gaudi", "Antonio Canova", "Antonio Donghi", "Antonio J. Manzanedo", "Antonio Mancini", "Antonio Mora", "Antonio Roybal", "Antony Gormley", "Apollinary Vasnetsov", "Apollonia Saintclair", "Aquirax Uno", "Archibald Thorburn", "Aries Moross", "Arik Brauer", "Aristarkh Lentulov", "Aristide Maillol", "Arkhyp Kuindzhi", "Armand Guillaumin", "Armand Point", "Arnold Bocklin", "Arnold B\u00f6cklin", "Arnold Schoenberg", "Aron Demetz", "Aron Wiesenfeld", "Arshile Gorky", "Art Fitzpatrick", "Art Frahm", "Art Spiegelman", "Artem Chebokha", "Artemisia Gentileschi", "Artgerm", "Arthur Adams", "Arthur Boyd", "Arthur Dove", "Arthur Garfield Dove", "Arthur Hacker", "Arthur Hughes", "Arthur Lismer", "Arthur Rackham", "Arthur Radebaugh", "Arthur Sarnoff", "Arthur Stanley Wilkinson", "Arthur Streeton", "Arthur Tress", "Arthur Wardle", "Artur Bordalo", "Arturo Souto", "Artus Scheiner", "Ary Scheffer", "Asaf Hanuka", "Asger Jorn", "Asher Brown Durand", "Ashley Willerton", "Ashley Wood", "Atay Ghailan", "Atelier Olschinsky", "Atey Ghailan", "Aubrey Beardsley", "Audrey Kawasaki", "August Friedrich Schenck", "August Macke", "August Sander", "August von Pettenkofen", "Auguste Herbin", "Auguste Mambour", "Auguste Toulmouche", "Augustus Edwin Mulready", "Augustus Jansson", "Augustus John", "Austin Osman Spare", "Axel T\u00f6rneman", "Ayami Kojima", "Ayan Nag", "Aykut Aydogdu", "Bakemono Zukushi", "Balthus", "Banksy", "Barbara Hepworth", "Barbara Kruger", "Barbara Stauffacher Solomon", "Barbara Takenaga", "Barclay Shaw", "Barkley L. Hendricks", "Barnett Newman", "Barry McGee", "Barry Windsor Smith", "Bart Sears", "Barthel Bruyn the Elder", "Barthel Bruyn the Younger", "Bartolome Esteban Murillo", "Basil Gogos", "Bastien Lecouffe-Deharme", "Bayard Wu", "Beatrix Potter", "Beauford Delaney", "Becky Cloonan", "Beeple", "Bella Kotak", "Ben Aronson", "Ben Goossens", "Ben Hatke", "Ben Nicholson", "Ben Quilty", "Ben Shahn", "Ben Templesmith", "Ben Wooten", "Benedetto Caliari", "Benedick Bana", "Benoit B. Mandelbrot", "Berend Strik", "Bernard Aubertin", "Bernard Buffet", "Bernardo Bellotto", "Bernardo Strozzi", "Berndnaut Smilde", "Bernie Wrightson", "Bert Hardy", "Bert Stern", "Berthe Morisot", "Bertil Nilsson", "Bess Hamiti", "Beth Conklin", "Bettina Rheims", "Bhupen Khakhar", "Bijou Karman", "Bill Brandt", "Bill Brauer", "Bill Carman", "Bill Durgin", "Bill Gekas", "Bill Henson", "Bill Jacklin", "Bill Medcalf", "Bill Sienkiewicz", "Bill Traylor", "Bill Viola", "Bill Ward", "Bill Watterson", "Billy Childish", "Bjarke Ingels", "Blek Le Rat", "Bo Bartlett", "Bo Chen", "Bob Byerley", "Bob Eggleton", "Bob Ross", "Bojan Jevtic", "Bojan Koturanovic", "Bordalo II", "Boris Grigoriev", "Boris Groh", "Boris Kustodiev", "Boris Vallejo", "Botero", "Brad Kunkle", "Brad Rigney", "Brandon Mably", "Brandon Woelfel", "Brenda Zlamany", "Brent Cotton", "Brent Heighton", "Brett Weston", "Brett Whiteley", "Brian Bolland", "Brian Despain", "Brian Froud", "Brian K. Vaughan", "Brian Kesinger", "Brian M. Viveros", "Brian Mashburn", "Brian Oldham", "Brian Stelfreeze", "Brian Sum", "Briana Mora", "Brice Marden", "Bridget Bate Tichenor", "Bridget Riley", "Briton Rivi\u00e8re", "Brooke DiDonato", "Brooke Shaden", "Brothers Grimm", "Brothers Hildebrandt", "Bruce Coville", "Bruce Munro", "Bruce Nauman", "Bruce Pennington", "Bruce Timm", "Bruno Catalano", "Bruno Munari", "Bruno Walpoth", "Bryan Hitch", "Butcher Billy", "C. R. W. Nevinson", "Cagnaccio Di San Pietro", "Camille Corot", "Camille Pissarro", "Camille Walala", "Canaletto", "Candido Portinari", "Carel Willink", "Carl Barks", "Carl Gustav Carus", "Carl Holsoe", "Carl Larsson", "Carl Spitzweg", "Carlo Crivelli", "Carlos Schwabe", "Carmen Saldana", "Carne Griffiths", "Carrie Mae Weems", "Casey Weldon", "Caspar David Friedrich", "Cassius Marcellus Coolidge", "Catherine Hyde", "Catrin Welz-Stein", "Cedric Peyravernay", "Chad Knight", "Chantal Joffe", "Charles Addams", "Charles Angrand", "Charles Blackman", "Charles Camoin", "Charles Dana Gibson", "Charles E. Burchfield", "Charles Gwathmey", "Charles Le Brun", "Charles Liu", "Charles Schridde", "Charles Schulz", "Charles Spencelayh", "Charles Vess", "Charles-Francois Daubigny", "Charlie Bowater", "Charline von Heyl", "Cha\u00efm Soutine", "Chen Zhen", "Chesley Bonestell", "Chiharu Shiota", "Ching Yeh", "Chip Zdarsky", "Chris Claremont", "Chris Cunningham", "Chris Foss", "Chris Leib", "Chris Mars", "Chris Moore", "Chris Ofili", "Chris Saunders", "Chris Turnham", "Chris Uminga", "Chris Van Allsburg", "Chris Ware", "Christian Dimitrov", "Christian Grajewski", "Christophe Vacher", "Christopher Balaskas", "Christopher Jin Baron", "Chuck Close", "Cicely Mary Barker", "Cindy Sherman", "Claire Hummel", "Clara Miller Burd", "Clara Peeters", "Clarence Holbrook Carter", "Claude Cahun", "Claude Monet", "Clemens Ascher", "Cliff Chiang", "Clive Madgwick", "Clovis Trouille", "Clyde Caldwell", "Coby Whitmore", "Coles Phillips", "Colin Geller", "Conor Harrington", "Conrad Roset", "Constant Permeke", "Constantin Brancusi", "Cory Arcangel", "Cory Loftis", "Costa Dvorezky", "Craig Davison", "Craig Mullins", "Craig Wylie", "Craola", "Cuno Amiet", "Cyril Rolando", "Dain Yoon", "Dale Chihuly", "Damien Hirst", "Dan Flavin", "Dan Mumford", "Dan Witz", "Daniel Buren", "Daniel Clowes", "Daniel Garber", "Daniel Merriam", "Daniel Ridgway Knight", "Daniela Uhlig", "Daniele Afferni", "Dante Gabriel Rossetti", "Dao Le Trong", "Dariusz Zawadzki", "Darren Bacon", "Darwyn Cooke", "Daryl Mandryk", "Dave Dorman", "Dave Gibbons", "Dave McKean", "David A. Hardy", "David Aja", "David B. Mattingly", "David Bomberg", "David Bowie", "David Burdeny", "David Burliuk", "David Choe", "David Driskell", "David Finch", "David Hockney", "David Inshaw", "David Ligare", "David Lynch", "David McClellan", "David Palumbo", "David Shrigley", "David Spriggs", "David Teniers the Younger", "David Wiesner", "Dean Cornwell", "Dean Ellis", "Death Burger", "Debbie Criswell", "Derek Boshier", "Desmond Morris", "Diane Arbus", "Diane Dillon", "Dick Bickenbach", "Diego Dayer", "Diego Rivera", "Diego Vel\u00e1zquez", "Dmitry Kustanovich", "Don Bluth", "Don Maitz", "Donald Judd", "Donato Giancola", "Dora Carrington", "Dora Maar", "Dorina Costras", "Dorothea Tanning", "Dorothy Lathrop", "Doug Chiang", "Douglas Smith", "Dr. Seuss", "Dunkelbunt Hundertwasser\u201d", "Dustin Nguyen", "Duy Huynh", "E. H. Shepard", "Earl Norem", "Ed Benedict", "Ed Binkley", "Ed Brubaker", "Ed Emshwiller", "Ed Freeman", "Ed Mell", "Ed Roth", "Eddie Campbell", "Eddie Mendoza", "Edgar Degas", "Edmund Dulac", "Edmund Leighton", "Edouard Manet", "Edouard Riou", "Eduardo Kobra", "Edvard Munch", "Edward Atkinson Hornel", "Edward Burne-Jones", "Edward Gorey", "Edward Hopper", "Edward John Poynter", "Edward Julius Detmold", "Edward Lear", "Edward Robert Hughes", "Edward Steichen", "Edward Weston", "Edwin Austin Abbey", "Edwin Deakin", "Edwin Henry Landseer", "Eero Saarinen", "Egon Schiele", "Eiichiro Oda", "Eileen Agar", "El Greco", "Elaine de Kooning", "Eleanor Vere Boyle", "Elenore Abbott", "Eliott Lilly", "Elizabeth Gadd", "Elizabeth Shippen Green", "Ellen Gallagher", "Ellen Jewett", "Elliot Lilly", "Elsa Beskow", "Emil Alzamora", "Emil Ferris", "Emil Nolde", "Emilia Wilk", "Emily Kame Kngwarreye", "Emma Geary", "Emmanuel Shiu", "Emmanuelle Moureaux", "Emory Douglas", "Enki Bilal", "Ephraim Moses Lilien", "Eric Fischl", "Eric Wallis", "Eric Zener", "Erich Heckel", "Erin Hanson", "Ernest Crichlow", "Ernie Barnes", "Ernst Fuchs", "Ernst Haas", "Ernst Haeckel", "Ernst Ludwig Kirchner", "Esao Andrews", "Etel Adnan", "Ethan Van Sciver", "Etienne Hebinger", "Ettore Sottsass", "Ettore Tito", "Eugene Delacroix", "Eugene von Guerard", "Eug\u00e8ne Grasset", "Evelyn De Morgan", "Everett Raymond Kinstler", "Evgeni Gordiets", "Ewald R\u00fcbsamen", "Eyvind Earle", "F Scott Hess", "Fabian Perez", "Fabio Hurtado", "Fairfield Porter", "Faith 47", "Faith Ringgold", "Fang Lijun", "Farel Dalrymple", "Fenghua Zhong", "Ferdinand Hodler", "Ferdinand Knab", "Ferdinand Van Kessel", "Fernand Khnopff", "Fernand Toussaint", "Fernando Herenu", "Filip Hodas", "Filippino Lippi", "Filippo Balbi", "Flora Borsi", "Ford Madox Brown", "Francesca Woodman", "Francis Bacon", "Francis Coates Jones", "Francis Picabia", "Francisco De Goya", "Francisco Mart\u00edn", "Frank Auerbach", "Frank Frazetta", "Frank Gehry", "Frank Holl", "Frank Lloyd Wright", "Frank Miller", "Frank Stella", "Frank Tinsley", "Frank Xavier Leyendecker", "Franklin Booth", "Franz Marc", "Franz Sedlacek", "Franz Xaver Winterhalter", "Frederic Church", "Frederic Remington", "Frederick Lord Leighton", "Frederick McCubbin", "Frida Kahlo", "Frits Van den Berghe", "Gabriel Dawe", "Gabriele M\u00fcnter", "Gaetano Pesce", "Galan Pang", "Gareth Pugh", "Gary Larson", "Gaston Bussi\u00e8re", "Gediminas Pranckevicius", "Genndy Tartakovsky", "Geof Darrow", "Georg Jensen", "Georg Karl Pfahler", "George Ault", "George Cruikshank", "George Dionysus Ehret", "George Frederic Watts", "George French Angas", "George Grosz", "George Herriman", "George Inness", "George Lucas", "George Luks", "George Stubbs", "George Tooker", "Georges Rouault", "Georges Seurat", "Georges de La Tour", "Georgia O\u2019Keeffe", "Gerald Brom", "Gerda Wegener", "Gerhard Munthe", "Gerhard Richter", "Gertrude Abercrombie", "Giacomo Balla", "Gianluca Foli", "Gifford Beal", "Gil Elvgren", "Gilbert Stuart", "Giorgio De Chirico", "Giotto Di Bondone", "Giovanni Battista Bracelli", "Giovanni Battista Gaulli", "Giovanni Battista Piranesi", "Giovanni Battista Venanzi", "Giovanni da Udina", "Giuseppe Arcimboldo", "Giuseppe de Nittis", "Gjon Mili", "Glen Orbik", "Glenn Fabry", "Gloria Stoll Karn", "Go Nagai", "Gordon Browne", "Gordon Parks", "Goro Fujita", "Grace Cossington Smith", "Grace Popp", "Grandma Moses", "Grant Wood", "Grayson Perry", "Greg Girard", "Greg Hildebrandt", "Greg Rutkowski", "Greg Simkins", "Gregory Crewdson", "Guerrilla Girls", "Guido Borelli Da Caluso", "Guido Crepax", "Guillermo del Toro", "Guo Pei", "Gustaf Tenggren", "Gustav Klimt", "Gustave Buchet", "Gustave Courbet", "Gustave Dor\u00e9", "Gustave Moreau", "Gustave Van de Woestijne", "Guy Billout", "Gwen John", "Gwenda Morgan", "H. R. (Hans Ruedi) Giger", "H.P. Lovecraft", "Haddon Sundblom", "Hajime Sorayama", "Hal Foster", "Hale Woodruff", "Hanna-Barbera", "Hannah Hoch", "Hans Arnold", "Hans Baldung", "Hans Baluschek", "Hans Bellmer", "Harold McCauley", "Haroon Mirza", "Harriet Backer", "Harry Clarke", "Hasui Kawase", "Hayao Miyazaki", "Hayv Kahraman", "Hein Gorny", "Heinrich Kley", "Heinrich Lefler", "Heinz Edelmann", "Helen Frankenthaler", "Helene Knoop", "Helene Schjerfbeck", "Helio Oiticica", "Helmut Newton", "Hendrick Avercamp", "Hendrick Cornelisz Vroom", "Hendrick Goltzius", "Hendrik Kerstens", "Henri De Toulouse Lautrec", "Henri Fantin Latour", "Henri Matisse", "Henri Rousseau", "Henri-Edmond Cross", "Henriette Grindat", "Henry Asencio", "Henry Fuseli", "Henry Moore", "Henry Moret", "Henry Ossawa Tanner", "Henry Raleigh", "Herbert List", "Herve Groussin", "Herv\u00e9 Guibert", "Hethe Srodawa", "Hieronymus Bosch", "Hikari Shimoda", "Hilma AF Klint", "Hirohiko Araki", "Hiroshi Nagai", "Hiroshi Sugimoto", "Hiroshi Yoshida", "Honor C. Appleton", "Honor\u00e9 Daumier", "Hope Gangloff", "Horace Vernet", "Hou China", "Howard Chandler Christy", "Howard Finster", "Howard Hodgkin", "Howard Pyle", "Hsiao-Ron Cheng", "Hubert Robert", "Hugh Ferriss", "Hugh Kretschmer", "Hyacinthe Rigaud", "Iain Faulkner", "Ian McQue", "Ian Miller", "Ida Rentoul Outhwaite", "Igor Morski", "Igor Wolski", "Igor Zenin", "Ilya Kuvshinov", "Ilya Repin", "Incarcerated Jerkfaces", "Ingrid Baars", "Inio Asano", "Irma Stern", "Iryna Yermolova", "Isaac Cordal", "Isaac Levitan", "Ismail Inceoglu", "Issac Levitan", "Istvan Banyai", "It\u014d Jakuch\u016b", "Ivan Aivazovsky", "Ivan Albright", "Ivan Bilibin", "Ivan Shishkin", "Iwan Baan", "J. J. Grandville", "J.C. Leyendecker", "J.M.W. Turner", "JC Leyendecker", "Jacek Yerka", "Jack Butler Yeats", "Jack Davis", "Jack Gaughan", "Jack Kirby", "Jackson Pollock", "Jacob Hashimoto", "Jacob Lawrence", "Jacob van Ruisdael", "Jacques Le Moyne", "Jacques Nathan-Garamond", "Jake Parker", "Jakub R\u00f3\u017calski", "James Abbott McNeill Whistler", "James C Christensen", "James Ensor", "James Gilleard", "James Gillray", "James Gurney", "James Jean", "James Montgomery Flagg", "James Paick", "James Stokoe", "James Thomas Watts", "James Tissot", "James Turrell", "Jamie Baldridge", "Jamie Hawkesworth", "Jamie Hewlett", "Jamie McKelvie", "Jamini Roy", "Jan Brett", "Jan Luyken", "Jan Pietersz Saenredam", "Jan Van Eyck", "Jan van Kessel the Elder", "Jane Graverol", "Jane Newland", "Janek Sedlar", "Jasmine Becket-Griffith", "Jason A. Engle", "Jason Chan", "Jason Edmiston", "Jasper Johns", "Jaume Plensa", "Jaya Suberg", "Jean Arp", "Jean Auguste Dominique Ingres", "Jean Bourdichon", "Jean Delville", "Jean Dubuffet", "Jean Fouquet", "Jean Giraud", "Jean Jullien", "Jean Marc Nattier", "Jean Metzinger", "Jean Nouvel", "Jean-Antoine Watteau", "Jean-Baptiste Monge", "Jean-Fran\u00e7ois Millet", "Jean-Honor\u00e9 Fragonard", "Jean-Louis Prevost", "Jean-L\u00e9on G\u00e9r\u00f4me", "Jean-Michel Basquiat", "Jean-Paul Riopelle", "Jeanloup Sieff", "Jeannette Guichard-Bunel", "Jed Henry", "Jef Wu", "Jeff Easley", "Jeff Goldblum", "Jeff Kinney", "Jeff Koons", "Jeff Legg", "Jeff Lemire", "Jeff Simpson", "Jeff Wall", "Jeffrey Catherine Jones", "Jeffrey Smith art", "Jeffrey T. Larson", "Jenny Saville", "JennyBird Alcantara", "Jeremiah Ketner", "Jeremy Geddes", "Jeremy Lipking", "Jeremy Mann", "Jerry Pinkney", "Jerry Siegel", "Jerzy Duda-Gracz", "Jesper Ejsing", "Jessica Rossier", "Jessica Woulfe", "Jessie Willcox Smith", "Jhonen Vasquez", "Jillian Tamaki", "Jim Burns", "Jim Davis", "Jim Lee", "Jim Mahfood", "Jim Woodring", "Jimmy Ernst", "Jimmy Lawlor", "Joachim Brohm", "Joan Mir\u00f3", "Joan Tuset", "Joanna Kustra", "Joao Ruas", "Joaqu\u00edn Sorolla", "Joe Bowler", "Joe De Mers", "Joe Fenton", "Joe Jusko", "Joe Madureira", "Joe Webb", "Joel Meyerowitz", "Joel Sternfeld", "Joey Chou", "Johann Wolfgang von Goethe", "Johannes Itten", "Johannes Vermeer", "Johannes Voss", "Johfra Bosschart", "John Anster Fitzgerald", "John Atherton", "John Atkinson Grimshaw", "John Bauer", "John Berkey", "John Blanche", "John Bratby", "John Cassaday", "John Constable", "John Currin", "John Duncan", "John Frederick Kensett", "John French Sloan", "John Harris", "John Howe", "John Hoyland", "John James Audubon", "John Kenn Mortensen", "John La Farge", "John Lavery", "John Martin", "John Perceval", "John Philip Falter", "John Salminen", "John Singer Sargent", "John Singleton Copley", "John Stezaker", "John Totleben", "John Wayne Gacy", "John Whitcomb", "John Wilhelm", "John William Waterhouse", "Jon Klassen", "Jon McCoy", "Jon Whitcomb", "Jordan Grimmer", "Jorge Jacinto", "Josan Gonzalez", "Josef Albers", "Joseph Cornell", "Joseph Ducreux", "Joseph Lorusso", "Joseph Mallord William Turner", "Joseph Stella", "Josephine Wall", "Josh Kao", "Josh Keyes", "Jos\u00e9 Clemente Orozco", "Jovana Rikalo", "Juan Gris", "Judy Chicago", "Juergen Teller", "Jules Bastien-Lepage", "Julia Contacessi", "Julian Calle", "Juliana Huxtable", "Julie Bell", "Julie Blackmon", "Julie Mehretu", "Julien Delval", "Julius Horsthuis", "Jun Kaneko", "Junji Ito", "Justin Gerard", "J\u00f3zef Mehoffer", "Kadir Nelson", "Kaethe Butcher", "Kapwani Kiwanga", "Karel Appel", "Karel Thole", "Karen Wallis", "Karl Blossfeldt", "Karl Schmidt-Rottluff", "Karol Bak", "Kasia Nowowiejska", "Kate Beaton", "Kate Greenaway", "Kathryn Morris Trotter", "Kati Horna", "Katsuhiro Otomo", "Katsushika Hokusai", "Kawanabe Ky\u014dsai", "Kaws", "Kay Nielsen", "Kay Sage", "Kazimir Malevich", "Kazuo Koike", "Kehinde Wiley", "Keith Haring", "Keith Negley", "Keith Parkinson", "Kelly Freas", "Kelly Mckernan", "Kelly Sue Deconnick", "Kelly Vivanco", "Ken Fairclough", "Ken Kelly", "Ken Sugimori", "Kengo Kuma", "Kenne Gregoire", "Kent Monkman", "Kentaro Miura", "Kevin Gnutzmans", "Kevin Sloan", "Kieron Gillen", "Kilian Eng", "Kim Jung Gi", "Kim Keever", "Kitagawa Utamaro", "Kitty Lange Kielland", "Klaus Burgle", "Klaus Janson", "Klaus Wittmann", "Kobayashi Kiyochika", "Konstantin Korovin", "Konstantin Yuon", "Koson Ohara", "Krenz Cushart", "Kris Kuksi", "Kuang Hong", "Kunisada", "Kuno Veeber", "Kurzgesagt", "K\u00e4the Kollwitz", "L. Birge Harrison", "Lady Pink", "Larry Elmore", "Larry Poons", "Larry Sultan", "Laurel Burch", "Laurent Grasso", "Laurie Greasley", "Laurie Lipton", "Lawren Harris", "Lee Krasner", "Lee Madgwick", "Lee Quinones", "Leiji Matsumoto", "Leon Kossoff", "Leonardo Da Vinci", "Leonetto Cappiello", "Leonid Afremov", "Leonora Carrington", "Les Edwards", "Lesley Vance", "Leticia Gillett", "Liam Wong", "Liang Mark", "Lisa Frank", "Lisa Keene", "Liu Ye", "Liubov Sergeevna Popova", "Lois van Baarle", "Loish", "Lorena Alvarez G\u00f3mez", "Lorenz Hideyoshi", "Loretta Lux", "Lori Earley", "Louis Comfort Tiffany", "Louis Glackens", "Louis Icart", "Louis Janmot", "Louis Rhead", "Louis Wain", "Louise Bourgeois", "Louise Dahl-Wolfe", "Lovis Corinth", "Luca Boni", "Lucas Cranach the Elder", "Lucian Freud", "Lucy Madox Brown", "Ludwig Mies van der Rohe", "Luis Royo", "Luisa Russo", "Lynd Ward", "Lynda Barry", "Lynda Benglis", "Lyonel Feininger", "Lyubov Popova", "L\u00e1szl\u00f3 Moholy-Nagy", "M.C. Escher", "M.W. Kaluta", "Mab Graves", "Maginel Wright Enright Barney", "Magnus Enckell", "Makoto Shinkai", "Malcolm Liepke", "Man Ray", "Mandy Disher", "Mao Hamaguchi", "Marat Latypov", "Marc Chagall", "Marc Davis", "Marc Samson", "Marc Simonetti", "Marcin Jakubowski", "Marco Mazzoni", "Marcus Selmer", "Marek Okon", "Margaret Brundage", "Margaret Macdonald Mackintosh", "Margaret Mee", "Margaux Valonia", "Maria Kreyn", "Maria Pascual Alberich", "Maria Sibylla Merian", "Marianne North", "Marianne von Werefkin", "Marie Guillemine Benoist", "Marie Spartali Stillman", "Marina Abramovi\u0107", "Marius Borgeaud", "Marjane Satrapi", "Mark Arian", "Mark Briscoe", "Mark Brooks", "Mark Keathley", "Mark Lovett", "Mark Rothko", "Mark Ryden", "Mark Seliger", "Marsden Hartley", "Martin Ansin", "Martin Deschambault", "Martin John Heade", "Martin Johnson Heade", "Martin Kippenberger", "Martine Johanna", "Martiros Saryan", "Mary Anning", "Mary Blair", "Mary Cassatt", "Masaaki Sasamoto", "Masamune Shirow", "Mat Collishaw", "Mati Klarwein", "Matias Hannecke", "Matt Bors", "Matt Fraction", "Matt Groening", "Matthias Gr\u00fcnewald", "Matthias Jung", "Matti Suuronen", "Maurice Sendak", "Max Beckmann", "Max Dupain", "Max Ernst", "Max Pechstein", "Max Weber", "Maxfield Parrish", "Maximilian Pirner", "Maximilien Luce", "Maxwell Boas", "Mead Schaeffer", "Meryl McMaster", "Michael Carson", "Michael Cheval", "Michael Deforge", "Michael Heizer", "Michael Hutter", "Michael Parkes", "Michael Sowa", "Michael Whelan", "Michal Karcz", "Michal Lisowski", "Michelangelo Buonarroti", "Michelangelo Merisi Da Caravaggio", "Mickalene Thomas", "Miho Hirano", "Mikalojus Konstantinas Ciurlionis", "Mike Campau", "Mike Deodato", "Mike Mayhew", "Mike Mignola", "Mike Winkelmann (Beeple)", "Mike Worrall", "Mikhail Larionov", "Mikhail Nesterov", "Mikhail Vrubel", "Mikko Lagerstedt", "Milo Manara", "Milton Avery", "Milton Caniff", "Milton Glaser", "Miriam Schapiro", "Moebius", "Mordecai Ardon", "Mort Kunstler", "Muxxi", "M\u00e9ret Oppenheim", "NC Wyeth", "NHK Animation", "Nagel Patrick", "Nan Goldin", "Naoki Urasawa", "Naoko Takeuchi", "Naomi Okubo", "Naoto Hattori", "Natalia Goncharova", "Nathan Coley", "Nathan Wirth", "Neil Boyle", "Neil Welliver", "Nele Zirnite", "Ni Chuanjing", "Nicholas Roerich", "Nick Knight", "Nick Sharratt", "Nick Silva", "Nicola Samori", "Nicolas Delort", "Nicolas Mignard", "Nicolas de Stael", "Nikolai Ge", "Nikolina Petolas", "Noah Bradley", "Nobuyoshi Araki", "Noelle Stevenson", "Noriyoshi Ohrai", "Norman Ackroyd", "Norman Bluhm", "Norman Foster", "Norman Rockwell", "OSGEMEOS", "Octavio Ocampo", "Odd Nerdrum", "Odilon Redon", "Ogawa Kazumasa", "Ohara Koson", "Olafur Eliasson", "Oleg Oprisco", "Olga Skomorokhova", "Olivier Bonhomme", "Olivier Valsecchi", "Ollie Hoff", "Os Gemeos", "Osamu Tezuka", "Oskar Fischinger", "Oskar Kokoschka", "Ossip Zadkine", "Otto Dix", "Otto Marseus van Schrieck", "Pablo Picasso", "Pamela Colman Smith", "Paolo Roversi", "Paolo Veronese", "Pascal Blanche", "Pascale Campion", "Patrice Murciano", "Patricia Polacco", "Patrick Brown", "Patrick Caulfield", "Patrick Dougherty", "Patrick Heron", "Patrick Woodroffe", "Paul Barson", "Paul Chadeisson", "Paul Corfield", "Paul C\u00e9zanne", "Paul Delvaux", "Paul Gauguin", "Paul Gustav Fischer", "Paul Henry", "Paul Klee", "Paul Laffoley", "Paul Lehr", "Paul Ranson", "Paul Strand", "Paul Wonner", "Paula Modersohn-Becker", "Paulus Potter", "Pawel Kuczynski", "Peter Andrew Jones", "Peter Bagge", "Peter De Seve", "Peter Doig", "Peter Elson", "Peter Gric", "Peter Holme III", "Peter Howson", "Peter Kemp", "Peter Max", "Peter Milligan", "Peter Mohrbacher", "Peter Paul Rubens", "Peter Sculthorpe", "Peter Wileman", "Peter Zumthor", "Phil Foglio", "Phil Jimenez", "Phil Koch", "Phil Noto", "Philip Guston", "Philippe Druillet", "Philippe Parreno", "Pierre Bonnard", "Pierre Puvis de Chavannes", "Pierre-Auguste Renoir", "Piet Hein Eek", "Piet Mondrian", "Pieter Aertsen", "Pieter Bruegel The Elder", "Pieter Claesz", "Pieter Jansz Saenredam", "Pieter de Hooch", "Piotr Jab\u0142o\u0144ski", "Pipilotti Rist", "Pixar", "Pixar Concept Artists", "Posuka Demizu", "Qian Xuan", "Qing Han", "Quentin Blake", "Quentin Tarantino", "Quint Buchholz", "RETNA (Marquis Lewis)", "RHADS", "ROA", "Rafael Albuquerque", "Rafa\u0142 Olbi\u0144ski", "Raffaello Sanizo", "Raina Telgemeier", "Raja Ravi Varma", "Ralph Horsley", "Ralph McQuarrie", "Ralph Steadman", "Ramon Casas", "Randolph Caldecott", "Raphael", "Raphael Lacoste", "Raphaelle Peale", "Ravi Zupa", "Ray Caesar", "Ray Donley", "Raymond Briggs", "Raymond Duchamp-Villon", "Raymond Leech", "Raymond Swanland", "Rayner Alencar", "Rebeca Saray", "Rebecca Guay", "Rebecca Louise Law", "Rebecca Sugar", "Reginald Marsh", "Rembrandt Van Rijn", "Remedios Varo", "Rene Laloux", "Rene Magritte", "Ren\u00e9 Lalique", "Reylia Slaby", "Rich Davies", "Richard Burlet", "Richard Corben", "Richard Dadd", "Richard Deacon", "Richard Diebenkorn", "Richard Doyle", "Richard Eurich", "Richard Hamilton", "Richard Lindner", "Richard McGuire", "Richard Misrach", "Richard S. Johnson", "Richard Scarry", "Rick Guidice", "Rob Gonsalves", "Rob Liefeld", "Robby Cavanaugh", "Robert Antoine Pinchon", "Robert Chew", "Robert Childress", "Robert Crumb", "Robert Farkas", "Robert Hagan", "Robert Irwin", "Robert M Cunningham", "Robert Maguire", "Robert McCall", "Robert Mcginnis", "Robert Motherwell", "Robert Neubecker", "Robert Rauschenberg", "Robert S. Duncanson", "Robert Stivers", "Robert Vonnoh", "Robert William Hume", "Robert Williams", "Roberto Ferri", "Roberto Matta", "Roberto Parada", "Rockwell Kent", "Rodney Matthews", "Rodr\u00edguez ARS", "Roger Ballen", "Roger Dean", "Roger de La Fresnaye", "Rolf Armstrong", "Romero Britto", "Ron Mueck", "Ron Walotsky", "Ronald Balfour", "Ross Tran", "Roy Gjertson", "Roy Lichtenstein", "Roz Chast", "Ruan Jia", "Rudolf Freund", "Rufino Tamayo", "Rumiko Takahashi", "Russ Mills", "Russell Ayto", "Ruth Bernhard", "Ruxing Gao", "Ryan Hewett", "Ryan McGinley", "Ryan Stegman", "Ryohei Hase", "Sacha Goldberger", "Sailor Moon", "Sakai Ho\u0304itsu", "Sally Mann", "Salomon van Ruysdael", "Salvador Dali", "Sam Bosma", "Sam Kieth", "Sam Spratt", "Samuel Earp", "Samuel Melton Fisher", "Samuel and Joseph Newsom", "Sandra Chevrier", "Sandro Botticelli", "Sandy Skoglund", "Saner Edgar", "Sanford Kossin", "Sangyeob Park", "Santiago Calatrava", "Santiago Caruso", "Sara Wollfalk", "Sarah Lucas", "Satoshi Kon", "Saturno Butto", "Saul Bass", "Saul Steinberg", "Saul Tepper", "Scarlett Hooft Graafland", "Scott Brundage", "Scott Listfield", "Scott Naismith", "Sean Scully", "Sean Yoro", "Seb Mckinnon", "Sebastian Errazuriz", "Serge Marshennikov", "Shaddy Safadi", "Shaun Tan", "Shawn Coss", "Sheilah Beckett", "Shepard Fairey", "Sherree Valentine Daines", "Shin Jeongho", "Shinji Aramaki", "Shintaro Kago", "Shohei Otomo", "Shotaro Ishinomori", "Shusei Nagaoko", "Sidney Nolan", "Silvestro Lega", "Simeon Solomon", "Simon Birch", "Simon Bisley", "Simon Stalenhag", "Simone Martini", "Sir James Guthrie", "Siya Oum", "Skottie Young", "Slim Aarons", "Sofonisba Anguissola", "Sonia Delaunay", "Sou Fujimoto", "Sparth", "Squeak Carnwath", "Stan And Jan Berenstain", "Stan Lee", "Stanislav Poltavsky", "Stanis\u0142aw Szukalski", "Stanley Donwood", "Stephan Martiniere", "Stephen Gammell", "Stephen Oakley", "Stephen Shore", "Stevan Dohanos", "Steve Argyle", "Steve Dillon", "Steve Ditko", "Steve Henderson", "Steve Lieber", "Steve McCurry", "Steven Belledin", "Storm Thorgerson", "Stuart Davis", "Stuart Haygarth", "Stuart Immonen", "Studio Ghibli", "Sue Bryce", "Susan Luo", "Susan Seddon Boulet", "Sven Nordqvist", "Syd Mead", "Sydney Edmunds", "Sydney Prior Hall", "Tadao Ando", "Taiy\u014d Matsumoto", "Takashi Murakami", "Takato Yamamoto", "Takeshi Obata", "Tamara Lempicka", "Tan Zhi Hui", "Tara McPherson", "Tari Ma\u0301rk Da\u0301vid", "Tatsuro Kiuchi", "Ted Nasmith", "Ted Wallace", "Teophilus Tetteh", "Terada Katsuya", "Teresa Ramos", "Terry Oakes", "Terry Redlin", "Tex Avery", "Theo van Rysselberghe", "Thomas Allom", "Thomas Benjamin Kennington", "Thomas Blackshear", "Thomas Cole", "Thomas Dodd", "Thomas Eakins", "Thomas Gainsborough", "Thomas Moran", "Thomas Rowlandson", "Thomas Saliot", "Thomas Struth", "Thomas Visscher", "Thomas W Schaller", "Thornton Oakley", "Th\u00e9odore G\u00e9ricault", "Tibor Nagy", "Till Freitag", "Tim Burton", "Tim Doyle", "Tim Hildebrandt", "Tim White", "Tintoretto", "Titian", "Todd McFarlane", "Todd Schorr", "Toei Animations", "Tokujin Yoshioka", "Tom Bagshaw", "Tom Hammick", "Tom Lovell", "Tom Roberts", "Tom Thomson", "Tom Whalen", "Tomasz Alen Kopera", "Tomer Hanuka", "Tomi Ungerer", "Tomma Abts", "Tomokazu Matsuyama", "Tony DiTerlizzi", "Tony Moore", "Toshiharu Mizutani", "Toumas Korpi", "Tove Jansson", "Tracey Emin", "Travis Louie", "Tristan Eaton", "Tsutomu Nihei", "Tyler Edlin", "Tyler Shields", "Tyler West", "Ub Iwerks", "Uemura Shoen", "Ul Di Rico", "Umberto Boccioni", "Utagawa Hiroshige", "Valerie Hegarty", "Vhils", "Victo Ngai", "Victor Adame Minguez", "Victor Brauner", "Victor Medina", "Victor Moscoso", "Victor Nizovtsev", "Victor Vasarely", "Victoria Crowe", "Viktor Vasnetsov", "Viktoria Gavrilenko", "Vincent Di Fate", "Vincent Tanguay", "Vincent Van Gogh", "Virgil Finlay", "Vito Acconci", "Vittorio Matteo Corcos", "Vivian Maier", "Viviane Sassen", "Vivienne Westwood", "Vladimir Kush", "W. Heath Robinson", "W.W. Denslow", "Wadim Kashin", "Walt Disney", "Walt Kelly", "Walter Crane", "Walter Kim", "Walter Langley", "Walter Percy Day", "Wangechi Mutu", "Warren Ellis", "Warwick Globe", "Wassily Kandinsky", "Wayne Barlowe", "Wendy Froud", "Wes Anderson", "Wilfredo Lam", "Will Barnet", "Will Eisner", "Willem de Kooning", "Willem van Haecht", "William Blake", "William Eggleston", "William Etty", "William Gropper", "William Henry Hunt", "William Hogarth", "William Holman Hunt", "William Kentridge", "William Morris", "William S. Burroughs", "William Steig", "William Stout", "William Wegman", "William Zorach", "William-Adolphe Bouguereau", "Wim Crouwel", "Wim Wenders", "Winslow Homer", "Winsor McCay", "Wojciech Ostrycharz", "Wolf Kahn", "Wolfgang Tillmans", "Worthington Whittredge", "Yaacov Agam", "Yang Jialun", "Yanjun Cheng", "Yasuo Kuniyoshi", "Yasushi Nirasawa", "Yasutomo Oka", "Yayi Morales", "Yayoi Kusama", "Yiannis Moralis", "Yinka Shonibare", "Yohann Schepacz", "Yoji Shinkawa", "Yoshitaka Amano", "Yoshiyuki Tomino", "Yue Minjun", "Yuri Ivanovich Pimenov", "Yuumei", "Yves Klein", "Yves Tanguy", "Zack Snyder", "Zaha Hadid", "Zanele Muholi", "Zdzis\u0142aw Beksi\u0144ski", "Zeen Chin", "Zhang Kechun", "Zhelong Xu", "Zhichao Cai", "Zinaida Serebriakova", "teamLab", "theCHAMBA", "tokyogenso", "\u00c9lisabeth Vig\u00e9e Le Brun", "\u00c9mile Bernard", "\u00c9mile Gall\u00e9", "\u00c9tienne-Louis Boull\u00e9e", "\u201cFriedensreich Regentag"]], "fourth_file": [["mood.yaml", "artist.yaml", "basic.yaml", "camera.yaml", "original.yaml"], {"default": "mood.yaml"}], "fourth_style": [["none", "random", "Abyssal Silence", "Aggressive", "Bittersweet Nostalgia", "Calm", "Celestial Harmony", "Chaos and Discord", "Chaotic", "Dark, Brooding Atmosphere", "Dreamy Serenity", "Dystopian Desolation", "Enchanted Whispers", "Energetic", "Enigmatic Wonder", "Eternal Twilight", "Ethereal Tranquility", "Frenetic Energy", "Gothic Elegance", "Happy", "Hushed Reverence", "Joyful Celebration", "Melancholic Reflection", "Mysterious", "Relaxed", "Romantic", "Sad", "Serene", "Spectral Whispers", "Surreal Euphoria", "Tense, Suspenseful Ambiance", "Whimsical Delight"]]}}, "input_order": {"required": ["text_positive", "text_negative", "base_file", "base_style", "second_file", "second_style", "third_file", "third_style", "fourth_file", "fourth_style"]}, "output": ["STRING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["positive_prompt", "negative_prompt", "used_templates"], "name": "iToolsPromptStylerExtra", "display_name": "iTools Prompt Styler Extra \ud83d\udd8c\ufe0f", "description": "Helps you quickly populate your prompt using templates from up to 4 YAML files.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsGridFiller": {"input": {"required": {"images": ["IMAGE", {}], "width": ["INT", {"default": 1024, "min": 256, "max": 8192}], "height": ["INT", {"default": 1024, "min": 256, "max": 8192}], "rows": ["INT", {"default": 3, "min": 1, "max": 10}], "cols": ["INT", {"default": 3, "min": 1, "max": 10}], "gaps": ["FLOAT", {"default": 2, "min": 0.0, "max": 50, "steps": 1}], "background_color": ["STRING", {"default": "#000000AA", "multiline": false}], "fill_direction": [["rows", "cols"], {"default": "rows"}]}}, "input_order": {"required": ["images", "width", "height", "rows", "cols", "gaps", "background_color", "fill_direction"]}, "output": ["IMAGE"], "output_is_list": [false, false, false, false, false, false, false], "output_name": ["images"], "name": "iToolsGridFiller", "display_name": "iTools Grid Filler \ud83d\udcf2", "description": "Arranging a set of images into specified rows and columns, applying optional spacing and background color", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsLineLoader": {"input": {"required": {"lines": ["STRING", {"default": "cat\ndog\nbunny", "multiline": true}], "seed": ["INT", {"default": 0, "control_after_generate": "increment", "min": 0, "max": 4095}]}}, "input_order": {"required": ["lines", "seed"]}, "output": ["STRING", "INT"], "output_is_list": [false, false], "output_name": ["line loaded", "count"], "name": "iToolsLineLoader", "display_name": "iTools Line Loader", "description": "Will return a line from a multi line text at given index, note that count start from zero.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsTextReplacer": {"input": {"required": {"text_in": ["STRING", {"forceInput": true, "multiline": false}], "match": ["STRING", {"forceInput": false, "multiline": false}], "replace": ["STRING", {"forceInput": false, "multiline": false}]}}, "input_order": {"required": ["text_in", "match", "replace"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["text_out"], "name": "iToolsTextReplacer", "display_name": "iTools Text Replacer", "description": "Help you replace a match in a given text.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsKSampler": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model used for denoising the input latent."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "The random seed used for creating the noise."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "The number of steps used in the denoising process."}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01, "tooltip": "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality."}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output."}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], {"tooltip": "The scheduler controls how noise is gradually removed to form the image."}], "positive": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to include in the image."}], "negative": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "latent_image": ["LATENT", {"tooltip": "The latent image to denoise."}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling."}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise"]}, "output": ["LATENT", "STRING"], "output_is_list": [false, false], "output_name": ["LATENT", "INFO"], "name": "iToolsKSampler", "display_name": "iTools KSampler", "description": "Identical to the original KSampler, but additionally provides the settings used to generate the image and the execution time.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false, "output_tooltips": ["The denoised latent."]}, "iToolsVaePreview": {"input": {"required": {"samples": ["LATENT", {"tooltip": "The latent to be decoded."}], "vae": ["VAE", {"tooltip": "The VAE model used for decoding the latent."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["samples", "vae"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "iToolsVaePreview", "display_name": "iTools Vae Preview \u26f3", "description": "Merges VAE decoding and image preview into one node.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsCheckerBoard": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 256, "max": 8192}], "height": ["INT", {"default": 1024, "min": 256, "max": 8192}], "rows": ["INT", {"default": 9, "min": 1, "max": 128}], "cols": ["INT", {"default": 9, "min": 1, "max": 128}], "pattern": [["random", "random uniform", "checkerboard", "horizontal stripes", "vertical stripes", "diagonal stripes", "rings", "cross", "plus", "portal", "gradient vertical", "gradient horizontal", "diamond", "diamond fill", "dotted frame", "border", "border edge"], {"default": "random uniform"}], "is_colored": ["BOOLEAN", {"default": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 4095}]}}, "input_order": {"required": ["width", "height", "rows", "cols", "pattern", "is_colored", "seed"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "iToolsCheckerBoard", "display_name": "iTools Checkerboard \ud83c\udfc1", "description": "Generates chessboard-like patterns, either in black and white or with random colors", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsLoadRandomImage": {"input": {"required": {"images_directory": ["STRING", {"default": "/ComfyUI/output", "multiline": false}], "seed": ["INT", {"default": 0, "min": 0, "max": 4095}]}}, "input_order": {"required": ["images_directory", "seed"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["image", "image name"], "name": "iToolsLoadRandomImage", "display_name": "iTools Load Random Image \ud83c\udfb2", "description": "Will return image from a given directory. it will also return the name of these image.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsPreviewText": {"input": {"required": {"text": ["STRING", {"forceInput": true}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["text"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [true], "output_name": ["text"], "name": "iToolsPreviewText", "display_name": "iTools Text Preview", "description": "Will show text from string input.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsRegexNode": {"input": {"required": {"text_in": ["STRING", {"forceInput": true, "multiline": false}], "regex_pattern": ["STRING", {"default": "", "forceInput": false, "multiline": false}], "pattern_picker": [["custom", "contains_hello", "cat_or_dog", "starts_with_abc", "ends_with_xyz", "any_character", "digit", "non_digit", "whitespace", "non_whitespace", "word_character", "non_word_character", "all_caps", "all_lower", "integer", "floating_point", "no_numbers", "email", "phone_number", "double_quoted", "double_quoted_plus", "single_quoted", "single_quoted_plus", "in_parentheses", "in_parentheses_plus", "angle_brackets", "angle_brackets_plus"], {"default": "custom"}], "replace_match": ["STRING", {"forceInput": false, "multiline": false}], "replace_non_match": ["STRING", {"forceInput": false, "multiline": false}]}}, "input_order": {"required": ["text_in", "regex_pattern", "pattern_picker", "replace_match", "replace_non_match"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["match"], "name": "iToolsRegexNode", "display_name": "iTools Regex Editor", "description": "Uses Regex to find, match, or modify text. Returns matches if no replacement is set, otherwise, replaces matches or non-matches as specified.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsPreviewImage": {"input": {"required": {"images": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "iToolsPreviewImage", "display_name": "iTools Image Preview \ud83c\udf7f", "description": "The easiest way to preview, compare current and previous images, and track your prompt history.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsCompareImage": {"input": {"required": {"A": ["IMAGE"], "B": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["A", "B"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "iToolsCompareImage", "display_name": "iTools Image Compare \ud83d\udd0d", "description": "Compare A and B images", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsPromptRecord": {"input": {"required": {"text": ["STRING", {"default": "", "multiline": true, "placeholder": "text"}]}}, "input_order": {"required": ["text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["text"], "name": "iToolsPromptRecord", "display_name": "iTools Prompt Record \ud83e\udeb6", "description": "Tracks your prompts during node execution or when using \u25b6 button.\nProvides quick access to previously used prompts. Includes a history system that saves your favorite prompts.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsPaintNode": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "iToolsPaintNode", "display_name": "iTools Paint Node (Beta)", "description": "Will paint", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "iToolsCropImage": {"input": {"required": {"resize_rule": [["free", "grid", "1:1", "2:3", "3:4", "4:5", "9:16", "9:21", "3:2", "4:3", "5:4", "16:9", "21:9"], {"default": "grid"}], "grid_step": ["INT", {"default": 64, "min": 1, "max": 128}], "image": [["example.png"], {"image_upload": true}]}, "optional": {}}, "input_order": {"required": ["resize_rule", "grid_step", "image"], "optional": []}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "iToolsCropImage", "display_name": "iTools Crop Image (Beta)", "description": "Crop an Image.", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsFreeChat": {"input": {"required": {"model": [["meta-llama/Llama-3.3-70B-Instruct-Turbo-Free", "meta-llama/Llama-Vision-Free", "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"], {"default": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"}], "chat": ["STRING", {"default": "", "placeholder": "Chat in supported languages", "multiline": true}]}}, "input_order": {"required": ["model", "chat"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["answer"], "name": "iToolsFreeChat", "display_name": "iTools Free Chat (API)", "description": "Chat with free Together.ai language models", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": true}, "iToolsFreeSchnell": {"input": {"required": {"prompt": ["STRING", {"forceInput": true}], "width": ["INT", {"default": 1024, "min": 0, "max": 2048}], "height": ["INT", {"default": 1024, "min": 0, "max": 2048}], "seed": ["INT", {"default": 0, "min": 0, "max": 4294967295}]}}, "input_order": {"required": ["prompt", "width", "height", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "iToolsFreeSchnell", "display_name": "iTools Free Schnell (API)", "description": "Will return free Flux-Schnell image from a together.ai free API", "python_module": "custom_nodes.ComfyUI-iTools", "category": "iTools", "output_node": false}, "FluxPro_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "landscape_4_3"}], "width": ["INT", {"default": 1024, "min": 512, "max": 1440, "step": 32}], "height": ["INT", {"default": 768, "min": 512, "max": 1440, "step": 32}], "num_inference_steps": ["INT", {"default": 28, "min": 1, "max": 100}], "guidance_scale": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 20.0}], "num_images": ["INT", {"default": 1, "min": 1, "max": 10}], "safety_tolerance": [["1", "2", "3", "4", "5", "6"], {"default": "2"}]}, "optional": {"seed": ["INT", {"default": -1}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_inference_steps", "guidance_scale", "num_images", "safety_tolerance"], "optional": ["seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxPro_fal", "display_name": "Flux Pro (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "FluxDev_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "landscape_4_3"}], "width": ["INT", {"default": 1024, "min": 512, "max": 1536, "step": 16}], "height": ["INT", {"default": 768, "min": 512, "max": 1536, "step": 16}], "num_inference_steps": ["INT", {"default": 28, "min": 1, "max": 100}], "guidance_scale": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 20.0}], "num_images": ["INT", {"default": 1, "min": 1, "max": 10}], "enable_safety_checker": ["BOOLEAN", {"default": true}]}, "optional": {"seed": ["INT", {"default": -1}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_inference_steps", "guidance_scale", "num_images", "enable_safety_checker"], "optional": ["seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxDev_fal", "display_name": "Flux Dev (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "FluxSchnell_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "landscape_4_3"}], "width": ["INT", {"default": 1024, "min": 512, "max": 1536, "step": 32}], "height": ["INT", {"default": 768, "min": 512, "max": 1536, "step": 32}], "num_inference_steps": ["INT", {"default": 4, "min": 1, "max": 100}], "num_images": ["INT", {"default": 1, "min": 1, "max": 10}], "enable_safety_checker": ["BOOLEAN", {"default": true}]}, "optional": {"seed": ["INT", {"default": -1}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_inference_steps", "num_images", "enable_safety_checker"], "optional": ["seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxSchnell_fal", "display_name": "Flux Schnell (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "FluxPro11_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "landscape_4_3"}], "width": ["INT", {"default": 1024, "min": 512, "max": 1440, "step": 32}], "height": ["INT", {"default": 768, "min": 512, "max": 1440, "step": 32}], "num_images": ["INT", {"default": 1, "min": 1, "max": 10}], "safety_tolerance": [["1", "2", "3", "4", "5", "6"], {"default": "2"}]}, "optional": {"seed": ["INT", {"default": -1}], "sync_mode": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_images", "safety_tolerance"], "optional": ["seed", "sync_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxPro11_fal", "display_name": "Flux Pro 1.1 (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "FluxUltra_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "aspect_ratio": [["21:9", "16:9", "4:3", "1:1", "3:4", "9:16", "9:21"], {"default": "16:9"}], "num_images": ["INT", {"default": 1, "min": 1, "max": 1}], "safety_tolerance": [["1", "2", "3", "4", "5", "6"], {"default": "2"}], "enable_safety_checker": ["BOOLEAN", {"default": true}], "raw": ["BOOLEAN", {"default": false}], "sync_mode": ["BOOLEAN", {"default": false}]}, "optional": {"seed": ["INT", {"default": -1}]}}, "input_order": {"required": ["prompt", "aspect_ratio", "num_images", "safety_tolerance", "enable_safety_checker", "raw", "sync_mode"], "optional": ["seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxUltra_fal", "display_name": "Flux Ultra (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "FluxGeneral_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "landscape_4_3"}], "width": ["INT", {"default": 1024, "min": 512, "max": 1536, "step": 16}], "height": ["INT", {"default": 768, "min": 512, "max": 1536, "step": 16}], "num_inference_steps": ["INT", {"default": 28, "min": 1, "max": 50}], "guidance_scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 20.0, "step": 0.1}], "real_cfg_scale": ["FLOAT", {"default": 3.3, "min": 0.0, "max": 5.0, "step": 0.1}], "num_images": ["INT", {"default": 1, "min": 1, "max": 4}], "enable_safety_checker": ["BOOLEAN", {"default": false}], "use_real_cfg": ["BOOLEAN", {"default": false}], "sync_mode": ["BOOLEAN", {"default": false}]}, "optional": {"seed": ["INT", {"default": -1}], "ip_adapter_scale": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 1.0, "step": 0.1}], "controlnet_conditioning_scale": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 1.0, "step": 0.1}], "ip_adapters": [["None", "XLabs-AI/flux-ip-adapter"], {"default": "None"}], "controlnets": [["None", "XLabs-AI/flux-controlnet-depth-v3", "Shakker-Labs/FLUX.1-dev-ControlNet-Depth", "jasperai/Flux.1-dev-Controlnet-Depth", "jasperai/Flux.1-dev-Controlnet-Surface-Normals", "XLabs-AI/flux-controlnet-canny-v3", "InstantX/FLUX.1-dev-Controlnet-Canny", "jasperai/Flux.1-dev-Controlnet-Upscaler", "promeai/FLUX.1-controlnet-lineart-promeai"], {"default": "None"}], "controlnet_unions": [["None", "Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro", "InstantX/FLUX.1-dev-Controlnet-Union"], {"default": "None"}], "controlnet_union_control_mode": [["canny", "tile", "depth", "blur", "pose", "gray", "low_quality"], {"default": "canny"}], "control_image": ["IMAGE"], "control_mask": ["MASK"], "ip_adapter_image": ["IMAGE"], "ip_adapter_mask": ["MASK"], "lora_path_1": ["STRING", {"default": ""}], "lora_scale_1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}], "lora_path_2": ["STRING", {"default": ""}], "lora_scale_2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_inference_steps", "guidance_scale", "real_cfg_scale", "num_images", "enable_safety_checker", "use_real_cfg", "sync_mode"], "optional": ["seed", "ip_adapter_scale", "controlnet_conditioning_scale", "ip_adapters", "controlnets", "controlnet_unions", "controlnet_union_control_mode", "control_image", "control_mask", "ip_adapter_image", "ip_adapter_mask", "lora_path_1", "lora_scale_1", "lora_path_2", "lora_scale_2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxGeneral_fal", "display_name": "Flux General (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "FluxLora_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "landscape_4_3"}], "width": ["INT", {"default": 1024, "min": 512, "max": 1536, "step": 16}], "height": ["INT", {"default": 768, "min": 512, "max": 1536, "step": 16}], "num_inference_steps": ["INT", {"default": 28, "min": 1, "max": 50}], "guidance_scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 20.0, "step": 0.1}], "num_images": ["INT", {"default": 1, "min": 1, "max": 4}], "enable_safety_checker": ["BOOLEAN", {"default": true}]}, "optional": {"seed": ["INT", {"default": -1}], "lora_path_1": ["STRING", {"default": ""}], "lora_scale_1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}], "lora_path_2": ["STRING", {"default": ""}], "lora_scale_2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_inference_steps", "guidance_scale", "num_images", "enable_safety_checker"], "optional": ["seed", "lora_path_1", "lora_scale_1", "lora_path_2", "lora_scale_2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FluxLora_fal", "display_name": "Flux LoRA (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "Recraft_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "square_hd"}], "width": ["INT", {"default": 512, "min": 512, "max": 2048, "step": 16}], "height": ["INT", {"default": 512, "min": 512, "max": 2048, "step": 16}], "style": [["any", "realistic_image", "digital_illustration", "vector_illustration", "realistic_image/b_and_w", "realistic_image/hard_flash", "realistic_image/hdr", "realistic_image/natural_light", "realistic_image/studio_portrait", "realistic_image/enterprise", "realistic_image/motion_blur", "digital_illustration/pixel_art", "digital_illustration/hand_drawn", "digital_illustration/grain", "digital_illustration/infantile_sketch", "digital_illustration/2d_art_poster", "digital_illustration/handmade_3d", "digital_illustration/hand_drawn_outline", "digital_illustration/engraving_color", "digital_illustration/2d_art_poster_2", "vector_illustration/engraving", "vector_illustration/line_art", "vector_illustration/line_circuit", "vector_illustration/linocut"], {"default": "realistic_image"}]}, "optional": {"style_id": ["STRING", {"default": ""}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "style"], "optional": ["style_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Recraft_fal", "display_name": "Recraft V3 (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "Sana_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image_size": [["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9", "custom"], {"default": "square_hd"}], "width": ["INT", {"default": 3840, "min": 512, "max": 4096, "step": 16}], "height": ["INT", {"default": 2160, "min": 512, "max": 4096, "step": 16}], "num_inference_steps": ["INT", {"default": 18, "min": 1, "max": 50}], "guidance_scale": ["FLOAT", {"default": 5.0, "min": 1.0, "max": 20.0, "step": 0.1}], "num_images": ["INT", {"default": 1, "min": 1, "max": 4}]}, "optional": {"negative_prompt": ["STRING", {"default": "", "multiline": true}], "seed": ["INT", {"default": -1}], "enable_safety_checker": ["BOOLEAN", {"default": true}], "output_format": [["png", "jpeg"], {"default": "png"}]}}, "input_order": {"required": ["prompt", "image_size", "width", "height", "num_inference_steps", "guidance_scale", "num_images"], "optional": ["negative_prompt", "seed", "enable_safety_checker", "output_format"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Sana_fal", "display_name": "Sana (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Image", "output_node": false}, "Kling_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "duration": [["5", "10"], {"default": "5"}], "aspect_ratio": [["16:9", "9:16", "1:1"], {"default": "16:9"}]}, "optional": {"image": ["IMAGE"]}}, "input_order": {"required": ["prompt", "duration", "aspect_ratio"], "optional": ["image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Kling_fal", "display_name": "Kling Video Generation (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "KlingPro10_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "duration": [["5", "10"], {"default": "5"}], "aspect_ratio": [["16:9", "9:16", "1:1"], {"default": "16:9"}]}, "optional": {"image": ["IMAGE"], "tail_image": ["IMAGE"]}}, "input_order": {"required": ["prompt", "duration", "aspect_ratio"], "optional": ["image", "tail_image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "KlingPro10_fal", "display_name": "Kling Pro v1.0 Video Generation (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "KlingPro16_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "duration": [["5", "10"], {"default": "5"}], "aspect_ratio": [["16:9", "9:16", "1:1"], {"default": "16:9"}]}, "optional": {"image": ["IMAGE"], "tail_image": ["IMAGE"]}}, "input_order": {"required": ["prompt", "duration", "aspect_ratio"], "optional": ["image", "tail_image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "KlingPro16_fal", "display_name": "Kling Pro v1.6 Video Generation (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "KlingMaster_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "duration": [["5", "10"], {"default": "5"}], "aspect_ratio": [["16:9", "9:16", "1:1"], {"default": "16:9"}]}, "optional": {"image": ["IMAGE"]}}, "input_order": {"required": ["prompt", "duration", "aspect_ratio"], "optional": ["image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "KlingMaster_fal", "display_name": "Kling Master v2.0 Video Generation (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "RunwayGen3_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image": ["IMAGE"], "duration": [["5", "10"], {"default": "5"}]}}, "input_order": {"required": ["prompt", "image", "duration"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "RunwayGen3_fal", "display_name": "Runway Gen3 Image-to-Video (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "LumaDreamMachine_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "mode": [["text-to-video", "image-to-video"], {"default": "text-to-video"}], "aspect_ratio": [["16:9", "9:16", "4:3", "3:4", "21:9", "9:21"], {"default": "16:9"}]}, "optional": {"image": ["IMAGE"], "end_image": ["IMAGE"], "loop": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["prompt", "mode", "aspect_ratio"], "optional": ["image", "end_image", "loop"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "LumaDreamMachine_fal", "display_name": "Luma Dream Machine (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "LoadVideoURL": {"input": {"required": {"url": ["STRING", {"default": "https://example.com/video.mp4"}], "force_rate": ["INT", {"default": 0, "min": 0, "max": 60, "step": 1}], "force_size": [["Disabled", "Custom Height", "Custom Width", "Custom", "256x?", "?x256", "256x256", "512x?", "?x512", "512x512"]], "custom_width": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "custom_height": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 1000000, "step": 1}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 1000000, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 1000000, "step": 1}]}}, "input_order": {"required": ["url", "force_rate", "force_size", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"]}, "output": ["IMAGE", "INT", "VHS_VIDEOINFO"], "output_is_list": [false, false, false], "output_name": ["frames", "frame_count", "video_info"], "name": "LoadVideoURL", "display_name": "Load Video from URL", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "video", "output_node": false}, "MiniMax_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image": ["IMAGE"]}}, "input_order": {"required": ["prompt", "image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "MiniMax_fal", "display_name": "MiniMax Video Generation (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "MiniMaxTextToVideo_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["prompt"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "MiniMaxTextToVideo_fal", "display_name": "MiniMax Text-to-Video (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "MiniMaxSubjectReference_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "subject_reference_image": ["IMAGE"], "prompt_optimizer": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["prompt", "subject_reference_image", "prompt_optimizer"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "MiniMaxSubjectReference_fal", "display_name": "MiniMax Subject Reference (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "VideoUpscaler_fal": {"input": {"required": {"video_url": ["STRING", {"default": ""}], "scale": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 4.0, "step": 0.5}]}}, "input_order": {"required": ["video_url", "scale"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "VideoUpscaler_fal", "display_name": "Video Upscaler (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "CombinedVideoGeneration_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image": ["IMAGE"], "kling_duration": [["5", "10"], {"default": "5"}], "kling_luma_aspect_ratio": [["16:9", "9:16", "1:1"], {"default": "16:9"}], "luma_loop": ["BOOLEAN", {"default": false}], "veo2_aspect_ratio": [["auto", "auto_prefer_portrait", "16:9", "9:16"], {"default": "auto"}], "veo2_duration": [["5s", "6s", "7s", "8s"], {"default": "5s"}], "enable_klingpro": ["BOOLEAN", {"default": true}], "enable_klingmaster": ["BOOLEAN", {"default": true}], "enable_minimax": ["BOOLEAN", {"default": true}], "enable_luma": ["BOOLEAN", {"default": true}], "enable_veo2": ["BOOLEAN", {"default": true}], "enable_wanpro": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["prompt", "image", "kling_duration", "kling_luma_aspect_ratio", "luma_loop", "veo2_aspect_ratio", "veo2_duration", "enable_klingpro", "enable_klingmaster", "enable_minimax", "enable_luma", "enable_veo2", "enable_wanpro"]}, "output": ["STRING", "STRING", "STRING", "STRING", "STRING", "STRING"], "output_is_list": [false, false, false, false, false, false], "output_name": ["klingpro_v1.6_video", "klingmaster_v2.0_video", "minimax_video", "luma_video", "veo2_video", "wanpro_video"], "name": "CombinedVideoGeneration_fal", "display_name": "Combined Video Generation (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "Veo2ImageToVideo_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image": ["IMAGE"], "aspect_ratio": [["auto", "auto_prefer_portrait", "16:9", "9:16"], {"default": "auto"}], "duration": [["5s", "6s", "7s", "8s"], {"default": "5s"}]}}, "input_order": {"required": ["prompt", "image", "aspect_ratio", "duration"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Veo2ImageToVideo_fal", "display_name": "Google Veo2 Image-to-Video (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "WanPro_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "image": ["IMAGE"]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647}], "enable_safety_checker": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["prompt", "image"], "optional": ["seed", "enable_safety_checker"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "WanPro_fal", "display_name": "Wan Pro Image-to-Video (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VideoGeneration", "output_node": false}, "LLM_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "model": [["google/gemini-flash-1.5-8b", "anthropic/claude-3.5-sonnet", "anthropic/claude-3-haiku", "google/gemini-pro-1.5", "google/gemini-flash-1.5", "meta-llama/llama-3.2-1b-instruct", "meta-llama/llama-3.2-3b-instruct", "meta-llama/llama-3.1-8b-instruct", "meta-llama/llama-3.1-70b-instruct", "openai/gpt-4o-mini", "openai/gpt-4o"], {"default": "google/gemini-flash-1.5-8b"}], "system_prompt": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["prompt", "model", "system_prompt"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "LLM_fal", "display_name": "LLM (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/LLM", "output_node": false}, "VLM_fal": {"input": {"required": {"prompt": ["STRING", {"default": "", "multiline": true}], "model": [["google/gemini-flash-1.5-8b", "anthropic/claude-3.5-sonnet", "anthropic/claude-3-haiku", "google/gemini-pro-1.5", "google/gemini-flash-1.5", "openai/gpt-4o"], {"default": "google/gemini-flash-1.5-8b"}], "system_prompt": ["STRING", {"default": "", "multiline": true}], "image": ["IMAGE"]}}, "input_order": {"required": ["prompt", "model", "system_prompt", "image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "VLM_fal", "display_name": "VLM (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/VLM", "output_node": false}, "FluxLoraTrainer_fal": {"input": {"required": {"images": ["IMAGE"], "steps": ["INT", {"default": 1000, "min": 100, "max": 10000, "step": 100}], "create_masks": ["BOOLEAN", {"default": true}], "is_style": ["BOOLEAN", {"default": false}]}, "optional": {"trigger_word": ["STRING", {"default": ""}], "images_zip_url": ["STRING", {"default": ""}], "is_input_format_already_preprocessed": ["BOOLEAN", {"default": false}], "data_archive_format": ["STRING", {"default": ""}]}}, "input_order": {"required": ["images", "steps", "create_masks", "is_style"], "optional": ["trigger_word", "images_zip_url", "is_input_format_already_preprocessed", "data_archive_format"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["lora_file_url"], "name": "FluxLoraTrainer_fal", "display_name": "Flux LoRA Trainer (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Training", "output_node": false}, "HunyuanVideoLoraTrainer_fal": {"input": {"required": {"images": ["IMAGE"], "steps": ["INT", {"default": 1000, "min": 100, "max": 10000, "step": 100}]}, "optional": {"trigger_word": ["STRING", {"default": ""}], "learning_rate": ["FLOAT", {"default": 0.0001, "min": 1e-05, "max": 0.01}], "do_caption": ["BOOLEAN", {"default": true}], "images_zip_url": ["STRING", {"default": ""}], "data_archive_format": ["STRING", {"default": ""}]}}, "input_order": {"required": ["images", "steps"], "optional": ["trigger_word", "learning_rate", "do_caption", "images_zip_url", "data_archive_format"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["lora_file_url"], "name": "HunyuanVideoLoraTrainer_fal", "display_name": "Hunyuan Video LoRA Trainer (fal)", "description": "", "python_module": "custom_nodes.ComfyUI-fal-API", "category": "FAL/Training", "output_node": false}, "BOOLConstant": {"input": {"required": {"value": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["value"], "name": "BOOLConstant", "display_name": "BOOL Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "INTConstant": {"input": {"required": {"value": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["value"], "name": "INTConstant", "display_name": "INT Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "FloatConstant": {"input": {"required": {"value": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 1e-05}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["value"], "name": "FloatConstant", "display_name": "Float Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "StringConstant": {"input": {"required": {"string": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringConstant", "display_name": "String Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "StringConstantMultiline": {"input": {"required": {"string": ["STRING", {"default": "", "multiline": true}], "strip_newlines": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["string", "strip_newlines"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringConstantMultiline", "display_name": "String Constant Multiline", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "ConditioningMultiCombine": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 20, "step": 1}], "operation": [["combine", "concat"], {"default": "combine"}], "conditioning_1": ["CONDITIONING"], "conditioning_2": ["CONDITIONING"]}}, "input_order": {"required": ["inputcount", "operation", "conditioning_1", "conditioning_2"]}, "output": ["CONDITIONING", "INT"], "output_is_list": [false, false], "output_name": ["combined", "inputcount"], "name": "ConditioningMultiCombine", "display_name": "Conditioning Multi Combine", "description": "\nCombines multiple conditioning nodes into one\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "mask_1", "mask_2", "mask_1_strength", "mask_2_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine", "display_name": "ConditioningSetMaskAndCombine", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine3": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "positive_3": ["CONDITIONING"], "negative_3": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_3": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_3_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "positive_3", "negative_3", "mask_1", "mask_2", "mask_3", "mask_1_strength", "mask_2_strength", "mask_3_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine3", "display_name": "ConditioningSetMaskAndCombine3", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine4": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "positive_3": ["CONDITIONING"], "negative_3": ["CONDITIONING"], "positive_4": ["CONDITIONING"], "negative_4": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_3": ["MASK"], "mask_4": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_3_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_4_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "positive_3", "negative_3", "positive_4", "negative_4", "mask_1", "mask_2", "mask_3", "mask_4", "mask_1_strength", "mask_2_strength", "mask_3_strength", "mask_4_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine4", "display_name": "ConditioningSetMaskAndCombine4", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine5": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "positive_3": ["CONDITIONING"], "negative_3": ["CONDITIONING"], "positive_4": ["CONDITIONING"], "negative_4": ["CONDITIONING"], "positive_5": ["CONDITIONING"], "negative_5": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_3": ["MASK"], "mask_4": ["MASK"], "mask_5": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_3_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_4_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_5_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "positive_3", "negative_3", "positive_4", "negative_4", "positive_5", "negative_5", "mask_1", "mask_2", "mask_3", "mask_4", "mask_5", "mask_1_strength", "mask_2_strength", "mask_3_strength", "mask_4_strength", "mask_5_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine5", "display_name": "ConditioningSetMaskAndCombine5", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "CondPassThrough": {"input": {"required": {}, "optional": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"]}}, "input_order": {"required": [], "optional": ["positive", "negative"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "CondPassThrough", "display_name": "CondPassThrough", "description": "\n    Simply passes through the positive and negative conditioning,\n    workaround for Set node not allowing bypassed inputs.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "DownloadAndLoadCLIPSeg": {"input": {"required": {"model": [["Kijai/clipseg-rd64-refined-fp16", "CIDAS/clipseg-rd64-refined"]]}}, "input_order": {"required": ["model"]}, "output": ["CLIPSEGMODEL"], "output_is_list": [false], "output_name": ["clipseg_model"], "name": "DownloadAndLoadCLIPSeg", "display_name": "(Down)load CLIPSeg", "description": "\nDownloads and loads CLIPSeg model with huggingface_hub,  \nto ComfyUI/models/clip_seg\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BatchCLIPSeg": {"input": {"required": {"images": ["IMAGE"], "text": ["STRING", {"multiline": false}], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.001}], "binary_mask": ["BOOLEAN", {"default": true}], "combine_mask": ["BOOLEAN", {"default": false}], "use_cuda": ["BOOLEAN", {"default": true}]}, "optional": {"blur_sigma": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "opt_model": ["CLIPSEGMODEL"], "prev_mask": ["MASK", {"default": null}], "image_bg_level": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "invert": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["images", "text", "threshold", "binary_mask", "combine_mask", "use_cuda"], "optional": ["blur_sigma", "opt_model", "prev_mask", "image_bg_level", "invert"]}, "output": ["MASK", "IMAGE"], "output_is_list": [false, false], "output_name": ["Mask", "Image"], "name": "BatchCLIPSeg", "display_name": "Batch CLIPSeg", "description": "\nSegments an image or batch of images using CLIPSeg.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "ColorToMask": {"input": {"required": {"images": ["IMAGE"], "invert": ["BOOLEAN", {"default": false}], "red": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "green": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "blue": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "threshold": ["INT", {"default": 10, "min": 0, "max": 255, "step": 1}], "per_batch": ["INT", {"default": 16, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["images", "invert", "red", "green", "blue", "threshold", "per_batch"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ColorToMask", "display_name": "Color To Mask", "description": "\nConverts chosen RGB value to a mask.  \nWith batch inputs, the **per_batch**  \ncontrols the number of images processed at once.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "CreateGradientMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CreateGradientMask", "display_name": "Create Gradient Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateTextMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "text_x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "text_y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "font_size": ["INT", {"default": 32, "min": 8, "max": 4096, "step": 1}], "font_color": ["STRING", {"default": "white"}], "text": ["STRING", {"default": "HELLO!", "multiline": true}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "start_rotation": ["INT", {"default": 0, "min": 0, "max": 359, "step": 1}], "end_rotation": ["INT", {"default": 0, "min": -359, "max": 359, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "text_x", "text_y", "font_size", "font_color", "text", "font", "width", "height", "start_rotation", "end_rotation"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "CreateTextMask", "display_name": "Create Text Mask", "description": "\nCreates a text image and mask.  \nLooks for fonts from this folder:  \nComfyUI/custom_nodes/ComfyUI-KJNodes/fonts\n  \nIf start_rotation and/or end_rotation are different values,  \ncreates animation between them.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "CreateAudioMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 16, "min": 1, "max": 255, "step": 1}], "scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.01}], "audio_path": ["STRING", {"default": "audio.wav"}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "scale", "audio_path", "width", "height"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CreateAudioMask", "display_name": "Create Audio Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/deprecated", "output_node": false}, "CreateFadeMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 2, "min": 2, "max": 10000, "step": 1}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "start_level": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "midpoint_level": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "end_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "midpoint_frame": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "width", "height", "interpolation", "start_level", "midpoint_level", "end_level", "midpoint_frame"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CreateFadeMask", "display_name": "Create Fade Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/deprecated", "output_node": false}, "CreateFadeMaskAdvanced": {"input": {"required": {"points_string": ["STRING", {"default": "0:(0.0),\n7:(1.0),\n15:(0.0)\n", "multiline": true}], "invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 16, "min": 2, "max": 10000, "step": 1}], "width": ["INT", {"default": 512, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 4096, "step": 1}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]]}}, "input_order": {"required": ["points_string", "invert", "frames", "width", "height", "interpolation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CreateFadeMaskAdvanced", "display_name": "Create Fade Mask Advanced", "description": "\nCreate a batch of masks interpolated between given frames and values. \nUses same syntax as Fizz' BatchValueSchedule.\nFirst value is the frame index (not that this starts from 0, not 1) \nand the second value inside the brackets is the float value of the mask in range 0.0 - 1.0  \n\nFor example the default values:  \n0:(0.0)  \n7:(1.0)  \n15:(0.0)  \n  \nWould create a mask batch fo 16 frames, starting from black, \ninterpolating with the chosen curve to fully white at the 8th frame, \nand interpolating from that to fully black at the 16th frame.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateFluidMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "inflow_count": ["INT", {"default": 3, "min": 0, "max": 255, "step": 1}], "inflow_velocity": ["INT", {"default": 1, "min": 0, "max": 255, "step": 1}], "inflow_radius": ["INT", {"default": 8, "min": 0, "max": 255, "step": 1}], "inflow_padding": ["INT", {"default": 50, "min": 0, "max": 255, "step": 1}], "inflow_duration": ["INT", {"default": 60, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "width", "height", "inflow_count", "inflow_velocity", "inflow_radius", "inflow_padding", "inflow_duration"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "CreateFluidMask", "display_name": "Create Fluid Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateShapeMask": {"input": {"required": {"shape": [["circle", "square", "triangle"], {"default": "circle"}], "frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "location_x": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "location_y": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "grow": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "shape_width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}], "shape_height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}]}}, "input_order": {"required": ["shape", "frames", "location_x", "location_y", "grow", "frame_width", "frame_height", "shape_width", "shape_height"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateShapeMask", "display_name": "Create Shape Mask", "description": "\nCreates a mask or batch of masks with the specified shape.  \nLocations are center locations.  \nGrow value is the amount to grow the shape on each frame, creating animated masks.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateVoronoiMask": {"input": {"required": {"frames": ["INT", {"default": 16, "min": 2, "max": 4096, "step": 1}], "num_points": ["INT", {"default": 15, "min": 1, "max": 4096, "step": 1}], "line_width": ["INT", {"default": 4, "min": 1, "max": 4096, "step": 1}], "speed": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["frames", "num_points", "line_width", "speed", "frame_width", "frame_height"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateVoronoiMask", "display_name": "Create Voronoi Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateMagicMask": {"input": {"required": {"frames": ["INT", {"default": 16, "min": 2, "max": 4096, "step": 1}], "depth": ["INT", {"default": 12, "min": 1, "max": 500, "step": 1}], "distortion": ["FLOAT", {"default": 1.5, "min": 0.0, "max": 100.0, "step": 0.01}], "seed": ["INT", {"default": 123, "min": 0, "max": 99999999, "step": 1}], "transitions": ["INT", {"default": 1, "min": 1, "max": 20, "step": 1}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["frames", "depth", "distortion", "seed", "transitions", "frame_width", "frame_height"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateMagicMask", "display_name": "Create Magic Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "GetMaskSizeAndCount": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["mask", "width", "height", "count"], "name": "GetMaskSizeAndCount", "display_name": "Get Mask Size & Count", "description": "\nReturns the width, height and batch size of the mask,  \nand passes it through unchanged.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "GrowMaskWithBlur": {"input": {"required": {"mask": ["MASK"], "expand": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "incremental_expandrate": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "tapered_corners": ["BOOLEAN", {"default": true}], "flip_input": ["BOOLEAN", {"default": false}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100, "step": 0.1}], "lerp_alpha": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "decay_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"fill_holes": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["mask", "expand", "incremental_expandrate", "tapered_corners", "flip_input", "blur_radius", "lerp_alpha", "decay_factor"], "optional": ["fill_holes"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "GrowMaskWithBlur", "display_name": "Grow Mask With Blur", "description": "\n# GrowMaskWithBlur\n- mask: Input mask or mask batch\n- expand: Expand or contract mask or mask batch by a given amount\n- incremental_expandrate: increase expand rate by a given amount per frame\n- tapered_corners: use tapered corners\n- flip_input: flip input mask\n- blur_radius: value higher than 0 will blur the mask\n- lerp_alpha: alpha value for interpolation between frames\n- decay_factor: decay value for interpolation between frames\n- fill_holes: fill holes in the mask (slow)", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "MaskBatchMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "mask_1": ["MASK"], "mask_2": ["MASK"]}}, "input_order": {"required": ["inputcount", "mask_1", "mask_2"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["masks"], "name": "MaskBatchMulti", "display_name": "Mask Batch Multi", "description": "\nCreates an image batch from multiple masks.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "OffsetMask": {"input": {"required": {"mask": ["MASK"], "x": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "y": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "angle": ["INT", {"default": 0, "min": -360, "max": 360, "step": 1, "display": "number"}], "duplication_factor": ["INT", {"default": 1, "min": 1, "max": 1000, "step": 1, "display": "number"}], "roll": ["BOOLEAN", {"default": false}], "incremental": ["BOOLEAN", {"default": false}], "padding_mode": [["empty", "border", "reflection"], {"default": "empty"}]}}, "input_order": {"required": ["mask", "x", "y", "angle", "duplication_factor", "roll", "incremental", "padding_mode"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "OffsetMask", "display_name": "Offset Mask", "description": "\nOffsets the mask by the specified amount.  \n - mask: Input mask or mask batch\n - x: Horizontal offset\n - y: Vertical offset\n - angle: Angle in degrees\n - roll: roll edge wrapping\n - duplication_factor: Number of times to duplicate the mask to form a batch\n - border padding_mode: Padding mode for the mask\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "RemapMaskRange": {"input": {"required": {"mask": ["MASK"], "min": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 1.0, "step": 0.01}], "max": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["mask", "min", "max"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "RemapMaskRange", "display_name": "Remap Mask Range", "description": "\nSets new min and max values for the mask.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "ResizeMask": {"input": {"required": {"mask": ["MASK"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "display": "number"}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "display": "number"}], "keep_proportions": ["BOOLEAN", {"default": false}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["mask", "width", "height", "keep_proportions", "upscale_method", "crop"]}, "output": ["MASK", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["mask", "width", "height"], "name": "ResizeMask", "display_name": "Resize Mask", "description": "\nResizes the mask or batch of masks to the specified width and height.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "RoundMask": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "RoundMask", "display_name": "Round Mask", "description": "\nRounds the mask or batch of masks to a binary mask.  \n<img src=\"https://github.com/kijai/ComfyUI-KJNodes/assets/40791699/52c85202-f74e-4b96-9dac-c8bda5ddcc40\" width=\"300\" height=\"250\" alt=\"RoundMask example\">\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "SeparateMasks": {"input": {"required": {"mask": ["MASK"], "size_threshold_width": ["INT", {"default": 256, "min": 0.0, "max": 4096, "step": 1}], "size_threshold_height": ["INT", {"default": 256, "min": 0.0, "max": 4096, "step": 1}], "mode": [["convex_polygons", "area"]], "max_poly_points": ["INT", {"default": 8, "min": 3, "max": 32, "step": 1}]}}, "input_order": {"required": ["mask", "size_threshold_width", "size_threshold_height", "mode", "max_poly_points"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "SeparateMasks", "display_name": "Separate Masks", "description": "Separates a mask into multiple masks based on the size of the connected components.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": true}, "AddLabel": {"input": {"required": {"image": ["IMAGE"], "text_x": ["INT", {"default": 10, "min": 0, "max": 4096, "step": 1}], "text_y": ["INT", {"default": 2, "min": 0, "max": 4096, "step": 1}], "height": ["INT", {"default": 48, "min": -1, "max": 4096, "step": 1}], "font_size": ["INT", {"default": 32, "min": 0, "max": 4096, "step": 1}], "font_color": ["STRING", {"default": "white"}], "label_color": ["STRING", {"default": "black"}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "text": ["STRING", {"default": "Text"}], "direction": [["up", "down", "left", "right", "overlay"], {"default": "up"}]}, "optional": {"caption": ["STRING", {"default": "", "forceInput": true}]}}, "input_order": {"required": ["image", "text_x", "text_y", "height", "font_size", "font_color", "label_color", "font", "text", "direction"], "optional": ["caption"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AddLabel", "display_name": "Add Label", "description": "\nCreates a new with the given text, and concatenates it to  \neither above or below the input image.  \nNote that this changes the input image's height!  \nFonts are loaded from this folder:  \nComfyUI/custom_nodes/ComfyUI-KJNodes/fonts\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "ColorMatch": {"input": {"required": {"image_ref": ["IMAGE"], "image_target": ["IMAGE"], "method": [["mkl", "hm", "reinhard", "mvgd", "hm-mvgd-hm", "hm-mkl-hm"], {"default": "mkl"}]}, "optional": {"strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["image_ref", "image_target", "method"], "optional": ["strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ColorMatch", "display_name": "Color Match", "description": "\ncolor-matcher enables color transfer across images which comes in handy for automatic  \ncolor-grading of photographs, paintings and film sequences as well as light-field  \nand stopmotion corrections.  \n\nThe methods behind the mappings are based on the approach from Reinhard et al.,  \nthe Monge-Kantorovich Linearization (MKL) as proposed by Pitie et al. and our analytical solution  \nto a Multi-Variate Gaussian Distribution (MVGD) transfer in conjunction with classical histogram   \nmatching. As shown below our HM-MVGD-HM compound outperforms existing methods.   \nhttps://github.com/hahnec/color-matcher/\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageTensorList": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageTensorList", "display_name": "Image Tensor List", "description": "\nCreates an image list from the input images.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CrossFadeImages": {"input": {"required": {"images_1": ["IMAGE"], "images_2": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transition_start_index": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "start_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "end_level": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["images_1", "images_2", "interpolation", "transition_start_index", "transitioning_frames", "start_level", "end_level"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CrossFadeImages", "display_name": "Cross Fade Images", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CrossFadeImagesMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "interpolation", "transitioning_frames"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CrossFadeImagesMulti", "display_name": "Cross Fade Images Multi", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GetImagesFromBatchIndexed": {"input": {"required": {"images": ["IMAGE"], "indexes": ["STRING", {"default": "0, 1, 2", "multiline": true}]}}, "input_order": {"required": ["images", "indexes"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "GetImagesFromBatchIndexed", "display_name": "Get Images From Batch Indexed", "description": "\nSelects and returns the images at the specified indices as an image batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GetImageRangeFromBatch": {"input": {"required": {"start_index": ["INT", {"default": 0, "min": -1, "max": 4096, "step": 1}], "num_frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}]}, "optional": {"images": ["IMAGE"], "masks": ["MASK"]}}, "input_order": {"required": ["start_index", "num_frames"], "optional": ["images", "masks"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "GetImageRangeFromBatch", "display_name": "Get Image or Mask Range From Batch", "description": "\nReturns a range of images from a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GetLatentRangeFromBatch": {"input": {"required": {"latents": ["LATENT"], "start_index": ["INT", {"default": 0, "min": -1, "max": 4096, "step": 1}], "num_frames": ["INT", {"default": 1, "min": -1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["latents", "start_index", "num_frames"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "GetLatentRangeFromBatch", "display_name": "Get Latent Range From Batch", "description": "\nReturns a range of latents from a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "GetImageSizeAndCount": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["image", "width", "height", "count"], "name": "GetImageSizeAndCount", "display_name": "Get Image Size & Count", "description": "\nReturns width, height and batch size of the image,  \nand passes it through unchanged.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "FastPreview": {"input": {"required": {"image": ["IMAGE"], "format": [["JPEG", "PNG", "WEBP"], {"default": "JPEG"}], "quality": ["INT", {"default": 75, "min": 1, "max": 100, "step": 1}]}}, "input_order": {"required": ["image", "format", "quality"]}, "output": [], "output_is_list": [], "output_name": [], "name": "FastPreview", "display_name": "Fast Preview", "description": "Experimental node for faster image previews by displaying through base64 it without saving to disk.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true}, "ImageBatchFilter": {"input": {"required": {"images": ["IMAGE"], "empty_color": ["STRING", {"default": "0, 0, 0"}], "empty_threshold": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"replacement_image": ["IMAGE"]}}, "input_order": {"required": ["images", "empty_color", "empty_threshold"], "optional": ["replacement_image"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["images", "removed_indices"], "name": "ImageBatchFilter", "display_name": "Image Batch Filter", "description": "Removes empty images from a batch", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageAndMaskPreview": {"input": {"required": {"mask_opacity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "mask_color": ["STRING", {"default": "255, 255, 255"}], "pass_through": ["BOOLEAN", {"default": false}]}, "optional": {"image": ["IMAGE"], "mask": ["MASK"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mask_opacity", "mask_color", "pass_through"], "optional": ["image", "mask"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["composite"], "name": "ImageAndMaskPreview", "display_name": "ImageAndMaskPreview", "description": "\nPreview an image or a mask, when both inputs are used  \ncomposites the mask on top of the image.\nwith pass_through on the preview is disabled and the  \ncomposite is returned from the composite slot instead,  \nthis allows for the preview to be passed for video combine  \nnodes for example.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": true}, "ImageAddMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "blending": [["add", "subtract", "multiply", "difference"], {"default": "add"}], "blend_amount": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "blending", "blend_amount"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "ImageAddMulti", "display_name": "Image Add Multi", "description": "\nAdd blends multiple images together.    \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageBatchMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"]}}, "input_order": {"required": ["inputcount", "image_1", "image_2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "ImageBatchMulti", "display_name": "Image Batch Multi", "description": "\nCreates an image batch from multiple images.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageBatchRepeatInterleaving": {"input": {"required": {"images": ["IMAGE"], "repeats": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["images", "repeats"], "optional": ["mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImageBatchRepeatInterleaving", "display_name": "ImageBatchRepeatInterleaving", "description": "\nRepeats each image in a batch by the specified number of times.  \nExample batch of 5 images: 0, 1 ,2, 3, 4  \nwith repeats 2 becomes batch of 10 images: 0, 0, 1, 1, 2, 2, 3, 3, 4, 4  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageBatchTestPattern": {"input": {"required": {"batch_size": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}], "start_from": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "text_x": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "text_y": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "font_size": ["INT", {"default": 255, "min": 8, "max": 4096, "step": 1}]}}, "input_order": {"required": ["batch_size", "start_from", "text_x", "text_y", "width", "height", "font", "font_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatchTestPattern", "display_name": "Image Batch Test Pattern", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "ImageConcanate": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "direction": [["right", "down", "left", "up"], {"default": "right"}], "match_image_size": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image1", "image2", "direction", "match_image_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageConcanate", "display_name": "Image Concatenate", "description": "\nConcatenates the image2 to image1 in the specified direction.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageConcatFromBatch": {"input": {"required": {"images": ["IMAGE"], "num_columns": ["INT", {"default": 3, "min": 1, "max": 255, "step": 1}], "match_image_size": ["BOOLEAN", {"default": false}], "max_resolution": ["INT", {"default": 4096}]}}, "input_order": {"required": ["images", "num_columns", "match_image_size", "max_resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageConcatFromBatch", "display_name": "Image Concatenate From Batch", "description": "\n    Concatenates images from a batch into a grid with a specified number of columns.\n    ", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageConcatMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "direction": [["right", "down", "left", "up"], {"default": "right"}], "match_image_size": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "direction", "match_image_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "ImageConcatMulti", "display_name": "Image Concatenate Multi", "description": "\nCreates an image from multiple images.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageCropByMask": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"]}}, "input_order": {"required": ["image", "mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ImageCropByMask", "display_name": "Image Crop By Mask", "description": "Crops the input images based on the provided mask.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageCropByMaskAndResize": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "base_resolution": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "padding": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "min_crop_resolution": ["INT", {"default": 128, "min": 0, "max": 16384, "step": 8}], "max_crop_resolution": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["image", "mask", "base_resolution", "padding", "min_crop_resolution", "max_crop_resolution"]}, "output": ["IMAGE", "MASK", "BBOX"], "output_is_list": [false, false, false], "output_name": ["images", "masks", "bbox"], "name": "ImageCropByMaskAndResize", "display_name": "Image Crop By Mask And Resize", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageCropByMaskBatch": {"input": {"required": {"image": ["IMAGE"], "masks": ["MASK"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "padding": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "preserve_size": ["BOOLEAN", {"default": false}], "bg_color": ["STRING", {"default": "0, 0, 0", "tooltip": "Color as RGB values in range 0-255, separated by commas."}]}}, "input_order": {"required": ["image", "masks", "width", "height", "padding", "preserve_size", "bg_color"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["images", "masks"], "name": "ImageCropByMaskBatch", "display_name": "Image Crop By Mask Batch", "description": "Crops the input images based on the provided masks.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageUncropByMask": {"input": {"required": {"destination": ["IMAGE"], "source": ["IMAGE"], "mask": ["MASK"], "bbox": ["BBOX"]}}, "input_order": {"required": ["destination", "source", "mask", "bbox"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ImageUncropByMask", "display_name": "Image Uncrop By Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGrabPIL": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "width": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "num_frames": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}], "delay": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["x", "y", "width", "height", "num_frames", "delay"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ImageGrabPIL", "display_name": "Image Grab PIL", "description": "\nCaptures an area specified by screen coordinates.  \nCan be used for realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGridComposite2x2": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "image3": ["IMAGE"], "image4": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2", "image3", "image4"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageGridComposite2x2", "display_name": "Image Grid Composite 2x2", "description": "\nConcatenates the 4 input images into a 2x2 grid. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGridComposite3x3": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "image3": ["IMAGE"], "image4": ["IMAGE"], "image5": ["IMAGE"], "image6": ["IMAGE"], "image7": ["IMAGE"], "image8": ["IMAGE"], "image9": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2", "image3", "image4", "image5", "image6", "image7", "image8", "image9"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageGridComposite3x3", "display_name": "Image Grid Composite 3x3", "description": "\nConcatenates the 9 input images into a 3x3 grid. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGridtoBatch": {"input": {"required": {"image": ["IMAGE"], "columns": ["INT", {"default": 3, "min": 1, "max": 8, "tooltip": "The number of columns in the grid."}], "rows": ["INT", {"default": 0, "min": 1, "max": 8, "tooltip": "The number of rows in the grid. Set to 0 for automatic calculation."}]}}, "input_order": {"required": ["image", "columns", "rows"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageGridtoBatch", "display_name": "Image Grid To Batch", "description": "Converts a grid of images to a batch of images.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageNoiseAugmentation": {"input": {"required": {"image": ["IMAGE"], "noise_aug_strength": ["FLOAT", {"default": null, "min": 0.0, "max": 100.0, "step": 0.001}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["image", "noise_aug_strength", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageNoiseAugmentation", "display_name": "Image Noise Augmentation", "description": "\n    Add noise to an image.  \n    ", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageNormalize_Neg1_To_1": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageNormalize_Neg1_To_1", "display_name": "Image Normalize -1 to 1", "description": "\nNormalize the images to be in the range [-1, 1]  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImagePass": {"input": {"required": {}, "optional": {"image": ["IMAGE"]}}, "input_order": {"required": [], "optional": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImagePass", "display_name": "ImagePass", "description": "\nPasses the image through without modifying it.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImagePadKJ": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "extra_padding": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "pad_mode": [["edge", "color"]], "color": ["STRING", {"default": "0, 0, 0", "tooltip": "Color as RGB values in range 0-255, separated by commas."}]}, "optional": {"mask": ["MASK"], "target_width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "forceInput": true}], "target_height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "forceInput": true}]}}, "input_order": {"required": ["image", "left", "right", "top", "bottom", "extra_padding", "pad_mode", "color"], "optional": ["mask", "target_width", "target_height"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["images", "masks"], "name": "ImagePadKJ", "display_name": "ImagePad KJ", "description": "Pad the input image and optionally mask with the specified padding.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImagePadForOutpaintMasked": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["image", "left", "top", "right", "bottom", "feathering"], "optional": ["mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaintMasked", "display_name": "Image Pad For Outpaint Masked", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "image", "output_node": false}, "ImagePadForOutpaintTargetSize": {"input": {"required": {"image": ["IMAGE"], "target_width": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "target_height": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["image", "target_width", "target_height", "feathering", "upscale_method"], "optional": ["mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaintTargetSize", "display_name": "Image Pad For Outpaint Target Size", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "image", "output_node": false}, "ImagePrepForICLora": {"input": {"required": {"reference_image": ["IMAGE"], "output_width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "output_height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "border_width": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}]}, "optional": {"latent_image": ["IMAGE"], "latent_mask": ["MASK"], "reference_mask": ["MASK"]}}, "input_order": {"required": ["reference_image", "output_width", "output_height", "border_width"], "optional": ["latent_image", "latent_mask", "reference_mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePrepForICLora", "display_name": "Image Prep For ICLora", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "image", "output_node": false}, "ImageResizeKJ": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "keep_proportion": ["BOOLEAN", {"default": false}], "divisible_by": ["INT", {"default": 2, "min": 0, "max": 512, "step": 1}]}, "optional": {"get_image_size": ["IMAGE"], "crop": [["disabled", "center", 0], {"tooltip": "0 will do the default center crop, this is a workaround for the widget order changing with the new frontend, as in old workflows the value of this widget becomes 0 automatically"}]}}, "input_order": {"required": ["image", "width", "height", "upscale_method", "keep_proportion", "divisible_by"], "optional": ["get_image_size", "crop"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "width", "height"], "name": "ImageResizeKJ", "display_name": "Resize Image (deprecated)", "description": "\nDEPRECATED!\n\nDue to ComfyUI frontend changes, this node should no longer be used, please check the   \nv2 of the node. This node is only kept to not completely break older workflows.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false, "deprecated": true}, "ImageResizeKJv2": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "keep_proportion": [["stretch", "resize", "pad", "pad_edge", "crop"], {"default": false}], "pad_color": ["STRING", {"default": "0, 0, 0", "tooltip": "Color to use for padding."}], "crop_position": [["center", "top", "bottom", "left", "right"], {"default": "center"}], "divisible_by": ["INT", {"default": 2, "min": 0, "max": 512, "step": 1}]}}, "input_order": {"required": ["image", "width", "height", "upscale_method", "keep_proportion", "pad_color", "crop_position", "divisible_by"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "width", "height"], "name": "ImageResizeKJv2", "display_name": "Resize Image v2", "description": "\nResizes the image to the specified width and height.  \nSize can be retrieved from the input.\n\nKeep proportions keeps the aspect ratio of the image, by  \nhighest dimension.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageUpscaleWithModelBatched": {"input": {"required": {"upscale_model": ["UPSCALE_MODEL"], "images": ["IMAGE"], "per_batch": ["INT", {"default": 16, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["upscale_model", "images", "per_batch"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageUpscaleWithModelBatched", "display_name": "Image Upscale With Model Batched", "description": "\nSame as ComfyUI native model upscaling node,  \nbut allows setting sub-batches for reduced VRAM usage.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "InsertImagesToBatchIndexed": {"input": {"required": {"original_images": ["IMAGE"], "images_to_insert": ["IMAGE"], "indexes": ["STRING", {"default": "0, 1, 2", "multiline": true}]}, "optional": {"mode": [["replace", "insert"]]}}, "input_order": {"required": ["original_images", "images_to_insert", "indexes"], "optional": ["mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "InsertImagesToBatchIndexed", "display_name": "Insert Images To Batch Indexed", "description": "\nInserts images at the specified indices into the original image batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "InsertLatentToIndexed": {"input": {"required": {"source": ["LATENT"], "destination": ["LATENT"], "index": ["INT", {"default": 0, "min": -1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["source", "destination", "index"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "InsertLatentToIndexed", "display_name": "Insert Latent To Index", "description": "\nInserts a latent at the specified index into the original latent batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "LoadAndResizeImage": {"input": {"required": {"image": [["example.png"], {"image_upload": true}], "resize": ["BOOLEAN", {"default": false}], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "repeat": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "keep_proportion": ["BOOLEAN", {"default": false}], "divisible_by": ["INT", {"default": 2, "min": 0, "max": 512, "step": 1}], "mask_channel": [["alpha", "red", "green", "blue"], {"tooltip": "Channel to use for the mask output"}], "background_color": ["STRING", {"default": "", "tooltip": "Fills the alpha channel with the specified color."}]}}, "input_order": {"required": ["image", "resize", "width", "height", "repeat", "keep_proportion", "divisible_by", "mask_channel", "background_color"]}, "output": ["IMAGE", "MASK", "INT", "INT", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["image", "mask", "width", "height", "image_path"], "name": "LoadAndResizeImage", "display_name": "Load & Resize Image", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "LoadImagesFromFolderKJ": {"input": {"required": {"folder": ["STRING", {"default": ""}], "width": ["INT", {"default": 1024, "min": 64, "step": 1}], "height": ["INT", {"default": 1024, "min": 64, "step": 1}], "keep_aspect_ratio": [["crop", "pad", "stretch"]]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "step": 1}], "start_index": ["INT", {"default": 0, "min": 0, "step": 1}], "include_subfolders": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["folder", "width", "height", "keep_aspect_ratio"], "optional": ["image_load_cap", "start_index", "include_subfolders"]}, "output": ["IMAGE", "MASK", "INT", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["image", "mask", "count", "image_path"], "name": "LoadImagesFromFolderKJ", "display_name": "Load Images From Folder (KJ)", "description": "Loads images from a folder into a batch, images are resized and loaded into a batch.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "MergeImageChannels": {"input": {"required": {"red": ["IMAGE"], "green": ["IMAGE"], "blue": ["IMAGE"]}, "optional": {"alpha": ["MASK", {"default": null}]}}, "input_order": {"required": ["red", "green", "blue"], "optional": ["alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "MergeImageChannels", "display_name": "Merge Image Channels", "description": "\nMerges channel data into an image.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "PadImageBatchInterleaved": {"input": {"required": {"images": ["IMAGE"], "empty_frames_per_image": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "pad_frame_value": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "add_after_last": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["images", "empty_frames_per_image", "pad_frame_value", "add_after_last"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["images", "masks"], "name": "PadImageBatchInterleaved", "display_name": "Pad Image Batch Interleaved", "description": "\nInserts empty frames between the images in a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "PreviewAnimation": {"input": {"required": {"fps": ["FLOAT", {"default": 8.0, "min": 0.01, "max": 1000.0, "step": 0.01}]}, "optional": {"images": ["IMAGE"], "masks": ["MASK"]}}, "input_order": {"required": ["fps"], "optional": ["images", "masks"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAnimation", "display_name": "Preview Animation", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": true}, "RemapImageRange": {"input": {"required": {"image": ["IMAGE"], "min": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 1.0, "step": 0.01}], "max": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "clamp": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "min", "max", "clamp"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RemapImageRange", "display_name": "Remap Image Range", "description": "\nRemaps the image values to the specified range. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ReverseImageBatch": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ReverseImageBatch", "display_name": "Reverse Image Batch", "description": "\nReverses the order of the images in a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ReplaceImagesInBatch": {"input": {"required": {"original_images": ["IMAGE"], "replacement_images": ["IMAGE"], "start_index": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}]}, "optional": {"original_masks": ["MASK"], "replacement_masks": ["MASK"]}}, "input_order": {"required": ["original_images", "replacement_images", "start_index"], "optional": ["original_masks", "replacement_masks"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ReplaceImagesInBatch", "display_name": "Replace Images In Batch", "description": "\nReplaces the images in a batch, starting from the specified start index,  \nwith the replacement images.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "SaveImageWithAlpha": {"input": {"required": {"images": ["IMAGE"], "mask": ["MASK"], "filename_prefix": ["STRING", {"default": "ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "mask", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImageWithAlpha", "display_name": "Save Image With Alpha", "description": "\nSaves an image and mask as .PNG with the mask as the alpha channel. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": true}, "SaveImageKJ": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to save."}], "filename_prefix": ["STRING", {"default": "ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}], "output_folder": ["STRING", {"default": "output", "tooltip": "The folder to save the images to."}]}, "optional": {"caption_file_extension": ["STRING", {"default": ".txt", "tooltip": "The extension for the caption file."}], "caption": ["STRING", {"forceInput": true, "tooltip": "string to save as .txt file"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "output_folder"], "optional": ["caption_file_extension", "caption"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["filename"], "name": "SaveImageKJ", "display_name": "Save Image KJ", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": true}, "ShuffleImageBatch": {"input": {"required": {"images": ["IMAGE"], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["images", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ShuffleImageBatch", "display_name": "Shuffle Image Batch", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "SplitImageChannels": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "MASK"], "output_is_list": [false, false, false, false], "output_name": ["red", "green", "blue", "mask"], "name": "SplitImageChannels", "display_name": "Split Image Channels", "description": "\nSplits image channels into images where the selected channel  \nis repeated for all channels, and the alpha as a mask. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "TransitionImagesMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transition_type": [["horizontal slide", "vertical slide", "box", "circle", "horizontal door", "vertical door", "fade"]], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "reverse": ["BOOLEAN", {"default": false}], "device": [["CPU", "GPU"], {"default": "CPU"}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "interpolation", "transition_type", "transitioning_frames", "blur_radius", "reverse", "device"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TransitionImagesMulti", "display_name": "Transition Images Multi", "description": "\nCreates transitions between images.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "TransitionImagesInBatch": {"input": {"required": {"images": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transition_type": [["horizontal slide", "vertical slide", "box", "circle", "horizontal door", "vertical door", "fade"]], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "reverse": ["BOOLEAN", {"default": false}], "device": [["CPU", "GPU"], {"default": "CPU"}]}}, "input_order": {"required": ["images", "interpolation", "transition_type", "transitioning_frames", "blur_radius", "reverse", "device"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TransitionImagesInBatch", "display_name": "Transition Images In Batch", "description": "\nCreates transitions between images in a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "BatchCropFromMask": {"input": {"required": {"original_images": ["IMAGE"], "masks": ["MASK"], "crop_size_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "bbox_smooth_alpha": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["original_images", "masks", "crop_size_mult", "bbox_smooth_alpha"]}, "output": ["IMAGE", "IMAGE", "BBOX", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["original_images", "cropped_images", "bboxes", "width", "height"], "name": "BatchCropFromMask", "display_name": "Batch Crop From Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BatchCropFromMaskAdvanced": {"input": {"required": {"original_images": ["IMAGE"], "masks": ["MASK"], "crop_size_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "bbox_smooth_alpha": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["original_images", "masks", "crop_size_mult", "bbox_smooth_alpha"]}, "output": ["IMAGE", "IMAGE", "MASK", "IMAGE", "MASK", "BBOX", "BBOX", "INT", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["original_images", "cropped_images", "cropped_masks", "combined_crop_image", "combined_crop_masks", "bboxes", "combined_bounding_box", "bbox_width", "bbox_height"], "name": "BatchCropFromMaskAdvanced", "display_name": "Batch Crop From Mask Advanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "FilterZeroMasksAndCorrespondingImages": {"input": {"required": {"masks": ["MASK"]}, "optional": {"original_images": ["IMAGE"]}}, "input_order": {"required": ["masks"], "optional": ["original_images"]}, "output": ["MASK", "IMAGE", "IMAGE", "INDEXES"], "output_is_list": [false, false, false, false], "output_name": ["non_zero_masks_out", "non_zero_mask_images_out", "zero_mask_images_out", "zero_mask_images_out_indexes"], "name": "FilterZeroMasksAndCorrespondingImages", "display_name": "FilterZeroMasksAndCorrespondingImages", "description": "\nFilter out all the empty (i.e. all zero) mask in masks  \nAlso filter out all the corresponding images in original_images by indexes if provide  \n  \noriginal_images (optional): If provided, need have same length as masks.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "InsertImageBatchByIndexes": {"input": {"required": {"images": ["IMAGE"], "images_to_insert": ["IMAGE"], "insert_indexes": ["INDEXES"]}}, "input_order": {"required": ["images", "images_to_insert", "insert_indexes"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images_after_insert"], "name": "InsertImageBatchByIndexes", "display_name": "Insert Image Batch By Indexes", "description": "\nThis node is designed to be use with node FilterZeroMasksAndCorrespondingImages\nIt inserts the images_to_insert into images according to insert_indexes\n\nReturns:\n    images_after_insert: updated original images with origonal sequence order\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "BatchUncrop": {"input": {"required": {"original_images": ["IMAGE"], "cropped_images": ["IMAGE"], "bboxes": ["BBOX"], "border_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_rescale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "border_top": ["BOOLEAN", {"default": true}], "border_bottom": ["BOOLEAN", {"default": true}], "border_left": ["BOOLEAN", {"default": true}], "border_right": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["original_images", "cropped_images", "bboxes", "border_blending", "crop_rescale", "border_top", "border_bottom", "border_left", "border_right"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BatchUncrop", "display_name": "Batch Uncrop", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BatchUncropAdvanced": {"input": {"required": {"original_images": ["IMAGE"], "cropped_images": ["IMAGE"], "cropped_masks": ["MASK"], "combined_crop_mask": ["MASK"], "bboxes": ["BBOX"], "border_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_rescale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "use_combined_mask": ["BOOLEAN", {"default": false}], "use_square_mask": ["BOOLEAN", {"default": true}]}, "optional": {"combined_bounding_box": ["BBOX", {"default": null}]}}, "input_order": {"required": ["original_images", "cropped_images", "cropped_masks", "combined_crop_mask", "bboxes", "border_blending", "crop_rescale", "use_combined_mask", "use_square_mask"], "optional": ["combined_bounding_box"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BatchUncropAdvanced", "display_name": "Batch Uncrop Advanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "SplitBboxes": {"input": {"required": {"bboxes": ["BBOX"], "index": ["INT", {"default": 0, "min": 0, "max": 99999999, "step": 1}]}}, "input_order": {"required": ["bboxes", "index"]}, "output": ["BBOX", "BBOX"], "output_is_list": [false, false], "output_name": ["bboxes_a", "bboxes_b"], "name": "SplitBboxes", "display_name": "Split Bboxes", "description": "\nSplits the specified bbox list at the given index into two lists.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BboxToInt": {"input": {"required": {"bboxes": ["BBOX"], "index": ["INT", {"default": 0, "min": 0, "max": 99999999, "step": 1}]}}, "input_order": {"required": ["bboxes", "index"]}, "output": ["INT", "INT", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["x_min", "y_min", "width", "height", "center_x", "center_y"], "name": "BboxToInt", "display_name": "Bbox To Int", "description": "\nReturns selected index from bounding box list as integers.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BboxVisualize": {"input": {"required": {"images": ["IMAGE"], "bboxes": ["BBOX"], "line_width": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}}, "input_order": {"required": ["images", "bboxes", "line_width"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "BboxVisualize", "display_name": "Bbox Visualize", "description": "\nVisualizes the specified bbox on the image.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "GenerateNoise": {"input": {"required": {"width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}], "multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 4096, "step": 0.01}], "constant_batch_noise": ["BOOLEAN", {"default": false}], "normalize": ["BOOLEAN", {"default": false}]}, "optional": {"model": ["MODEL"], "sigmas": ["SIGMAS"], "latent_channels": [["4", "16"]], "shape": [["BCHW", "BCTHW", "BTCHW"]]}}, "input_order": {"required": ["width", "height", "batch_size", "seed", "multiplier", "constant_batch_noise", "normalize"], "optional": ["model", "sigmas", "latent_channels", "shape"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "GenerateNoise", "display_name": "Generate Noise", "description": "\nGenerates noise for injection or to be used as empty latents on samplers with add_noise off.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "FlipSigmasAdjusted": {"input": {"required": {"sigmas": ["SIGMAS"], "divide_by_last_sigma": ["BOOLEAN", {"default": false}], "divide_by": ["FLOAT", {"default": 1, "min": 1, "max": 255, "step": 0.01}], "offset_by": ["INT", {"default": 1, "min": -100, "max": 100, "step": 1}]}}, "input_order": {"required": ["sigmas", "divide_by_last_sigma", "divide_by", "offset_by"]}, "output": ["SIGMAS", "STRING"], "output_is_list": [false, false], "output_name": ["SIGMAS", "sigmas_string"], "name": "FlipSigmasAdjusted", "display_name": "Flip Sigmas Adjusted", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "InjectNoiseToLatent": {"input": {"required": {"latents": ["LATENT"], "strength": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 200.0, "step": 0.0001}], "noise": ["LATENT"], "normalize": ["BOOLEAN", {"default": false}], "average": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"], "mix_randn_amount": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.001}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["latents", "strength", "noise", "normalize", "average"], "optional": ["mask", "mix_randn_amount", "seed"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "InjectNoiseToLatent", "display_name": "Inject Noise To Latent", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "CustomSigmas": {"input": {"required": {"sigmas_string": ["STRING", {"default": "14.615, 6.475, 3.861, 2.697, 1.886, 1.396, 0.963, 0.652, 0.399, 0.152, 0.029", "multiline": true}], "interpolate_to_steps": ["INT", {"default": 10, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["sigmas_string", "interpolate_to_steps"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "CustomSigmas", "display_name": "Custom Sigmas", "description": "\nCreates a sigmas tensor from a string of comma separated values.  \nExamples: \n   \nNvidia's optimized AYS 10 step schedule for SD 1.5:  \n14.615, 6.475, 3.861, 2.697, 1.886, 1.396, 0.963, 0.652, 0.399, 0.152, 0.029  \nSDXL:   \n14.615, 6.315, 3.771, 2.181, 1.342, 0.862, 0.555, 0.380, 0.234, 0.113, 0.029  \nSVD:  \n700.00, 54.5, 15.886, 7.977, 4.248, 1.789, 0.981, 0.403, 0.173, 0.034, 0.002  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "StringToFloatList": {"input": {"required": {"string": ["STRING", {"default": "1, 2, 3", "multiline": true}]}}, "input_order": {"required": ["string"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "StringToFloatList", "display_name": "String to Float List", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "WidgetToString": {"input": {"required": {"id": ["INT", {"default": 0}], "widget_name": ["STRING", {"multiline": false}], "return_all": ["BOOLEAN", {"default": false}]}, "optional": {"any_input": ["*", {}], "node_title": ["STRING", {"multiline": false}], "allowed_float_decimals": ["INT", {"default": 2, "min": 0, "max": 10, "tooltip": "Number of decimal places to display for float values"}]}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "prompt": "PROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["id", "widget_name", "return_all"], "optional": ["any_input", "node_title", "allowed_float_decimals"], "hidden": ["extra_pnginfo", "prompt", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "WidgetToString", "display_name": "Widget To String", "description": "\nSelects a node and it's specified widget and outputs the value as a string.  \nIf no node id or title is provided it will use the 'any_input' link and use that node.  \nTo see node id's, enable node id display from Manager badge menu.  \nAlternatively you can search with the node title. Node titles ONLY exist if they  \nare manually edited!  \nThe 'any_input' is required for making sure the node you want the value from exists in the workflow.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "SaveStringKJ": {"input": {"required": {"string": ["STRING", {"forceInput": true, "tooltip": "string to save as .txt file"}], "filename_prefix": ["STRING", {"default": "text", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}], "output_folder": ["STRING", {"default": "output", "tooltip": "The folder to save the images to."}]}, "optional": {"file_extension": ["STRING", {"default": ".txt", "tooltip": "The extension for the caption file."}]}}, "input_order": {"required": ["string", "filename_prefix", "output_folder"], "optional": ["file_extension"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["filename"], "name": "SaveStringKJ", "display_name": "Save String KJ", "description": "Saves the input string to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": true}, "DummyOut": {"input": {"required": {"any_input": ["*", {}]}}, "input_order": {"required": ["any_input"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "DummyOut", "display_name": "Dummy Out", "description": "\nDoes nothing, used to trigger generic workflow output.    \nA way to get previews in the UI without saving anything to disk.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": true}, "GetLatentsFromBatchIndexed": {"input": {"required": {"latents": ["LATENT"], "indexes": ["STRING", {"default": "0, 1, 2", "multiline": true}], "latent_format": [["BCHW", "BTCHW", "BCTHW"], {"default": "BCHW"}]}}, "input_order": {"required": ["latents", "indexes", "latent_format"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "GetLatentsFromBatchIndexed", "display_name": "Get Latents From Batch Indexed", "description": "\nSelects and returns the latents at the specified indices as an latent batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "ScaleBatchPromptSchedule": {"input": {"required": {"input_str": ["STRING", {"forceInput": true, "default": "0:(0.0),\n7:(1.0),\n15:(0.0)\n"}], "old_frame_count": ["INT", {"forceInput": true, "default": 1, "min": 1, "max": 4096, "step": 1}], "new_frame_count": ["INT", {"forceInput": true, "default": 1, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["input_str", "old_frame_count", "new_frame_count"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ScaleBatchPromptSchedule", "display_name": "Scale Batch Prompt Schedule", "description": "\nScales a batch schedule from Fizz' nodes BatchPromptSchedule\nto a different frame count.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "CameraPoseVisualizer": {"input": {"required": {"pose_file_path": ["STRING", {"default": "", "multiline": false}], "base_xval": ["FLOAT", {"default": 0.2, "min": 0, "max": 100, "step": 0.01}], "zval": ["FLOAT", {"default": 0.3, "min": 0, "max": 100, "step": 0.01}], "scale": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 10.0, "step": 0.01}], "use_exact_fx": ["BOOLEAN", {"default": false}], "relative_c2w": ["BOOLEAN", {"default": true}], "use_viewer": ["BOOLEAN", {"default": false}]}, "optional": {"cameractrl_poses": ["CAMERACTRL_POSES", {"default": null}]}}, "input_order": {"required": ["pose_file_path", "base_xval", "zval", "scale", "use_exact_fx", "relative_c2w", "use_viewer"], "optional": ["cameractrl_poses"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CameraPoseVisualizer", "display_name": "Camera Pose Visualizer", "description": "\nVisualizes the camera poses, from Animatediff-Evolved CameraCtrl Pose  \nor a .txt file with RealEstate camera intrinsics and coordinates, in a 3D plot. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "AppendStringsToList": {"input": {"required": {"string1": ["STRING", {"default": "", "forceInput": true}], "string2": ["STRING", {"default": "", "forceInput": true}]}}, "input_order": {"required": ["string1", "string2"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "AppendStringsToList", "display_name": "Append Strings To List", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "JoinStrings": {"input": {"required": {"string1": ["STRING", {"default": "", "forceInput": true}], "string2": ["STRING", {"default": "", "forceInput": true}], "delimiter": ["STRING", {"default": " ", "multiline": false}]}}, "input_order": {"required": ["string1", "string2", "delimiter"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "JoinStrings", "display_name": "Join Strings", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "JoinStringMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "string_1": ["STRING", {"default": "", "forceInput": true}], "string_2": ["STRING", {"default": "", "forceInput": true}], "delimiter": ["STRING", {"default": " ", "multiline": false}], "return_list": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["inputcount", "string_1", "string_2", "delimiter", "return_list"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["string"], "name": "JoinStringMulti", "display_name": "Join String Multi", "description": "\nCreates single string, or a list of strings, from  \nmultiple input strings.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "SomethingToString": {"input": {"required": {"input": ["*", {}]}, "optional": {"prefix": ["STRING", {"default": ""}], "suffix": ["STRING", {"default": ""}]}}, "input_order": {"required": ["input"], "optional": ["prefix", "suffix"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SomethingToString", "display_name": "Something To String", "description": "\nConverts any type to a string.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "Sleep": {"input": {"required": {"input": ["*", {}], "minutes": ["INT", {"default": 0, "min": 0, "max": 1439}], "seconds": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 59.99, "step": 0.01}]}}, "input_order": {"required": ["input", "minutes", "seconds"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Sleep", "display_name": "Sleep", "description": "\nDelays the execution for the input amount of time.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "VRAM_Debug": {"input": {"required": {"empty_cache": ["BOOLEAN", {"default": true}], "gc_collect": ["BOOLEAN", {"default": true}], "unload_all_models": ["BOOLEAN", {"default": false}]}, "optional": {"any_input": ["*", {}], "image_pass": ["IMAGE"], "model_pass": ["MODEL"]}}, "input_order": {"required": ["empty_cache", "gc_collect", "unload_all_models"], "optional": ["any_input", "image_pass", "model_pass"]}, "output": ["*", "IMAGE", "MODEL", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["any_output", "image_pass", "model_pass", "freemem_before", "freemem_after"], "name": "VRAM_Debug", "display_name": "VRAM Debug", "description": "\nReturns the inputs unchanged, they are only used as triggers,  \nand performs comfy model management functions and garbage collection,  \nreports free VRAM before and after the operations.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "EmptyLatentImagePresets": {"input": {"required": {"dimensions": [["512 x 512 (1:1)", "768 x 512 (1.5:1)", "960 x 512 (1.875:1)", "1024 x 512 (2:1)", "1024 x 576 (1.778:1)", "1536 x 640 (2.4:1)", "1344 x 768 (1.75:1)", "1216 x 832 (1.46:1)", "1152 x 896 (1.286:1)", "1024 x 1024 (1:1)"], {"default": "512 x 512 (1:1)"}], "invert": ["BOOLEAN", {"default": false}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["dimensions", "invert", "batch_size"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["Latent", "Width", "Height"], "name": "EmptyLatentImagePresets", "display_name": "Empty Latent Image Presets", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "EmptyLatentImageCustomPresets": {"input": {"required": {"dimensions": [[]], "invert": ["BOOLEAN", {"default": false}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["dimensions", "invert", "batch_size"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["Latent", "Width", "Height"], "name": "EmptyLatentImageCustomPresets", "display_name": "Empty Latent Image Custom Presets", "description": "\nGenerates an empty latent image with the specified dimensions.  \nThe choices are loaded from 'custom_dimensions.json' in the nodes folder.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "ModelPassThrough": {"input": {"required": {}, "optional": {"model": ["MODEL"]}}, "input_order": {"required": [], "optional": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["model"], "name": "ModelPassThrough", "display_name": "ModelPass", "description": "\n    Simply passes through the model,\n    workaround for Set node not allowing bypassed inputs.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "ModelSaveKJ": {"input": {"required": {"model": ["MODEL"], "filename_prefix": ["STRING", {"default": "diffusion_models/ComfyUI"}], "model_key_prefix": ["STRING", {"default": "model.diffusion_model."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "filename_prefix", "model_key_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ModelSaveKJ", "display_name": "Model Save KJ", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "advanced/model_merging", "output_node": true}, "SetShakkerLabsUnionControlNetType": {"input": {"required": {"control_net": ["CONTROL_NET"], "type": [["auto", "canny", "tile", "depth", "blur", "pose", "gray", "low quality"]]}}, "input_order": {"required": ["control_net", "type"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "SetShakkerLabsUnionControlNetType", "display_name": "Set Shakker Labs Union ControlNet Type", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "conditioning/controlnet", "output_node": false}, "StyleModelApplyAdvanced": {"input": {"required": {"conditioning": ["CONDITIONING"], "style_model": ["STYLE_MODEL"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["conditioning", "style_model", "clip_vision_output", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "StyleModelApplyAdvanced", "display_name": "Style Model Apply Advanced", "description": "StyleModelApply but with strength parameter", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "NormalizedAmplitudeToMask": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_offset": ["INT", {"default": 0, "min": -255, "max": 255, "step": 1}], "location_x": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "location_y": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "size": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}], "shape": [["none", "circle", "square", "triangle"], {"default": "none"}], "color": [["white", "amplitude"], {"default": "amplitude"}]}}, "input_order": {"required": ["normalized_amp", "width", "height", "frame_offset", "location_x", "location_y", "size", "shape", "color"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "NormalizedAmplitudeToMask", "display_name": "NormalizedAmplitudeToMask", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nCreates masks based on the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "NormalizedAmplitudeToFloatList": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"]}}, "input_order": {"required": ["normalized_amp"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "NormalizedAmplitudeToFloatList", "display_name": "NormalizedAmplitudeToFloatList", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nCreates a list of floats from the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "OffsetMaskByNormalizedAmplitude": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"], "mask": ["MASK"], "x": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "y": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "rotate": ["BOOLEAN", {"default": false}], "angle_multiplier": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001, "display": "number"}]}}, "input_order": {"required": ["normalized_amp", "mask", "x", "y", "rotate", "angle_multiplier"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "OffsetMaskByNormalizedAmplitude", "display_name": "OffsetMaskByNormalizedAmplitude", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nOffsets masks based on the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "ImageTransformByNormalizedAmplitude": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"], "zoom_scale": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001, "display": "number"}], "x_offset": ["INT", {"default": 0, "min": -16383, "max": 16384, "step": 1, "display": "number"}], "y_offset": ["INT", {"default": 0, "min": -16383, "max": 16384, "step": 1, "display": "number"}], "cumulative": ["BOOLEAN", {"default": false}], "image": ["IMAGE"]}}, "input_order": {"required": ["normalized_amp", "zoom_scale", "x_offset", "y_offset", "cumulative", "image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageTransformByNormalizedAmplitude", "display_name": "ImageTransformByNormalizedAmplitude", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nTransforms image based on the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "AudioConcatenate": {"input": {"required": {"audio1": ["AUDIO"], "audio2": ["AUDIO"], "direction": [["right", "left"], {"default": "right"}]}}, "input_order": {"required": ["audio1", "audio2", "direction"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioConcatenate", "display_name": "AudioConcatenate", "description": "\nConcatenates the audio1 to audio2 in the specified direction.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "SplineEditor": {"input": {"required": {"points_store": ["STRING", {"multiline": false}], "coordinates": ["STRING", {"multiline": false}], "mask_width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "mask_height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "points_to_sample": ["INT", {"default": 16, "min": 2, "max": 1000, "step": 1}], "sampling_method": [["path", "time", "controlpoints"], {"default": "time"}], "interpolation": [["cardinal", "monotone", "basis", "linear", "step-before", "step-after", "polar", "polar-reverse"], {"default": "cardinal"}], "tension": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "repeat_output": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "float_output_type": [["list", "pandas series", "tensor"], {"default": "list"}]}, "optional": {"min_value": ["FLOAT", {"default": 0.0, "min": -10000.0, "max": 10000.0, "step": 0.01}], "max_value": ["FLOAT", {"default": 1.0, "min": -10000.0, "max": 10000.0, "step": 0.01}], "bg_image": ["IMAGE"]}}, "input_order": {"required": ["points_store", "coordinates", "mask_width", "mask_height", "points_to_sample", "sampling_method", "interpolation", "tension", "repeat_output", "float_output_type"], "optional": ["min_value", "max_value", "bg_image"]}, "output": ["MASK", "STRING", "FLOAT", "INT", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["mask", "coord_str", "float", "count", "normalized_str"], "name": "SplineEditor", "display_name": "Spline Editor", "description": "\n# WORK IN PROGRESS  \nDo not count on this as part of your workflow yet,  \nprobably contains lots of bugs and stability is not  \nguaranteed!!  \n  \n## Graphical editor to create values for various   \n## schedules and/or mask batches.  \n\n**Shift + click** to add control point at end.\n**Ctrl + click** to add control point (subdivide) between two points.  \n**Right click on a point** to delete it.    \nNote that you can't delete from start/end.  \n  \nRight click on canvas for context menu:  \nThese are purely visual options, doesn't affect the output:  \n - Toggle handles visibility\n - Display sample points: display the points to be returned.  \n\n**points_to_sample** value sets the number of samples  \nreturned from the **drawn spline itself**, this is independent from the  \nactual control points, so the interpolation type matters.  \nsampling_method: \n - time: samples along the time axis, used for schedules  \n - path: samples along the path itself, useful for coordinates  \n\noutput types:\n - mask batch  \n        example compatible nodes: anything that takes masks  \n - list of floats\n        example compatible nodes: IPAdapter weights  \n - pandas series\n        example compatible nodes: anything that takes Fizz'  \n        nodes Batch Value Schedule  \n - torch tensor  \n        example compatible nodes: unknown\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "CreateShapeImageOnPath": {"input": {"required": {"shape": [["circle", "square", "triangle"], {"default": "circle"}], "coordinates": ["STRING", {"forceInput": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "shape_width": ["INT", {"default": 128, "min": 2, "max": 4096, "step": 1}], "shape_height": ["INT", {"default": 128, "min": 2, "max": 4096, "step": 1}], "shape_color": ["STRING", {"default": "white"}], "bg_color": ["STRING", {"default": "black"}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100, "step": 0.1}], "intensity": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 100.0, "step": 0.01}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}], "trailing": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "border_width": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "border_color": ["STRING", {"default": "black"}]}}, "input_order": {"required": ["shape", "coordinates", "frame_width", "frame_height", "shape_width", "shape_height", "shape_color", "bg_color", "blur_radius", "intensity"], "optional": ["size_multiplier", "trailing", "border_width", "border_color"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["image", "mask"], "name": "CreateShapeImageOnPath", "display_name": "Create Shape Image On Path", "description": "\nCreates an image or batch of images with the specified shape.  \nLocations are center locations.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CreateShapeMaskOnPath": {"input": {"required": {"shape": [["circle", "square", "triangle"], {"default": "circle"}], "coordinates": ["STRING", {"forceInput": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "shape_width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}], "shape_height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["shape", "coordinates", "frame_width", "frame_height", "shape_width", "shape_height"], "optional": ["size_multiplier"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateShapeMaskOnPath", "display_name": "Create Shape Mask On Path", "description": "\nCreates a mask or batch of masks with the specified shape.  \nLocations are center locations.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateTextOnPath": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "text": ["STRING", {"default": "text", "multiline": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "font_size": ["INT", {"default": 42}], "alignment": [["left", "center", "right"], {"default": "center"}], "text_color": ["STRING", {"default": "white"}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["coordinates", "text", "frame_width", "frame_height", "font", "font_size", "alignment", "text_color"], "optional": ["size_multiplier"]}, "output": ["IMAGE", "MASK", "MASK"], "output_is_list": [false, false, false], "output_name": ["image", "mask", "mask_inverted"], "name": "CreateTextOnPath", "display_name": "Create Text On Path", "description": "\nCreates a mask or batch of masks with the specified text.  \nLocations are center locations.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateGradientFromCoords": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "start_color": ["STRING", {"default": "white"}], "end_color": ["STRING", {"default": "black"}], "multiplier": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["coordinates", "frame_width", "frame_height", "start_color", "end_color", "multiplier"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "CreateGradientFromCoords", "display_name": "Create Gradient From Coords", "description": "\nCreates a gradient image from coordinates.    \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CutAndDragOnPath": {"input": {"required": {"image": ["IMAGE"], "coordinates": ["STRING", {"forceInput": true}], "mask": ["MASK"], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "inpaint": ["BOOLEAN", {"default": true}]}, "optional": {"bg_image": ["IMAGE"]}}, "input_order": {"required": ["image", "coordinates", "mask", "frame_width", "frame_height", "inpaint"], "optional": ["bg_image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["image", "mask"], "name": "CutAndDragOnPath", "display_name": "Cut And Drag On Path", "description": "\nCuts the masked area from the image, and drags it along the path. If inpaint is enabled, and no bg_image is provided, the cut area is filled using cv2 TELEA algorithm.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GradientToFloat": {"input": {"required": {"image": ["IMAGE"], "steps": ["INT", {"default": 10, "min": 2, "max": 10000, "step": 1}]}}, "input_order": {"required": ["image", "steps"]}, "output": ["FLOAT", "FLOAT"], "output_is_list": [false, false], "output_name": ["float_x", "float_y"], "name": "GradientToFloat", "display_name": "Gradient To Float", "description": "\nCalculates list of floats from image.    \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "WeightScheduleExtend": {"input": {"required": {"input_values_1": ["FLOAT", {"default": 0.0, "forceInput": true}], "input_values_2": ["FLOAT", {"default": 0.0, "forceInput": true}], "output_type": [["match_input", "list", "pandas series", "tensor"], {"default": "match_input"}]}}, "input_order": {"required": ["input_values_1", "input_values_2", "output_type"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "WeightScheduleExtend", "display_name": "Weight Schedule Extend", "description": "\nExtends, and converts if needed, different value lists/series  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "MaskOrImageToWeight": {"input": {"required": {"output_type": [["list", "pandas series", "tensor", "string"], {"default": "list"}]}, "optional": {"images": ["IMAGE"], "masks": ["MASK"]}}, "input_order": {"required": ["output_type"], "optional": ["images", "masks"]}, "output": ["FLOAT", "STRING"], "output_is_list": [false, false], "output_name": ["FLOAT", "STRING"], "name": "MaskOrImageToWeight", "display_name": "Mask Or Image To Weight", "description": "\nGets the mean values from mask or image batch  \nand returns that as the selected output type.   \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "WeightScheduleConvert": {"input": {"required": {"input_values": ["FLOAT", {"default": 0.0, "forceInput": true}], "output_type": [["match_input", "list", "pandas series", "tensor"], {"default": "list"}], "invert": ["BOOLEAN", {"default": false}], "repeat": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}]}, "optional": {"remap_to_frames": ["INT", {"default": 0}], "interpolation_curve": ["FLOAT", {"forceInput": true}], "remap_values": ["BOOLEAN", {"default": false}], "remap_min": ["FLOAT", {"default": 0.0, "min": -100000, "max": 100000.0, "step": 0.01}], "remap_max": ["FLOAT", {"default": 1.0, "min": -100000, "max": 100000.0, "step": 0.01}]}}, "input_order": {"required": ["input_values", "output_type", "invert", "repeat"], "optional": ["remap_to_frames", "interpolation_curve", "remap_values", "remap_min", "remap_max"]}, "output": ["FLOAT", "STRING", "INT"], "output_is_list": [false, false, false], "output_name": ["FLOAT", "STRING", "INT"], "name": "WeightScheduleConvert", "display_name": "Weight Schedule Convert", "description": "\nConverts different value lists/series to another type.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "FloatToMask": {"input": {"required": {"input_values": ["FLOAT", {"forceInput": true, "default": 0}], "width": ["INT", {"default": 100, "min": 1}], "height": ["INT", {"default": 100, "min": 1}]}}, "input_order": {"required": ["input_values", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "FloatToMask", "display_name": "Float To Mask", "description": "\nGenerates a batch of masks based on the input float values.\nThe batch size is determined by the length of the input float values.\nEach mask is generated with the specified width and height.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "FloatToSigmas": {"input": {"required": {"float_list": ["FLOAT", {"default": 0.0, "forceInput": true}]}}, "input_order": {"required": ["float_list"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "FloatToSigmas", "display_name": "Float To Sigmas", "description": "\nCreates a sigmas tensor from list of float values.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "SigmasToFloat": {"input": {"required": {"sigmas": ["SIGMAS"]}}, "input_order": {"required": ["sigmas"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["float"], "name": "SigmasToFloat", "display_name": "Sigmas To Float", "description": "\nCreates a float list from sigmas tensors.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "PlotCoordinates": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "text": ["STRING", {"default": "title", "multiline": false}], "width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "bbox_width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}], "bbox_height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["coordinates", "text", "width", "height", "bbox_width", "bbox_height"], "optional": ["size_multiplier"]}, "output": ["IMAGE", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["images", "width", "height", "bbox_width", "bbox_height"], "name": "PlotCoordinates", "display_name": "Plot Coordinates", "description": "\nPlots coordinates to sequence of images using Matplotlib.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "InterpolateCoords": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "interpolation_curve": ["FLOAT", {"forceInput": true}]}}, "input_order": {"required": ["coordinates", "interpolation_curve"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["coordinates"], "name": "InterpolateCoords", "display_name": "Interpolate Coords", "description": "\nInterpolates coordinates based on a curve.   \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "PointsEditor": {"input": {"required": {"points_store": ["STRING", {"multiline": false}], "coordinates": ["STRING", {"multiline": false}], "neg_coordinates": ["STRING", {"multiline": false}], "bbox_store": ["STRING", {"multiline": false}], "bboxes": ["STRING", {"multiline": false}], "bbox_format": [["xyxy", "xywh"]], "width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "normalize": ["BOOLEAN", {"default": false}]}, "optional": {"bg_image": ["IMAGE"]}}, "input_order": {"required": ["points_store", "coordinates", "neg_coordinates", "bbox_store", "bboxes", "bbox_format", "width", "height", "normalize"], "optional": ["bg_image"]}, "output": ["STRING", "STRING", "BBOX", "MASK", "IMAGE"], "output_is_list": [false, false, false, false, false], "output_name": ["positive_coords", "negative_coords", "bbox", "bbox_mask", "cropped_image"], "name": "PointsEditor", "display_name": "Points Editor", "description": "\n# WORK IN PROGRESS  \nDo not count on this as part of your workflow yet,  \nprobably contains lots of bugs and stability is not  \nguaranteed!!  \n  \n## Graphical editor to create coordinates\n\n**Shift + click** to add a positive (green) point.\n**Shift + right click** to add a negative (red) point.\n**Ctrl + click** to draw a box.  \n**Right click on a point** to delete it.    \nNote that you can't delete from start/end of the points array.  \n  \nTo add an image select the node and copy/paste or drag in the image.  \nOr from the bg_image input on queue (first frame of the batch).  \n\n**THE IMAGE IS SAVED TO THE NODE AND WORKFLOW METADATA**  \nyou can clear the image from the context menu by right clicking on the canvas  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "StabilityAPI_SD3": {"input": {"required": {"prompt": ["STRING", {"multiline": true}], "n_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"default": 123, "min": 0, "max": 4294967294, "step": 1}], "model": [["sd3", "sd3-turbo"], {"default": "sd3"}], "aspect_ratio": [["1:1", "16:9", "21:9", "2:3", "3:2", "4:5", "5:4", "9:16", "9:21"], {"default": "1:1"}], "output_format": [["png", "jpeg"], {"default": "jpeg"}]}, "optional": {"api_key": ["STRING", {"multiline": true}], "image": ["IMAGE"], "img2img_strength": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "disable_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["prompt", "n_prompt", "seed", "model", "aspect_ratio", "output_format"], "optional": ["api_key", "image", "img2img_strength", "disable_metadata"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityAPI_SD3", "display_name": "Stability API SD3", "description": "\n## Calls StabilityAI API\n   \nAlthough you may have multiple keys in your account,  \nyou should use the same key for all requests to this API.  \n\nGet your API key here: https://platform.stability.ai/account/keys  \nRecommended to set the key in the config.json -file under this  \nnode packs folder.  \n# WARNING:  \nOtherwise the API key may get saved in the image metadata even  \nwith \"disable_metadata\" on if the workflow includes save nodes  \nseparate from this node.  \n   \nsd3 requires 6.5 credits per generation  \nsd3-turbo requires 4 credits per generation  \n\nIf no image is provided, mode is set to text-to-image  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "SoundReactive": {"input": {"required": {"sound_level": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 99999, "step": 0.01}], "start_range_hz": ["INT", {"default": 150, "min": 0, "max": 9999, "step": 1}], "end_range_hz": ["INT", {"default": 2000, "min": 0, "max": 9999, "step": 1}], "multiplier": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 99999, "step": 0.01}], "smoothing_factor": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "normalize": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["sound_level", "start_range_hz", "end_range_hz", "multiplier", "smoothing_factor", "normalize"]}, "output": ["FLOAT", "INT"], "output_is_list": [false, false], "output_name": ["sound_level", "sound_level_int"], "name": "SoundReactive", "display_name": "Sound Reactive", "description": "\nReacts to the sound level of the input.  \nUses your browsers sound input options and requires.  \nMeant to be used with realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "StableZero123_BatchSchedule": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "azimuth_points_string": ["STRING", {"default": "0:(0.0),\n7:(1.0),\n15:(0.0)\n", "multiline": true}], "elevation_points_string": ["STRING", {"default": "0:(0.0),\n7:(0.0),\n15:(0.0)\n", "multiline": true}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "interpolation", "azimuth_points_string", "elevation_points_string"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "StableZero123_BatchSchedule", "display_name": "Stable Zero123 Batch Schedule", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "SV3D_BatchSchedule": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 21, "min": 1, "max": 4096}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "azimuth_points_string": ["STRING", {"default": "0:(0.0),\n9:(180.0),\n20:(360.0)\n", "multiline": true}], "elevation_points_string": ["STRING", {"default": "0:(0.0),\n9:(0.0),\n20:(0.0)\n", "multiline": true}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "interpolation", "azimuth_points_string", "elevation_points_string"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SV3D_BatchSchedule", "display_name": "SV3D Batch Schedule", "description": "\nAllow scheduling of the azimuth and elevation conditions for SV3D.  \nNote that SV3D is still a video model and the schedule needs to always go forward  \nhttps://huggingface.co/stabilityai/sv3d\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "LoadResAdapterNormalization": {"input": {"required": {"model": ["MODEL"], "resadapter_path": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"]]}}, "input_order": {"required": ["model", "resadapter_path"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoadResAdapterNormalization", "display_name": "LoadResAdapterNormalization", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "Superprompt": {"input": {"required": {"instruction_prompt": ["STRING", {"default": "Expand the following prompt to add more detail", "multiline": true}], "prompt": ["STRING", {"default": "", "multiline": true, "forceInput": true}], "max_new_tokens": ["INT", {"default": 128, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["instruction_prompt", "prompt", "max_new_tokens"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Superprompt", "display_name": "Superprompt", "description": "\n# SuperPrompt\nA T5 model fine-tuned on the SuperPrompt dataset for  \nupsampling text prompts to more detailed descriptions.  \nMeant to be used as a pre-generation step for text-to-image  \nmodels that benefit from more detailed prompts.  \nhttps://huggingface.co/roborovski/superprompt-v1\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "GLIGENTextBoxApplyBatchCoords": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "latents": ["LATENT"], "clip": ["CLIP"], "gligen_textbox_model": ["GLIGEN"], "coordinates": ["STRING", {"forceInput": true}], "text": ["STRING", {"multiline": true}], "width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}], "height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["conditioning_to", "latents", "clip", "gligen_textbox_model", "coordinates", "text", "width", "height"], "optional": ["size_multiplier"]}, "output": ["CONDITIONING", "IMAGE"], "output_is_list": [false, false], "output_name": ["conditioning", "coord_preview"], "name": "GLIGENTextBoxApplyBatchCoords", "display_name": "GLIGENTextBoxApplyBatchCoords", "description": "\nThis node allows scheduling GLIGEN text box positions in a batch,  \nto be used with AnimateDiff-Evolved. Intended to pair with the  \nSpline Editor -node.  \n\nGLIGEN model can be downloaded through the Manage's \"Install Models\" menu.  \nOr directly from here:  \nhttps://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/tree/main  \n  \nInputs:  \n- **latents** input is used to calculate batch size  \n- **clip** is your standard text encoder, use same as for the main prompt  \n- **gligen_textbox_model** connects to GLIGEN Loader  \n- **coordinates** takes a json string of points, directly compatible  \nwith the spline editor node.\n- **text** is the part of the prompt to set position for  \n- **width** and **height** are the size of the GLIGEN bounding box  \n  \nOutputs:\n- **conditioning** goes between to clip text encode and the sampler  \n- **coord_preview** is an optional preview of the coordinates and  \nbounding boxes.\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "Intrinsic_lora_sampling": {"input": {"required": {"model": ["MODEL"], "lora_name": [["intrinsic_lora_sd15_albedo.safetensors", "intrinsic_lora_sd15_depth.safetensors", "intrinsic_lora_sd15_normal.safetensors", "intrinsic_lora_sd15_shading.safetensors", "intrinsic_loras.txt"]], "task": [["depth map", "surface normals", "albedo", "shading"], {"default": "depth map"}], "text": ["STRING", {"multiline": true, "default": ""}], "clip": ["CLIP"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1, "max": 4096, "step": 1}]}, "optional": {"image": ["IMAGE"], "optional_latent": ["LATENT"]}}, "input_order": {"required": ["model", "lora_name", "task", "text", "clip", "vae", "per_batch"], "optional": ["image", "optional_latent"]}, "output": ["IMAGE", "LATENT"], "output_is_list": [false, false], "output_name": ["IMAGE", "LATENT"], "name": "Intrinsic_lora_sampling", "display_name": "Intrinsic Lora Sampling", "description": "\nSampler to use the intrinsic loras:  \nhttps://github.com/duxiaodan/intrinsic-lora  \nThese LoRAs are tiny and thus included  \nwith this node pack.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes", "output_node": false}, "CheckpointPerturbWeights": {"input": {"required": {"model": ["MODEL"], "joint_blocks": ["FLOAT", {"default": 0.02, "min": 0.001, "max": 10.0, "step": 0.001}], "final_layer": ["FLOAT", {"default": 0.02, "min": 0.001, "max": 10.0, "step": 0.001}], "rest_of_the_blocks": ["FLOAT", {"default": 0.02, "min": 0.001, "max": 10.0, "step": 0.001}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["model", "joint_blocks", "final_layer", "rest_of_the_blocks", "seed"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "CheckpointPerturbWeights", "display_name": "CheckpointPerturbWeights", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true}, "Screencap_mss": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "width": ["INT", {"default": 512, "min": 0, "max": 10000, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 10000, "step": 1}], "num_frames": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}], "delay": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["x", "y", "width", "height", "num_frames", "delay"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Screencap_mss", "display_name": "Screencap mss", "description": "\nCaptures an area specified by screen coordinates.  \nCan be used for realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "WebcamCaptureCV2": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "width": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "cam_index": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "release": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["x", "y", "width", "height", "cam_index", "release"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "WebcamCaptureCV2", "display_name": "Webcam Capture CV2", "description": "\nCaptures a frame from a webcam using CV2.  \nCan be used for realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "DifferentialDiffusionAdvanced": {"input": {"required": {"model": ["MODEL"], "samples": ["LATENT"], "mask": ["MASK"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["model", "samples", "mask", "multiplier"]}, "output": ["MODEL", "LATENT"], "output_is_list": [false, false], "output_name": ["MODEL", "LATENT"], "name": "DifferentialDiffusionAdvanced", "display_name": "Differential Diffusion Advanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "_for_testing", "output_node": false}, "FluxBlockLoraLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}]}, "optional": {"lora_name": [["AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"], {"tooltip": "The name of the LoRA."}], "opt_lora_path": ["STRING", {"forceInput": true, "tooltip": "Absolute path of the LoRA."}], "blocks": ["SELECTEDBLOCKS"]}}, "input_order": {"required": ["model", "strength_model"], "optional": ["lora_name", "opt_lora_path", "blocks"]}, "output": ["MODEL", "STRING"], "output_is_list": [false, false], "output_name": ["model", "rank"], "name": "FluxBlockLoraLoader", "display_name": "Flux Block Lora Loader", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "output_tooltips": ["The modified diffusion model.", "possible rank of the LoRA."]}, "FluxBlockLoraSelect": {"input": {"required": {"double_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37."]}, "output": ["SELECTEDBLOCKS"], "output_is_list": [false], "output_name": ["blocks"], "name": "FluxBlockLoraSelect", "display_name": "Flux Block Lora Select", "description": "Select individual block alpha values, value of 0 removes the block altogether", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "output_tooltips": ["The modified diffusion model."]}, "HunyuanVideoBlockLoraSelect": {"input": {"required": {"double_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.19.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.38.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.39.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "double_blocks.19.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37.", "single_blocks.38.", "single_blocks.39."]}, "output": ["SELECTEDBLOCKS"], "output_is_list": [false], "output_name": ["blocks"], "name": "HunyuanVideoBlockLoraSelect", "display_name": "Hunyuan Video Block Lora Select", "description": "Select individual block alpha values, value of 0 removes the block altogether", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "output_tooltips": ["The modified diffusion model."]}, "CustomControlNetWeightsFluxFromList": {"input": {"required": {"list_of_floats": ["FLOAT", {"forceInput": true}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"], "autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["list_of_floats"], "optional": ["uncond_multiplier", "cn_extras", "autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "CustomControlNetWeightsFluxFromList", "display_name": "Custom ControlNet Weights Flux From List", "description": "Creates controlnet weights from a list of floats for Advanced-ControlNet", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/controlnet", "output_node": false}, "CheckpointLoaderKJ": {"input": {"required": {"ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2", "fp16", "bf16", "fp32"]], "compute_dtype": [["default", "fp16", "bf16", "fp32"], {"default": "default", "tooltip": "The compute dtype to use for the model."}], "patch_cublaslinear": ["BOOLEAN", {"default": false, "tooltip": "Enable or disable the patching, won't take effect on already loaded models!"}], "sage_attention": [["disabled", "auto", "sageattn_qk_int8_pv_fp16_cuda", "sageattn_qk_int8_pv_fp16_triton", "sageattn_qk_int8_pv_fp8_cuda"], {"default": false, "tooltip": "Patch comfy attention to use sageattn."}], "enable_fp16_accumulation": ["BOOLEAN", {"default": false, "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."}]}}, "input_order": {"required": ["ckpt_name", "weight_dtype", "compute_dtype", "patch_cublaslinear", "sage_attention", "enable_fp16_accumulation"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderKJ", "display_name": "CheckpointLoaderKJ", "description": "Experimental node for patching torch.nn.Linear with CublasLinear.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true, "experimental": true}, "DiffusionModelLoaderKJ": {"input": {"required": {"model_name": [["IC-Light/iclight_sd15_fc.safetensors", "flux-dev-de-distill.safetensors", "flux1-dev-fp8.safetensors", "flux1-dev.safetensors", "flux1-fill-dev.safetensors", "fluxmania_III.safetensors", "hunyuan_video_720_cfgdistill_fp8_e4m3fn.safetensors", "skyreels_hunyuan_i2v_fp8_e4m3fn.safetensors", "wan2.1_i2v_480p_14B_bf16.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2", "fp16", "bf16", "fp32"]], "compute_dtype": [["default", "fp16", "bf16", "fp32"], {"default": "default", "tooltip": "The compute dtype to use for the model."}], "patch_cublaslinear": ["BOOLEAN", {"default": false, "tooltip": "Enable or disable the patching, won't take effect on already loaded models!"}], "sage_attention": [["disabled", "auto", "sageattn_qk_int8_pv_fp16_cuda", "sageattn_qk_int8_pv_fp16_triton", "sageattn_qk_int8_pv_fp8_cuda"], {"default": false, "tooltip": "Patch comfy attention to use sageattn."}], "enable_fp16_accumulation": ["BOOLEAN", {"default": false, "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."}]}}, "input_order": {"required": ["model_name", "weight_dtype", "compute_dtype", "patch_cublaslinear", "sage_attention", "enable_fp16_accumulation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "DiffusionModelLoaderKJ", "display_name": "Diffusion Model Loader KJ", "description": "Node for patching torch.nn.Linear with CublasLinear.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true, "experimental": true}, "TorchCompileModelFluxAdvanced": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "double_blocks": ["STRING", {"default": "0-18", "multiline": true}], "single_blocks": ["STRING", {"default": "0-37", "multiline": true}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}]}, "optional": {"dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "double_blocks", "single_blocks", "dynamic"], "optional": ["dynamo_cache_size_limit"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelFluxAdvanced", "display_name": "TorchCompileModelFluxAdvanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileModelHyVideo": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"], {"default": "inductor"}], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}], "compile_single_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile single blocks"}], "compile_double_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile double blocks"}], "compile_txt_in": ["BOOLEAN", {"default": false, "tooltip": "Compile txt_in layers"}], "compile_vector_in": ["BOOLEAN", {"default": false, "tooltip": "Compile vector_in layers"}], "compile_final_layer": ["BOOLEAN", {"default": false, "tooltip": "Compile final layer"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit", "compile_single_blocks", "compile_double_blocks", "compile_txt_in", "compile_vector_in", "compile_final_layer"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelHyVideo", "display_name": "TorchCompileModelHyVideo", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileVAE": {"input": {"required": {"vae": ["VAE"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "compile_encoder": ["BOOLEAN", {"default": true, "tooltip": "Compile encoder"}], "compile_decoder": ["BOOLEAN", {"default": true, "tooltip": "Compile decoder"}]}}, "input_order": {"required": ["vae", "backend", "fullgraph", "mode", "compile_encoder", "compile_decoder"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "TorchCompileVAE", "display_name": "TorchCompileVAE", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileControlNet": {"input": {"required": {"controlnet": ["CONTROL_NET"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}]}}, "input_order": {"required": ["controlnet", "backend", "fullgraph", "mode"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "TorchCompileControlNet", "display_name": "TorchCompileControlNet", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "PatchModelPatcherOrder": {"input": {"required": {"model": ["MODEL"], "patch_order": [["object_patch_first", "weight_patch_first"], {"default": "weight_patch_first", "tooltip": "Patch the comfy patch_model function to load weight patches (LoRAs) before compiling the model"}], "full_load": [["enabled", "disabled", "auto"], {"default": "auto", "tooltip": "Disabling may help with memory issues when loading large models, when changing this you should probably force model reload to avoid issues!"}]}}, "input_order": {"required": ["model", "patch_order", "full_load"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PatchModelPatcherOrder", "display_name": "Patch Model Patcher Order", "description": "Patch the comfy patch_model function patching order, useful for torch.compile (used as object_patch) as it should come last if you want to use LoRAs with compile", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "TorchCompileLTXModel": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileLTXModel", "display_name": "TorchCompileLTXModel", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileCosmosModel": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "tooltip": "Set the dynamo cache size limit"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileCosmosModel", "display_name": "TorchCompileCosmosModel", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileModelWanVideo": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"], {"default": "inductor"}], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}], "compile_transformer_blocks_only": ["BOOLEAN", {"default": false, "tooltip": "Compile only transformer blocks"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit", "compile_transformer_blocks_only"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelWanVideo", "display_name": "TorchCompileModelWanVideo", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "PathchSageAttentionKJ": {"input": {"required": {"model": ["MODEL"], "sage_attention": [["disabled", "auto", "sageattn_qk_int8_pv_fp16_cuda", "sageattn_qk_int8_pv_fp16_triton", "sageattn_qk_int8_pv_fp8_cuda"], {"default": false, "tooltip": "Global patch comfy attention to use sageattn, once patched to revert back to normal you would need to run this node again with disabled option."}]}}, "input_order": {"required": ["model", "sage_attention"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PathchSageAttentionKJ", "display_name": "Patch Sage Attention KJ", "description": "Experimental node for patching attention mode. This doesn't use the model patching system and thus can't be disabled without running the node again with 'disabled' option.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "LeapfusionHunyuanI2VPatcher": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT"], "index": ["INT", {"default": 0, "min": -1, "max": 1000, "step": 1, "tooltip": "The index of the latent to be replaced. 0 for first frame and -1 for last"}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The start percentage of steps to apply"}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The end percentage of steps to apply"}], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["model", "latent", "index", "start_percent", "end_percent", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LeapfusionHunyuanI2VPatcher", "display_name": "Leapfusion Hunyuan I2V Patcher", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "VAELoaderKJ": {"input": {"required": {"vae_name": [["YOZORA.vae.pt", "ae.safetensors", "flux_vae.safetensors", "hunyuan_video_vae_bf16.safetensors", "sdxl.vae.safetensors", "vae-ft-mse-840000-ema-pruned.ckpt", "wan_2.1_vae.safetensors"]], "device": [["main_device", "cpu"]], "weight_dtype": [["bf16", "fp16", "fp32"]]}}, "input_order": {"required": ["vae_name", "device", "weight_dtype"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "VAELoaderKJ", "display_name": "VAELoader KJ", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/vae", "output_node": false}, "ScheduledCFGGuidance": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 100.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "cfg", "start_percent", "end_percent"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "ScheduledCFGGuidance", "display_name": "Scheduled CFG Guidance", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "ApplyRifleXRoPE_HunuyanVideo": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT", {"tooltip": "Only used to get the latent count"}], "k": ["INT", {"default": 4, "min": 1, "max": 100, "step": 1, "tooltip": "Index of intrinsic frequency"}]}}, "input_order": {"required": ["model", "latent", "k"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyRifleXRoPE_HunuyanVideo", "display_name": "Apply RifleXRoPE HunuyanVideo", "description": "Extends the potential frame count of HunyuanVideo using this method: https://github.com/thu-ml/RIFLEx", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "ApplyRifleXRoPE_WanVideo": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT", {"tooltip": "Only used to get the latent count"}], "k": ["INT", {"default": 6, "min": 1, "max": 100, "step": 1, "tooltip": "Index of intrinsic frequency"}]}}, "input_order": {"required": ["model", "latent", "k"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyRifleXRoPE_WanVideo", "display_name": "Apply RifleXRoPE WanVideo", "description": "Extends the potential frame count of HunyuanVideo using this method: https://github.com/thu-ml/RIFLEx", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "WanVideoTeaCacheKJ": {"input": {"required": {"model": ["MODEL"], "rel_l1_thresh": ["FLOAT", {"default": 0.275, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Threshold for to determine when to apply the cache, compromise between speed and accuracy. When using coefficients a good value range is something between 0.2-0.4 for all but 1.3B model, which should be about 10 times smaller, same as when not using coefficients."}], "start_percent": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The start percentage of the steps to use with TeaCache."}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The end percentage of the steps to use with TeaCache."}], "cache_device": [["main_device", "offload_device"], {"default": "offload_device", "tooltip": "Device to cache to"}], "coefficients": [["disabled", "1.3B", "14B", "i2v_480", "i2v_720"], {"default": "i2v_480", "tooltip": "Coefficients for rescaling the relative l1 distance, if disabled the threshold value should be about 10 times smaller than the value used with coefficients."}]}}, "input_order": {"required": ["model", "rel_l1_thresh", "start_percent", "end_percent", "cache_device", "coefficients"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["model"], "name": "WanVideoTeaCacheKJ", "display_name": "WanVideo Tea Cache (native)", "description": "\nPatch WanVideo model to use TeaCache. Speeds up inference by caching the output and  \napplying it instead of doing the step.  Best results are achieved by choosing the  \nappropriate coefficients for the model. Early steps should never be skipped, with too  \naggressive values this can happen and the motion suffers. Starting later can help with that too.   \nWhen NOT using coefficients, the threshold value should be  \nabout 10 times smaller than the value used with coefficients.  \n\nOfficial recommended values https://github.com/ali-vilab/TeaCache/tree/main/TeaCache4Wan2.1:\n\n\n<pre style='font-family:monospace'>\n+-------------------+--------+---------+--------+\n|       Model       |  Low   | Medium  |  High  |\n+-------------------+--------+---------+--------+\n| Wan2.1 t2v 1.3B  |  0.05  |  0.07   |  0.08  |\n| Wan2.1 t2v 14B   |  0.14  |  0.15   |  0.20  |\n| Wan2.1 i2v 480P  |  0.13  |  0.19   |  0.26  |\n| Wan2.1 i2v 720P  |  0.18  |  0.20   |  0.30  |\n+-------------------+--------+---------+--------+\n</pre> \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/teacache", "output_node": false, "experimental": true}, "WanVideoEnhanceAVideoKJ": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT", {"tooltip": "Only used to get the latent count"}], "weight": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Strength of the enhance effect"}]}}, "input_order": {"required": ["model", "latent", "weight"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["model"], "name": "WanVideoEnhanceAVideoKJ", "display_name": "WanVideo Enhance A Video (native)", "description": "https://github.com/NUS-HPC-AI-Lab/Enhance-A-Video", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "SkipLayerGuidanceWanVideo": {"input": {"required": {"model": ["MODEL"], "blocks": ["STRING", {"default": "10", "multiline": false}], "start_percent": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "blocks", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "SkipLayerGuidanceWanVideo", "display_name": "Skip Layer Guidance WanVideo", "description": "Simplified skip layer guidance that only skips the uncond on selected blocks", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "advanced/guidance", "output_node": false, "experimental": true}, "TimerNodeKJ": {"input": {"required": {"any_input": ["*", {}], "mode": [["start", "stop"]], "name": ["STRING", {"default": "Timer"}]}, "optional": {"timer": ["TIMER"]}}, "input_order": {"required": ["any_input", "mode", "name"], "optional": ["timer"]}, "output": ["*", "TIMER", "INT"], "output_is_list": [false, false, false], "output_name": ["any_output", "timer", "time"], "name": "TimerNodeKJ", "display_name": "Timer Node KJ", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "HunyuanVideoEncodeKeyframesToCond": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "vae": ["VAE"], "start_frame": ["IMAGE"], "end_frame": ["IMAGE"], "num_frames": ["INT", {"default": 33, "min": 2, "max": 4096, "step": 1}], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to encode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}, "optional": {"negative": ["CONDITIONING"]}}, "input_order": {"required": ["model", "positive", "vae", "start_frame", "end_frame", "num_frames", "tile_size", "overlap", "temporal_size", "temporal_overlap"], "optional": ["negative"]}, "output": ["MODEL", "CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false, false], "output_name": ["model", "positive", "negative", "latent"], "name": "HunyuanVideoEncodeKeyframesToCond", "display_name": "HunyuanVideo Encode Keyframes To Cond", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/videomodels", "output_node": false}, "CFGZeroStarAndInit": {"input": {"required": {"model": ["MODEL"], "use_zero_init": ["BOOLEAN", {"default": true}], "zero_init_steps": ["INT", {"default": 0, "min": 0, "tooltip": "for zero init, starts from 0 so first step is always zeroed out if use_zero_init enabled"}]}}, "input_order": {"required": ["model", "use_zero_init", "zero_init_steps"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "CFGZeroStarAndInit", "display_name": "CFG Zero Star/Init", "description": "https://github.com/WeichenFan/CFG-Zero-star", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "ModelPatchTorchSettings": {"input": {"required": {"model": ["MODEL"], "enable_fp16_accumulation": ["BOOLEAN", {"default": false, "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."}]}}, "input_order": {"required": ["model", "enable_fp16_accumulation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelPatchTorchSettings", "display_name": "Model Patch Torch Settings", "description": "Adds callbacks to model to set torch settings before and after running the model.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true, "experimental": true}, "CreateInstanceDiffusionTracking": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "bbox_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "bbox_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "class_name": ["STRING", {"default": "class_name"}], "class_id": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "prompt": ["STRING", {"default": "prompt", "multiline": true}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}], "fit_in_frame": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["coordinates", "width", "height", "bbox_width", "bbox_height", "class_name", "class_id", "prompt"], "optional": ["size_multiplier", "fit_in_frame"]}, "output": ["TRACKING", "STRING", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["tracking", "prompt", "width", "height", "bbox_width", "bbox_height"], "name": "CreateInstanceDiffusionTracking", "display_name": "CreateInstanceDiffusionTracking", "description": "\nCreates tracking data to be used with InstanceDiffusion:  \nhttps://github.com/logtd/ComfyUI-InstanceDiffusion  \n  \nInstanceDiffusion prompt format:  \n\"class_id.class_name\": \"prompt\",  \nfor example:  \n\"1.head\": \"((head))\",  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/InstanceDiffusion", "output_node": false}, "AppendInstanceDiffusionTracking": {"input": {"required": {"tracking_1": ["TRACKING", {"forceInput": true}], "tracking_2": ["TRACKING", {"forceInput": true}]}, "optional": {"prompt_1": ["STRING", {"default": "", "forceInput": true}], "prompt_2": ["STRING", {"default": "", "forceInput": true}]}}, "input_order": {"required": ["tracking_1", "tracking_2"], "optional": ["prompt_1", "prompt_2"]}, "output": ["TRACKING", "STRING"], "output_is_list": [false, false], "output_name": ["tracking", "prompt"], "name": "AppendInstanceDiffusionTracking", "display_name": "AppendInstanceDiffusionTracking", "description": "\nAppends tracking data to be used with InstanceDiffusion:  \nhttps://github.com/logtd/ComfyUI-InstanceDiffusion  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/InstanceDiffusion", "output_node": false}, "DrawInstanceDiffusionTracking": {"input": {"required": {"image": ["IMAGE"], "tracking": ["TRACKING", {"forceInput": true}], "box_line_width": ["INT", {"default": 2, "min": 1, "max": 10, "step": 1}], "draw_text": ["BOOLEAN", {"default": true}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "font_size": ["INT", {"default": 20}]}}, "input_order": {"required": ["image", "tracking", "box_line_width", "draw_text", "font", "font_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "DrawInstanceDiffusionTracking", "display_name": "DrawInstanceDiffusionTracking", "description": "\nDraws the tracking data from  \nCreateInstanceDiffusionTracking -node.\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/InstanceDiffusion", "output_node": false}, "InpaintPreprocessor": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"]}, "optional": {"black_pixel_for_xinsir_cn": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "mask"], "optional": ["black_pixel_for_xinsir_cn"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "InpaintPreprocessor", "display_name": "Inpaint Preprocessor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/others", "output_node": false}, "LeReS-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"rm_nearest": ["FLOAT", {"default": 0, "min": 0, "max": 100.0, "step": 0.01}], "rm_background": ["FLOAT", {"default": 0, "min": 0, "max": 100.0, "step": 0.01}], "boost": [["disable", "enable"], {"default": "disable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["rm_nearest", "rm_background", "boost", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LeReS-DepthMapPreprocessor", "display_name": "LeReS Depth Map (enable boost for leres++)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "M-LSDPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"score_threshold": ["FLOAT", {"default": 0.1, "min": 0.01, "max": 2.0, "step": 0.01}], "dist_threshold": ["FLOAT", {"default": 0.1, "min": 0.01, "max": 20.0, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["score_threshold", "dist_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "M-LSDPreprocessor", "display_name": "M-LSD Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "DWPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"detect_hand": [["enable", "disable"], {"default": "enable"}], "detect_body": [["enable", "disable"], {"default": "enable"}], "detect_face": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "bbox_detector": [["yolox_l.torchscript.pt", "yolox_l.onnx", "yolo_nas_l_fp16.onnx", "yolo_nas_m_fp16.onnx", "yolo_nas_s_fp16.onnx"], {"default": "yolox_l.onnx"}], "pose_estimator": [["dw-ll_ucoco_384_bs5.torchscript.pt", "dw-ll_ucoco_384.onnx", "dw-ll_ucoco.onnx"], {"default": "dw-ll_ucoco_384_bs5.torchscript.pt"}], "scale_stick_for_xinsr_cn": [["disable", "enable"], {"default": "disable"}]}}, "input_order": {"required": ["image"], "optional": ["detect_hand", "detect_body", "detect_face", "resolution", "bbox_detector", "pose_estimator", "scale_stick_for_xinsr_cn"]}, "output": ["IMAGE", "POSE_KEYPOINT"], "output_is_list": [false, false], "output_name": ["IMAGE", "POSE_KEYPOINT"], "name": "DWPreprocessor", "display_name": "DWPose Estimator", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "AnimalPosePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"bbox_detector": [["yolox_l.torchscript.pt", "yolox_l.onnx", "yolo_nas_l_fp16.onnx", "yolo_nas_m_fp16.onnx", "yolo_nas_s_fp16.onnx"], {"default": "yolox_l.torchscript.pt"}], "pose_estimator": [["rtmpose-m_ap10k_256_bs5.torchscript.pt", "rtmpose-m_ap10k_256.onnx"], {"default": "rtmpose-m_ap10k_256_bs5.torchscript.pt"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["bbox_detector", "pose_estimator", "resolution"]}, "output": ["IMAGE", "POSE_KEYPOINT"], "output_is_list": [false, false], "output_name": ["IMAGE", "POSE_KEYPOINT"], "name": "AnimalPosePreprocessor", "display_name": "AnimalPose Estimator (AP10K)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "HEDPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "HEDPreprocessor", "display_name": "HED Soft-Edge Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "FakeScribblePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FakeScribblePreprocessor", "display_name": "Fake Scribble Lines (aka scribble_hed)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "ColorPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ColorPreprocessor", "display_name": "Color Pallete", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/T2IAdapter-only", "output_node": false}, "BinaryPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"bin_threshold": ["INT", {"default": 100, "min": 0, "max": 255, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["bin_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BinaryPreprocessor", "display_name": "Binary Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "DensePosePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"model": [["densepose_r50_fpn_dl.torchscript", "densepose_r101_fpn_dl.torchscript"], {"default": "densepose_r50_fpn_dl.torchscript"}], "cmap": [["Viridis (MagicAnimate)", "Parula (CivitAI)"], {"default": "Viridis (MagicAnimate)"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["model", "cmap", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DensePosePreprocessor", "display_name": "DensePose Estimator", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "TilePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"pyrUp_iters": ["INT", {"default": 3, "min": 1, "max": 10, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["pyrUp_iters", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TilePreprocessor", "display_name": "Tile", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/tile", "output_node": false}, "TTPlanet_TileGF_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"scale_factor": ["FLOAT", {"default": 1.0, "min": 1.0, "max": 8.0, "step": 0.01}], "blur_strength": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 10.0, "step": 0.01}], "radius": ["INT", {"default": 7, "min": 1, "max": 20, "step": 1}], "eps": ["FLOAT", {"default": 0.01, "min": 0.001, "max": 0.1, "step": 0.001}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["scale_factor", "blur_strength", "radius", "eps", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TTPlanet_TileGF_Preprocessor", "display_name": "TTPlanet Tile GuidedFilter", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/tile", "output_node": false}, "TTPlanet_TileSimple_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"scale_factor": ["FLOAT", {"default": 1.0, "min": 1.0, "max": 8.0, "step": 0.01}], "blur_strength": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["image"], "optional": ["scale_factor", "blur_strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TTPlanet_TileSimple_Preprocessor", "display_name": "TTPlanet Tile Simple", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/tile", "output_node": false}, "LineartStandardPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"guassian_sigma": ["FLOAT", {"default": 6.0, "min": 0, "max": 100.0, "step": 0.01}], "intensity_threshold": ["INT", {"default": 8, "min": 0, "max": 16, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["guassian_sigma", "intensity_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LineartStandardPreprocessor", "display_name": "Standard Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "DiffusionEdge_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"environment": [["indoor", "urban", "natrual"], {"default": "indoor"}], "patch_batch_size": ["INT", {"default": 4, "min": 1, "max": 16, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["environment", "patch_batch_size", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DiffusionEdge_Preprocessor", "display_name": "Diffusion Edge (batch size \u2191 => speed \u2191, VRAM \u2191)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "MeshGraphormer-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"mask_bbox_padding": ["INT", {"default": 30, "min": 0, "max": 100}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "mask_type": [["based_on_depth", "tight_bboxes", "original"], {"default": "based_on_depth"}], "mask_expand": ["INT", {"default": 5, "min": -16384, "max": 16384, "step": 1}], "rand_seed": ["INT", {"default": 88, "min": 0, "max": 18446744073709551615, "step": 1}], "detect_thr": ["FLOAT", {"default": 0.6, "min": 0.1, "max": 1, "step": 0.01}], "presence_thr": ["FLOAT", {"default": 0.6, "min": 0.1, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["image"], "optional": ["mask_bbox_padding", "resolution", "mask_type", "mask_expand", "rand_seed", "detect_thr", "presence_thr"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "INPAINTING_MASK"], "name": "MeshGraphormer-DepthMapPreprocessor", "display_name": "MeshGraphormer Hand Refiner", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "MeshGraphormer+ImpactDetector-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"], "bbox_detector": ["BBOX_DETECTOR"]}, "optional": {"bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.1, "max": 1, "step": 0.01}], "bbox_dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "bbox_crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10.0, "step": 0.01}], "drop_size": ["INT", {"default": 10, "min": 1, "max": 16384, "step": 1}], "mask_bbox_padding": ["INT", {"default": 30, "min": 0, "max": 100, "step": 1}], "mask_type": [["based_on_depth", "tight_bboxes", "original"], {"default": "based_on_depth"}], "mask_expand": ["INT", {"default": 5, "min": -16384, "max": 16384, "step": 1}], "rand_seed": ["INT", {"default": 88, "min": 0, "max": 18446744073709551615, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image", "bbox_detector"], "optional": ["bbox_threshold", "bbox_dilation", "bbox_crop_factor", "drop_size", "mask_bbox_padding", "mask_type", "mask_expand", "rand_seed", "resolution"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "INPAINTING_MASK"], "name": "MeshGraphormer+ImpactDetector-DepthMapPreprocessor", "display_name": "MeshGraphormer Hand Refiner With External Detector", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "DepthAnythingPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"ckpt_name": [["depth_anything_vitl14.pth", "depth_anything_vitb14.pth", "depth_anything_vits14.pth"], {"default": "depth_anything_vitl14.pth"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["ckpt_name", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DepthAnythingPreprocessor", "display_name": "Depth Anything", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "Zoe_DepthAnythingPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"environment": [["indoor", "outdoor"], {"default": "indoor"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["environment", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Zoe_DepthAnythingPreprocessor", "display_name": "Zoe Depth Anything", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "OpenposePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"detect_hand": [["enable", "disable"], {"default": "enable"}], "detect_body": [["enable", "disable"], {"default": "enable"}], "detect_face": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "scale_stick_for_xinsr_cn": [["disable", "enable"], {"default": "disable"}]}}, "input_order": {"required": ["image"], "optional": ["detect_hand", "detect_body", "detect_face", "resolution", "scale_stick_for_xinsr_cn"]}, "output": ["IMAGE", "POSE_KEYPOINT"], "output_is_list": [false, false], "output_name": ["IMAGE", "POSE_KEYPOINT"], "name": "OpenposePreprocessor", "display_name": "OpenPose Pose", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "TEEDPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe_steps": ["INT", {"default": 2, "min": 0, "max": 10, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe_steps", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TEEDPreprocessor", "display_name": "TEEDPreprocessor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "LineArtPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"coarse": [["disable", "enable"], {"default": "disable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["coarse", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LineArtPreprocessor", "display_name": "Realistic Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "OneFormer-COCO-SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OneFormer-COCO-SemSegPreprocessor", "display_name": "OneFormer COCO Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "OneFormer-ADE20K-SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OneFormer-ADE20K-SemSegPreprocessor", "display_name": "OneFormer ADE20K Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "AnimeLineArtPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AnimeLineArtPreprocessor", "display_name": "Anime Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "PyraCannyPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"low_threshold": ["INT", {"default": 64, "min": 0, "max": 255, "step": 1}], "high_threshold": ["INT", {"default": 128, "min": 0, "max": 255, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["low_threshold", "high_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PyraCannyPreprocessor", "display_name": "PyraCanny", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "CannyEdgePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"low_threshold": ["INT", {"default": 100, "min": 0, "max": 255, "step": 1}], "high_threshold": ["INT", {"default": 200, "min": 0, "max": 255, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["low_threshold", "high_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CannyEdgePreprocessor", "display_name": "Canny Edge", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "AnyLineArtPreprocessor_aux": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"merge_with_lineart": [["lineart_standard", "lineart_realisitic", "lineart_anime", "manga_line"], {"default": "lineart_standard"}], "resolution": ["INT", {"default": 1280, "min": 64, "max": 16384, "step": 8}], "lineart_lower_bound": ["FLOAT", {"default": 0, "min": 0, "max": 1, "step": 0.01}], "lineart_upper_bound": ["FLOAT", {"default": 1, "min": 0, "max": 1, "step": 0.01}], "object_min_size": ["INT", {"default": 36, "min": 1, "max": 16384, "step": 1}], "object_connectivity": ["INT", {"default": 1, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image"], "optional": ["merge_with_lineart", "resolution", "lineart_lower_bound", "lineart_upper_bound", "object_min_size", "object_connectivity"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "AnyLineArtPreprocessor_aux", "display_name": "AnyLine Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "AnimeFace_SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"remove_background_using_abg": ["BOOLEAN", {"default": true}], "resolution": ["INT", {"default": 512, "min": 512, "max": 512, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["remove_background_using_abg", "resolution"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "ABG_CHARACTER_MASK (MASK)"], "name": "AnimeFace_SemSegPreprocessor", "display_name": "Anime Face Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "ImageLuminanceDetector": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"gamma_correction": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 2.0, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["gamma_correction", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageLuminanceDetector", "display_name": "Image Luminance", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Recolor", "output_node": false}, "ImageIntensityDetector": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"gamma_correction": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 2.0, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["gamma_correction", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageIntensityDetector", "display_name": "Image Intensity", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Recolor", "output_node": false}, "SAMPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SAMPreprocessor", "display_name": "SAM Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/others", "output_node": false}, "MediaPipe-FaceMeshPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"max_faces": ["INT", {"default": 10, "min": 1, "max": 50, "step": 1}], "min_confidence": ["FLOAT", {"default": 0.5, "min": 0.1, "max": 1, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["max_faces", "min_confidence", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MediaPipe-FaceMeshPreprocessor", "display_name": "MediaPipe Face Mesh", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "Manga2Anime_LineArt_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Manga2Anime_LineArt_Preprocessor", "display_name": "Manga Lineart (aka lineart_anime_denoise)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Metric3D-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"backbone": [["vit-small", "vit-large", "vit-giant2"], {"default": "vit-small"}], "fx": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "fy": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["backbone", "fx", "fy", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Metric3D-DepthMapPreprocessor", "display_name": "Metric3D Depth Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "Metric3D-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"backbone": [["vit-small", "vit-large", "vit-giant2"], {"default": "vit-small"}], "fx": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "fy": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["backbone", "fx", "fy", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Metric3D-NormalMapPreprocessor", "display_name": "Metric3D Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "PiDiNetPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PiDiNetPreprocessor", "display_name": "PiDiNet Soft-Edge Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "BAE-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BAE-NormalMapPreprocessor", "display_name": "BAE Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "DepthAnythingV2Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"ckpt_name": [["depth_anything_v2_vitg.pth", "depth_anything_v2_vitl.pth", "depth_anything_v2_vitb.pth", "depth_anything_v2_vits.pth"], {"default": "depth_anything_v2_vitl.pth"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["ckpt_name", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DepthAnythingV2Preprocessor", "display_name": "Depth Anything V2 - Relative", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "UniFormer-SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UniFormer-SemSegPreprocessor", "display_name": "UniFormer Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SemSegPreprocessor", "display_name": "Semantic Segmentor (legacy, alias for UniFormer)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "ShufflePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["image"], "optional": ["resolution", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ShufflePreprocessor", "display_name": "Content Shuffle", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/T2IAdapter-only", "output_node": false}, "MiDaS-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"a": ["FLOAT", {"default": 6.283185307179586, "min": 0.0, "max": 15.707963267948966, "step": 0.01}], "bg_threshold": ["FLOAT", {"default": 0.1, "min": 0, "max": 1, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["a", "bg_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MiDaS-NormalMapPreprocessor", "display_name": "MiDaS Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "MiDaS-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"a": ["FLOAT", {"default": 6.283185307179586, "min": 0.0, "max": 15.707963267948966, "step": 0.01}], "bg_threshold": ["FLOAT", {"default": 0.1, "min": 0, "max": 1, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["a", "bg_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MiDaS-DepthMapPreprocessor", "display_name": "MiDaS Depth Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "DSINE-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"fov": ["FLOAT", {"default": 60.0, "min": 0, "max": 365.0, "step": 0.01}], "iterations": ["INT", {"default": 5, "min": 1, "max": 20, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["fov", "iterations", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DSINE-NormalMapPreprocessor", "display_name": "DSINE Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "SavePoseKpsAsJsonFile": {"input": {"required": {"pose_kps": ["POSE_KEYPOINT"], "filename_prefix": ["STRING", {"default": "PoseKeypoint"}]}}, "input_order": {"required": ["pose_kps", "filename_prefix"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SavePoseKpsAsJsonFile", "display_name": "Save Pose Keypoints", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Pose Keypoint Postprocess", "output_node": true}, "FacialPartColoringFromPoseKps": {"input": {"required": {"pose_kps": ["POSE_KEYPOINT"], "mode": [["point", "polygon"], {"default": "polygon"}], "skin": ["STRING", {"default": "rgb(0, 153, 255)", "multiline": false}], "left_eye": ["STRING", {"default": "rgb(0, 204, 153)", "multiline": false}], "right_eye": ["STRING", {"default": "rgb(255, 153, 0)", "multiline": false}], "nose": ["STRING", {"default": "rgb(255, 102, 255)", "multiline": false}], "upper_lip": ["STRING", {"default": "rgb(102, 0, 51)", "multiline": false}], "inner_mouth": ["STRING", {"default": "rgb(255, 204, 255)", "multiline": false}], "lower_lip": ["STRING", {"default": "rgb(255, 0, 102)", "multiline": false}]}}, "input_order": {"required": ["pose_kps", "mode", "skin", "left_eye", "right_eye", "nose", "upper_lip", "inner_mouth", "lower_lip"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FacialPartColoringFromPoseKps", "display_name": "Colorize Facial Parts from PoseKPS", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Pose Keypoint Postprocess", "output_node": false}, "UpperBodyTrackingFromPoseKps": {"input": {"required": {"pose_kps": ["POSE_KEYPOINT"], "id_include": ["STRING", {"default": "", "multiline": false}], "Head_width_height": ["STRING", {"default": "256, 256", "multiline": false}], "Neck_width_height": ["STRING", {"default": "100, 100", "multiline": false}], "Shoulder_width_height": ["STRING", {"default": "", "multiline": false}], "Torso_width_height": ["STRING", {"default": "350, 450", "multiline": false}], "RArm_width_height": ["STRING", {"default": "128, 256", "multiline": false}], "RForearm_width_height": ["STRING", {"default": "128, 256", "multiline": false}], "LArm_width_height": ["STRING", {"default": "128, 256", "multiline": false}], "LForearm_width_height": ["STRING", {"default": "128, 256", "multiline": false}]}}, "input_order": {"required": ["pose_kps", "id_include", "Head_width_height", "Neck_width_height", "Shoulder_width_height", "Torso_width_height", "RArm_width_height", "RForearm_width_height", "LArm_width_height", "LForearm_width_height"]}, "output": ["TRACKING", "STRING"], "output_is_list": [false, false], "output_name": ["tracking", "prompt"], "name": "UpperBodyTrackingFromPoseKps", "display_name": "Upper Body Tracking From PoseKps (InstanceDiffusion)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Pose Keypoint Postprocess", "output_node": false}, "RenderPeopleKps": {"input": {"required": {"kps": ["POSE_KEYPOINT"], "render_body": ["BOOLEAN", {"default": true}], "render_hand": ["BOOLEAN", {"default": true}], "render_face": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["kps", "render_body", "render_hand", "render_face"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RenderPeopleKps", "display_name": "Render Pose JSON (Human)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Pose Keypoint Postprocess", "output_node": false}, "RenderAnimalKps": {"input": {"required": {"kps": ["POSE_KEYPOINT"]}}, "input_order": {"required": ["kps"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RenderAnimalKps", "display_name": "Render Pose JSON (Animal)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Pose Keypoint Postprocess", "output_node": false}, "ScribblePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ScribblePreprocessor", "display_name": "Scribble Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Scribble_XDoG_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["INT", {"default": 32, "min": 1, "max": 64, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Scribble_XDoG_Preprocessor", "display_name": "Scribble XDoG Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Scribble_PiDiNet_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"]], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Scribble_PiDiNet_Preprocessor", "display_name": "Scribble PiDiNet Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Unimatch_OptFlowPreprocessor": {"input": {"required": {"image": ["IMAGE"], "ckpt_name": [["gmflow-scale1-mixdata.pth", "gmflow-scale2-mixdata.pth", "gmflow-scale2-regrefine6-mixdata.pth"], {"default": "gmflow-scale2-regrefine6-mixdata.pth"}], "backward_flow": ["BOOLEAN", {"default": false}], "bidirectional_flow": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "ckpt_name", "backward_flow", "bidirectional_flow"]}, "output": ["OPTICAL_FLOW", "IMAGE"], "output_is_list": [false, false], "output_name": ["OPTICAL_FLOW", "PREVIEW_IMAGE"], "name": "Unimatch_OptFlowPreprocessor", "display_name": "Unimatch Optical Flow", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Optical Flow", "output_node": false}, "MaskOptFlow": {"input": {"required": {"optical_flow": ["OPTICAL_FLOW"], "mask": ["MASK"]}}, "input_order": {"required": ["optical_flow", "mask"]}, "output": ["OPTICAL_FLOW", "IMAGE"], "output_is_list": [false, false], "output_name": ["OPTICAL_FLOW", "PREVIEW_IMAGE"], "name": "MaskOptFlow", "display_name": "Mask Optical Flow (DragNUWA)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Optical Flow", "output_node": false}, "Zoe-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Zoe-DepthMapPreprocessor", "display_name": "Zoe Depth Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "AIO_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"preprocessor": [["none", "LeReS-DepthMapPreprocessor", "M-LSDPreprocessor", "DWPreprocessor", "AnimalPosePreprocessor", "HEDPreprocessor", "FakeScribblePreprocessor", "ColorPreprocessor", "BinaryPreprocessor", "DensePosePreprocessor", "TilePreprocessor", "TTPlanet_TileGF_Preprocessor", "TTPlanet_TileSimple_Preprocessor", "LineartStandardPreprocessor", "MeshGraphormer-DepthMapPreprocessor", "DepthAnythingPreprocessor", "Zoe_DepthAnythingPreprocessor", "OpenposePreprocessor", "TEEDPreprocessor", "LineArtPreprocessor", "OneFormer-COCO-SemSegPreprocessor", "OneFormer-ADE20K-SemSegPreprocessor", "AnimeLineArtPreprocessor", "PyraCannyPreprocessor", "CannyEdgePreprocessor", "AnyLineArtPreprocessor_aux", "AnimeFace_SemSegPreprocessor", "ImageLuminanceDetector", "ImageIntensityDetector", "SAMPreprocessor", "MediaPipe-FaceMeshPreprocessor", "Manga2Anime_LineArt_Preprocessor", "Metric3D-DepthMapPreprocessor", "Metric3D-NormalMapPreprocessor", "PiDiNetPreprocessor", "BAE-NormalMapPreprocessor", "DepthAnythingV2Preprocessor", "UniFormer-SemSegPreprocessor", "SemSegPreprocessor", "ShufflePreprocessor", "MiDaS-NormalMapPreprocessor", "MiDaS-DepthMapPreprocessor", "DSINE-NormalMapPreprocessor", "ScribblePreprocessor", "Scribble_XDoG_Preprocessor", "Scribble_PiDiNet_Preprocessor", "Zoe-DepthMapPreprocessor"], {"default": "none"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["preprocessor", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AIO_Preprocessor", "display_name": "AIO Aux Preprocessor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ControlNetPreprocessorSelector": {"input": {"required": {"preprocessor": [["none", "LeReS-DepthMapPreprocessor", "M-LSDPreprocessor", "DWPreprocessor", "AnimalPosePreprocessor", "HEDPreprocessor", "FakeScribblePreprocessor", "ColorPreprocessor", "BinaryPreprocessor", "DensePosePreprocessor", "TilePreprocessor", "TTPlanet_TileGF_Preprocessor", "TTPlanet_TileSimple_Preprocessor", "LineartStandardPreprocessor", "MeshGraphormer-DepthMapPreprocessor", "DepthAnythingPreprocessor", "Zoe_DepthAnythingPreprocessor", "OpenposePreprocessor", "TEEDPreprocessor", "LineArtPreprocessor", "OneFormer-COCO-SemSegPreprocessor", "OneFormer-ADE20K-SemSegPreprocessor", "AnimeLineArtPreprocessor", "PyraCannyPreprocessor", "CannyEdgePreprocessor", "AnyLineArtPreprocessor_aux", "AnimeFace_SemSegPreprocessor", "ImageLuminanceDetector", "ImageIntensityDetector", "SAMPreprocessor", "MediaPipe-FaceMeshPreprocessor", "Manga2Anime_LineArt_Preprocessor", "Metric3D-DepthMapPreprocessor", "Metric3D-NormalMapPreprocessor", "PiDiNetPreprocessor", "BAE-NormalMapPreprocessor", "DepthAnythingV2Preprocessor", "UniFormer-SemSegPreprocessor", "SemSegPreprocessor", "ShufflePreprocessor", "MiDaS-NormalMapPreprocessor", "MiDaS-DepthMapPreprocessor", "DSINE-NormalMapPreprocessor", "ScribblePreprocessor", "Scribble_XDoG_Preprocessor", "Scribble_PiDiNet_Preprocessor", "Zoe-DepthMapPreprocessor"]]}}, "input_order": {"required": ["preprocessor"]}, "output": [["none", "LeReS-DepthMapPreprocessor", "M-LSDPreprocessor", "DWPreprocessor", "AnimalPosePreprocessor", "HEDPreprocessor", "FakeScribblePreprocessor", "ColorPreprocessor", "BinaryPreprocessor", "DensePosePreprocessor", "TilePreprocessor", "TTPlanet_TileGF_Preprocessor", "TTPlanet_TileSimple_Preprocessor", "LineartStandardPreprocessor", "MeshGraphormer-DepthMapPreprocessor", "DepthAnythingPreprocessor", "Zoe_DepthAnythingPreprocessor", "OpenposePreprocessor", "TEEDPreprocessor", "LineArtPreprocessor", "OneFormer-COCO-SemSegPreprocessor", "OneFormer-ADE20K-SemSegPreprocessor", "AnimeLineArtPreprocessor", "PyraCannyPreprocessor", "CannyEdgePreprocessor", "AnyLineArtPreprocessor_aux", "AnimeFace_SemSegPreprocessor", "ImageLuminanceDetector", "ImageIntensityDetector", "SAMPreprocessor", "MediaPipe-FaceMeshPreprocessor", "Manga2Anime_LineArt_Preprocessor", "Metric3D-DepthMapPreprocessor", "Metric3D-NormalMapPreprocessor", "PiDiNetPreprocessor", "BAE-NormalMapPreprocessor", "DepthAnythingV2Preprocessor", "UniFormer-SemSegPreprocessor", "SemSegPreprocessor", "ShufflePreprocessor", "MiDaS-NormalMapPreprocessor", "MiDaS-DepthMapPreprocessor", "DSINE-NormalMapPreprocessor", "ScribblePreprocessor", "Scribble_XDoG_Preprocessor", "Scribble_PiDiNet_Preprocessor", "Zoe-DepthMapPreprocessor"]], "output_is_list": [false], "output_name": ["preprocessor"], "name": "ControlNetPreprocessorSelector", "display_name": "Preprocessor Selector", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "PixelPerfectResolution": {"input": {"required": {"original_image": ["IMAGE"], "image_gen_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "image_gen_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "resize_mode": [["Just Resize", "Crop and Resize", "Resize and Fill"], {"default": "Just Resize"}]}}, "input_order": {"required": ["original_image", "image_gen_width", "image_gen_height", "resize_mode"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["RESOLUTION (INT)"], "name": "PixelPerfectResolution", "display_name": "Pixel Perfect Resolution", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ImageGenResolutionFromImage": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE_GEN_WIDTH (INT)", "IMAGE_GEN_HEIGHT (INT)"], "name": "ImageGenResolutionFromImage", "display_name": "Generation Resolution From Image", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ImageGenResolutionFromLatent": {"input": {"required": {"latent": ["LATENT"]}}, "input_order": {"required": ["latent"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE_GEN_WIDTH (INT)", "IMAGE_GEN_HEIGHT (INT)"], "name": "ImageGenResolutionFromLatent", "display_name": "Generation Resolution From Latent", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "HintImageEnchance": {"input": {"required": {"hint_image": ["IMAGE"], "image_gen_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "image_gen_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "resize_mode": [["Just Resize", "Crop and Resize", "Resize and Fill"], {"default": "Just Resize"}]}}, "input_order": {"required": ["hint_image", "image_gen_width", "image_gen_height", "resize_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "HintImageEnchance", "display_name": "Enchance And Resize Hint Images", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ExecuteAllControlNetPreprocessors": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ExecuteAllControlNetPreprocessors", "display_name": "Execute All ControlNet Preprocessors", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ControlNetAuxSimpleAddText": {"input": {"required": {"image": ["IMAGE"], "text": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["image", "text"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ControlNetAuxSimpleAddText", "display_name": "ControlNetAuxSimpleAddText", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "LumaAIClient": {"input": {"required": {"api_key": ["STRING", {"default": ""}]}}, "input_order": {"required": ["api_key"]}, "output": ["LUMACLIENT"], "output_is_list": [false], "output_name": ["client"], "name": "LumaAIClient", "display_name": "LumaAI Client", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI", "output_node": false}, "ImgBBUpload": {"input": {"required": {"image": ["IMAGE"], "api_key": ["STRING", {"default": "", "multiline": false}], "expire": ["BOOLEAN", {"default": false}], "expiration_time": ["INT", {"default": 60, "min": 60, "max": 15552000, "step": 1}]}}, "input_order": {"required": ["image", "api_key", "expire", "expiration_time"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["image_url"], "name": "ImgBBUpload", "display_name": "ImgBB Upload", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "image/upload", "output_node": false}, "LumaText2Video": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "model": [["ray-flash-2", "ray-2", "ray-1.6"]], "prompt": ["STRING", {"multiline": true, "default": ""}], "duration": [["5s", "9s"]], "loop": ["BOOLEAN", {"default": false}], "aspect_ratio": [["9:16", "3:4", "1:1", "4:3", "16:9", "21:9"]], "resolution": [["540p", "720p"]], "save": ["BOOLEAN", {"default": true}]}, "optional": {"filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "model", "prompt", "duration", "loop", "aspect_ratio", "resolution", "save"], "optional": ["filename"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["video_url", "generation_id"], "name": "LumaText2Video", "display_name": "Text to Video", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Ray", "output_node": true}, "LumaImage2Video": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "prompt": ["STRING", {"multiline": true, "default": ""}], "model": [["ray-flash-2", "ray-2", "ray-1.6"]], "duration": [["5s", "9s"]], "loop": ["BOOLEAN", {"default": false}], "resolution": [["540p", "720p"]], "save": ["BOOLEAN", {"default": true}]}, "optional": {"init_image_url": ["STRING", {"default": "", "forceInput": true}], "final_image_url": ["STRING", {"default": "", "forceInput": true}], "filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "prompt", "model", "duration", "loop", "resolution", "save"], "optional": ["init_image_url", "final_image_url", "filename"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["video_url", "generation_id"], "name": "LumaImage2Video", "display_name": "Image to Video", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Ray", "output_node": false}, "LumaInterpolateGenerations": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "prompt": ["STRING", {"multiline": true, "default": ""}], "model": [["ray-flash-2", "ray-2", "ray-1.6"]], "resolution": [["540p", "720p"]], "save": ["BOOLEAN", {"default": true}], "generation_id_1": ["STRING", {"default": "", "forceInput": true}], "generation_id_2": ["STRING", {"default": "", "forceInput": true}]}, "optional": {"filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "prompt", "model", "resolution", "save", "generation_id_1", "generation_id_2"], "optional": ["filename"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["video_url", "generation_id"], "name": "LumaInterpolateGenerations", "display_name": "Interpolate Generations", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Ray", "output_node": false}, "LumaExtendGeneration": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "prompt": ["STRING", {"multiline": true, "default": ""}], "model": [["ray-flash-2", "ray-2", "ray-1.6"]], "loop": ["BOOLEAN", {"default": false}], "resolution": [["540p", "720p"]], "save": ["BOOLEAN", {"default": true}]}, "optional": {"init_image_url": ["STRING", {"default": "", "forceInput": true}], "final_image_url": ["STRING", {"default": "", "forceInput": true}], "init_generation_id": ["STRING", {"default": "", "forceInput": true}], "final_generation_id": ["STRING", {"default": "", "forceInput": true}], "filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "prompt", "model", "loop", "resolution", "save"], "optional": ["init_image_url", "final_image_url", "init_generation_id", "final_generation_id", "filename"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["video_url", "generation_id"], "name": "LumaExtendGeneration", "display_name": "Extend Generation", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Ray", "output_node": false}, "LumaPreviewVideo": {"input": {"required": {"video_url": ["STRING", {"forceInput": true}]}}, "input_order": {"required": ["video_url"]}, "output": [], "output_is_list": [], "output_name": [], "name": "LumaPreviewVideo", "display_name": "LumaAI Preview Video", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Utils", "output_node": true}, "Reference": {"input": {"required": {"image_url": ["STRING", {"forceInput": true}], "weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image_url", "weight"]}, "output": ["REFERENCE"], "output_is_list": [false], "output_name": ["reference"], "name": "Reference", "display_name": "Reference", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Photon", "output_node": false}, "ConcatReferences": {"input": {"required": {}, "optional": {"reference_1": ["REFERENCE", {"forceInput": true}], "reference_2": ["REFERENCE", {"forceInput": true}], "reference_3": ["REFERENCE", {"forceInput": true}], "reference_4": ["REFERENCE", {"forceInput": true}]}}, "input_order": {"required": [], "optional": ["reference_1", "reference_2", "reference_3", "reference_4"]}, "output": ["CONCAT_REFERENCES"], "output_is_list": [false], "output_name": ["concat_references"], "name": "ConcatReferences", "display_name": "ConcatReferences", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Photon", "output_node": false}, "CharacterReference": {"input": {"required": {}, "optional": {"character_image_url_1": ["STRING", {"forceInput": true}], "character_image_url_2": ["STRING", {"forceInput": true}], "character_image_url_3": ["STRING", {"forceInput": true}], "character_image_url_4": ["STRING", {"forceInput": true}]}}, "input_order": {"required": [], "optional": ["character_image_url_1", "character_image_url_2", "character_image_url_3", "character_image_url_4"]}, "output": ["CHARACTER_REFERENCE"], "output_is_list": [false], "output_name": ["character_reference"], "name": "CharacterReference", "display_name": "CharacterReference", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Photon", "output_node": false}, "LumaImageGeneration": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "model": [["photon-1", "photon-flash-1"]], "prompt": ["STRING", {"forceInput": true}], "aspect_ratio": [["9:16", "3:4", "1:1", "4:3", "16:9", "21:9"]]}, "optional": {"image_ref": ["CONCAT_REFERENCES", {"forceInput": true}], "style_ref": ["REFERENCE", {"forceInput": true}], "character_ref": ["CHARACTER_REFERENCE", {"forceInput": true}], "filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "model", "prompt", "aspect_ratio"], "optional": ["image_ref", "style_ref", "character_ref", "filename"]}, "output": ["STRING", "STRING", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["image_url", "generation_id", "image"], "name": "LumaImageGeneration", "display_name": "Image Generation", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Photon", "output_node": true}, "LumaModifyImage": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "model": [["photon-1", "photon-flash-1"]], "prompt": ["STRING", {"forceInput": true}], "modify_image_ref": ["REFERENCE", {"forceInput": true}]}}, "input_order": {"required": ["client", "model", "prompt", "modify_image_ref"]}, "output": ["STRING", "STRING", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["image_url", "generation_id", "image"], "name": "LumaModifyImage", "display_name": "Modify Image", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Photon", "output_node": true}, "LumaAddAudio2Video": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "generation_id": ["STRING", {"default": "", "forceInput": true}], "prompt": ["STRING", {"multiline": true, "default": ""}], "negative_prompt": ["STRING", {"multiline": true, "default": ""}], "save": ["BOOLEAN", {"default": true}]}, "optional": {"filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "generation_id", "prompt", "negative_prompt", "save"], "optional": ["filename"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["video_url", "generation_id"], "name": "LumaAddAudio2Video", "display_name": "Add Audio to Video", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Audio", "output_node": false}, "LumaUpscaleGeneration": {"input": {"required": {"client": ["LUMACLIENT", {"forceInput": true}], "generation_id": ["STRING", {"default": "", "forceInput": true}], "resolution": [["540p", "720p", "1080p", "4k"]], "save": ["BOOLEAN", {"default": true}]}, "optional": {"filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["client", "generation_id", "resolution", "save"], "optional": ["filename"]}, "output": ["STRING", "STRING"], "output_is_list": [false, false], "output_name": ["video_url", "generation_id"], "name": "LumaUpscaleGeneration", "display_name": "Upscale Generation", "description": "", "python_module": "custom_nodes.ComfyUI-LumaAI-API", "category": "LumaAI/Upscale", "output_node": false}, "IPAdapter": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "weight_type": [["standard", "prompt is more important", "style transfer"]]}, "optional": {"attn_mask": ["MASK"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "start_at", "end_at", "weight_type"], "optional": ["attn_mask"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapter", "display_name": "IPAdapter", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterAdvanced": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_type", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterAdvanced", "display_name": "IPAdapter Advanced", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]], "encode_batch_size": ["INT", {"default": 0, "min": 0, "max": 4096}]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_type", "start_at", "end_at", "embeds_scaling", "encode_batch_size"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterBatch", "display_name": "IPAdapter Batch (Adv.)", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterFaceID": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_faceidv2": ["FLOAT", {"default": 1.0, "min": -1, "max": 5.0, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"], "insightface": ["INSIGHTFACE"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_faceidv2", "weight_type", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision", "insightface"]}, "output": ["MODEL", "IMAGE"], "output_is_list": [false, false], "output_name": ["MODEL", "face_image"], "name": "IPAdapterFaceID", "display_name": "IPAdapter FaceID", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/faceid", "output_node": false}, "IPAdapterFaceIDKolors": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_faceidv2": ["FLOAT", {"default": 1.0, "min": -1, "max": 5.0, "step": 0.05}], "weight_kolors": ["FLOAT", {"default": 1.0, "min": -1, "max": 5.0, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"], "insightface": ["INSIGHTFACE"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_faceidv2", "weight_kolors", "weight_type", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision", "insightface"]}, "output": ["MODEL", "IMAGE"], "output_is_list": [false, false], "output_name": ["MODEL", "face_image"], "name": "IPAdapterFaceIDKolors", "display_name": "IPAdapter FaceID Kolors", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/faceid", "output_node": false}, "IPAAdapterFaceIDBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_faceidv2": ["FLOAT", {"default": 1.0, "min": -1, "max": 5.0, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"], "insightface": ["INSIGHTFACE"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_faceidv2", "weight_type", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision", "insightface"]}, "output": ["MODEL", "IMAGE"], "output_is_list": [false, false], "output_name": ["MODEL", "face_image"], "name": "IPAAdapterFaceIDBatch", "display_name": "IPAdapter FaceID Batch", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/faceid", "output_node": false}, "IPAdapterTiled": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "sharpening": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.05}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_type", "combine_embeds", "start_at", "end_at", "sharpening", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL", "IMAGE", "MASK"], "output_is_list": [false, false, false], "output_name": ["MODEL", "tiles", "masks"], "name": "IPAdapterTiled", "display_name": "IPAdapter Tiled", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/tiled", "output_node": false}, "IPAdapterTiledBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "sharpening": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.05}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]], "encode_batch_size": ["INT", {"default": 0, "min": 0, "max": 4096}]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_type", "start_at", "end_at", "sharpening", "embeds_scaling", "encode_batch_size"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL", "IMAGE", "MASK"], "output_is_list": [false, false, false], "output_name": ["MODEL", "tiles", "masks"], "name": "IPAdapterTiledBatch", "display_name": "IPAdapter Tiled Batch", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/tiled", "output_node": false}, "IPAdapterEmbeds": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "pos_embed": ["EMBEDS"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"neg_embed": ["EMBEDS"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "pos_embed", "weight", "weight_type", "start_at", "end_at", "embeds_scaling"], "optional": ["neg_embed", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterEmbeds", "display_name": "IPAdapter Embeds", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/embeds", "output_node": false}, "IPAdapterEmbedsBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "pos_embed": ["EMBEDS"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 3, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"neg_embed": ["EMBEDS"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "pos_embed", "weight", "weight_type", "start_at", "end_at", "embeds_scaling"], "optional": ["neg_embed", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterEmbedsBatch", "display_name": "IPAdapter Embeds Batch", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/embeds", "output_node": false}, "IPAdapterStyleComposition": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image_style": ["IMAGE"], "image_composition": ["IMAGE"], "weight_style": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_composition": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "expand_style": ["BOOLEAN", {"default": false}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"], {"default": "average"}], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image_style", "image_composition", "weight_style", "weight_composition", "expand_style", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterStyleComposition", "display_name": "IPAdapter Style & Composition SDXL", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/style_composition", "output_node": false}, "IPAdapterStyleCompositionBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image_style": ["IMAGE"], "image_composition": ["IMAGE"], "weight_style": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_composition": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "expand_style": ["BOOLEAN", {"default": false}], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image_style", "image_composition", "weight_style", "weight_composition", "expand_style", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterStyleCompositionBatch", "display_name": "IPAdapter Style & Composition Batch SDXL", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/style_composition", "output_node": false}, "IPAdapterMS": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_faceidv2": ["FLOAT", {"default": 1.0, "min": -1, "max": 5.0, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]], "layer_weights": ["STRING", {"default": "", "multiline": true}]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"], "insightface": ["INSIGHTFACE"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_faceidv2", "weight_type", "combine_embeds", "start_at", "end_at", "embeds_scaling", "layer_weights"], "optional": ["image_negative", "attn_mask", "clip_vision", "insightface"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterMS", "display_name": "IPAdapter Mad Scientist", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/dev", "output_node": false}, "IPAdapterClipVisionEnhancer": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]], "enhance_tiles": ["INT", {"default": 2, "min": 1, "max": 16}], "enhance_ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_type", "combine_embeds", "start_at", "end_at", "embeds_scaling", "enhance_tiles", "enhance_ratio"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterClipVisionEnhancer", "display_name": "IPAdapter ClipVision Enhancer", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/dev", "output_node": false}, "IPAdapterClipVisionEnhancerBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]], "enhance_tiles": ["INT", {"default": 2, "min": 1, "max": 16}], "enhance_ratio": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.05}], "encode_batch_size": ["INT", {"default": 0, "min": 0, "max": 4096}]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "weight_type", "start_at", "end_at", "embeds_scaling", "enhance_tiles", "enhance_ratio", "encode_batch_size"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterClipVisionEnhancerBatch", "display_name": "IPAdapter ClipVision Enhancer Batch", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/dev", "output_node": false}, "IPAdapterFromParams": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "ipadapter_params": ["IPADAPTER_PARAMS"], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "ipadapter_params", "combine_embeds", "embeds_scaling"], "optional": ["image_negative", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterFromParams", "display_name": "IPAdapter from Params", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/params", "output_node": false}, "IPAdapterPreciseStyleTransfer": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "style_boost": ["FLOAT", {"default": 1.0, "min": -5, "max": 5, "step": 0.05}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "style_boost", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterPreciseStyleTransfer", "display_name": "IPAdapter Precise Style Transfer", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterPreciseStyleTransferBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "style_boost": ["FLOAT", {"default": 1.0, "min": -5, "max": 5, "step": 0.05}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "style_boost", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterPreciseStyleTransferBatch", "display_name": "IPAdapter Precise Style Transfer Batch", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterPreciseComposition": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "composition_boost": ["FLOAT", {"default": 0.0, "min": -5, "max": 5, "step": 0.05}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "composition_boost", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterPreciseComposition", "display_name": "IPAdapter Precise Composition", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterPreciseCompositionBatch": {"input": {"required": {"model": ["MODEL"], "ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1, "max": 5, "step": 0.05}], "composition_boost": ["FLOAT", {"default": 0.0, "min": -5, "max": 5, "step": 0.05}], "combine_embeds": [["concat", "add", "subtract", "average", "norm average"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "embeds_scaling": [["V only", "K+V", "K+V w/ C penalty", "K+mean(V) w/ C penalty"]]}, "optional": {"image_negative": ["IMAGE"], "attn_mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["model", "ipadapter", "image", "weight", "composition_boost", "combine_embeds", "start_at", "end_at", "embeds_scaling"], "optional": ["image_negative", "attn_mask", "clip_vision"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "IPAdapterPreciseCompositionBatch", "display_name": "IPAdapter Precise Composition Batch", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterUnifiedLoader": {"input": {"required": {"model": ["MODEL"], "preset": [["LIGHT - SD1.5 only (low strength)", "STANDARD (medium strength)", "VIT-G (medium strength)", "PLUS (high strength)", "PLUS FACE (portraits)", "FULL FACE - SD1.5 only (portraits stronger)"]]}, "optional": {"ipadapter": ["IPADAPTER"]}}, "input_order": {"required": ["model", "preset"], "optional": ["ipadapter"]}, "output": ["MODEL", "IPADAPTER"], "output_is_list": [false, false], "output_name": ["model", "ipadapter"], "name": "IPAdapterUnifiedLoader", "display_name": "IPAdapter Unified Loader", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter", "output_node": false}, "IPAdapterUnifiedLoaderFaceID": {"input": {"required": {"model": ["MODEL"], "preset": [["FACEID", "FACEID PLUS - SD1.5 only", "FACEID PLUS V2", "FACEID PORTRAIT (style transfer)", "FACEID PORTRAIT UNNORM - SDXL only (strong)"]], "lora_strength": ["FLOAT", {"default": 0.6, "min": 0, "max": 1, "step": 0.01}], "provider": [["CPU", "CUDA", "ROCM", "DirectML", "OpenVINO", "CoreML"]]}, "optional": {"ipadapter": ["IPADAPTER"]}}, "input_order": {"required": ["model", "preset", "lora_strength", "provider"], "optional": ["ipadapter"]}, "output": ["MODEL", "IPADAPTER"], "output_is_list": [false, false], "output_name": ["MODEL", "ipadapter"], "name": "IPAdapterUnifiedLoaderFaceID", "display_name": "IPAdapter Unified Loader FaceID", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/faceid", "output_node": false}, "IPAdapterModelLoader": {"input": {"required": {"ipadapter_file": [["ip-adapter-full-face_sd15.safetensors", "ip-adapter-plus-face_sd15.safetensors", "ip-adapter-plus-face_sdxl_vit-h.safetensors", "ip-adapter-plus_sd15.safetensors", "ip-adapter-plus_sdxl_vit-h.safetensors", "ip-adapter_sd15.safetensors", "ip-adapter_sd15_light_v11.bin", "ip-adapter_sd15_vit-G.safetensors", "ip-adapter_sdxl.safetensors", "ip-adapter_sdxl_vit-h.safetensors"]]}}, "input_order": {"required": ["ipadapter_file"]}, "output": ["IPADAPTER"], "output_is_list": [false], "output_name": ["IPADAPTER"], "name": "IPAdapterModelLoader", "display_name": "IPAdapter Model Loader", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/loaders", "output_node": false}, "IPAdapterInsightFaceLoader": {"input": {"required": {"provider": [["CPU", "CUDA", "ROCM"]], "model_name": [["buffalo_l", "antelopev2"]]}}, "input_order": {"required": ["provider", "model_name"]}, "output": ["INSIGHTFACE"], "output_is_list": [false], "output_name": ["INSIGHTFACE"], "name": "IPAdapterInsightFaceLoader", "display_name": "IPAdapter InsightFace Loader", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/loaders", "output_node": false}, "IPAdapterUnifiedLoaderCommunity": {"input": {"required": {"model": ["MODEL"], "preset": [["Composition", "Kolors"]]}, "optional": {"ipadapter": ["IPADAPTER"]}}, "input_order": {"required": ["model", "preset"], "optional": ["ipadapter"]}, "output": ["MODEL", "IPADAPTER"], "output_is_list": [false, false], "output_name": ["model", "ipadapter"], "name": "IPAdapterUnifiedLoaderCommunity", "display_name": "IPAdapter Unified Loader Community", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/loaders", "output_node": false}, "IPAdapterEncoder": {"input": {"required": {"ipadapter": ["IPADAPTER"], "image": ["IMAGE"], "weight": ["FLOAT", {"default": 1.0, "min": -1.0, "max": 3.0, "step": 0.01}]}, "optional": {"mask": ["MASK"], "clip_vision": ["CLIP_VISION"]}}, "input_order": {"required": ["ipadapter", "image", "weight"], "optional": ["mask", "clip_vision"]}, "output": ["EMBEDS", "EMBEDS"], "output_is_list": [false, false], "output_name": ["pos_embed", "neg_embed"], "name": "IPAdapterEncoder", "display_name": "IPAdapter Encoder", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/embeds", "output_node": false}, "IPAdapterCombineEmbeds": {"input": {"required": {"embed1": ["EMBEDS"], "method": [["concat", "add", "subtract", "average", "norm average", "max", "min"]]}, "optional": {"embed2": ["EMBEDS"], "embed3": ["EMBEDS"], "embed4": ["EMBEDS"], "embed5": ["EMBEDS"]}}, "input_order": {"required": ["embed1", "method"], "optional": ["embed2", "embed3", "embed4", "embed5"]}, "output": ["EMBEDS"], "output_is_list": [false], "output_name": ["EMBEDS"], "name": "IPAdapterCombineEmbeds", "display_name": "IPAdapter Combine Embeds", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/embeds", "output_node": false}, "IPAdapterNoise": {"input": {"required": {"type": [["fade", "dissolve", "gaussian", "shuffle"]], "strength": ["FLOAT", {"default": 1.0, "min": 0, "max": 1, "step": 0.05}], "blur": ["INT", {"default": 0, "min": 0, "max": 32, "step": 1}]}, "optional": {"image_optional": ["IMAGE"]}}, "input_order": {"required": ["type", "strength", "blur"], "optional": ["image_optional"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "IPAdapterNoise", "display_name": "IPAdapter Noise", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/utils", "output_node": false}, "PrepImageForClipVision": {"input": {"required": {"image": ["IMAGE"], "interpolation": [["LANCZOS", "BICUBIC", "HAMMING", "BILINEAR", "BOX", "NEAREST"]], "crop_position": [["top", "bottom", "left", "right", "center", "pad"]], "sharpening": ["FLOAT", {"default": 0.0, "min": 0, "max": 1, "step": 0.05}]}}, "input_order": {"required": ["image", "interpolation", "crop_position", "sharpening"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PrepImageForClipVision", "display_name": "Prep Image For ClipVision", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/utils", "output_node": false}, "IPAdapterSaveEmbeds": {"input": {"required": {"embeds": ["EMBEDS"], "filename_prefix": ["STRING", {"default": "IP_embeds"}]}}, "input_order": {"required": ["embeds", "filename_prefix"]}, "output": [], "output_is_list": [], "output_name": [], "name": "IPAdapterSaveEmbeds", "display_name": "IPAdapter Save Embeds", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/embeds", "output_node": true}, "IPAdapterLoadEmbeds": {"input": {"required": {"embeds": [[]]}}, "input_order": {"required": ["embeds"]}, "output": ["EMBEDS"], "output_is_list": [false], "output_name": ["EMBEDS"], "name": "IPAdapterLoadEmbeds", "display_name": "IPAdapter Load Embeds", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/embeds", "output_node": false}, "IPAdapterWeights": {"input": {"required": {"weights": ["STRING", {"default": "1.0, 0.0", "multiline": true}], "timing": [["custom", "linear", "ease_in_out", "ease_in", "ease_out", "random"], {"default": "linear"}], "frames": ["INT", {"default": 0, "min": 0, "max": 9999, "step": 1}], "start_frame": ["INT", {"default": 0, "min": 0, "max": 9999, "step": 1}], "end_frame": ["INT", {"default": 9999, "min": 0, "max": 9999, "step": 1}], "add_starting_frames": ["INT", {"default": 0, "min": 0, "max": 9999, "step": 1}], "add_ending_frames": ["INT", {"default": 0, "min": 0, "max": 9999, "step": 1}], "method": [["full batch", "shift batches", "alternate batches"], {"default": "full batch"}]}, "optional": {"image": ["IMAGE"]}}, "input_order": {"required": ["weights", "timing", "frames", "start_frame", "end_frame", "add_starting_frames", "add_ending_frames", "method"], "optional": ["image"]}, "output": ["FLOAT", "FLOAT", "INT", "IMAGE", "IMAGE", "WEIGHTS_STRATEGY"], "output_is_list": [false, false, false, false, false, false], "output_name": ["weights", "weights_invert", "total_frames", "image_1", "image_2", "weights_strategy"], "name": "IPAdapterWeights", "display_name": "IPAdapter Weights", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/weights", "output_node": false}, "IPAdapterCombineWeights": {"input": {"required": {"weights_1": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.05}], "weights_2": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.05}]}}, "input_order": {"required": ["weights_1", "weights_2"]}, "output": ["FLOAT", "INT"], "output_is_list": [false, false], "output_name": ["weights", "count"], "name": "IPAdapterCombineWeights", "display_name": "IPAdapter Combine Weights", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/utils", "output_node": false}, "IPAdapterWeightsFromStrategy": {"input": {"required": {"weights_strategy": ["WEIGHTS_STRATEGY"]}, "optional": {"image": ["IMAGE"]}}, "input_order": {"required": ["weights_strategy"], "optional": ["image"]}, "output": ["FLOAT", "FLOAT", "INT", "IMAGE", "IMAGE", "WEIGHTS_STRATEGY"], "output_is_list": [false, false, false, false, false, false], "output_name": ["weights", "weights_invert", "total_frames", "image_1", "image_2", "weights_strategy"], "name": "IPAdapterWeightsFromStrategy", "display_name": "IPAdapter Weights From Strategy", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/weights", "output_node": false}, "IPAdapterPromptScheduleFromWeightsStrategy": {"input": {"required": {"weights_strategy": ["WEIGHTS_STRATEGY"], "prompt": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["weights_strategy", "prompt"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["prompt_schedule"], "name": "IPAdapterPromptScheduleFromWeightsStrategy", "display_name": "Prompt Schedule From Weights Strategy", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/weights", "output_node": false}, "IPAdapterRegionalConditioning": {"input": {"required": {"image": ["IMAGE"], "image_weight": ["FLOAT", {"default": 1.0, "min": -1.0, "max": 3.0, "step": 0.05}], "prompt_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.05}], "weight_type": [["linear", "ease in", "ease out", "ease in-out", "reverse in-out", "weak input", "weak output", "weak middle", "strong middle", "style transfer", "composition", "strong style transfer", "style and composition", "style transfer precise", "composition precise"]], "start_at": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_at": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"mask": ["MASK"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"]}}, "input_order": {"required": ["image", "image_weight", "prompt_weight", "weight_type", "start_at", "end_at"], "optional": ["mask", "positive", "negative"]}, "output": ["IPADAPTER_PARAMS", "CONDITIONING", "CONDITIONING"], "output_is_list": [false, false, false], "output_name": ["IPADAPTER_PARAMS", "POSITIVE", "NEGATIVE"], "name": "IPAdapterRegionalConditioning", "display_name": "IPAdapter Regional Conditioning", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/params", "output_node": false}, "IPAdapterCombineParams": {"input": {"required": {"params_1": ["IPADAPTER_PARAMS"], "params_2": ["IPADAPTER_PARAMS"]}, "optional": {"params_3": ["IPADAPTER_PARAMS"], "params_4": ["IPADAPTER_PARAMS"], "params_5": ["IPADAPTER_PARAMS"]}}, "input_order": {"required": ["params_1", "params_2"], "optional": ["params_3", "params_4", "params_5"]}, "output": ["IPADAPTER_PARAMS"], "output_is_list": [false], "output_name": ["IPADAPTER_PARAMS"], "name": "IPAdapterCombineParams", "display_name": "IPAdapter Combine Params", "description": "", "python_module": "custom_nodes.ComfyUI_IPAdapter_plus", "category": "ipadapter/params", "output_node": false}, "TimestepKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_timestep_kf": ["TIMESTEP_KEYFRAME"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "cn_weights": ["CONTROL_NET_WEIGHTS"], "latent_keyframe": ["LATENT_KEYFRAME"], "null_latent_kf_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "mask_optional": ["MASK"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_timestep_kf", "strength", "cn_weights", "latent_keyframe", "null_latent_kf_strength", "inherit_missing", "guarantee_steps", "mask_optional"], "hidden": ["autosize"]}, "output": ["TIMESTEP_KEYFRAME"], "output_is_list": [false], "output_name": ["TIMESTEP_KF"], "name": "TimestepKeyframe", "display_name": "Timestep Keyframe \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "ACN_TimestepKeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "strength_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease-in", "ease-out", "ease-in-out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}]}, "optional": {"prev_timestep_kf": ["TIMESTEP_KEYFRAME"], "cn_weights": ["CONTROL_NET_WEIGHTS"], "latent_keyframe": ["LATENT_KEYFRAME"], "null_latent_kf_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "mask_optional": ["MASK"], "print_keyframes": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "strength_start", "strength_end", "interpolation", "intervals"], "optional": ["prev_timestep_kf", "cn_weights", "latent_keyframe", "null_latent_kf_strength", "inherit_missing", "mask_optional", "print_keyframes"], "hidden": ["autosize"]}, "output": ["TIMESTEP_KEYFRAME"], "output_is_list": [false], "output_name": ["TIMESTEP_KF"], "name": "ACN_TimestepKeyframeInterpolation", "display_name": "Timestep Keyframe Interp. \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "ACN_TimestepKeyframeFromStrengthList": {"input": {"required": {"float_strengths": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_timestep_kf": ["TIMESTEP_KEYFRAME"], "cn_weights": ["CONTROL_NET_WEIGHTS"], "latent_keyframe": ["LATENT_KEYFRAME"], "null_latent_kf_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "mask_optional": ["MASK"], "print_keyframes": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["float_strengths", "start_percent", "end_percent"], "optional": ["prev_timestep_kf", "cn_weights", "latent_keyframe", "null_latent_kf_strength", "inherit_missing", "mask_optional", "print_keyframes"], "hidden": ["autosize"]}, "output": ["TIMESTEP_KEYFRAME"], "output_is_list": [false], "output_name": ["TIMESTEP_KF"], "name": "ACN_TimestepKeyframeFromStrengthList", "display_name": "Timestep Keyframe From List \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "LatentKeyframe": {"input": {"required": {"batch_index": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991, "step": 1}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"prev_latent_kf": ["LATENT_KEYFRAME"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_index", "strength"], "optional": ["prev_latent_kf"], "hidden": ["autosize"]}, "output": ["LATENT_KEYFRAME"], "output_is_list": [false], "output_name": ["LATENT_KF"], "name": "LatentKeyframe", "display_name": "Latent Keyframe \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "LatentKeyframeTiming": {"input": {"required": {"batch_index_from": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991, "step": 1}], "batch_index_to_excl": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991, "step": 1}], "strength_from": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_to": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease-in", "ease-out", "ease-in-out"]]}, "optional": {"prev_latent_kf": ["LATENT_KEYFRAME"], "print_keyframes": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_index_from", "batch_index_to_excl", "strength_from", "strength_to", "interpolation"], "optional": ["prev_latent_kf", "print_keyframes"], "hidden": ["autosize"]}, "output": ["LATENT_KEYFRAME"], "output_is_list": [false], "output_name": ["LATENT_KF"], "name": "LatentKeyframeTiming", "display_name": "Latent Keyframe Interp. \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "LatentKeyframeBatchedGroup": {"input": {"required": {"float_strengths": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}]}, "optional": {"prev_latent_kf": ["LATENT_KEYFRAME"], "print_keyframes": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["float_strengths"], "optional": ["prev_latent_kf", "print_keyframes"], "hidden": ["autosize"]}, "output": ["LATENT_KEYFRAME"], "output_is_list": [false], "output_name": ["LATENT_KF"], "name": "LatentKeyframeBatchedGroup", "display_name": "Latent Keyframe From List \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "LatentKeyframeGroup": {"input": {"required": {"index_strengths": ["STRING", {"multiline": true, "default": ""}]}, "optional": {"prev_latent_kf": ["LATENT_KEYFRAME"], "latent_optional": ["LATENT"], "print_keyframes": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["index_strengths"], "optional": ["prev_latent_kf", "latent_optional", "print_keyframes"], "hidden": ["autosize"]}, "output": ["LATENT_KEYFRAME"], "output_is_list": [false], "output_name": ["LATENT_KF"], "name": "LatentKeyframeGroup", "display_name": "Latent Keyframe Group \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/keyframes", "output_node": false}, "ACN_AdvancedControlNetApply_v2": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"], "timestep_kf": ["TIMESTEP_KEYFRAME"], "latent_kf_override": ["LATENT_KEYFRAME"], "weights_override": ["CONTROL_NET_WEIGHTS"], "vae_optional": ["VAE"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive", "negative", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["mask_optional", "timestep_kf", "latent_kf_override", "weights_override", "vae_optional"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ACN_AdvancedControlNetApply_v2", "display_name": "Apply Advanced ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "output_node": false}, "ACN_AdvancedControlNetApplySingle_v2": {"input": {"required": {"conditioning": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"], "timestep_kf": ["TIMESTEP_KEYFRAME"], "latent_kf_override": ["LATENT_KEYFRAME"], "weights_override": ["CONTROL_NET_WEIGHTS"], "vae_optional": ["VAE"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["conditioning", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["mask_optional", "timestep_kf", "latent_kf_override", "weights_override", "vae_optional"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "MODEL"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "model_opt"], "name": "ACN_AdvancedControlNetApplySingle_v2", "display_name": "Apply Advanced ControlNet(1) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "output_node": false}, "ACN_ControlNetLoaderAdvanced": {"input": {"required": {"cnet": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}, "optional": {"_tk_opt": ["TIMESTEP_KEYFRAME"]}}, "input_order": {"required": ["cnet"], "optional": ["_tk_opt"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_ControlNetLoaderAdvanced", "display_name": "Load Advanced ControlNet Model \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "output_node": false}, "ACN_DiffControlNetLoaderAdvanced": {"input": {"required": {"model": ["MODEL"], "cnet": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}, "optional": {"_tk_opt": ["TIMESTEP_KEYFRAME"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["model", "cnet"], "optional": ["_tk_opt"], "hidden": ["autosize"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_DiffControlNetLoaderAdvanced", "display_name": "Load Advanced ControlNet Model (diff) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "output_node": false}, "ACN_ScaledSoftControlNetWeights": {"input": {"required": {"base_multiplier": ["FLOAT", {"default": 0.825, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["base_multiplier"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_ScaledSoftControlNetWeights", "display_name": "Scaled Soft Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights", "output_node": false}, "ScaledSoftMaskedUniversalWeights": {"input": {"required": {"mask": ["MASK"], "min_base_multiplier": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "max_base_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["mask", "min_base_multiplier", "max_base_multiplier"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ScaledSoftMaskedUniversalWeights", "display_name": "Scaled Soft Masked Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights", "output_node": false}, "ACN_SoftControlNetWeightsSD15": {"input": {"required": {"output_0": ["FLOAT", {"default": 0.09941396206337118, "min": 0.0, "max": 10.0, "step": 0.001}], "output_1": ["FLOAT", {"default": 0.12050177219802567, "min": 0.0, "max": 10.0, "step": 0.001}], "output_2": ["FLOAT", {"default": 0.14606275417942507, "min": 0.0, "max": 10.0, "step": 0.001}], "output_3": ["FLOAT", {"default": 0.17704576264172736, "min": 0.0, "max": 10.0, "step": 0.001}], "output_4": ["FLOAT", {"default": 0.214600924414215, "min": 0.0, "max": 10.0, "step": 0.001}], "output_5": ["FLOAT", {"default": 0.26012233262329093, "min": 0.0, "max": 10.0, "step": 0.001}], "output_6": ["FLOAT", {"default": 0.3152997971191405, "min": 0.0, "max": 10.0, "step": 0.001}], "output_7": ["FLOAT", {"default": 0.3821815722656249, "min": 0.0, "max": 10.0, "step": 0.001}], "output_8": ["FLOAT", {"default": 0.4632503906249999, "min": 0.0, "max": 10.0, "step": 0.001}], "output_9": ["FLOAT", {"default": 0.561515625, "min": 0.0, "max": 10.0, "step": 0.001}], "output_10": ["FLOAT", {"default": 0.6806249999999999, "min": 0.0, "max": 10.0, "step": 0.001}], "output_11": ["FLOAT", {"default": 0.825, "min": 0.0, "max": 10.0, "step": 0.001}], "middle_0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["output_0", "output_1", "output_2", "output_3", "output_4", "output_5", "output_6", "output_7", "output_8", "output_9", "output_10", "output_11", "middle_0"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_SoftControlNetWeightsSD15", "display_name": "ControlNet Soft Weights [SD1.5] \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights/ControlNet", "output_node": false}, "ACN_CustomControlNetWeightsSD15": {"input": {"required": {"output_0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_9": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_10": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "output_11": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "middle_0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["output_0", "output_1", "output_2", "output_3", "output_4", "output_5", "output_6", "output_7", "output_8", "output_9", "output_10", "output_11", "middle_0"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_CustomControlNetWeightsSD15", "display_name": "ControlNet Custom Weights [SD1.5] \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights/ControlNet", "output_node": false}, "ACN_CustomControlNetWeightsFlux": {"input": {"required": {"input_0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_9": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_10": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_11": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_12": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_13": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_14": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_15": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_16": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_17": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_18": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["input_0", "input_1", "input_2", "input_3", "input_4", "input_5", "input_6", "input_7", "input_8", "input_9", "input_10", "input_11", "input_12", "input_13", "input_14", "input_15", "input_16", "input_17", "input_18"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_CustomControlNetWeightsFlux", "display_name": "ControlNet Custom Weights [Flux] \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights/ControlNet", "output_node": false}, "ACN_SoftT2IAdapterWeights": {"input": {"required": {"input_0": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 10.0, "step": 0.001}], "input_1": ["FLOAT", {"default": 0.62, "min": 0.0, "max": 10.0, "step": 0.001}], "input_2": ["FLOAT", {"default": 0.825, "min": 0.0, "max": 10.0, "step": 0.001}], "input_3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["input_0", "input_1", "input_2", "input_3"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_SoftT2IAdapterWeights", "display_name": "T2IAdapter Soft Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights/T2IAdapter", "output_node": false}, "ACN_CustomT2IAdapterWeights": {"input": {"required": {"input_0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "input_3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["input_0", "input_1", "input_2", "input_3"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_CustomT2IAdapterWeights", "display_name": "T2IAdapter Custom Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights/T2IAdapter", "output_node": false}, "ACN_DefaultUniversalWeights": {"input": {"optional": {"cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"optional": ["cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ACN_DefaultUniversalWeights", "display_name": "Default Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights", "output_node": false}, "ACN_ExtrasMiddleMult": {"input": {"required": {"middle_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["middle_mult"], "optional": ["cn_extras"], "hidden": ["autosize"]}, "output": ["CN_WEIGHTS_EXTRAS"], "output_is_list": [false], "output_name": ["cn_extras"], "name": "ACN_ExtrasMiddleMult", "display_name": "Middle Weight Extras \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/weights/extras", "output_node": false}, "ACN_SparseCtrlRGBPreprocessor": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"], "latent_size": ["LATENT"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["image", "vae", "latent_size"], "hidden": ["autosize"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["proc_IMAGE"], "name": "ACN_SparseCtrlRGBPreprocessor", "display_name": "RGB SparseCtrl \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/SparseCtrl/preprocess", "output_node": false}, "ACN_SparseCtrlLoaderAdvanced": {"input": {"required": {"sparsectrl_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]], "use_motion": ["BOOLEAN", {"default": true}], "motion_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"sparse_method": ["SPARSE_METHOD"], "tk_optional": ["TIMESTEP_KEYFRAME"], "context_aware": [["nearest_hint", "off"]], "sparse_hint_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "sparse_nonhint_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "sparse_mask_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["sparsectrl_name", "use_motion", "motion_strength", "motion_scale"], "optional": ["sparse_method", "tk_optional", "context_aware", "sparse_hint_mult", "sparse_nonhint_mult", "sparse_mask_mult"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_SparseCtrlLoaderAdvanced", "display_name": "Load SparseCtrl Model \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/SparseCtrl", "output_node": false}, "ACN_SparseCtrlMergedLoaderAdvanced": {"input": {"required": {"sparsectrl_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]], "control_net_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]], "use_motion": ["BOOLEAN", {"default": true}], "motion_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"sparse_method": ["SPARSE_METHOD"], "tk_optional": ["TIMESTEP_KEYFRAME"]}}, "input_order": {"required": ["sparsectrl_name", "control_net_name", "use_motion", "motion_strength", "motion_scale"], "optional": ["sparse_method", "tk_optional"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_SparseCtrlMergedLoaderAdvanced", "display_name": "\ud83e\uddeaLoad Merged SparseCtrl Model \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/SparseCtrl/experimental", "output_node": false}, "ACN_SparseCtrlIndexMethodNode": {"input": {"required": {"indexes": ["STRING", {"default": "0"}]}}, "input_order": {"required": ["indexes"]}, "output": ["SPARSE_METHOD"], "output_is_list": [false], "output_name": ["SPARSE_METHOD"], "name": "ACN_SparseCtrlIndexMethodNode", "display_name": "SparseCtrl Index Method \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/SparseCtrl", "output_node": false}, "ACN_SparseCtrlSpreadMethodNode": {"input": {"required": {"spread": [["uniform", "starting", "ending", "center"]]}}, "input_order": {"required": ["spread"]}, "output": ["SPARSE_METHOD"], "output_is_list": [false], "output_name": ["SPARSE_METHOD"], "name": "ACN_SparseCtrlSpreadMethodNode", "display_name": "SparseCtrl Spread Method \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/SparseCtrl", "output_node": false}, "ACN_SparseCtrlWeightExtras": {"input": {"optional": {"cn_extras": ["CN_WEIGHTS_EXTRAS"], "sparse_hint_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "sparse_nonhint_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "sparse_mask_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"optional": ["cn_extras", "sparse_hint_mult", "sparse_nonhint_mult", "sparse_mask_mult"], "hidden": ["autosize"]}, "output": ["CN_WEIGHTS_EXTRAS"], "output_is_list": [false], "output_name": ["cn_extras"], "name": "ACN_SparseCtrlWeightExtras", "display_name": "SparseCtrl Weight Extras \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/SparseCtrl/extras", "output_node": false}, "ACN_ControlNet++LoaderSingle": {"input": {"required": {"name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]], "control_type": [["openpose", "depth", "hed/pidi/scribble/ted", "canny/lineart/mlsd", "normal", "segment", "tile", "inpaint/outpaint", "none"], {"default": "none"}]}}, "input_order": {"required": ["name", "control_type"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_ControlNet++LoaderSingle", "display_name": "Load ControlNet++ Model (Single) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/ControlNet++", "output_node": false}, "ACN_ControlNet++LoaderAdvanced": {"input": {"required": {"plus_input": ["PLUS_INPUT"], "name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}}, "input_order": {"required": ["plus_input", "name"]}, "output": ["CONTROL_NET", "IMAGE"], "output_is_list": [false, false], "output_name": ["CONTROL_NET", "IMAGE"], "name": "ACN_ControlNet++LoaderAdvanced", "display_name": "Load ControlNet++ Model (Multi) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/ControlNet++", "output_node": false}, "ACN_ControlNet++InputNode": {"input": {"required": {"image": ["IMAGE"], "control_type": [["openpose", "depth", "hed/pidi/scribble/ted", "canny/lineart/mlsd", "normal", "segment", "tile", "inpaint/outpaint"]]}, "optional": {"prev_plus_input": ["PLUS_INPUT"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["image", "control_type"], "optional": ["prev_plus_input"], "hidden": ["autosize"]}, "output": ["PLUS_INPUT"], "output_is_list": [false], "output_name": ["PLUS_INPUT"], "name": "ACN_ControlNet++InputNode", "display_name": "ControlNet++ Input \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/ControlNet++", "output_node": false}, "ACN_CtrLoRALoader": {"input": {"required": {"base": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]], "lora": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}}, "input_order": {"required": ["base", "lora"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_CtrLoRALoader", "display_name": "Load CtrLoRA Model \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/CtrLoRA", "output_node": false}, "ACN_ReferencePreprocessor": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"], "latent_size": ["LATENT"]}}, "input_order": {"required": ["image", "vae", "latent_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["proc_IMAGE"], "name": "ACN_ReferencePreprocessor", "display_name": "Reference Preproccessor \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/Reference/preprocess", "output_node": false}, "ACN_ReferenceControlNet": {"input": {"required": {"reference_type": [["reference_attn", "reference_adain", "reference_attn+adain"]], "style_fidelity": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["reference_type", "style_fidelity", "ref_weight"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_ReferenceControlNet", "display_name": "Reference ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/Reference", "output_node": false}, "ACN_ReferenceControlNetFinetune": {"input": {"required": {"attn_style_fidelity": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_style_fidelity": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["attn_style_fidelity", "attn_ref_weight", "attn_strength", "adain_style_fidelity", "adain_ref_weight", "adain_strength"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ACN_ReferenceControlNetFinetune", "display_name": "Reference ControlNet (Finetune) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "Adv-ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d/Reference", "output_node": false}, "LoadImagesFromDirectory": {"input": {"required": {"directory": ["STRING", {"default": ""}]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "start_index": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "start_index"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "INT"], "name": "LoadImagesFromDirectory", "display_name": "\ud83d\udeabLoad Images [DEPRECATED] \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false}, "ScaledSoftControlNetWeights": {"input": {"required": {"base_multiplier": ["FLOAT", {"default": 0.825, "min": 0.0, "max": 1.0, "step": 0.001}], "flip_weights": ["BOOLEAN", {"default": false}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["base_multiplier", "flip_weights"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "ScaledSoftControlNetWeights", "display_name": "Scaled Soft Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false}, "SoftControlNetWeights": {"input": {"required": {"weight_00": ["FLOAT", {"default": 0.09941396206337118, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_01": ["FLOAT", {"default": 0.12050177219802567, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_02": ["FLOAT", {"default": 0.14606275417942507, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_03": ["FLOAT", {"default": 0.17704576264172736, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_04": ["FLOAT", {"default": 0.214600924414215, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_05": ["FLOAT", {"default": 0.26012233262329093, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_06": ["FLOAT", {"default": 0.3152997971191405, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_07": ["FLOAT", {"default": 0.3821815722656249, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_08": ["FLOAT", {"default": 0.4632503906249999, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_09": ["FLOAT", {"default": 0.561515625, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_10": ["FLOAT", {"default": 0.6806249999999999, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_11": ["FLOAT", {"default": 0.825, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_12": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "flip_weights": ["BOOLEAN", {"default": false}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["weight_00", "weight_01", "weight_02", "weight_03", "weight_04", "weight_05", "weight_06", "weight_07", "weight_08", "weight_09", "weight_10", "weight_11", "weight_12", "flip_weights"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "SoftControlNetWeights", "display_name": "ControlNet Soft Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "CustomControlNetWeights": {"input": {"required": {"weight_00": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_01": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_02": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_03": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_04": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_05": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_06": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_07": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_08": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_09": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_10": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_11": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_12": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "flip_weights": ["BOOLEAN", {"default": false}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["weight_00", "weight_01", "weight_02", "weight_03", "weight_04", "weight_05", "weight_06", "weight_07", "weight_08", "weight_09", "weight_10", "weight_11", "weight_12", "flip_weights"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "CustomControlNetWeights", "display_name": "ControlNet Custom Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "SoftT2IAdapterWeights": {"input": {"required": {"weight_00": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_01": ["FLOAT", {"default": 0.62, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_02": ["FLOAT", {"default": 0.825, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_03": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "flip_weights": ["BOOLEAN", {"default": false}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["weight_00", "weight_01", "weight_02", "weight_03", "flip_weights"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "SoftT2IAdapterWeights", "display_name": "T2IAdapter Soft Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "CustomT2IAdapterWeights": {"input": {"required": {"weight_00": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_01": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_02": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "weight_03": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "flip_weights": ["BOOLEAN", {"default": false}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["weight_00", "weight_01", "weight_02", "weight_03", "flip_weights"], "optional": ["uncond_multiplier", "cn_extras"], "hidden": ["autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "CustomT2IAdapterWeights", "display_name": "T2IAdapter Custom Weights \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "ACN_AdvancedControlNetApply": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"], "timestep_kf": ["TIMESTEP_KEYFRAME"], "latent_kf_override": ["LATENT_KEYFRAME"], "weights_override": ["CONTROL_NET_WEIGHTS"], "model_optional": ["MODEL"], "vae_optional": ["VAE"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive", "negative", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["mask_optional", "timestep_kf", "latent_kf_override", "weights_override", "model_optional", "vae_optional"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING", "MODEL"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "model_opt"], "name": "ACN_AdvancedControlNetApply", "display_name": "Apply Advanced ControlNet \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "ACN_AdvancedControlNetApplySingle": {"input": {"required": {"conditioning": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"], "timestep_kf": ["TIMESTEP_KEYFRAME"], "latent_kf_override": ["LATENT_KEYFRAME"], "weights_override": ["CONTROL_NET_WEIGHTS"], "model_optional": ["MODEL"], "vae_optional": ["VAE"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["conditioning", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["mask_optional", "timestep_kf", "latent_kf_override", "weights_override", "model_optional", "vae_optional"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "MODEL"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "model_opt"], "name": "ACN_AdvancedControlNetApplySingle", "display_name": "Apply Advanced ControlNet(1) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "ControlNetLoaderAdvanced": {"input": {"required": {"control_net_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}, "optional": {"tk_optional": ["TIMESTEP_KEYFRAME"]}}, "input_order": {"required": ["control_net_name"], "optional": ["tk_optional"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ControlNetLoaderAdvanced", "display_name": "Load Advanced ControlNet Model \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "DiffControlNetLoaderAdvanced": {"input": {"required": {"model": ["MODEL"], "control_net_name": [["FLUX.1-dev-Controlnet-Inpainting-Beta.safetensors", "UnionFlux.safetensors", "control_sd15_canny.pth", "control_sd15_depth.pth", "control_sd15_normal.pth", "control_v11f1p_sd15_depth_fp16.safetensors", "control_v11p_sd15_lineart_fp16.safetensors", "control_v11p_sd15_openpose.pth", "diffusers_xl_canny_full.safetensors", "diffusers_xl_depth_full.safetensors", "flux-canny-controlnet-v3.safetensors", "flux-depth-controlnet-v3.safetensors", "flux1-jasperai-dev-upscaler.safetensors", "jasperai_flux_depth_controlnet.safetensors", "jasperai_flux_surface_normals_controlnet.safetensors", "sai_xl_canny_256lora.safetensors", "sai_xl_depth_256lora.safetensors"]]}, "optional": {"tk_optional": ["TIMESTEP_KEYFRAME"]}, "hidden": {"autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["model", "control_net_name"], "optional": ["tk_optional"], "hidden": ["autosize"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "DiffControlNetLoaderAdvanced", "display_name": "Load Advanced ControlNet Model (diff) \ud83d\udec2\ud83c\udd50\ud83c\udd52\ud83c\udd5d", "description": "", "python_module": "custom_nodes.ComfyUI-Advanced-ControlNet", "category": "", "output_node": false, "deprecated": true}, "Int": {"input": {"required": {"Number": ["STRING", {}]}}, "input_order": {"required": ["Number"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "Int", "display_name": "Int", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "Literals", "output_node": false}, "Float": {"input": {"required": {"Number": ["STRING", {}]}}, "input_order": {"required": ["Number"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "Float", "display_name": "Float", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "Literals", "output_node": false}, "String": {"input": {"required": {"String": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["String"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "String", "display_name": "String", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "Literals", "output_node": false}, "KepStringLiteral": {"input": {"required": {"String": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["String"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "KepStringLiteral", "display_name": "String", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "Literals", "output_node": false}, "Operation": {"input": {"required": {"A Type": [["Int", "Float"]], "B Type": [["Int", "Float"]], "Operation": [["A+B", "A-B", "A*B", "A/B"]]}, "optional": {"A - Int": ["INT", {"forceInput": true}], "A - Float": ["FLOAT", {"forceInput": true}], "B - Int": ["INT", {"forceInput": true}], "B - Float": ["FLOAT", {"forceInput": true}]}}, "input_order": {"required": ["A Type", "B Type", "Operation"], "optional": ["A - Int", "A - Float", "B - Int", "B - Float"]}, "output": ["INT", "FLOAT"], "output_is_list": [false, false], "output_name": ["INT", "FLOAT"], "name": "Operation", "display_name": "Operation", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "Literals", "output_node": false}, "Checkpoint": {"input": {"required": {"literal": ["STRING", {"multiline": true, "default": "CRM.pth\ncardosAnime_v20.safetensors\ndynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors\nepicrealism_naturalSinRC1VAE.safetensors\nflat2DAnimerge_v45Sharp.safetensors\njuggernautXL_juggXIByRundiffusion.safetensors\njuggernautXL_v9Rdphoto2Lightning.safetensors\njuggernaut_reborn.safetensors\nltx-video-2b-v0.9.5.safetensors\nphoton_v1.safetensors\nrealisticVisionV60B1_v51HyperVAE.safetensors\nsd_xl_base_1.0_0.9vae.safetensors\nturbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"}]}}, "input_order": {"required": ["literal"]}, "output": ["*"], "output_is_list": [true], "output_name": ["Selected Checkpoints"], "name": "Checkpoint", "display_name": "Checkpoint", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "List Stuff", "output_node": false}, "Lora": {"input": {"required": {"literal": ["STRING", {"multiline": true, "default": "AnimateLCM_sd15_t2v_lora.safetensors\nC4D.safetensors\nFLUX.1-Turbo-Alpha.safetensors\nRetro_Comic_Flux_v1_renderartist.safetensors\nSkinDetails_flux_lora_v8.safetensors\nSoccer_Uniform_By_Stable_Yogi.safetensors\ncomfyui_subject_lora16.safetensors\nflux_dev_frostinglane_araminta_k.safetensors\nflux_realism_lora.safetensors\nhunyuan_evelyn.safetensors\nhunyuan_flat_color_v2.safetensors\nhunyuan_hunter.safetensors\nhunyuan_redhairedwoman.safetensors\nhunyuan_werewolf.safetensors\nip-adapter-faceid-plusv2_sd15_lora.safetensors\nip-adapter-faceid-plusv2_sdxl_lora.safetensors\nip-adapter-faceid_sd15_lora.safetensors\nip-adapter-faceid_sdxl_lora.safetensors\nps1_style_SDXL_v2.safetensors\nsdxl_lightning_4step_lora.safetensors\nyarn_art_Flux_LoRA.safetensors"}]}}, "input_order": {"required": ["literal"]}, "output": ["*"], "output_is_list": [true], "output_name": ["Selected Loras"], "name": "Lora", "display_name": "Lora", "description": "", "python_module": "custom_nodes.ComfyLiterals", "category": "List Stuff", "output_node": false}, "Mask By Text": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "precision": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "normalize": [["no", "yes"]]}}, "input_order": {"required": ["image", "prompt", "negative_prompt", "precision", "normalize"]}, "output": ["IMAGE", "IMAGE"], "output_is_list": [false, false], "output_name": ["thresholded_mask", "raw_mask"], "name": "Mask By Text", "display_name": "Mask By Text", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Mask Morphology": {"input": {"required": {"image": ["IMAGE"], "distance": ["INT", {"default": 5, "min": 0, "max": 128, "step": 1}], "op": [["dilate", "erode", "open", "close"]]}}, "input_order": {"required": ["image", "distance", "op"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Mask Morphology", "display_name": "Mask Morphology", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Combine Masks": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "op": [["union (max)", "intersection (min)", "difference", "multiply", "multiply_alpha", "add", "greater_or_equal", "greater"]], "clamp_result": [["yes", "no"]], "round_result": [["no", "yes"]]}}, "input_order": {"required": ["image1", "image2", "op", "clamp_result", "round_result"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Combine Masks", "display_name": "Combine Masks", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Unary Mask Op": {"input": {"required": {"image": ["IMAGE"], "op": [["invert", "average", "round", "clamp", "abs"]]}}, "input_order": {"required": ["image", "op"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Unary Mask Op", "display_name": "Unary Mask Op", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Unary Image Op": {"input": {"required": {"image": ["IMAGE"], "op": [["invert", "average", "round", "clamp", "abs"]]}}, "input_order": {"required": ["image", "op"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Unary Image Op", "display_name": "Unary Image Op", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Blur": {"input": {"required": {"image": ["IMAGE"], "radius": ["INT", {"default": 10, "min": 0, "max": 48, "step": 1}], "sigma_factor": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 3.0, "step": 0.01}]}}, "input_order": {"required": ["image", "radius", "sigma_factor"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Blur", "display_name": "Blur", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Image To Mask": {"input": {"required": {"image": ["IMAGE"], "method": [["intensity", "alpha"]]}}, "input_order": {"required": ["image", "method"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "Image To Mask", "display_name": "Image To Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Mix Images By Mask": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "mask": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2", "mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Mix Images By Mask", "display_name": "Mix Images By Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Mix Color By Mask": {"input": {"required": {"image": ["IMAGE"], "r": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "g": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "b": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "mask": ["IMAGE"]}}, "input_order": {"required": ["image", "r", "g", "b", "mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Mix Color By Mask", "display_name": "Mix Color By Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Mask To Region": {"input": {"required": {"mask": ["IMAGE"], "padding": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "constraints": [["keep_ratio", "keep_ratio_divisible", "multiple_of", "ignore"]], "constraint_x": ["INT", {"default": 64, "min": 2, "max": 1048576, "step": 1}], "constraint_y": ["INT", {"default": 64, "min": 2, "max": 1048576, "step": 1}], "min_width": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "min_height": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "batch_behavior": [["match_ratio", "match_size"]]}}, "input_order": {"required": ["mask", "padding", "constraints", "constraint_x", "constraint_y", "min_width", "min_height", "batch_behavior"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Mask To Region", "display_name": "Mask To Region", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Cut By Mask": {"input": {"required": {"image": ["IMAGE"], "mask": ["IMAGE"], "force_resize_width": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "force_resize_height": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}]}, "optional": {"mask_mapping_optional": ["MASK_MAPPING"]}}, "input_order": {"required": ["image", "mask", "force_resize_width", "force_resize_height"], "optional": ["mask_mapping_optional"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Cut By Mask", "display_name": "Cut By Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Paste By Mask": {"input": {"required": {"image_base": ["IMAGE"], "image_to_paste": ["IMAGE"], "mask": ["IMAGE"], "resize_behavior": [["resize", "keep_ratio_fill", "keep_ratio_fit", "source_size", "source_size_unmasked"]]}, "optional": {"mask_mapping_optional": ["MASK_MAPPING"]}}, "input_order": {"required": ["image_base", "image_to_paste", "mask", "resize_behavior"], "optional": ["mask_mapping_optional"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Paste By Mask", "display_name": "Paste By Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Get Image Size": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["width", "height"], "name": "Get Image Size", "display_name": "Get Image Size", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Change Channel Count": {"input": {"required": {"image": ["IMAGE"], "kind": [["mask", "RGB", "RGBA"]]}}, "input_order": {"required": ["image", "kind"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Change Channel Count", "display_name": "Change Channel Count", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Constant Mask": {"input": {"required": {"value": ["FLOAT", {"default": 0.0, "min": -8.0, "max": 8.0, "step": 0.01}], "explicit_height": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "explicit_width": ["INT", {"default": 0, "min": 0, "max": 1048576, "step": 1}]}, "optional": {"copy_image_size": ["IMAGE"]}}, "input_order": {"required": ["value", "explicit_height", "explicit_width"], "optional": ["copy_image_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Constant Mask", "display_name": "Constant Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Prune By Mask": {"input": {"required": {"image": ["IMAGE"], "mask": ["IMAGE"]}}, "input_order": {"required": ["image", "mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Prune By Mask", "display_name": "Prune By Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Separate Mask Components": {"input": {"required": {"mask": ["IMAGE"]}}, "input_order": {"required": ["mask"]}, "output": ["IMAGE", "MASK_MAPPING"], "output_is_list": [false, false], "output_name": ["mask", "mask_mappings"], "name": "Separate Mask Components", "display_name": "Separate Mask Components", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Create Rect Mask": {"input": {"required": {"mode": [["percent", "pixels"]], "origin": [["topleft", "bottomleft", "topright", "bottomright"]], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1048576, "step": 1}], "width": ["FLOAT", {"default": 50, "min": 0, "max": 1048576, "step": 1}], "height": ["FLOAT", {"default": 50, "min": 0, "max": 1048576, "step": 1}], "image_width": ["INT", {"default": 512, "min": 64, "max": 1048576, "step": 64}], "image_height": ["INT", {"default": 512, "min": 64, "max": 1048576, "step": 64}]}, "optional": {"copy_image_size": ["IMAGE"]}}, "input_order": {"required": ["mode", "origin", "x", "y", "width", "height", "image_width", "image_height"], "optional": ["copy_image_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Create Rect Mask", "display_name": "Create Rect Mask", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Make Image Batch": {"input": {"required": {"image1": ["IMAGE"]}, "optional": {"image2": ["IMAGE"], "image3": ["IMAGE"], "image4": ["IMAGE"], "image5": ["IMAGE"], "image6": ["IMAGE"]}}, "input_order": {"required": ["image1"], "optional": ["image2", "image3", "image4", "image5", "image6"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Make Image Batch", "display_name": "Make Image Batch", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Create QR Code": {"input": {"required": {"text": ["STRING", {"multiline": true}], "size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "qr_version": ["INT", {"default": 1, "min": 1, "max": 40, "step": 1}], "error_correction": [["L", "M", "Q", "H"], {"default": "H"}], "box_size": ["INT", {"default": 10, "min": 1, "max": 100, "step": 1}], "border": ["INT", {"default": 4, "min": 0, "max": 100, "step": 1}]}}, "input_order": {"required": ["text", "size", "qr_version", "error_correction", "box_size", "border"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Create QR Code", "display_name": "Create QR Code", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Convert Color Space": {"input": {"required": {"in_space": [["RGB", "HSV", "HSL"]], "out_space": [["RGB", "HSV", "HSL"]], "image": ["IMAGE"]}}, "input_order": {"required": ["in_space", "out_space", "image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Convert Color Space", "display_name": "Convert Color Space", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "MasqueradeIncrementer": {"input": {"required": {"seed": ["INT", {"default": 0, "min": -1, "max": 18446744073709551615, "step": 1}], "max_value": ["INT", {"default": 1, "min": 1, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["seed", "max_value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "MasqueradeIncrementer", "display_name": "Incrementer", "description": "", "python_module": "custom_nodes.masquerade-nodes-comfyui", "category": "Masquerade Nodes", "output_node": false}, "Context Big (rgthree)": {"input": {"required": {}, "optional": {"base_ctx": ["RGTHREE_CONTEXT"], "model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent": ["LATENT"], "images": ["IMAGE"], "seed": ["INT", {"forceInput": true}], "steps": ["INT", {"forceInput": true}], "step_refiner": ["INT", {"forceInput": true}], "cfg": ["FLOAT", {"forceInput": true}], "ckpt_name": [["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], {"forceInput": true}], "sampler": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], {"forceInput": true}], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], {"forceInput": true}], "clip_width": ["INT", {"forceInput": true}], "clip_height": ["INT", {"forceInput": true}], "text_pos_g": ["STRING", {"forceInput": true}], "text_pos_l": ["STRING", {"forceInput": true}], "text_neg_g": ["STRING", {"forceInput": true}], "text_neg_l": ["STRING", {"forceInput": true}], "mask": ["MASK"], "control_net": ["CONTROL_NET"]}, "hidden": {}}, "input_order": {"required": [], "optional": ["base_ctx", "model", "clip", "vae", "positive", "negative", "latent", "images", "seed", "steps", "step_refiner", "cfg", "ckpt_name", "sampler", "scheduler", "clip_width", "clip_height", "text_pos_g", "text_pos_l", "text_neg_g", "text_neg_l", "mask", "control_net"], "hidden": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT", "INT", "INT", "FLOAT", ["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], ["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], "INT", "INT", "STRING", "STRING", "STRING", "STRING", "MASK", "CONTROL_NET"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED", "STEPS", "STEP_REFINER", "CFG", "CKPT_NAME", "SAMPLER", "SCHEDULER", "CLIP_WIDTH", "CLIP_HEIGHT", "TEXT_POS_G", "TEXT_POS_L", "TEXT_NEG_G", "TEXT_NEG_L", "MASK", "CONTROL_NET"], "name": "Context Big (rgthree)", "display_name": "Context Big (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context (rgthree)": {"input": {"required": {}, "optional": {"base_ctx": ["RGTHREE_CONTEXT"], "model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent": ["LATENT"], "images": ["IMAGE"], "seed": ["INT", {"forceInput": true}]}, "hidden": {"version": "FLOAT"}}, "input_order": {"required": [], "optional": ["base_ctx", "model", "clip", "vae", "positive", "negative", "latent", "images", "seed"], "hidden": ["version"]}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED"], "name": "Context (rgthree)", "display_name": "Context (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Switch (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED"], "name": "Context Switch (rgthree)", "display_name": "Context Switch (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Switch Big (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT", "INT", "INT", "FLOAT", ["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], ["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], "INT", "INT", "STRING", "STRING", "STRING", "STRING", "MASK", "CONTROL_NET"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED", "STEPS", "STEP_REFINER", "CFG", "CKPT_NAME", "SAMPLER", "SCHEDULER", "CLIP_WIDTH", "CLIP_HEIGHT", "TEXT_POS_G", "TEXT_POS_L", "TEXT_NEG_G", "TEXT_NEG_L", "MASK", "CONTROL_NET"], "name": "Context Switch Big (rgthree)", "display_name": "Context Switch Big (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Merge (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED"], "name": "Context Merge (rgthree)", "display_name": "Context Merge (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Merge Big (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT", "INT", "INT", "FLOAT", ["CRM.pth", "cardosAnime_v20.safetensors", "dynavisionXLAllInOneStylized_releaseV0610Bakedvae.safetensors", "epicrealism_naturalSinRC1VAE.safetensors", "flat2DAnimerge_v45Sharp.safetensors", "juggernautXL_juggXIByRundiffusion.safetensors", "juggernautXL_v9Rdphoto2Lightning.safetensors", "juggernaut_reborn.safetensors", "ltx-video-2b-v0.9.5.safetensors", "photon_v1.safetensors", "realisticVisionV60B1_v51HyperVAE.safetensors", "sd_xl_base_1.0_0.9vae.safetensors", "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"], ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], ["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"], "INT", "INT", "STRING", "STRING", "STRING", "STRING", "MASK", "CONTROL_NET"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED", "STEPS", "STEP_REFINER", "CFG", "CKPT_NAME", "SAMPLER", "SCHEDULER", "CLIP_WIDTH", "CLIP_HEIGHT", "TEXT_POS_G", "TEXT_POS_L", "TEXT_NEG_G", "TEXT_NEG_L", "MASK", "CONTROL_NET"], "name": "Context Merge Big (rgthree)", "display_name": "Context Merge Big (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Display Int (rgthree)": {"input": {"required": {"input": ["INT", {"forceInput": true}]}}, "input_order": {"required": ["input"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Display Int (rgthree)", "display_name": "Display Int (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": true}, "Display Any (rgthree)": {"input": {"required": {"source": ["*", {}]}}, "input_order": {"required": ["source"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Display Any (rgthree)", "display_name": "Display Any (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": true}, "Lora Loader Stack (rgthree)": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_01": [["None", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_01": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lora_02": [["None", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_02": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lora_03": [["None", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_03": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lora_04": [["None", "AnimateLCM_sd15_t2v_lora.safetensors", "C4D.safetensors", "FLUX.1-Turbo-Alpha.safetensors", "Retro_Comic_Flux_v1_renderartist.safetensors", "SkinDetails_flux_lora_v8.safetensors", "Soccer_Uniform_By_Stable_Yogi.safetensors", "comfyui_subject_lora16.safetensors", "flux_dev_frostinglane_araminta_k.safetensors", "flux_realism_lora.safetensors", "hunyuan_evelyn.safetensors", "hunyuan_flat_color_v2.safetensors", "hunyuan_hunter.safetensors", "hunyuan_redhairedwoman.safetensors", "hunyuan_werewolf.safetensors", "ip-adapter-faceid-plusv2_sd15_lora.safetensors", "ip-adapter-faceid-plusv2_sdxl_lora.safetensors", "ip-adapter-faceid_sd15_lora.safetensors", "ip-adapter-faceid_sdxl_lora.safetensors", "ps1_style_SDXL_v2.safetensors", "sdxl_lightning_4step_lora.safetensors", "yarn_art_Flux_LoRA.safetensors"]], "strength_04": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "clip", "lora_01", "strength_01", "lora_02", "strength_02", "lora_03", "strength_03", "lora_04", "strength_04"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "Lora Loader Stack (rgthree)", "display_name": "Lora Loader Stack (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Seed (rgthree)": {"input": {"required": {"seed": ["INT", {"default": 0, "min": -1125899906842624, "max": 1125899906842624}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["seed"], "hidden": ["prompt", "extra_pnginfo", "unique_id"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["SEED"], "name": "Seed (rgthree)", "display_name": "Seed (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image Inset Crop (rgthree)": {"input": {"required": {"image": ["IMAGE"], "measurement": [["Pixels", "Percentage"]], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["image", "measurement", "left", "right", "top", "bottom"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Inset Crop (rgthree)", "display_name": "Image Inset Crop (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Prompt (rgthree)": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_model": ["MODEL"], "opt_clip": ["CLIP"], "insert_lora": [["CHOOSE", "DISABLE LORAS", "AnimateLCM_sd15_t2v_lora", "C4D", "FLUX.1-Turbo-Alpha", "Retro_Comic_Flux_v1_renderartist", "SkinDetails_flux_lora_v8", "Soccer_Uniform_By_Stable_Yogi", "comfyui_subject_lora16", "flux_dev_frostinglane_araminta_k", "flux_realism_lora", "hunyuan_evelyn", "hunyuan_flat_color_v2", "hunyuan_hunter", "hunyuan_redhairedwoman", "hunyuan_werewolf", "ip-adapter-faceid-plusv2_sd15_lora", "ip-adapter-faceid-plusv2_sdxl_lora", "ip-adapter-faceid_sd15_lora", "ip-adapter-faceid_sdxl_lora", "ps1_style_SDXL_v2", "sdxl_lightning_4step_lora", "yarn_art_Flux_LoRA"]], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt"], "optional": ["opt_model", "opt_clip", "insert_lora", "insert_embedding", "insert_saved"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "MODEL", "CLIP", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["CONDITIONING", "MODEL", "CLIP", "TEXT"], "name": "Power Prompt (rgthree)", "display_name": "Power Prompt (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Prompt - Simple (rgthree)": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_clip": ["CLIP"], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt"], "optional": ["opt_clip", "insert_embedding", "insert_saved"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "STRING"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "TEXT"], "name": "Power Prompt - Simple (rgthree)", "display_name": "Power Prompt - Simple (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "KSampler Config (rgthree)": {"input": {"required": {"steps_total": ["INT", {"default": 30, "min": 1, "max": 16384, "step": 1}], "refiner_step": ["INT", {"default": 24, "min": 1, "max": 16384, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.5}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]]}}, "input_order": {"required": ["steps_total", "refiner_step", "cfg", "sampler_name", "scheduler"]}, "output": ["INT", "INT", "FLOAT", ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"], ["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "output_is_list": [false, false, false, false, false], "output_name": ["STEPS", "REFINER_STEP", "CFG", "SAMPLER", "SCHEDULER"], "name": "KSampler Config (rgthree)", "display_name": "KSampler Config (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SDXL Empty Latent Image (rgthree)": {"input": {"required": {"dimensions": [["1536 x 640   (landscape)", "1344 x 768   (landscape)", "1216 x 832   (landscape)", "1152 x 896   (landscape)", "1024 x 1024  (square)", " 896 x 1152  (portrait)", " 832 x 1216  (portrait)", " 768 x 1344  (portrait)", " 640 x 1536  (portrait)"], {"default": "1024 x 1024  (square)"}], "clip_scale": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 10.0, "step": 0.5}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["dimensions", "clip_scale", "batch_size"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["LATENT", "CLIP_WIDTH", "CLIP_HEIGHT"], "name": "SDXL Empty Latent Image (rgthree)", "display_name": "SDXL Empty Latent Image (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SDXL Power Prompt - Positive (rgthree)": {"input": {"required": {"prompt_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "prompt_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_model": ["MODEL"], "opt_clip": ["CLIP"], "opt_clip_width": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "opt_clip_height": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "insert_lora": [["CHOOSE", "DISABLE LORAS", "AnimateLCM_sd15_t2v_lora", "C4D", "FLUX.1-Turbo-Alpha", "Retro_Comic_Flux_v1_renderartist", "SkinDetails_flux_lora_v8", "Soccer_Uniform_By_Stable_Yogi", "comfyui_subject_lora16", "flux_dev_frostinglane_araminta_k", "flux_realism_lora", "hunyuan_evelyn", "hunyuan_flat_color_v2", "hunyuan_hunter", "hunyuan_redhairedwoman", "hunyuan_werewolf", "ip-adapter-faceid-plusv2_sd15_lora", "ip-adapter-faceid-plusv2_sdxl_lora", "ip-adapter-faceid_sd15_lora", "ip-adapter-faceid_sdxl_lora", "ps1_style_SDXL_v2", "sdxl_lightning_4step_lora", "yarn_art_Flux_LoRA"]], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]], "target_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "target_height": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_height": ["INT", {"default": -1, "min": -1, "max": 16384}]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt_g", "prompt_l"], "optional": ["opt_model", "opt_clip", "opt_clip_width", "opt_clip_height", "insert_lora", "insert_embedding", "insert_saved", "target_width", "target_height", "crop_width", "crop_height"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "MODEL", "CLIP", "STRING", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["CONDITIONING", "MODEL", "CLIP", "TEXT_G", "TEXT_L"], "name": "SDXL Power Prompt - Positive (rgthree)", "display_name": "SDXL Power Prompt - Positive (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SDXL Power Prompt - Simple / Negative (rgthree)": {"input": {"required": {"prompt_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "prompt_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_clip": ["CLIP"], "opt_clip_width": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "opt_clip_height": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]], "target_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "target_height": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_height": ["INT", {"default": -1, "min": -1, "max": 16384}]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt_g", "prompt_l"], "optional": ["opt_clip", "opt_clip_width", "opt_clip_height", "insert_embedding", "insert_saved", "target_width", "target_height", "crop_width", "crop_height"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["CONDITIONING", "TEXT_G", "TEXT_L"], "name": "SDXL Power Prompt - Simple / Negative (rgthree)", "display_name": "SDXL Power Prompt - Simple / Negative (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Any Switch (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Any Switch (rgthree)", "display_name": "Any Switch (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image Comparer (rgthree)": {"input": {"required": {}, "optional": {"image_a": ["IMAGE"], "image_b": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": [], "optional": ["image_a", "image_b"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Image Comparer (rgthree)", "display_name": "Image Comparer (rgthree)", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": true}, "Power Lora Loader (rgthree)": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"]}, "optional": {}, "hidden": {}}, "input_order": {"required": ["model", "clip"], "optional": [], "hidden": []}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "Power Lora Loader (rgthree)", "display_name": "Power Lora Loader (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Primitive (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Power Primitive (rgthree)", "display_name": "Power Primitive (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image or Latent Size (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["WIDTH", "HEIGHT"], "name": "Image or Latent Size (rgthree)", "display_name": "Image or Latent Size (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "UltralyticsDetectorProvider": {"input": {"required": {"model_name": [["bbox/face_yolov8m.pt", "bbox/hand_yolov8s.pt", "segm/person_yolov8m-seg.pt"]]}}, "input_order": {"required": ["model_name"]}, "output": ["BBOX_DETECTOR", "SEGM_DETECTOR"], "output_is_list": [false, false], "output_name": ["BBOX_DETECTOR", "SEGM_DETECTOR"], "name": "UltralyticsDetectorProvider", "display_name": "UltralyticsDetectorProvider", "description": "", "python_module": "custom_nodes.ComfyUI-Impact-Subpack", "category": "ImpactPack", "output_node": false}, "VHS_VideoCombine": {"input": {"required": {"images": ["IMAGE"], "frame_rate": ["FLOAT", {"default": 8, "min": 1, "step": 1}], "loop_count": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "filename_prefix": ["STRING", {"default": "AnimateDiff"}], "format": [["image/gif", "image/webp", "video/16bit-png", "video/8bit-png", ["video/ProRes", [["profile", ["1", "2", "3", "4"], {"default": "3"}]]], ["video/av1-webm", [["pix_fmt", ["yuv420p10le", "yuv420p"]], ["crf", "INT", {"default": 23, "min": 0, "max": 100, "step": 1}], ["input_color_depth", ["8bit", "16bit"]], ["save_metadata", "BOOLEAN", {"default": true}]]], ["video/ffmpeg-gif", [["dither", ["bayer", "heckbert", "floyd_steinberg", "sierra2", "sierra2_4a", "sierra3", "burkes", "atkinson", "none"], {"default": "sierra2_4a"}, "[0:v] split [a][b]; [a] palettegen=reserve_transparent=on:transparency_color=ffffff [p]; [b][p] paletteuse=dither=$val"]]], ["video/h264-mp4", [["pix_fmt", ["yuv420p", "yuv420p10le"]], ["crf", "INT", {"default": 19, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]]], ["video/h265-mp4", [["pix_fmt", ["yuv420p10le", "yuv420p"]], ["crf", "INT", {"default": 22, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}]]], ["video/nvenc_h264-mp4", [["pix_fmt", ["yuv420p", "yuv420p10le", "rgba"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]]], ["video/nvenc_hevc-mp4", [["pix_fmt", ["yuv420p", "yuv420p10le", "rgba"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]]], ["video/webm", [["pix_fmt", ["yuv420p", "yuva420p"]], ["crf", "INT", {"default": 20, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]]]]], "pingpong": ["BOOLEAN", {"default": false}], "save_output": ["BOOLEAN", {"default": true}]}, "optional": {"audio": ["AUDIO"], "meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["images", "frame_rate", "loop_count", "filename_prefix", "format", "pingpong", "save_output"], "optional": ["audio", "meta_batch", "vae"], "hidden": ["prompt", "extra_pnginfo", "unique_id"]}, "output": ["VHS_FILENAMES"], "output_is_list": [false], "output_name": ["Filenames"], "name": "VHS_VideoCombine", "display_name": "Video Combine \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Combine \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine an image sequence into a video</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be turned into a video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: (optional) audio to add to the video</div></div><div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long image sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided, the node will take latents as input instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Unlike on Load Video, this isn't always a strict upgrade over using a standalone VAE Decode.</div><div style=\"font-size: 1em\">If you have multiple Video Combine outputs, then the VAE decode will be performed for each output node increasing execution time</div><div style=\"font-size: 1em\">If you make any change to output settings on the Video Combine (such as changing the output format), the VAE decode will be performed again as the decoded result is (by design) not cached</div></div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frame_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_rate: The frame rate which will be used for the output video. Consider converting this to an input and connecting this to a Load Video with Video Info(Loaded)->fps. When including audio, failure to properly set this will result in audio desync</div></div><div vhs_title=\"loop_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loop_count: The number of additional times the video should repeat. Can cause performance issues when used with long (100+ frames) sequences</div></div><div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A prefix to add to the name of the output filename. This can include subfolders or format strings.</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: The output format to use. Formats starting with, 'image' are saved with PIL, but formats starting with 'video' utilize the video_formats system. 'video' options require ffmpeg and selecting one frequently adds additional options to the node.</div></div><div vhs_title=\"pingpong\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pingpong: Play the video normally, then repeat the video in reverse so that it 'pingpongs' back and forth. This is frequently used to minimize the appearance of skips on very short animations.</div></div><div vhs_title=\"save_output\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_output: Specifies if output files should be saved to the output folder, or the temporary output folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the processed result. If advanced previews is enabled, the output is always converted to a format viewable from the browser. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div><div vhs_title=\"Common Format Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Common Format Widgets: <div vhs_title=\"crf\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crf: Determines how much to prioritize quality over filesize. Numbers vary between formats, but on each format that includes it, the default value provides visually loss less output</div></div><div vhs_title=\"pix_fmt\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pix_fmt: The pixel format to use for output. Alternative options will often have higher quality at the cost of increased file size and reduced compatibility with external software.<div style=\"font-size: 1em\"><div vhs_title=\"yuv420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p: The most common and default format</div></div><div vhs_title=\"yuv420p10le\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p10le: Use 10 bit color depth. This can improve color quality when combined with 16bit input color depth</div></div><div vhs_title=\"yuva420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuva420p: Include transparency in the output video</div></div></div></div></div><div vhs_title=\"input_color_depth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">input_color_depth: VHS supports outputting 16bit images. While this produces higher quality output, the difference usually isn't visible without postprocessing and it significantly increases file size and processing time.</div></div><div vhs_title=\"save_metadata\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_metadata: Determines if metadata for the workflow should be included in the output video file</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": true}, "VHS_LoadVideo": {"input": {"required": {"video": [[]], "force_rate": ["INT", {"default": 0, "min": 0, "max": 60, "step": 1}], "force_size": [["Disabled", "Custom Height", "Custom Width", "Custom", "256x?", "?x256", "256x256", "512x?", "?x512", "512x512"]], "custom_width": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "custom_height": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "force_size", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["meta_batch", "vae"], "hidden": ["unique_id"]}, "output": ["IMAGE", "INT", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "frame_count", "audio", "video_info"], "name": "VHS_LoadVideo", "display_name": "Load Video (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoPath": {"input": {"required": {"video": ["STRING", {"placeholder": "X://insert/path/here.mp4", "vhs_path_extensions": ["webm", "mp4", "mkv", "gif", "mov"]}], "force_rate": ["INT", {"default": 0, "min": 0, "max": 60, "step": 1}], "force_size": [["Disabled", "Custom Height", "Custom Width", "Custom", "256x?", "?x256", "256x256", "512x?", "?x512", "512x512"]], "custom_width": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "custom_height": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "force_size", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["meta_batch", "vae"], "hidden": ["unique_id"]}, "output": ["IMAGE", "INT", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "frame_count", "audio", "video_info"], "name": "VHS_LoadVideoPath", "display_name": "Load Video (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoFFmpeg": {"input": {"required": {"video": [[]], "force_rate": ["INT", {"default": 0, "min": 0, "max": 60, "step": 1}], "force_size": [["Disabled", "Custom Height", "Custom Width", "Custom", "256x?", "?x256", "256x256", "512x?", "?x512", "512x512"]], "custom_width": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "custom_height": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "force_size", "custom_width", "custom_height", "frame_load_cap", "start_time"], "optional": ["meta_batch", "vae"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "mask", "audio", "video_info"], "name": "VHS_LoadVideoFFmpeg", "display_name": "Load Video FFmpeg (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video FFmpeg \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false, "experimental": true}, "VHS_LoadVideoFFmpegPath": {"input": {"required": {"video": ["STRING", {"placeholder": "X://insert/path/here.mp4", "vhs_path_extensions": ["webm", "mp4", "mkv", "gif", "mov"]}], "force_rate": ["INT", {"default": 0, "min": 0, "max": 60, "step": 1}], "force_size": [["Disabled", "Custom Height", "Custom Width", "Custom", "256x?", "?x256", "256x256", "512x?", "?x512", "512x512"]], "custom_width": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "custom_height": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "force_size", "custom_width", "custom_height", "frame_load_cap", "start_time"], "optional": ["meta_batch", "vae"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "mask", "audio", "video_info"], "name": "VHS_LoadVideoFFmpegPath", "display_name": "Load Video FFmpeg (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video FFmpeg (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false, "experimental": true}, "VHS_LoadImagePath": {"input": {"required": {"image": ["STRING", {"placeholder": "X://insert/path/here.png", "vhs_path_extensions": [".tiff", ".pgm", ".tif", ".ppm", ".jpeg", ".jpg", ".png", ".webp", ".bmp"]}], "force_size": [["Disabled", "Custom Height", "Custom Width", "Custom", "256x?", "?x256", "256x256", "512x?", "?x512", "512x512"]], "custom_width": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}], "custom_height": ["INT", {"default": 512, "min": 0, "max": 8192, "step": 8}]}, "optional": {"vae": ["VAE"]}}, "input_order": {"required": ["image", "force_size", "custom_width", "custom_height"], "optional": ["vae"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "mask"], "name": "VHS_LoadImagePath", "display_name": "Load Image (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Image (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Load a single image from a given path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"image\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image: The image file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false, "experimental": true}, "VHS_LoadImages": {"input": {"required": {"directory": [["3d"]]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "meta_batch": ["VHS_BatchManager"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "skip_first_images", "select_every_nth", "meta_batch"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "frame_count"], "name": "VHS_LoadImages", "display_name": "Load Images (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from a subdirectory of the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files</div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"choose folder to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose folder to upload: An upload button is provided to upload a local folder containing images to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImagesPath": {"input": {"required": {"directory": ["STRING", {"placeholder": "X://path/to/images", "vhs_path_extensions": []}]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "meta_batch": ["VHS_BatchManager"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "skip_first_images", "select_every_nth", "meta_batch"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "frame_count"], "name": "VHS_LoadImagesPath", "display_name": "Load Images (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Images (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of images which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Keeps only the first of every n frames and discard the rest.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadAudio": {"input": {"required": {"audio_file": ["STRING", {"default": "input/", "vhs_path_extensions": ["wav", "mp3", "ogg", "m4a", "flac"]}]}, "optional": {"seek_seconds": ["FLOAT", {"default": 0, "min": 0}]}}, "input_order": {"required": ["audio_file"], "optional": ["seek_seconds"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["audio"], "name": "VHS_LoadAudio", "display_name": "Load Audio (Path)\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Audio (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio_file\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio_file: The audio file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"seek_seconds\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">seek_seconds: An offset from the start of the sound file that the audio should start from</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_LoadAudioUpload": {"input": {"required": {"audio": [[]], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01}], "duration": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01}]}}, "input_order": {"required": ["audio", "start_time", "duration"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["audio"], "name": "VHS_LoadAudioUpload", "display_name": "Load Audio (Upload)\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Audio (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from the input directory</div></div><div style=\"font-size: 0.8em\">Very similar in functionality to the built-in LoadAudio. It was originally added before VHS swapped to use Comfy's internal AUDIO format, but provides the additional options for start time and duration</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio file to be loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: An offset from the start of the sound file that the audio should start from</div></div><div vhs_title=\"duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">duration: A maximum limit for the audio. Disabled if 0</div></div><div vhs_title=\"choose audio to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose audio to upload: An upload button is provided to upload an audio file to the input folder</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_AudioToVHSAudio": {"input": {"required": {"audio": ["AUDIO"]}}, "input_order": {"required": ["audio"]}, "output": ["VHS_AUDIO"], "output_is_list": [false], "output_name": ["vhs_audio"], "name": "VHS_AudioToVHSAudio", "display_name": "Audio to legacy VHS_AUDIO\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Audio to legacy VHS_AUDIO \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: An input in the standardized AUDIO format</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the legacy VHS_AUDIO format for use with external nodes</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_VHSAudioToAudio": {"input": {"required": {"vhs_audio": ["VHS_AUDIO"]}}, "input_order": {"required": ["vhs_audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["audio"], "name": "VHS_VHSAudioToAudio", "display_name": "Legacy VHS_AUDIO to Audio\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Legacy VHS_AUDIO to Audio \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An input in the legacy VHS_AUDIO format produced by an external node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the standardized AUDIO format</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_PruneOutputs": {"input": {"required": {"filenames": ["VHS_FILENAMES"], "options": [["Intermediate", "Intermediate and Utility"]]}}, "input_order": {"required": ["filenames", "options"]}, "output": [], "output_is_list": [], "output_name": [], "name": "VHS_PruneOutputs", "display_name": "Prune Outputs \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Prune Outputs \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Automates deletion of undesired outputs from a Video Combine node.</div></div><div style=\"font-size: 0.8em\">Video Combine produces a number of file outputs in addition to the final output. Some of these, such as a video file without audio included, are implementation limitations and are not feasible to solve. As an alternative, the Prune Outputs node is added to automate the deletion of these file outputs if they are not desired</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A connection from a Video Combine node to indicate which outputs should be pruned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"options\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">options: Which files should be deleted<div style=\"font-size: 1em\"><div vhs_title=\"Intermediate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate: Delete any files that were required for intermediate processing but are not the final output, like the no-audio output file when audio is included</div></div><div vhs_title=\"Intermediate and Utility\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate and Utility: Delete all produced files that aren't the final output, including the first frame png</div></div></div></div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": true}, "VHS_BatchManager": {"input": {"required": {"frames_per_batch": ["INT", {"default": 16, "min": 1, "max": 9007199254740991, "step": 1}]}, "hidden": {"prompt": "PROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["frames_per_batch"], "hidden": ["prompt", "unique_id"]}, "output": ["VHS_BatchManager"], "output_is_list": [false], "output_name": ["meta_batch"], "name": "VHS_BatchManager", "display_name": "Meta Batch Manager \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Meta Batch Manager \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split the processing of a very long video into sets of smaller Meta Batches</div></div><div style=\"font-size: 0.8em\">The Meta Batch Manager allows for extremely long input videos to be processed when all other methods for fitting the content in RAM fail. It does not effect VRAM usage.</div><div style=\"font-size: 0.8em\">It must be connected to at least one Input (a Load Video or Load Images) AND at least one Video Combine</div><div style=\"font-size: 0.8em\"><img src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/7cb3fb7e-59d8-4cb2-a09f-9c6698de8b1f style=\"width: 0px; min-width: 100%\"></div><div style=\"font-size: 0.8em\">It functions by holding both the inputs and ouputs open between executions, and automatically requeue's the workflow until one of the inputs is unable to provide additional images.</div><div style=\"font-size: 0.8em\">Because each sub execution only contains a subset of the total frames, each sub execution creates a hard window which temporal smoothing can not be applied across. This results in jumps in the output.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: Add all connected nodes to this Meta Batch</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frames_per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frames_per_batch: How many frames to process for each sub execution. If loading as image, each frame will use about 50MB of RAM (not VRAM), and this can safely be set in the 100-1000 range, depending on available memory. When loading and combining from latent space (no blue image noodles exist), this value can be much higher, around the 2,000 to 20,000 range</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfo": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT", "FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false, false], "output_name": ["source_fps\ud83d\udfe8", "source_frame_count\ud83d\udfe8", "source_duration\ud83d\udfe8", "source_width\ud83d\udfe8", "source_height\ud83d\udfe8", "loaded_fps\ud83d\udfe6", "loaded_frame_count\ud83d\udfe6", "loaded_duration\ud83d\udfe6", "loaded_width\ud83d\udfe6", "loaded_height\ud83d\udfe6"], "name": "VHS_VideoInfo", "display_name": "Video Info \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps\ud83d\udfe8: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count\ud83d\udfe8: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration\ud83d\udfe8: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width\ud83d\udfe8: The width</div></div><div vhs_title=\"source_height\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height\ud83d\udfe8: The height</div></div><div vhs_title=\"loaded_fps\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps\ud83d\udfe6: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count\ud83d\udfe6: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration\ud83d\udfe6: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width\ud83d\udfe6: The width of the video after scaling. These coordinates are in image space even if loading to latent space</div></div><div vhs_title=\"loaded_height\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height\ud83d\udfe6: The height of the video after scaling. These coordinates are in image space even if loading to latent space</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfoSource": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["fps\ud83d\udfe8", "frame_count\ud83d\udfe8", "duration\ud83d\udfe8", "width\ud83d\udfe8", "height\ud83d\udfe8"], "name": "VHS_VideoInfoSource", "display_name": "Video Info (Source) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info Source \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself without accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps\ud83d\udfe8: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count\ud83d\udfe8: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration\ud83d\udfe8: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width\ud83d\udfe8: The original width</div></div><div vhs_title=\"source_height\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height\ud83d\udfe8: The original height</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfoLoaded": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["fps\ud83d\udfe6", "frame_count\ud83d\udfe6", "duration\ud83d\udfe6", "width\ud83d\udfe6", "height\ud83d\udfe6"], "name": "VHS_VideoInfoLoaded", "display_name": "Video Info (Loaded) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info Loaded \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself after accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"loaded_fps\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps\ud83d\udfe6: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count\ud83d\udfe6: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration\ud83d\udfe6: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width\ud83d\udfe6: The width of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div><div vhs_title=\"loaded_height\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height\ud83d\udfe6: The height of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_SelectFilename": {"input": {"required": {"filenames": ["VHS_FILENAMES"], "index": ["INT", {"default": -1, "step": 1, "min": -1}]}}, "input_order": {"required": ["filenames", "index"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["Filename"], "name": "VHS_SelectFilename", "display_name": "Select Filename \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Select Filename \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Select a single filename from the VHS_FILENAMES output by a Video Combine and return it as a string</div></div><div style=\"font-size: 0.8em\">Take care when combining this node with Prune Outputs. The VHS_FILENAMES object is immutable and will always contain the full list of output files, but execution order is undefined behavior (currently, Prune Outputs will generally execute first) and SelectFilename may return a path to a file that no longer exists.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A VHS_FILENAMES from a Video Combine node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename: A string representation of the full output path for the chosen file</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">index: The index of which file should be selected. The default, -1, chooses the most complete output</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VAEEncodeBatched": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1}]}}, "input_order": {"required": ["pixels", "vae", "per_batch"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VHS_VAEEncodeBatched", "display_name": "VAE Encode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Encode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Encode images as latents with a manually specified batch size.</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when encoding images.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Encode or to encode directly from a Load Video</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"pixels\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pixels: The images to be encoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when encoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The encoded latents.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to encode in each batch.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/batched nodes", "output_node": false}, "VHS_VAEDecodeBatched": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1}]}}, "input_order": {"required": ["samples", "vae", "per_batch"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VHS_VAEDecodeBatched", "display_name": "VAE Decode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Decode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Decode latents to images with a manually specified batch size</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when decoding latents.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Decode or to decode from a Video Combine directly</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"samples\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">samples: The latents to be decoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when decoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The decoded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to decode in each batch.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/batched nodes", "output_node": false}, "VHS_SplitLatents": {"input": {"required": {"latents": ["LATENT"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["latents", "split_index"]}, "output": ["LATENT", "INT", "LATENT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["LATENT_A", "A_count", "LATENT_B", "B_count"], "name": "VHS_SplitLatents", "display_name": "Split Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of latents into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_A: The first group of latents</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of latents in group A. This will be equal to split_index unless the latents input has length less than split_index</div></div><div vhs_title=\"LATENT_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_B: The second group of latents</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of latents in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SplitImages": {"input": {"required": {"images": ["IMAGE"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["images", "split_index"]}, "output": ["IMAGE", "INT", "IMAGE", "INT"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE_A", "A_count", "IMAGE_B", "B_count"], "name": "VHS_SplitImages", "display_name": "Split Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of images into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_A: The first group of images</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of images in group A. This will be equal to split_index unless the images input has length less than split_index</div></div><div vhs_title=\"IMAGE_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_B: The second group of images</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of images in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SplitMasks": {"input": {"required": {"mask": ["MASK"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["mask", "split_index"]}, "output": ["MASK", "INT", "MASK", "INT"], "output_is_list": [false, false, false, false], "output_name": ["MASK_A", "A_count", "MASK_B", "B_count"], "name": "VHS_SplitMasks", "display_name": "Split Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of masks into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The masks to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_A: The first group of masks</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of masks in group A. This will be equal to split_index unless the mask input has length less than split_index</div></div><div vhs_title=\"MASK_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_B: The second group of masks</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of masks in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_MergeLatents": {"input": {"required": {"latents_A": ["LATENT"], "latents_B": ["LATENT"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["latents_A", "latents_B", "merge_strategy", "scale_method", "crop"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_MergeLatents", "display_name": "Merge Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of latents into a single group of latents</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_A: The first group of latents</div></div><div vhs_title=\"latents_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_B: The first group of latents</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The combined group of latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_MergeImages": {"input": {"required": {"images_A": ["IMAGE"], "images_B": ["IMAGE"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["images_A", "images_B", "merge_strategy", "scale_method", "crop"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_MergeImages", "display_name": "Merge Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of images into a single group of images</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_A: The first group of images</div></div><div vhs_title=\"images_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_B: The first group of images</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The combined group of images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_MergeMasks": {"input": {"required": {"mask_A": ["MASK"], "mask_B": ["MASK"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["mask_A", "mask_B", "merge_strategy", "scale_method", "crop"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_MergeMasks", "display_name": "Merge Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of masks into a single group of masks</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_A: The first group of masks</div></div><div vhs_title=\"mask_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_B: The first group of masks</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The combined group of masks</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_GetLatentCount": {"input": {"required": {"latents": ["LATENT"]}}, "input_order": {"required": ["latents"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetLatentCount", "display_name": "Get Latent Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Latent Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of latents in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_GetImageCount": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetImageCount", "display_name": "Get Image Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Image Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of images in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_GetMaskCount": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetMaskCount", "display_name": "Get Mask Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Mask Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of masks in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of masks in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_DuplicateLatents": {"input": {"required": {"latents": ["LATENT"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["latents", "multiply_by"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_DuplicateLatents", "display_name": "Repeat Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a latent to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The latent with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the output. Equal to the length of the input latent * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the latent should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_DuplicateImages": {"input": {"required": {"images": ["IMAGE"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["images", "multiply_by"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_DuplicateImages", "display_name": "Repeat Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a image to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"IMAGES\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGES: The image to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The image with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of image in the output. Equal to the length of the input image * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_DuplicateMasks": {"input": {"required": {"mask": ["MASK"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["mask", "multiply_by"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_DuplicateMasks", "display_name": "Repeat Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a mask to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The masks to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The mask with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the output. Equal to the length of the input mask * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_SelectEveryNthLatent": {"input": {"required": {"latents": ["LATENT"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_latents": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["latents", "select_every_nth", "skip_first_latents"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_SelectEveryNthLatent", "display_name": "Select Every Nth Latent \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Latent \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 latent for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The output latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_latents: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the latent into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SelectEveryNthImage": {"input": {"required": {"images": ["IMAGE"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["images", "select_every_nth", "skip_first_images"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_SelectEveryNthImage", "display_name": "Select Every Nth Image \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Image \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 image for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The output images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the image into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SelectEveryNthMask": {"input": {"required": {"mask": ["MASK"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_masks": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["mask", "select_every_nth", "skip_first_masks"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_SelectEveryNthMask", "display_name": "Select Every Nth Mask \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Mask \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 mask for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The output mask</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_mask: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the mask into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_SelectLatents": {"input": {"required": {"latent": ["LATENT"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["latent", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VHS_SelectLatents", "display_name": "Select Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SelectImages": {"input": {"required": {"image": ["IMAGE"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VHS_SelectImages", "display_name": "Select Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SelectMasks": {"input": {"required": {"mask": ["MASK"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mask", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "VHS_SelectMasks", "display_name": "Select Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_Unbatch": {"input": {"required": {"batched": ["*"]}}, "input_order": {"required": ["batched"]}, "output": ["*"], "output_is_list": [false], "output_name": ["unbatched"], "name": "VHS_Unbatch", "display_name": "Unbatch \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Unbatch \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Experimental node to unbatch a list of items into a single concatenated item</div></div><div style=\"font-size: 0.8em\">Useful for when you want a single video output from a complex workflow</div><div style=\"font-size: 0.8em\">Has no relation to the Meta Batch system of VHS</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"batched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">batched: Any input which may or may not be batched</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"unbatched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">unbatched: A single output element. Torch tensors are concatenated across dim 0, all other types are added which functions as concatenation for strings and arrays, but may give undesired results for other types</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false, "experimental": true}, "UltimateSDUpscale": {"input": {"required": {"image": ["IMAGE"], "model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "upscale_by": ["FLOAT", {"default": 2, "min": 0.05, "max": 4, "step": 0.05}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "upscale_model": ["UPSCALE_MODEL"], "mode_type": [["Linear", "Chess", "None"]], "tile_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "tile_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "tile_padding": ["INT", {"default": 32, "min": 0, "max": 8192, "step": 8}], "seam_fix_mode": [["None", "Band Pass", "Half Tile", "Half Tile + Intersections"]], "seam_fix_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "seam_fix_width": ["INT", {"default": 64, "min": 0, "max": 8192, "step": 8}], "seam_fix_mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "seam_fix_padding": ["INT", {"default": 16, "min": 0, "max": 8192, "step": 8}], "force_uniform_tiles": ["BOOLEAN", {"default": true}], "tiled_decode": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "model", "positive", "negative", "vae", "upscale_by", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "upscale_model", "mode_type", "tile_width", "tile_height", "mask_blur", "tile_padding", "seam_fix_mode", "seam_fix_denoise", "seam_fix_width", "seam_fix_mask_blur", "seam_fix_padding", "force_uniform_tiles", "tiled_decode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UltimateSDUpscale", "display_name": "Ultimate SD Upscale", "description": "", "python_module": "custom_nodes.ComfyUI_UltimateSDUpscale", "category": "image/upscaling", "output_node": false}, "UltimateSDUpscaleNoUpscale": {"input": {"required": {"upscaled_image": ["IMAGE"], "model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "mode_type": [["Linear", "Chess", "None"]], "tile_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "tile_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "tile_padding": ["INT", {"default": 32, "min": 0, "max": 8192, "step": 8}], "seam_fix_mode": [["None", "Band Pass", "Half Tile", "Half Tile + Intersections"]], "seam_fix_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "seam_fix_width": ["INT", {"default": 64, "min": 0, "max": 8192, "step": 8}], "seam_fix_mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "seam_fix_padding": ["INT", {"default": 16, "min": 0, "max": 8192, "step": 8}], "force_uniform_tiles": ["BOOLEAN", {"default": true}], "tiled_decode": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["upscaled_image", "model", "positive", "negative", "vae", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "mode_type", "tile_width", "tile_height", "mask_blur", "tile_padding", "seam_fix_mode", "seam_fix_denoise", "seam_fix_width", "seam_fix_mask_blur", "seam_fix_padding", "force_uniform_tiles", "tiled_decode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UltimateSDUpscaleNoUpscale", "display_name": "Ultimate SD Upscale (No Upscale)", "description": "", "python_module": "custom_nodes.ComfyUI_UltimateSDUpscale", "category": "image/upscaling", "output_node": false}, "UltimateSDUpscaleCustomSample": {"input": {"required": {"image": ["IMAGE"], "model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "upscale_by": ["FLOAT", {"default": 2, "min": 0.05, "max": 4, "step": 0.05}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "mode_type": [["Linear", "Chess", "None"]], "tile_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "tile_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "tile_padding": ["INT", {"default": 32, "min": 0, "max": 8192, "step": 8}], "seam_fix_mode": [["None", "Band Pass", "Half Tile", "Half Tile + Intersections"]], "seam_fix_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "seam_fix_width": ["INT", {"default": 64, "min": 0, "max": 8192, "step": 8}], "seam_fix_mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "seam_fix_padding": ["INT", {"default": 16, "min": 0, "max": 8192, "step": 8}], "force_uniform_tiles": ["BOOLEAN", {"default": true}], "tiled_decode": ["BOOLEAN", {"default": false}]}, "optional": {"upscale_model": ["UPSCALE_MODEL"], "custom_sampler": ["SAMPLER"], "custom_sigmas": ["SIGMAS"]}}, "input_order": {"required": ["image", "model", "positive", "negative", "vae", "upscale_by", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "mode_type", "tile_width", "tile_height", "mask_blur", "tile_padding", "seam_fix_mode", "seam_fix_denoise", "seam_fix_width", "seam_fix_mask_blur", "seam_fix_padding", "force_uniform_tiles", "tiled_decode"], "optional": ["upscale_model", "custom_sampler", "custom_sigmas"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UltimateSDUpscaleCustomSample", "display_name": "Ultimate SD Upscale (Custom Sample)", "description": "", "python_module": "custom_nodes.ComfyUI_UltimateSDUpscale", "category": "image/upscaling", "output_node": false}, "UnetLoaderGGUF": {"input": {"required": {"unet_name": [["flux1-dev-Q4_K_S.gguf"]]}}, "input_order": {"required": ["unet_name"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UnetLoaderGGUF", "display_name": "Unet Loader (GGUF)", "description": "", "python_module": "custom_nodes.ComfyUI-GGUF", "category": "bootleg", "output_node": false}, "CLIPLoaderGGUF": {"input": {"required": {"clip_name": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["stable_diffusion", "stable_cascade", "sd3", "stable_audio", "mochi", "ltxv", "pixart", "cosmos", "lumina2", "wan", "hidream", "chroma", "ace"]]}}, "input_order": {"required": ["clip_name", "type"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPLoaderGGUF", "display_name": "CLIPLoader (GGUF)", "description": "", "python_module": "custom_nodes.ComfyUI-GGUF", "category": "bootleg", "output_node": false}, "DualCLIPLoaderGGUF": {"input": {"required": {"clip_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["sdxl", "sd3", "flux", "hunyuan_video", "hidream"]]}}, "input_order": {"required": ["clip_name1", "clip_name2", "type"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "DualCLIPLoaderGGUF", "display_name": "DualCLIPLoader (GGUF)", "description": "", "python_module": "custom_nodes.ComfyUI-GGUF", "category": "bootleg", "output_node": false}, "TripleCLIPLoaderGGUF": {"input": {"required": {"clip_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name3": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "TripleCLIPLoaderGGUF", "display_name": "TripleCLIPLoader (GGUF)", "description": "", "python_module": "custom_nodes.ComfyUI-GGUF", "category": "bootleg", "output_node": false}, "QuadrupleCLIPLoaderGGUF": {"input": {"required": {"clip_name1": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name3": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name4": [["Long-ViT-L-14-GmP-SAE-full-model.safetensors", "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors", "clip-vit-large-patch14/model.safetensors", "clip_g.safetensors", "clip_l.safetensors", "google_t5xxl_fp8_e4m3fn.safetensors", "llava_llama3_fp8_scaled.safetensors", "t5-v1_1-xxl-encoder-Q4_K_S.gguf", "t5xxl_fp16.safetensors", "t5xxl_fp8_e4m3fn.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3", "clip_name4"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "QuadrupleCLIPLoaderGGUF", "display_name": "QuadrupleCLIPLoader (GGUF)", "description": "", "python_module": "custom_nodes.ComfyUI-GGUF", "category": "bootleg", "output_node": false}, "UnetLoaderGGUFAdvanced": {"input": {"required": {"unet_name": [["flux1-dev-Q4_K_S.gguf"]], "dequant_dtype": [["default", "target", "float32", "float16", "bfloat16"], {"default": "default"}], "patch_dtype": [["default", "target", "float32", "float16", "bfloat16"], {"default": "default"}], "patch_on_device": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["unet_name", "dequant_dtype", "patch_dtype", "patch_on_device"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UnetLoaderGGUFAdvanced", "display_name": "Unet Loader (GGUF/Advanced)", "description": "", "python_module": "custom_nodes.ComfyUI-GGUF", "category": "bootleg", "output_node": false}, "KSampler Gradually Adding More Denoise (efficient)": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform", "beta", "linear_quadratic", "kl_optimal"]], "start_denoise": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "denoise_increment": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.1}], "denoise_increment_steps": ["INT", {"default": 20, "min": 1, "max": 10000}]}, "optional": {"optional_vae": ["VAE"]}}, "input_order": {"required": ["model", "positive", "negative", "latent_image", "seed", "steps", "cfg", "sampler_name", "scheduler", "start_denoise", "denoise_increment", "denoise_increment_steps"], "optional": ["optional_vae"]}, "output": ["MODEL", "CONDITIONING", "CONDITIONING", "LATENT", "VAE"], "output_is_list": [false, false, false, false, false], "output_name": ["MODEL", "CONDITIONING+", "CONDITIONING-", "LATENT", "VAE"], "name": "KSampler Gradually Adding More Denoise (efficient)", "display_name": "KSampler Gradually Adding More Denoise (efficient)", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/others", "output_node": true}, "GMFSS Fortuna VFI": {"input": {"required": {"ckpt_name": [["GMFSS_fortuna_union", "GMFSS_fortuna"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "GMFSS Fortuna VFI", "display_name": "GMFSS Fortuna VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "IFRNet VFI": {"input": {"required": {"ckpt_name": [["IFRNet_S_Vimeo90K.pth", "IFRNet_L_Vimeo90K.pth", "IFRNet_S_GoPro.pth", "IFRNet_L_GoPro.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}], "scale_factor": [[0.25, 0.5, 1.0, 2.0, 4.0], {"default": 1.0}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier", "scale_factor"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "IFRNet VFI", "display_name": "IFRNet VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "IFUnet VFI": {"input": {"required": {"ckpt_name": [["IFUNet.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}], "scale_factor": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 100, "step": 0.1}], "ensemble": ["BOOLEAN", {"default": true}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier", "scale_factor", "ensemble"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "IFUnet VFI", "display_name": "IFUnet VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "M2M VFI": {"input": {"required": {"ckpt_name": [["M2M.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "M2M VFI", "display_name": "M2M VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "RIFE VFI": {"input": {"required": {"ckpt_name": [["rife40.pth", "rife41.pth", "sudo_rife4_269.662_testV1_scale1.pth", "rife42.pth", "rife43.pth", "rife44.pth", "rife45.pth", "rife46.pth", "rife47.pth", "rife48.pth", "rife49.pth"], {"default": "rife47.pth"}], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 1}], "fast_mode": ["BOOLEAN", {"default": true}], "ensemble": ["BOOLEAN", {"default": true}], "scale_factor": [[0.25, 0.5, 1.0, 2.0, 4.0], {"default": 1.0}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier", "fast_mode", "ensemble", "scale_factor"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RIFE VFI", "display_name": "RIFE VFI (recommend rife47 and rife49)", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "Sepconv VFI": {"input": {"required": {"ckpt_name": [["sepconv.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Sepconv VFI", "display_name": "Sepconv VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "AMT VFI": {"input": {"required": {"ckpt_name": [["amt-s.pth", "amt-l.pth", "amt-g.pth", "gopro_amt-s.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 1, "min": 1, "max": 100}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AMT VFI", "display_name": "AMT VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "FILM VFI": {"input": {"required": {"ckpt_name": [["film_net_fp32.pt"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FILM VFI", "display_name": "FILM VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "Make Interpolation State List": {"input": {"required": {"frame_indices": ["STRING", {"multiline": true, "default": "1,2,3"}], "is_skip_list": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["frame_indices", "is_skip_list"]}, "output": ["INTERPOLATION_STATES"], "output_is_list": [false], "output_name": ["INTERPOLATION_STATES"], "name": "Make Interpolation State List", "display_name": "Make Interpolation State List", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "STMFNet VFI": {"input": {"required": {"ckpt_name": [["stmfnet.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 2}], "duplicate_first_last_frames": ["BOOLEAN", {"default": false}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier", "duplicate_first_last_frames"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "STMFNet VFI", "display_name": "STMFNet VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "FLAVR VFI": {"input": {"required": {"ckpt_name": [["FLAVR_2x.pth", "FLAVR_4x.pth", "FLAVR_8x.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 2}], "duplicate_first_last_frames": ["BOOLEAN", {"default": false}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier", "duplicate_first_last_frames"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FLAVR VFI", "display_name": "FLAVR VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "CAIN VFI": {"input": {"required": {"ckpt_name": [["pretrained_cain.pth"]], "frames": ["IMAGE"], "clear_cache_after_n_frames": ["INT", {"default": 10, "min": 1, "max": 1000}], "multiplier": ["INT", {"default": 2, "min": 2, "max": 1000}]}, "optional": {"optional_interpolation_states": ["INTERPOLATION_STATES"]}}, "input_order": {"required": ["ckpt_name", "frames", "clear_cache_after_n_frames", "multiplier"], "optional": ["optional_interpolation_states"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CAIN VFI", "display_name": "CAIN VFI", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation/VFI", "output_node": false}, "VFI FloatToInt": {"input": {"required": {"float": ["FLOAT", {"default": 0, "min": 0, "step": 0.01}]}}, "input_order": {"required": ["float"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "VFI FloatToInt", "display_name": "VFI FloatToInt", "description": "", "python_module": "custom_nodes.ComfyUI-Frame-Interpolation", "category": "ComfyUI-Frame-Interpolation", "output_node": false}}